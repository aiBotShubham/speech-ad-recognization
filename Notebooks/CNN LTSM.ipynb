{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f850fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11dc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_test, y_pred): \n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test))*100, np.abs((y_test - y_pred) / y_test)*100\n",
    "\n",
    "def sliding_window_input(df, input_length, idx):\n",
    "\twindow = df.values[idx:input_length+idx,:]\n",
    "\treturn window\n",
    "\n",
    "def sliding_window_output(df, input_length, output_length, idx):\n",
    "\twindow = df.values[input_length+idx:input_length+output_length+idx]\n",
    "\treturn window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049476ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configs():\n",
    "\tepochs = [100]\n",
    "\tbatch_size = [32]\n",
    "\tn_nodes1 = [64]\n",
    "\tn_nodes2 = [32]\n",
    "\tfilter1 = [16]\n",
    "\tfilter2 = [32]\n",
    "\tkernel_size = [6]\n",
    "\tconfigs = []\n",
    "\tfor a in epochs:\n",
    "\t\tfor b in batch_size:\n",
    "\t\t\tfor c in n_nodes1:\n",
    "\t\t\t\tfor d in n_nodes2:\n",
    "\t\t\t\t\tfor e in filter1:\n",
    "\t\t\t\t\t\tfor f in filter2:\n",
    "\t\t\t\t\t\t\tfor g in kernel_size:\n",
    "\t\t\t\t\t\t\t\tcfg = [a,b,c,d,e,f,g]\n",
    "\t\t\t\t\t\t\t\tconfigs.append(cfg)\n",
    "\tprint('Total configs: %d' % len(configs))\n",
    "\treturn configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61c2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data, config, output_length, X_test, input_length, index, repeats):\n",
    "\tprint('Run:', str(index), '/', str(repeats))\n",
    "\t# start time\n",
    "\tstart = time.time()\n",
    "\tprint('Configuration:', config)\n",
    "\t# define parameters\n",
    "\tepochs, batch_size, n_nodes1, n_nodes2, filter1, filter2, kernel_size = config\n",
    "\t# convert data to supervised learning environment\n",
    "\tX_train = np.stack([sliding_window_input(data, input_length, i) for i in range(len(data)-input_length)])[:-output_length]\n",
    "\ty_train = np.stack([sliding_window_output(data['Upper Stillwater'], input_length, output_length, i) for i in range(len(data)-(input_length+output_length))])\n",
    "\ty_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "\tprint('Feature Training Tensor (samples, timesteps, features):', X_train.shape)\n",
    "\tprint('Target Training Tensor (samples, timesteps, features):', y_train.shape)\n",
    "\t# define parameters\n",
    "\tn_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\t# define residual CNN-LSTM\n",
    "\tvisible1 = Input(shape = (n_timesteps,n_features))\n",
    "\t\n",
    "\tmodel = Conv1D(filter1, kernel_size, padding = 'causal')(visible1)\n",
    "\tresidual1 = ReLU()(model)\n",
    "\tmodel = Conv1D(filter1, kernel_size, padding = 'causal')(residual1)\n",
    "\tmodel = Add()([residual1, model])\n",
    "\tmodel = ReLU()(model)\n",
    "\t\n",
    "\tmodel = Conv1D(filter1, kernel_size, padding = 'causal')(model)\n",
    "\tresidual2 = ReLU()(model)\n",
    "\tmodel = Conv1D(filter1, kernel_size, padding = 'causal')(residual2)\n",
    "\tmodel = Add()([residual2, model])\n",
    "\tmodel = ReLU()(model)\n",
    "\tmodel = MaxPooling1D()(model)\n",
    "\t\n",
    "\tmodel = Conv1D(filter2, kernel_size, padding = 'causal')(model)\n",
    "\tresidual3 = ReLU()(model)\n",
    "\tmodel = Conv1D(filter2, kernel_size, padding = 'causal')(residual3)\n",
    "\tmodel = Add()([residual3, model])\n",
    "\tmodel = ReLU()(model)\n",
    "\t\n",
    "\tmodel = Conv1D(filter2, kernel_size, padding = 'causal')(model)\n",
    "\tresidual4 = ReLU()(model)\n",
    "\tmodel = Conv1D(filter2, kernel_size, padding = 'causal')(residual4)\n",
    "\tmodel = Add()([residual4, model])\n",
    "\tmodel = ReLU()(model)\n",
    "\tmodel = MaxPooling1D()(model)\n",
    "\t\n",
    "\tmodel = Conv1D(n_nodes1, kernel_size, padding = 'causal')(model)\n",
    "\tresidual5 = ReLU()(model)\n",
    "\tmodel = Conv1D(n_nodes1, kernel_size, padding = 'causal')(residual5)\n",
    "\tmodel = Add()([residual5, model])\n",
    "\tmodel = ReLU()(model)\n",
    "\t\n",
    "\tmodel = Conv1D(n_nodes1, kernel_size, padding = 'causal')(model)\n",
    "\tresidual6 = ReLU()(model)\n",
    "\tmodel = Conv1D(n_nodes1, kernel_size, padding = 'causal')(residual6)\n",
    "\tmodel = Add()([residual6, model])\n",
    "\tmodel = ReLU()(model)\n",
    "\tmodel = MaxPooling1D()(model)\n",
    "\t\n",
    "\tmodel = Flatten()(model)\n",
    "\tmodel = RepeatVector(n_outputs)(model)\n",
    "\t\n",
    "\tmodel = LSTM(n_nodes1, activation='relu', return_sequences=True)(model)\n",
    "\tmodel = LSTM(n_nodes1, activation='relu', return_sequences=True)(model)\n",
    "\tmodel = LSTM(n_nodes1, activation='relu', return_sequences=True)(model)\n",
    "\tmodel = LSTM(n_nodes1, activation='relu', return_sequences=True)(model)\n",
    "\t\n",
    "\tdense = TimeDistributed(Dense(n_nodes2, activation='relu'))(model)\n",
    "\toutput = TimeDistributed(Dense(1))(dense)\n",
    "\tmodel = Model(inputs = visible1, outputs = output)\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t#model.summary()\n",
    "\t# fit network\n",
    "\tes = EarlyStopping(monitor='loss', mode='min', patience = 10)\n",
    "\thistory = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, validation_split=0.2, callbacks = [es])\n",
    "\t# test model against hold-out set\n",
    "\ty_pred = model.predict(X_test)\n",
    "\tprint('\\n Elapsed time:', round((time.time() - start)/60,3), 'minutes')\n",
    "\treturn y_pred, history\n",
    "\n",
    "def get_stats(y_pred, y_test):\n",
    "\tprint('Mean Absolute Error:', round((mean_absolute_error(y_test, y_pred)/np.mean(y_test))*100,3), '%')\n",
    "\tprint('Root Mean Squared Error:', round(((mean_squared_error(y_test, y_pred)**0.5)/np.mean(y_test))*100,3), '%')\n",
    "\tprint('Median Absolute Error:', round((median_absolute_error(y_test, y_pred)/np.mean(y_test))*100,3), '%')\n",
    "\tprint('NSE:', round(r2_score(y_test, y_pred), 3))\n",
    "\tprint('Explained Variance:', round(explained_variance_score(y_test, y_pred),3), '\\n')\n",
    "\t\n",
    "def get_stats_df(y_pred, y_test):\n",
    "\tMeanae = str(round((mean_absolute_error(y_test, y_pred)/np.mean(y_test))*100,3))\n",
    "\tRMSE = str(round(((mean_squared_error(y_test, y_pred)**0.5)/np.mean(y_test))*100,3))\n",
    "\tMedae = str(round((median_absolute_error(y_test, y_pred)/np.mean(y_test))*100,3))\n",
    "\tNSE = str(round(r2_score(y_test, y_pred), 3))\n",
    "\tExpvar = str(round(explained_variance_score(y_test, y_pred),3))\n",
    "\tstats = [[Meanae], [RMSE], [Medae], [NSE], [Expvar]]\n",
    "\tindex = ['Mean Absolute Error (%)', 'Root Mean Squared Error (%)', 'Median Absolute Error (%)', 'NSE', 'Explained Variance']\n",
    "\treturn stats, index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a45534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ape(true, test):\n",
    "\tvalue = (abs(true - test)/true)*100\n",
    "\treturn np.array(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa69d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_runs(repeats, data, cfg, output_length, X_test, input_length, y_test):\n",
    "\tprint('Start of Training Period:', data.index[0])\n",
    "\tprint('End of Training Period:', data.index[-1], '\\n')\n",
    "\toutput = [build_model(data, cfg, output_length, X_test, input_length, i, repeats) for i in range(1, repeats+1)]\n",
    "\ty_pred = [sv_scaler.inverse_transform(output[i][0][0].reshape(-1,1)) for i in range(len(output))]\n",
    "\t\n",
    "\tloss = [pd.DataFrame(output[i][1].history['loss']) for i in range(len(output))]\n",
    "\tval_loss = [pd.DataFrame(output[i][1].history['val_loss']) for i in range(len(output))]\n",
    "\tmax_epochs = max([len(loss[i]) for i in range(len(loss))])\n",
    "\tloss = [loss[i].values for i in range(len(loss))]\n",
    "\tval_loss = [val_loss[i].values for i in range(len(val_loss))]\n",
    "\tfor i in range(len(loss)):\n",
    "\t\tif len(loss[i]) == max_epochs:\n",
    "\t\t\tloss[i] = loss[i]\n",
    "\t\telse:\n",
    "\t\t\twhile len(loss[i]) < max_epochs:\n",
    "\t\t\t\tloss[i] = np.append(loss[i], np.nan)\n",
    "\t\t\t\tval_loss[i] = np.append(val_loss[i], np.nan)\n",
    "\t\tloss[i] = pd.DataFrame(loss[i])\n",
    "\t\tval_loss[i] = pd.DataFrame(val_loss[i])\n",
    "\tloss_df = reduce(lambda x, y: pd.merge(x, y, left_index = True, right_index = True), loss)\n",
    "\tval_loss_df = reduce(lambda x, y: pd.merge(x, y, left_index = True, right_index = True), val_loss)\n",
    "\t\n",
    "\tloss_avg = loss_df.mean(axis = 1)\n",
    "\tloss_avg.name = 'loss_avg'\n",
    "\tval_loss_std = val_loss_df.std(axis = 1)\n",
    "\tval_loss_std.name = 'val_loss_std'\n",
    "\tval_loss_avg = val_loss_df.mean(axis = 1)\n",
    "\tval_loss_avg.name = 'val_loss_avg'\n",
    "\tupper_val = pd.Series(val_loss_avg.values + 1.96*val_loss_std.values/(repeats**(0.5)))\n",
    "\tupper_val.name = 'upper_val'\n",
    "\tlower_val = pd.Series(val_loss_avg.values - 1.96*val_loss_std.values/(repeats**(0.5)))\n",
    "\tlower_val.name = 'lower_val'\n",
    "\thistory = reduce(lambda x, y: pd.merge(x, y, left_index = True, right_index = True), [loss_avg, val_loss_avg, upper_val, lower_val])\n",
    "\thistory.columns = ['loss_avg', 'val_loss_avg', 'upper_val', 'lower_val']\n",
    "\t\n",
    "\tplt.figure(figsize=(20,10))\n",
    "\tplt.plot(history.index, history.loss_avg.values, color='Blue', linewidth=2, linestyle='solid', label=\"Training Loss (80%)\")\n",
    "\tplt.plot(history.index, history.val_loss_avg.values, color='Orange', linewidth=2, linestyle='solid', label=\"Validation Loss (20%)\")\n",
    "\tplt.fill_between(history.index, history.upper_val, history.lower_val, color='Orange', alpha=.15, label = '95% Confidence Interval')\n",
    "\tplt.title(str(y_test.index[0].year)+\" Model Learning Curve\", fontsize = 18)\n",
    "\tplt.ylabel(\"Loss: Mean Squared Error\", fontsize=14)\n",
    "\tplt.xlabel(\"Experiences\", fontsize=14)\n",
    "\tplt.legend(fontsize=14, loc = 'upper left');\n",
    "\tplt.savefig(fname = str(y_test.index[0].year)+'_lc.pdf',bbox_inches = 'tight');\n",
    "\t\n",
    "\tdf = pd.DataFrame(np.concatenate(y_pred, axis = 1), index = y_test.index.strftime('%B %d'))\n",
    "\tspills = np.stack([sv.max() for i in range(len(y_test))])\n",
    "\tfuture_idx = range(1, len(y_test)+1)\n",
    "\tx_labels = y_test.index\n",
    "\tx_labels = x_labels.strftime('%B %d')\n",
    "\t[get_stats(y_test.values, y_pred[i]) for i in range(len(output))]\n",
    "\t\n",
    "\tq1, q3 = df.quantile(q = 0.25, axis = 1), df.quantile(q = 0.75, axis = 1)\n",
    "\tiqr = q3 - q1\n",
    "\tupper_bnd = q3 + 1.5*iqr\n",
    "\tlower_bnd = q1 - 1.5*iqr\n",
    "\t\n",
    "\tfiltered_avg = np.stack([df.iloc[i][(df.iloc[i] < upper_bnd[i]) & (df.iloc[i] > lower_bnd[i])].mean() for i in range(len(df))])\n",
    "\tfiltered_std = np.stack([df.iloc[i][(df.iloc[i] < upper_bnd[i]) & (df.iloc[i] > lower_bnd[i])].std() for i in range(len(df))])\n",
    "\tupper = filtered_avg + 1.96*filtered_std/(repeats**(0.5))\n",
    "\tlower = filtered_avg - 1.96*filtered_std/(repeats**(0.5))\n",
    "\tcellText, rows = get_stats_df(y_test.values, filtered_avg.reshape(-1,))\n",
    "\t\n",
    "\tplt.figure(figsize=(20,10))\n",
    "\tplt.boxplot(df)\n",
    "\tplt.xticks([i for i in future_idx],x_labels)\n",
    "\tplt.plot(future_idx, filtered_avg, color='Red', linewidth=2, linestyle='solid', label=\"Forecasted\")\n",
    "\tplt.plot(future_idx, y_test.values, color='Green', linewidth=2, linestyle='solid', label=\"Actual\")\n",
    "\tplt.plot(future_idx, spills, color = 'black', linewidth = 2, linestyle='dashed', label=\"Spill Limit\")\n",
    "\tplt.fill_between(future_idx, upper, lower, color='k', alpha=.15, label = '95% Confidence Interval')\n",
    "\tplt.table(cellText = cellText, rowLabels = rows, colLabels = ['Stats'], bbox = [0.2,0.4,0.1,0.5])\n",
    "\tplt.title(str(y_test.index[0].year)+\" Upper Stillwater Reservoir\", fontsize = 18)\n",
    "\tplt.ylabel(\"Storage Volume (ac-ft)\", fontsize=14)\n",
    "\tplt.xlabel(\"Future Time\", fontsize=14)\n",
    "\tplt.legend(fontsize=14, loc = 'upper left');\n",
    "\tplt.savefig(fname = str(y_test.index[0].year)+'_fc.pdf',bbox_inches = 'tight');\n",
    "\t\n",
    "\terrors = np.stack(np.array([ape(y_test.values[i], df.mean(axis = 1).values[i]) for i in range(len(df))]))\n",
    "\tupper = np.stack(np.array([ape(y_test.values[i], df.mean(axis = 1).values[i] + (df.std(axis = 1).values[i]*1.96)/(repeats**0.5)) for i in range(len(df))]))\n",
    "\tlower = np.stack(np.array([ape(y_test.values[i], df.mean(axis = 1).values[i] - (df.std(axis = 1).values[i]*1.96)/(repeats**0.5)) for i in range(len(df))]))\n",
    "\terrors_df = pd.DataFrame(lower, columns = ['Lower Limit'])\n",
    "\terrors_df['Average'] = errors\n",
    "\terrors_df['Upper Limit'] = upper\n",
    "\terrors_df.index = df.index\n",
    "\terrors_df.plot(kind = 'bar', figsize = [20,10], title = 'Absolute Percent Error (%)');\n",
    "\treturn df, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57806e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pickle.load(open('project_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d29b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Upper Stillwater</th>\n",
       "      <th>Beaver Divide</th>\n",
       "      <th>Brighton</th>\n",
       "      <th>Brown Duck</th>\n",
       "      <th>Chepeta</th>\n",
       "      <th>Currant Creek</th>\n",
       "      <th>Five Points Lake</th>\n",
       "      <th>Hayden Fork</th>\n",
       "      <th>Kings Cabin</th>\n",
       "      <th>Lakefork #1</th>\n",
       "      <th>...</th>\n",
       "      <th>Mosby Mtn.</th>\n",
       "      <th>Parleys Summit</th>\n",
       "      <th>Rock Creek</th>\n",
       "      <th>Rocky Basin-Settleme</th>\n",
       "      <th>Smith  Morehouse</th>\n",
       "      <th>Snowbird</th>\n",
       "      <th>Thaynes Canyon</th>\n",
       "      <th>Timpanogos Divide</th>\n",
       "      <th>Trial Lake</th>\n",
       "      <th>Trout Creek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-07</th>\n",
       "      <td>11975.857143</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>9.185714</td>\n",
       "      <td>4.828571</td>\n",
       "      <td>5.671429</td>\n",
       "      <td>2.057143</td>\n",
       "      <td>6.514286</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>3.157143</td>\n",
       "      <td>3.942857</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657143</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.014286</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.028571</td>\n",
       "      <td>2.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-14</th>\n",
       "      <td>11786.428571</td>\n",
       "      <td>3.471429</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>5.442857</td>\n",
       "      <td>6.042857</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>6.914286</td>\n",
       "      <td>5.685714</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>5.542857</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>7.585714</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>13.871429</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>7.385714</td>\n",
       "      <td>7.185714</td>\n",
       "      <td>3.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-21</th>\n",
       "      <td>11623.285714</td>\n",
       "      <td>5.185714</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>6.928571</td>\n",
       "      <td>7.371429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>6.685714</td>\n",
       "      <td>4.057143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.885714</td>\n",
       "      <td>6.671429</td>\n",
       "      <td>3.371429</td>\n",
       "      <td>9.114286</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>16.542857</td>\n",
       "      <td>9.128571</td>\n",
       "      <td>11.328571</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>4.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-28</th>\n",
       "      <td>11408.714286</td>\n",
       "      <td>5.842857</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>7.785714</td>\n",
       "      <td>3.842857</td>\n",
       "      <td>8.971429</td>\n",
       "      <td>6.914286</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>5.328571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>6.942857</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>9.357143</td>\n",
       "      <td>6.742857</td>\n",
       "      <td>17.085714</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>11.957143</td>\n",
       "      <td>9.457143</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-04</th>\n",
       "      <td>11234.857143</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>8.657143</td>\n",
       "      <td>8.585714</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>9.828571</td>\n",
       "      <td>8.071429</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.985714</td>\n",
       "      <td>...</td>\n",
       "      <td>4.442857</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.771429</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>19.028571</td>\n",
       "      <td>11.842857</td>\n",
       "      <td>12.742857</td>\n",
       "      <td>10.742857</td>\n",
       "      <td>4.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-07</th>\n",
       "      <td>24207.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.042857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-14</th>\n",
       "      <td>29784.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>31295.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-28</th>\n",
       "      <td>30845.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-05</th>\n",
       "      <td>30153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Upper Stillwater  Beaver Divide   Brighton  Brown Duck   Chepeta  \\\n",
       "Date                                                                           \n",
       "1990-01-07      11975.857143       2.371429   9.185714    4.828571  5.671429   \n",
       "1990-01-14      11786.428571       3.471429  11.142857    5.442857  6.042857   \n",
       "1990-01-21      11623.285714       5.185714  13.200000    6.928571  7.371429   \n",
       "1990-01-28      11408.714286       5.842857  14.071429    7.428571  7.785714   \n",
       "1990-02-04      11234.857143       6.500000  15.700000    8.657143  8.585714   \n",
       "...                      ...            ...        ...         ...       ...   \n",
       "2020-06-07      24207.857143       0.000000   0.000000    0.157143  0.000000   \n",
       "2020-06-14      29784.285714       0.000000   0.071429    0.671429  0.000000   \n",
       "2020-06-21      31295.714286       0.000000   0.000000    0.000000  0.000000   \n",
       "2020-06-28      30845.857143       0.000000   0.000000    0.000000  0.000000   \n",
       "2020-07-05      30153.000000       0.000000   0.050000    0.050000  0.000000   \n",
       "\n",
       "            Currant Creek  Five Points Lake  Hayden Fork  Kings Cabin  \\\n",
       "Date                                                                    \n",
       "1990-01-07       2.057143          6.514286     5.100000     3.157143   \n",
       "1990-01-14       2.600000          6.914286     5.685714     3.400000   \n",
       "1990-01-21       3.571429          8.857143     6.685714     4.057143   \n",
       "1990-01-28       3.842857          8.971429     6.914286     4.200000   \n",
       "1990-02-04       4.500000          9.828571     8.071429     4.500000   \n",
       "...                   ...               ...          ...          ...   \n",
       "2020-06-07       0.000000          0.057143     0.000000     0.000000   \n",
       "2020-06-14       0.000000          0.428571     0.042857     0.000000   \n",
       "2020-06-21       0.000000          0.000000     0.000000     0.000000   \n",
       "2020-06-28       0.000000          0.000000     0.000000     0.000000   \n",
       "2020-07-05       0.000000          0.000000     0.025000     0.000000   \n",
       "\n",
       "            Lakefork #1  ...  Mosby Mtn.  Parleys Summit  Rock Creek  \\\n",
       "Date                     ...                                           \n",
       "1990-01-07     3.942857  ...    2.657143        4.500000    1.800000   \n",
       "1990-01-14     4.000000  ...    2.857143        5.542857    2.271429   \n",
       "1990-01-21     5.000000  ...    3.885714        6.671429    3.371429   \n",
       "1990-01-28     5.328571  ...    4.071429        6.942857    3.400000   \n",
       "1990-02-04     5.985714  ...    4.442857        8.000000    3.771429   \n",
       "...                 ...  ...         ...             ...         ...   \n",
       "2020-06-07     0.100000  ...    0.000000        0.000000    0.000000   \n",
       "2020-06-14     0.357143  ...    0.142857        0.057143    0.000000   \n",
       "2020-06-21     0.000000  ...    0.000000        0.000000    0.000000   \n",
       "2020-06-28     0.000000  ...    0.000000        0.000000    0.000000   \n",
       "2020-07-05     0.025000  ...    0.000000        0.000000    0.000000   \n",
       "\n",
       "            Rocky Basin-Settleme  Smith  Morehouse   Snowbird  Thaynes Canyon  \\\n",
       "Date                                                                            \n",
       "1990-01-07              7.014286          4.428571  11.857143        6.142857   \n",
       "1990-01-14              7.585714          5.214286  13.871429        7.142857   \n",
       "1990-01-21              9.114286          6.285714  16.542857        9.128571   \n",
       "1990-01-28              9.357143          6.742857  17.085714       10.100000   \n",
       "1990-02-04             10.142857          7.714286  19.028571       11.842857   \n",
       "...                          ...               ...        ...             ...   \n",
       "2020-06-07              0.000000          0.000000   1.042857        0.000000   \n",
       "2020-06-14              0.057143          0.000000   0.628571        0.014286   \n",
       "2020-06-21              0.000000          0.000000   0.085714        0.000000   \n",
       "2020-06-28              0.000000          0.000000   0.000000        0.000000   \n",
       "2020-07-05              0.075000          0.000000   0.100000        0.000000   \n",
       "\n",
       "            Timpanogos Divide  Trial Lake  Trout Creek  \n",
       "Date                                                    \n",
       "1990-01-07           6.500000    6.028571     2.828571  \n",
       "1990-01-14           7.385714    7.185714     3.057143  \n",
       "1990-01-21          11.328571    9.200000     4.057143  \n",
       "1990-01-28          11.957143    9.457143     4.300000  \n",
       "1990-02-04          12.742857   10.742857     4.642857  \n",
       "...                       ...         ...          ...  \n",
       "2020-06-07           0.000000    0.057143     0.000000  \n",
       "2020-06-14           0.114286    0.285714     0.000000  \n",
       "2020-06-21           0.000000    0.000000     0.000000  \n",
       "2020-06-28           0.000000    0.000000     0.000000  \n",
       "2020-07-05           0.000000    0.000000     0.000000  \n",
       "\n",
       "[1592 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ebc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
