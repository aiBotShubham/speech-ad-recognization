{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33392872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import pickle\n",
    "def load_data(in_dir):\n",
    "    f = open(in_dir,'rb')\n",
    "    train_data,train_label,test_data,test_label,valid_data,valid_label,pernums_valid = pickle.load(f)\n",
    "    return train_data,train_label,test_data,test_label,valid_data,valid_label,pernums_valid\n",
    "\n",
    "# data_path = 'adress_512.pkl'\n",
    "data_path = 'adress_Att_Net.pkl'\n",
    "checkpoint = 'checkpoint/'\n",
    "\n",
    "train_data,train_label,test_data,test_label,valid_data,valid_label,pernums_valid = load_data(data_path)\n",
    "\n",
    "# converting training images into torch format\n",
    "train_x = train_data\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_label\n",
    "train_y = train_y.reshape(2379).astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "# train_x.shape, train_y.shape\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "# my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "# tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "# tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "CTX = torch.device('cuda')\n",
    "\n",
    "train_dataset = TensorDataset(train_x.to(CTX),train_y.to(CTX)) # create your datset\n",
    "\n",
    " # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09537d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "val_x = valid_data\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = valid_label\n",
    "val_y = val_y.reshape(297).astype(float);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "# shape of training data\n",
    "\n",
    "val_dataset = TensorDataset(val_x,val_y) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4701d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 64\n",
    "val_size = 297\n",
    "# train_size = train_x.size(0) - val_size \n",
    "\n",
    "# train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "# print(f\"Length of Train Data : {len(train_data)}\")\n",
    "# print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 2379\n",
    "#Length of Validation Data : 297\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_dataset,batch_size, shuffle = True, num_workers = 0)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d492176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda())   # Calculate loss\n",
    "        acc = accuracy(out, labels.to(torch.int64).cuda())           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "#         print(x.shape())\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n",
    "    \n",
    "    \n",
    "class Att_Net(ImageClassificationBase):   \n",
    "    def __init__(self):\n",
    "        super(Att_Net, self).__init__()\n",
    "        #The LW_CNN module utilizes three convolutions (C), two max-pooling\n",
    "        # (MP), one average-pooling (AP), and one batch normalization\n",
    "        # (BN) layer.\n",
    "        self.LW_CNN = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "#             Conv2d(300, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(256),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Defining another 2D convolution layer\n",
    "#             Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(128),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=1, stride=1),\n",
    "            \n",
    "              #C1, we used 120 number of kernels with size (11\n",
    "              # × 11) using (4 × 4) stride setting without padding to extract\n",
    "              # initially hidden patterns from input data. \n",
    "              Conv2d(3, 120, kernel_size=(11,11), stride=(4,4), padding=0),\n",
    "              MaxPool2d(kernel_size=(3,3), stride=None),\n",
    "              Conv2d(120, 256, kernel_size=(5,5), stride=(1,1), padding='same'),\n",
    "              MaxPool2d(kernel_size=(3,3)),\n",
    "              Conv2d(256, 384, kernel_size=(3,3), padding='same'),\n",
    "#               MaxPool2d(kernel_size=1, stride=0),\n",
    "#               Conv2d(128, 1, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "              torch.nn.AvgPool2d(kernel_size=(3,3), stride=1),\n",
    "              BatchNorm2d(384),\n",
    "              ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(384 * 12 * 1, 256),\n",
    "            Linear(256, 64),\n",
    "            Linear(64, 2),\n",
    "        )\n",
    "\n",
    "        self.attention = CBAM(gate_channels=384)\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.size(3),x.size(2),x.size(1))\n",
    "#         print(x.size)\n",
    "        x = self.LW_CNN(x)\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f81fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Att_Net(\n",
      "  (LW_CNN): Sequential(\n",
      "    (0): Conv2d(3, 120, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(120, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): AvgPool2d(kernel_size=(3, 3), stride=1, padding=0)\n",
      "    (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=4608, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (attention): CBAM(\n",
      "    (ChannelGate): ChannelGate(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten()\n",
      "        (1): Linear(in_features=384, out_features=24, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=24, out_features=384, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (SpatialGate): SpatialGate(\n",
      "      (compress): ChannelPool()\n",
      "      (spatial): BasicConv(\n",
      "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Att_Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477fd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 120, 30, 126]          43,680\n",
      "         MaxPool2d-2          [-1, 120, 10, 42]               0\n",
      "            Conv2d-3          [-1, 256, 10, 42]         768,256\n",
      "         MaxPool2d-4           [-1, 256, 3, 14]               0\n",
      "            Conv2d-5           [-1, 384, 3, 14]         885,120\n",
      "         AvgPool2d-6           [-1, 384, 1, 12]               0\n",
      "       BatchNorm2d-7           [-1, 384, 1, 12]             768\n",
      "              ReLU-8           [-1, 384, 1, 12]               0\n",
      "           Flatten-9                  [-1, 384]               0\n",
      "           Linear-10                   [-1, 24]           9,240\n",
      "             ReLU-11                   [-1, 24]               0\n",
      "           Linear-12                  [-1, 384]           9,600\n",
      "          Flatten-13                  [-1, 384]               0\n",
      "           Linear-14                   [-1, 24]           9,240\n",
      "             ReLU-15                   [-1, 24]               0\n",
      "           Linear-16                  [-1, 384]           9,600\n",
      "      ChannelGate-17           [-1, 384, 1, 12]               0\n",
      "      ChannelPool-18             [-1, 2, 1, 12]               0\n",
      "           Conv2d-19             [-1, 1, 1, 12]              98\n",
      "      BatchNorm2d-20             [-1, 1, 1, 12]               2\n",
      "        BasicConv-21             [-1, 1, 1, 12]               0\n",
      "      SpatialGate-22           [-1, 384, 1, 12]               0\n",
      "             CBAM-23           [-1, 384, 1, 12]               0\n",
      "           Linear-24                  [-1, 256]       1,179,904\n",
      "           Linear-25                   [-1, 64]          16,448\n",
      "           Linear-26                    [-1, 2]             130\n",
      "================================================================\n",
      "Total params: 2,932,086\n",
      "Trainable params: 2,932,086\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 5.10\n",
      "Params size (MB): 11.19\n",
      "Estimated Total Size (MB): 17.03\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (512, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a72cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.7140, val_loss: 0.6931, val_acc: 0.5434\n",
      "Epoch [1], train_loss: 0.6822, val_loss: 0.6900, val_acc: 0.5272\n",
      "Epoch [2], train_loss: 0.6762, val_loss: 0.6604, val_acc: 0.5441\n",
      "Epoch [3], train_loss: 0.6870, val_loss: 0.7270, val_acc: 0.4533\n",
      "Epoch [4], train_loss: 0.6686, val_loss: 0.6693, val_acc: 0.5678\n",
      "Epoch [5], train_loss: 0.6643, val_loss: 0.6868, val_acc: 0.5324\n",
      "Epoch [6], train_loss: 0.6603, val_loss: 0.6781, val_acc: 0.5298\n",
      "Epoch [7], train_loss: 0.6600, val_loss: 0.6627, val_acc: 0.5324\n",
      "Epoch [8], train_loss: 0.6578, val_loss: 0.6555, val_acc: 0.5243\n",
      "Epoch [9], train_loss: 0.6640, val_loss: 0.6592, val_acc: 0.5350\n",
      "Epoch [10], train_loss: 0.6591, val_loss: 0.6499, val_acc: 0.5350\n",
      "Epoch [11], train_loss: 0.6584, val_loss: 0.6588, val_acc: 0.5321\n",
      "Epoch [12], train_loss: 0.6556, val_loss: 0.6524, val_acc: 0.5321\n",
      "Epoch [13], train_loss: 0.6599, val_loss: 0.6579, val_acc: 0.5721\n",
      "Epoch [14], train_loss: 0.6568, val_loss: 0.6556, val_acc: 0.5402\n",
      "Epoch [15], train_loss: 0.6532, val_loss: 0.6567, val_acc: 0.5347\n",
      "Epoch [16], train_loss: 0.6545, val_loss: 0.6581, val_acc: 0.5165\n",
      "Epoch [17], train_loss: 0.6514, val_loss: 0.6503, val_acc: 0.5295\n",
      "Epoch [18], train_loss: 0.6502, val_loss: 0.6675, val_acc: 0.5376\n",
      "Epoch [19], train_loss: 0.6523, val_loss: 0.6500, val_acc: 0.5646\n",
      "Epoch [20], train_loss: 0.6480, val_loss: 0.6528, val_acc: 0.5373\n",
      "Epoch [21], train_loss: 0.6517, val_loss: 0.6512, val_acc: 0.5600\n",
      "Epoch [22], train_loss: 0.6576, val_loss: 0.6495, val_acc: 0.5451\n",
      "Epoch [23], train_loss: 0.6526, val_loss: 0.6561, val_acc: 0.5561\n",
      "Epoch [24], train_loss: 0.6481, val_loss: 0.6407, val_acc: 0.6085\n",
      "Epoch [25], train_loss: 0.6494, val_loss: 0.6596, val_acc: 0.5428\n",
      "Epoch [26], train_loss: 0.6443, val_loss: 0.6652, val_acc: 0.5786\n",
      "Epoch [27], train_loss: 0.6501, val_loss: 0.6451, val_acc: 0.5217\n",
      "Epoch [28], train_loss: 0.6488, val_loss: 0.6509, val_acc: 0.5698\n",
      "Epoch [29], train_loss: 0.6435, val_loss: 0.6375, val_acc: 0.6140\n",
      "Epoch [30], train_loss: 0.6362, val_loss: 0.6660, val_acc: 0.5379\n",
      "Epoch [31], train_loss: 0.6410, val_loss: 0.6508, val_acc: 0.5643\n",
      "Epoch [32], train_loss: 0.6337, val_loss: 0.6454, val_acc: 0.5857\n",
      "Epoch [33], train_loss: 0.6362, val_loss: 0.6720, val_acc: 0.5669\n",
      "Epoch [34], train_loss: 0.6352, val_loss: 0.6595, val_acc: 0.5506\n",
      "Epoch [35], train_loss: 0.6340, val_loss: 0.6361, val_acc: 0.5698\n",
      "Epoch [36], train_loss: 0.6295, val_loss: 0.6416, val_acc: 0.6004\n",
      "Epoch [37], train_loss: 0.6216, val_loss: 0.6989, val_acc: 0.5776\n",
      "Epoch [38], train_loss: 0.6217, val_loss: 0.6321, val_acc: 0.6215\n",
      "Epoch [39], train_loss: 0.6174, val_loss: 0.6895, val_acc: 0.5588\n",
      "Epoch [40], train_loss: 0.6083, val_loss: 0.7446, val_acc: 0.5324\n",
      "Epoch [41], train_loss: 0.6126, val_loss: 0.6736, val_acc: 0.6082\n",
      "Epoch [42], train_loss: 0.6102, val_loss: 0.6771, val_acc: 0.5727\n",
      "Epoch [43], train_loss: 0.6141, val_loss: 0.7041, val_acc: 0.5704\n",
      "Epoch [44], train_loss: 0.5918, val_loss: 0.6810, val_acc: 0.5678\n",
      "Epoch [45], train_loss: 0.6086, val_loss: 0.6531, val_acc: 0.5249\n",
      "Epoch [46], train_loss: 0.5865, val_loss: 0.7655, val_acc: 0.6030\n",
      "Epoch [47], train_loss: 0.5927, val_loss: 0.6268, val_acc: 0.6209\n",
      "Epoch [48], train_loss: 0.5800, val_loss: 0.6717, val_acc: 0.5568\n",
      "Epoch [49], train_loss: 0.5665, val_loss: 0.6880, val_acc: 0.5965\n",
      "Epoch [50], train_loss: 0.5728, val_loss: 0.7223, val_acc: 0.6137\n",
      "Epoch [51], train_loss: 0.5606, val_loss: 0.6834, val_acc: 0.5617\n",
      "Epoch [52], train_loss: 0.5571, val_loss: 0.7106, val_acc: 0.5838\n",
      "Epoch [53], train_loss: 0.5412, val_loss: 0.6865, val_acc: 0.6137\n",
      "Epoch [54], train_loss: 0.5300, val_loss: 0.8234, val_acc: 0.5805\n",
      "Epoch [55], train_loss: 0.5075, val_loss: 0.8460, val_acc: 0.5617\n",
      "Epoch [56], train_loss: 0.5037, val_loss: 0.7045, val_acc: 0.5480\n",
      "Epoch [57], train_loss: 0.4731, val_loss: 0.9437, val_acc: 0.5734\n",
      "Epoch [58], train_loss: 0.4455, val_loss: 0.8221, val_acc: 0.5701\n",
      "Epoch [59], train_loss: 0.4596, val_loss: 0.8868, val_acc: 0.5678\n",
      "Epoch [60], train_loss: 0.4576, val_loss: 0.9282, val_acc: 0.5649\n",
      "Epoch [61], train_loss: 0.4042, val_loss: 0.7451, val_acc: 0.5783\n",
      "Epoch [62], train_loss: 0.4035, val_loss: 0.7739, val_acc: 0.6206\n",
      "Epoch [63], train_loss: 0.3668, val_loss: 1.2271, val_acc: 0.5037\n",
      "Epoch [64], train_loss: 0.3888, val_loss: 0.7938, val_acc: 0.5542\n",
      "Epoch [65], train_loss: 0.3854, val_loss: 1.6695, val_acc: 0.5646\n",
      "Epoch [66], train_loss: 0.3927, val_loss: 0.7907, val_acc: 0.5919\n",
      "Epoch [67], train_loss: 0.3754, val_loss: 1.1349, val_acc: 0.5640\n",
      "Epoch [68], train_loss: 0.3381, val_loss: 0.9376, val_acc: 0.6342\n",
      "Epoch [69], train_loss: 0.3539, val_loss: 0.8725, val_acc: 0.6147\n",
      "Epoch [70], train_loss: 0.2857, val_loss: 0.8793, val_acc: 0.5870\n",
      "Epoch [71], train_loss: 0.3052, val_loss: 1.0239, val_acc: 0.6475\n",
      "Epoch [72], train_loss: 0.2664, val_loss: 1.2855, val_acc: 0.6284\n",
      "Epoch [73], train_loss: 0.2628, val_loss: 1.5780, val_acc: 0.5997\n",
      "Epoch [74], train_loss: 0.2904, val_loss: 1.2206, val_acc: 0.6046\n",
      "Epoch [75], train_loss: 0.2738, val_loss: 0.9031, val_acc: 0.5831\n",
      "Epoch [76], train_loss: 0.2211, val_loss: 1.3739, val_acc: 0.6134\n",
      "Epoch [77], train_loss: 0.2468, val_loss: 1.6748, val_acc: 0.5516\n",
      "Epoch [78], train_loss: 0.2815, val_loss: 1.1022, val_acc: 0.6183\n",
      "Epoch [79], train_loss: 0.2261, val_loss: 1.5860, val_acc: 0.6206\n",
      "Epoch [80], train_loss: 0.2419, val_loss: 1.9997, val_acc: 0.5770\n",
      "Epoch [81], train_loss: 0.1998, val_loss: 1.8591, val_acc: 0.5825\n",
      "Epoch [82], train_loss: 0.1997, val_loss: 1.6368, val_acc: 0.5864\n",
      "Epoch [83], train_loss: 0.1775, val_loss: 1.9064, val_acc: 0.5753\n",
      "Epoch [84], train_loss: 0.1802, val_loss: 1.6099, val_acc: 0.6043\n",
      "Epoch [85], train_loss: 0.2001, val_loss: 1.8975, val_acc: 0.5939\n",
      "Epoch [86], train_loss: 0.1883, val_loss: 1.5365, val_acc: 0.6310\n",
      "Epoch [87], train_loss: 0.1668, val_loss: 1.9515, val_acc: 0.6521\n",
      "Epoch [88], train_loss: 0.1739, val_loss: 1.2477, val_acc: 0.6046\n",
      "Epoch [89], train_loss: 0.1456, val_loss: 1.6015, val_acc: 0.6066\n",
      "Epoch [90], train_loss: 0.1369, val_loss: 1.9722, val_acc: 0.6150\n",
      "Epoch [91], train_loss: 0.1800, val_loss: 1.4190, val_acc: 0.6092\n",
      "Epoch [92], train_loss: 0.1539, val_loss: 2.5435, val_acc: 0.5939\n",
      "Epoch [93], train_loss: 0.1579, val_loss: 1.7784, val_acc: 0.5783\n",
      "Epoch [94], train_loss: 0.2252, val_loss: 1.3791, val_acc: 0.5962\n",
      "Epoch [95], train_loss: 0.1903, val_loss: 1.6101, val_acc: 0.5809\n",
      "Epoch [96], train_loss: 0.1434, val_loss: 2.1284, val_acc: 0.5724\n",
      "Epoch [97], train_loss: 0.1410, val_loss: 2.0923, val_acc: 0.5890\n",
      "Epoch [98], train_loss: 0.1127, val_loss: 2.2010, val_acc: 0.6095\n",
      "Epoch [99], train_loss: 0.1103, val_loss: 2.2949, val_acc: 0.5783\n",
      "Epoch [100], train_loss: 0.1430, val_loss: 2.7383, val_acc: 0.5779\n",
      "Epoch [101], train_loss: 0.2936, val_loss: 1.4236, val_acc: 0.5776\n",
      "Epoch [102], train_loss: 0.1489, val_loss: 2.6472, val_acc: 0.5695\n",
      "Epoch [103], train_loss: 0.1206, val_loss: 1.7918, val_acc: 0.6153\n",
      "Epoch [104], train_loss: 0.1367, val_loss: 1.8017, val_acc: 0.6105\n",
      "Epoch [105], train_loss: 0.1204, val_loss: 1.9272, val_acc: 0.6072\n",
      "Epoch [106], train_loss: 0.0952, val_loss: 2.4218, val_acc: 0.6153\n",
      "Epoch [107], train_loss: 0.0904, val_loss: 2.5290, val_acc: 0.6179\n",
      "Epoch [108], train_loss: 0.0819, val_loss: 2.8903, val_acc: 0.6287\n",
      "Epoch [109], train_loss: 0.1095, val_loss: 3.1422, val_acc: 0.5994\n",
      "Epoch [110], train_loss: 0.0918, val_loss: 2.5239, val_acc: 0.6359\n",
      "Epoch [111], train_loss: 0.0851, val_loss: 2.3020, val_acc: 0.6079\n",
      "Epoch [112], train_loss: 0.1049, val_loss: 1.5647, val_acc: 0.5809\n",
      "Epoch [113], train_loss: 0.1042, val_loss: 2.3645, val_acc: 0.5994\n",
      "Epoch [114], train_loss: 0.0829, val_loss: 2.6087, val_acc: 0.6017\n",
      "Epoch [115], train_loss: 0.1057, val_loss: 2.0916, val_acc: 0.6475\n",
      "Epoch [116], train_loss: 0.1198, val_loss: 2.2431, val_acc: 0.5786\n",
      "Epoch [117], train_loss: 0.1503, val_loss: 1.5312, val_acc: 0.6342\n",
      "Epoch [118], train_loss: 0.1768, val_loss: 2.0099, val_acc: 0.5945\n",
      "Epoch [119], train_loss: 0.1037, val_loss: 2.3477, val_acc: 0.6101\n",
      "Epoch [120], train_loss: 0.1199, val_loss: 2.8404, val_acc: 0.5916\n",
      "Epoch [121], train_loss: 0.1531, val_loss: 1.6324, val_acc: 0.5997\n",
      "Epoch [122], train_loss: 0.0821, val_loss: 2.8074, val_acc: 0.6202\n",
      "Epoch [123], train_loss: 0.0685, val_loss: 2.0812, val_acc: 0.6284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124], train_loss: 0.1045, val_loss: 3.1856, val_acc: 0.6192\n",
      "Epoch [125], train_loss: 0.0912, val_loss: 1.5764, val_acc: 0.6261\n",
      "Epoch [126], train_loss: 0.0872, val_loss: 2.2893, val_acc: 0.6498\n",
      "Epoch [127], train_loss: 0.0959, val_loss: 1.7612, val_acc: 0.5779\n",
      "Epoch [128], train_loss: 0.0782, val_loss: 2.0572, val_acc: 0.6362\n",
      "Epoch [129], train_loss: 0.1287, val_loss: 1.4940, val_acc: 0.6258\n",
      "Epoch [130], train_loss: 0.0864, val_loss: 2.1198, val_acc: 0.6127\n",
      "Epoch [131], train_loss: 0.0876, val_loss: 2.5121, val_acc: 0.5968\n",
      "Epoch [132], train_loss: 0.0570, val_loss: 4.2946, val_acc: 0.5783\n",
      "Epoch [133], train_loss: 0.1345, val_loss: 1.7019, val_acc: 0.5682\n",
      "Epoch [134], train_loss: 0.0668, val_loss: 2.4816, val_acc: 0.6098\n",
      "Epoch [135], train_loss: 0.0857, val_loss: 2.0865, val_acc: 0.6026\n",
      "Epoch [136], train_loss: 0.0887, val_loss: 2.2701, val_acc: 0.6108\n",
      "Epoch [137], train_loss: 0.1802, val_loss: 1.6528, val_acc: 0.5838\n",
      "Epoch [138], train_loss: 0.0887, val_loss: 1.8256, val_acc: 0.6020\n",
      "Epoch [139], train_loss: 0.0816, val_loss: 3.0318, val_acc: 0.5968\n",
      "Epoch [140], train_loss: 0.0782, val_loss: 2.2358, val_acc: 0.6153\n",
      "Epoch [141], train_loss: 0.0544, val_loss: 3.1567, val_acc: 0.6173\n",
      "Epoch [142], train_loss: 0.0889, val_loss: 1.5674, val_acc: 0.6449\n",
      "Epoch [143], train_loss: 0.0531, val_loss: 2.6423, val_acc: 0.6121\n",
      "Epoch [144], train_loss: 0.0476, val_loss: 2.2366, val_acc: 0.6069\n",
      "Epoch [145], train_loss: 0.0372, val_loss: 2.3548, val_acc: 0.6502\n",
      "Epoch [146], train_loss: 0.0322, val_loss: 2.7246, val_acc: 0.6121\n",
      "Epoch [147], train_loss: 0.0679, val_loss: 2.1956, val_acc: 0.6176\n",
      "Epoch [148], train_loss: 0.0391, val_loss: 2.2297, val_acc: 0.6176\n",
      "Epoch [149], train_loss: 0.0157, val_loss: 3.6244, val_acc: 0.5913\n",
      "Epoch [150], train_loss: 0.0314, val_loss: 3.0171, val_acc: 0.6160\n",
      "Epoch [151], train_loss: 0.0506, val_loss: 2.4766, val_acc: 0.5727\n",
      "Epoch [152], train_loss: 0.0202, val_loss: 3.3628, val_acc: 0.6098\n",
      "Epoch [153], train_loss: 0.0304, val_loss: 4.1027, val_acc: 0.6206\n",
      "Epoch [154], train_loss: 0.0873, val_loss: 1.9769, val_acc: 0.6101\n",
      "Epoch [155], train_loss: 0.1100, val_loss: 1.2070, val_acc: 0.6371\n",
      "Epoch [156], train_loss: 0.0534, val_loss: 2.3431, val_acc: 0.6446\n",
      "Epoch [157], train_loss: 0.0398, val_loss: 2.3583, val_acc: 0.6101\n",
      "Epoch [158], train_loss: 0.0430, val_loss: 2.5393, val_acc: 0.6098\n",
      "Epoch [159], train_loss: 0.0553, val_loss: 3.3602, val_acc: 0.5675\n",
      "Epoch [160], train_loss: 0.0577, val_loss: 1.7394, val_acc: 0.6524\n",
      "Epoch [161], train_loss: 0.0215, val_loss: 3.0544, val_acc: 0.6498\n",
      "Epoch [162], train_loss: 0.0845, val_loss: 1.7236, val_acc: 0.6011\n",
      "Epoch [163], train_loss: 0.0849, val_loss: 2.3788, val_acc: 0.5890\n",
      "Epoch [164], train_loss: 0.0441, val_loss: 2.8877, val_acc: 0.6212\n",
      "Epoch [165], train_loss: 0.0461, val_loss: 1.8347, val_acc: 0.6443\n",
      "Epoch [166], train_loss: 0.0624, val_loss: 2.0782, val_acc: 0.6043\n",
      "Epoch [167], train_loss: 0.0294, val_loss: 2.4565, val_acc: 0.5991\n",
      "Epoch [168], train_loss: 0.0168, val_loss: 4.6345, val_acc: 0.5936\n",
      "Epoch [169], train_loss: 0.0548, val_loss: 2.3117, val_acc: 0.5939\n",
      "Epoch [170], train_loss: 0.0567, val_loss: 2.4591, val_acc: 0.6150\n",
      "Epoch [171], train_loss: 0.0292, val_loss: 3.5027, val_acc: 0.6049\n",
      "Epoch [172], train_loss: 0.0226, val_loss: 2.3871, val_acc: 0.6359\n",
      "Epoch [173], train_loss: 0.0367, val_loss: 2.6959, val_acc: 0.6183\n",
      "Epoch [174], train_loss: 0.0244, val_loss: 2.9976, val_acc: 0.6186\n",
      "Epoch [175], train_loss: 0.0225, val_loss: 6.8880, val_acc: 0.5646\n",
      "Epoch [176], train_loss: 0.0735, val_loss: 2.3539, val_acc: 0.6498\n",
      "Epoch [177], train_loss: 0.0324, val_loss: 3.1285, val_acc: 0.6232\n",
      "Epoch [178], train_loss: 0.0335, val_loss: 2.8482, val_acc: 0.5756\n",
      "Epoch [179], train_loss: 0.0902, val_loss: 2.0167, val_acc: 0.6131\n",
      "Epoch [180], train_loss: 0.0498, val_loss: 2.0000, val_acc: 0.6261\n",
      "Epoch [181], train_loss: 0.2377, val_loss: 2.1854, val_acc: 0.5701\n",
      "Epoch [182], train_loss: 0.0913, val_loss: 1.7537, val_acc: 0.5815\n",
      "Epoch [183], train_loss: 0.0481, val_loss: 1.5472, val_acc: 0.6420\n",
      "Epoch [184], train_loss: 0.0412, val_loss: 3.5168, val_acc: 0.5884\n",
      "Epoch [185], train_loss: 0.0881, val_loss: 1.4069, val_acc: 0.6251\n",
      "Epoch [186], train_loss: 0.0314, val_loss: 2.9664, val_acc: 0.5809\n",
      "Epoch [187], train_loss: 0.0234, val_loss: 2.3006, val_acc: 0.6319\n",
      "Epoch [188], train_loss: 0.0405, val_loss: 2.2087, val_acc: 0.5913\n",
      "Epoch [189], train_loss: 0.0275, val_loss: 3.4796, val_acc: 0.6342\n",
      "Epoch [190], train_loss: 0.0193, val_loss: 3.5746, val_acc: 0.6235\n",
      "Epoch [191], train_loss: 0.0962, val_loss: 2.7290, val_acc: 0.5828\n",
      "Epoch [192], train_loss: 0.0425, val_loss: 3.2251, val_acc: 0.6092\n",
      "Epoch [193], train_loss: 0.0424, val_loss: 3.1015, val_acc: 0.6206\n",
      "Epoch [194], train_loss: 0.0680, val_loss: 1.8268, val_acc: 0.6414\n",
      "Epoch [195], train_loss: 0.0122, val_loss: 2.9676, val_acc: 0.6046\n",
      "Epoch [196], train_loss: 0.0049, val_loss: 3.2352, val_acc: 0.6017\n",
      "Epoch [197], train_loss: 0.0009, val_loss: 3.4844, val_acc: 0.6179\n",
      "Epoch [198], train_loss: 0.0004, val_loss: 3.5819, val_acc: 0.6232\n",
      "Epoch [199], train_loss: 0.0002, val_loss: 3.6149, val_acc: 0.6365\n",
      "Epoch [200], train_loss: 0.0003, val_loss: 3.8854, val_acc: 0.6176\n",
      "Epoch [201], train_loss: 0.0003, val_loss: 3.8457, val_acc: 0.6020\n",
      "Epoch [202], train_loss: 0.0003, val_loss: 3.7829, val_acc: 0.6183\n",
      "Epoch [203], train_loss: 0.0001, val_loss: 4.0894, val_acc: 0.6072\n",
      "Epoch [204], train_loss: 0.0001, val_loss: 3.9975, val_acc: 0.6206\n",
      "Epoch [205], train_loss: 0.0001, val_loss: 4.0406, val_acc: 0.6101\n",
      "Epoch [206], train_loss: 0.0001, val_loss: 4.1543, val_acc: 0.6206\n",
      "Epoch [207], train_loss: 0.0001, val_loss: 4.1137, val_acc: 0.5991\n",
      "Epoch [208], train_loss: 0.0000, val_loss: 4.0431, val_acc: 0.6287\n",
      "Epoch [209], train_loss: 0.0000, val_loss: 4.1436, val_acc: 0.6261\n",
      "Epoch [210], train_loss: 0.0000, val_loss: 4.1256, val_acc: 0.6232\n",
      "Epoch [211], train_loss: 0.0000, val_loss: 4.2152, val_acc: 0.6153\n",
      "Epoch [212], train_loss: 0.0000, val_loss: 4.3766, val_acc: 0.6206\n",
      "Epoch [213], train_loss: 0.0000, val_loss: 4.2736, val_acc: 0.6179\n",
      "Epoch [214], train_loss: 0.0001, val_loss: 4.2644, val_acc: 0.6206\n",
      "Epoch [215], train_loss: 0.0001, val_loss: 4.4237, val_acc: 0.6258\n",
      "Epoch [216], train_loss: 0.0000, val_loss: 4.4236, val_acc: 0.6206\n",
      "Epoch [217], train_loss: 0.0000, val_loss: 4.3515, val_acc: 0.6232\n",
      "Epoch [218], train_loss: 0.0000, val_loss: 4.3471, val_acc: 0.6150\n",
      "Epoch [219], train_loss: 0.0000, val_loss: 4.3835, val_acc: 0.6258\n",
      "Epoch [220], train_loss: 0.0000, val_loss: 4.5749, val_acc: 0.6284\n",
      "Epoch [221], train_loss: 0.0000, val_loss: 4.4564, val_acc: 0.6124\n",
      "Epoch [222], train_loss: 0.0000, val_loss: 4.4069, val_acc: 0.6098\n",
      "Epoch [223], train_loss: 0.0000, val_loss: 4.3243, val_acc: 0.6206\n",
      "Epoch [224], train_loss: 0.0000, val_loss: 4.4817, val_acc: 0.6206\n",
      "Epoch [225], train_loss: 0.0001, val_loss: 4.4441, val_acc: 0.6232\n",
      "Epoch [226], train_loss: 0.0000, val_loss: 4.5313, val_acc: 0.6150\n",
      "Epoch [227], train_loss: 0.0000, val_loss: 4.4797, val_acc: 0.6339\n",
      "Epoch [228], train_loss: 0.0000, val_loss: 4.7014, val_acc: 0.6202\n",
      "Epoch [229], train_loss: 0.0000, val_loss: 4.5991, val_acc: 0.6206\n",
      "Epoch [230], train_loss: 0.0000, val_loss: 4.7115, val_acc: 0.6206\n",
      "Epoch [231], train_loss: 0.0000, val_loss: 4.7427, val_acc: 0.6124\n",
      "Epoch [232], train_loss: 0.0000, val_loss: 4.6511, val_acc: 0.6206\n",
      "Epoch [233], train_loss: 0.0000, val_loss: 4.7260, val_acc: 0.6176\n",
      "Epoch [234], train_loss: 0.0000, val_loss: 4.6833, val_acc: 0.6284\n",
      "Epoch [235], train_loss: 0.0000, val_loss: 4.8489, val_acc: 0.6206\n",
      "Epoch [236], train_loss: 0.0000, val_loss: 4.8016, val_acc: 0.6179\n",
      "Epoch [237], train_loss: 0.0000, val_loss: 4.6771, val_acc: 0.6150\n",
      "Epoch [238], train_loss: 0.0000, val_loss: 4.7997, val_acc: 0.6179\n",
      "Epoch [239], train_loss: 0.0000, val_loss: 4.6877, val_acc: 0.6232\n",
      "Epoch [240], train_loss: 0.0000, val_loss: 4.7803, val_acc: 0.6258\n",
      "Epoch [241], train_loss: 0.0000, val_loss: 4.8211, val_acc: 0.6232\n",
      "Epoch [242], train_loss: 0.0000, val_loss: 4.8579, val_acc: 0.6232\n",
      "Epoch [243], train_loss: 0.0000, val_loss: 4.8283, val_acc: 0.6179\n",
      "Epoch [244], train_loss: 0.0000, val_loss: 4.8209, val_acc: 0.6206\n",
      "Epoch [245], train_loss: 0.0000, val_loss: 4.9993, val_acc: 0.6206\n",
      "Epoch [246], train_loss: 0.0000, val_loss: 4.7566, val_acc: 0.6258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [247], train_loss: 0.0000, val_loss: 4.7786, val_acc: 0.6336\n",
      "Epoch [248], train_loss: 0.0000, val_loss: 4.9350, val_acc: 0.6258\n",
      "Epoch [249], train_loss: 0.0000, val_loss: 4.8252, val_acc: 0.6339\n",
      "Epoch [250], train_loss: 0.0000, val_loss: 5.0877, val_acc: 0.6150\n",
      "Epoch [251], train_loss: 0.0000, val_loss: 5.1540, val_acc: 0.6098\n",
      "Epoch [252], train_loss: 0.0000, val_loss: 5.0085, val_acc: 0.6124\n",
      "Epoch [253], train_loss: 0.0000, val_loss: 4.9708, val_acc: 0.6124\n",
      "Epoch [254], train_loss: 0.0000, val_loss: 5.1149, val_acc: 0.6124\n",
      "Epoch [255], train_loss: 0.0000, val_loss: 4.9669, val_acc: 0.6150\n",
      "Epoch [256], train_loss: 0.0000, val_loss: 5.1123, val_acc: 0.6176\n",
      "Epoch [257], train_loss: 0.0000, val_loss: 5.0266, val_acc: 0.6124\n",
      "Epoch [258], train_loss: 0.0000, val_loss: 5.1605, val_acc: 0.6124\n",
      "Epoch [259], train_loss: 0.0003, val_loss: 5.2878, val_acc: 0.6469\n",
      "Epoch [260], train_loss: 0.2975, val_loss: 1.7668, val_acc: 0.5936\n",
      "Epoch [261], train_loss: 0.2518, val_loss: 1.3396, val_acc: 0.5597\n",
      "Epoch [262], train_loss: 0.1895, val_loss: 2.1277, val_acc: 0.5568\n",
      "Epoch [263], train_loss: 0.1116, val_loss: 2.3470, val_acc: 0.5962\n",
      "Epoch [264], train_loss: 0.0667, val_loss: 0.8964, val_acc: 0.6528\n",
      "Epoch [265], train_loss: 0.1413, val_loss: 2.3155, val_acc: 0.6368\n",
      "Epoch [266], train_loss: 0.0735, val_loss: 2.9400, val_acc: 0.6176\n",
      "Epoch [267], train_loss: 0.0877, val_loss: 1.5351, val_acc: 0.5910\n",
      "Epoch [268], train_loss: 0.1111, val_loss: 2.9131, val_acc: 0.5701\n",
      "Epoch [269], train_loss: 0.1207, val_loss: 2.2600, val_acc: 0.5704\n",
      "Epoch [270], train_loss: 0.0630, val_loss: 2.2883, val_acc: 0.6449\n",
      "Epoch [271], train_loss: 0.0218, val_loss: 3.0873, val_acc: 0.6316\n",
      "Epoch [272], train_loss: 0.0341, val_loss: 1.6830, val_acc: 0.6583\n",
      "Epoch [273], train_loss: 0.0440, val_loss: 2.7322, val_acc: 0.5988\n",
      "Epoch [274], train_loss: 0.0201, val_loss: 3.3288, val_acc: 0.5893\n",
      "Epoch [275], train_loss: 0.0442, val_loss: 2.4726, val_acc: 0.5750\n",
      "Epoch [276], train_loss: 0.0451, val_loss: 2.7656, val_acc: 0.5802\n",
      "Epoch [277], train_loss: 0.0478, val_loss: 2.9578, val_acc: 0.5988\n",
      "Epoch [278], train_loss: 0.0599, val_loss: 2.5276, val_acc: 0.6066\n",
      "Epoch [279], train_loss: 0.0184, val_loss: 3.5729, val_acc: 0.5887\n",
      "Epoch [280], train_loss: 0.0324, val_loss: 2.8122, val_acc: 0.5535\n",
      "Epoch [281], train_loss: 0.0354, val_loss: 5.6576, val_acc: 0.5408\n",
      "Epoch [282], train_loss: 0.0651, val_loss: 1.6330, val_acc: 0.6147\n",
      "Epoch [283], train_loss: 0.0144, val_loss: 3.1504, val_acc: 0.6176\n",
      "Epoch [284], train_loss: 0.0134, val_loss: 4.4403, val_acc: 0.5936\n",
      "Epoch [285], train_loss: 0.1642, val_loss: 2.0776, val_acc: 0.5812\n",
      "Epoch [286], train_loss: 0.0484, val_loss: 3.0149, val_acc: 0.6258\n",
      "Epoch [287], train_loss: 0.0171, val_loss: 2.9532, val_acc: 0.6046\n",
      "Epoch [288], train_loss: 0.0299, val_loss: 3.7900, val_acc: 0.6072\n",
      "Epoch [289], train_loss: 0.0263, val_loss: 3.2929, val_acc: 0.6121\n",
      "Epoch [290], train_loss: 0.0107, val_loss: 3.5406, val_acc: 0.6580\n",
      "Epoch [291], train_loss: 0.0083, val_loss: 3.9305, val_acc: 0.5887\n",
      "Epoch [292], train_loss: 0.0207, val_loss: 3.4963, val_acc: 0.5994\n",
      "Epoch [293], train_loss: 0.0367, val_loss: 3.7857, val_acc: 0.5802\n",
      "Epoch [294], train_loss: 0.0226, val_loss: 3.7549, val_acc: 0.6362\n",
      "Epoch [295], train_loss: 0.0127, val_loss: 3.8981, val_acc: 0.6046\n",
      "Epoch [296], train_loss: 0.0139, val_loss: 3.3488, val_acc: 0.6124\n",
      "Epoch [297], train_loss: 0.0031, val_loss: 3.6738, val_acc: 0.6206\n",
      "Epoch [298], train_loss: 0.0120, val_loss: 3.1772, val_acc: 0.6075\n",
      "Epoch [299], train_loss: 0.0301, val_loss: 3.2926, val_acc: 0.5939\n",
      "Epoch [300], train_loss: 0.0080, val_loss: 3.1078, val_acc: 0.6069\n",
      "Epoch [301], train_loss: 0.0053, val_loss: 4.5326, val_acc: 0.6388\n",
      "Epoch [302], train_loss: 0.0106, val_loss: 3.5682, val_acc: 0.6043\n",
      "Epoch [303], train_loss: 0.0018, val_loss: 3.8776, val_acc: 0.6127\n",
      "Epoch [304], train_loss: 0.0016, val_loss: 4.1942, val_acc: 0.6046\n",
      "Epoch [305], train_loss: 0.0005, val_loss: 3.7579, val_acc: 0.6183\n",
      "Epoch [306], train_loss: 0.0009, val_loss: 4.5109, val_acc: 0.6127\n",
      "Epoch [307], train_loss: 0.0001, val_loss: 4.5449, val_acc: 0.6023\n",
      "Epoch [308], train_loss: 0.0000, val_loss: 4.5457, val_acc: 0.6101\n",
      "Epoch [309], train_loss: 0.0000, val_loss: 4.6302, val_acc: 0.6127\n",
      "Epoch [310], train_loss: 0.0000, val_loss: 4.5214, val_acc: 0.6101\n",
      "Epoch [311], train_loss: 0.0000, val_loss: 4.5872, val_acc: 0.6127\n",
      "Epoch [312], train_loss: 0.0000, val_loss: 4.7082, val_acc: 0.6020\n",
      "Epoch [313], train_loss: 0.0000, val_loss: 4.4808, val_acc: 0.6075\n",
      "Epoch [314], train_loss: 0.0000, val_loss: 4.6722, val_acc: 0.5965\n",
      "Epoch [315], train_loss: 0.0000, val_loss: 4.7956, val_acc: 0.6046\n",
      "Epoch [316], train_loss: 0.0000, val_loss: 4.7357, val_acc: 0.6072\n",
      "Epoch [317], train_loss: 0.0001, val_loss: 4.5367, val_acc: 0.6046\n",
      "Epoch [318], train_loss: 0.0000, val_loss: 4.7309, val_acc: 0.5939\n",
      "Epoch [319], train_loss: 0.0000, val_loss: 4.7839, val_acc: 0.6017\n",
      "Epoch [320], train_loss: 0.0003, val_loss: 4.4223, val_acc: 0.6235\n",
      "Epoch [321], train_loss: 0.0016, val_loss: 4.9829, val_acc: 0.6023\n",
      "Epoch [322], train_loss: 0.0291, val_loss: 4.1603, val_acc: 0.5857\n",
      "Epoch [323], train_loss: 0.0606, val_loss: 2.6668, val_acc: 0.6505\n",
      "Epoch [324], train_loss: 0.0737, val_loss: 1.7293, val_acc: 0.5971\n",
      "Epoch [325], train_loss: 0.0243, val_loss: 2.0568, val_acc: 0.5884\n",
      "Epoch [326], train_loss: 0.0531, val_loss: 3.7136, val_acc: 0.5919\n",
      "Epoch [327], train_loss: 0.0584, val_loss: 2.5760, val_acc: 0.5910\n",
      "Epoch [328], train_loss: 0.0324, val_loss: 2.3338, val_acc: 0.6333\n",
      "Epoch [329], train_loss: 0.0055, val_loss: 3.4058, val_acc: 0.5884\n",
      "Epoch [330], train_loss: 0.0203, val_loss: 2.0146, val_acc: 0.6580\n",
      "Epoch [331], train_loss: 0.0723, val_loss: 1.5173, val_acc: 0.6153\n",
      "Epoch [332], train_loss: 0.1322, val_loss: 2.1963, val_acc: 0.5776\n",
      "Epoch [333], train_loss: 0.0463, val_loss: 3.3390, val_acc: 0.5718\n",
      "Epoch [334], train_loss: 0.0322, val_loss: 2.8728, val_acc: 0.5835\n",
      "Epoch [335], train_loss: 0.0226, val_loss: 3.0531, val_acc: 0.5965\n",
      "Epoch [336], train_loss: 0.0263, val_loss: 2.4130, val_acc: 0.5588\n",
      "Epoch [337], train_loss: 0.0480, val_loss: 2.8631, val_acc: 0.5805\n",
      "Epoch [338], train_loss: 0.0062, val_loss: 3.0470, val_acc: 0.5614\n",
      "Epoch [339], train_loss: 0.0313, val_loss: 2.3448, val_acc: 0.5936\n",
      "Epoch [340], train_loss: 0.0162, val_loss: 3.1735, val_acc: 0.6284\n",
      "Epoch [341], train_loss: 0.0105, val_loss: 3.1405, val_acc: 0.5962\n",
      "Epoch [342], train_loss: 0.0125, val_loss: 3.1969, val_acc: 0.6280\n",
      "Epoch [343], train_loss: 0.0027, val_loss: 3.3439, val_acc: 0.6121\n",
      "Epoch [344], train_loss: 0.0007, val_loss: 3.7849, val_acc: 0.6066\n",
      "Epoch [345], train_loss: 0.0002, val_loss: 3.8054, val_acc: 0.5851\n",
      "Epoch [346], train_loss: 0.0001, val_loss: 3.9698, val_acc: 0.5932\n",
      "Epoch [347], train_loss: 0.0001, val_loss: 4.0464, val_acc: 0.5880\n",
      "Epoch [348], train_loss: 0.0001, val_loss: 4.0612, val_acc: 0.6011\n",
      "Epoch [349], train_loss: 0.0001, val_loss: 4.2333, val_acc: 0.5932\n",
      "Epoch [350], train_loss: 0.0001, val_loss: 4.1416, val_acc: 0.5932\n",
      "Epoch [351], train_loss: 0.0000, val_loss: 4.2131, val_acc: 0.6011\n",
      "Epoch [352], train_loss: 0.0001, val_loss: 4.1996, val_acc: 0.5958\n",
      "Epoch [353], train_loss: 0.0000, val_loss: 4.2851, val_acc: 0.5851\n",
      "Epoch [354], train_loss: 0.0000, val_loss: 4.1888, val_acc: 0.6037\n",
      "Epoch [355], train_loss: 0.0000, val_loss: 4.2168, val_acc: 0.5932\n",
      "Epoch [356], train_loss: 0.0000, val_loss: 4.4364, val_acc: 0.6037\n",
      "Epoch [357], train_loss: 0.0000, val_loss: 4.3117, val_acc: 0.5985\n",
      "Epoch [358], train_loss: 0.0000, val_loss: 4.4309, val_acc: 0.6063\n",
      "Epoch [359], train_loss: 0.0000, val_loss: 4.4293, val_acc: 0.5958\n",
      "Epoch [360], train_loss: 0.0000, val_loss: 4.4673, val_acc: 0.6011\n",
      "Epoch [361], train_loss: 0.0000, val_loss: 4.4790, val_acc: 0.5877\n",
      "Epoch [362], train_loss: 0.0000, val_loss: 4.4707, val_acc: 0.5955\n",
      "Epoch [363], train_loss: 0.0000, val_loss: 4.4610, val_acc: 0.5903\n",
      "Epoch [364], train_loss: 0.0000, val_loss: 4.5730, val_acc: 0.5932\n",
      "Epoch [365], train_loss: 0.0000, val_loss: 4.4161, val_acc: 0.5903\n",
      "Epoch [366], train_loss: 0.0000, val_loss: 4.5766, val_acc: 0.6011\n",
      "Epoch [367], train_loss: 0.0000, val_loss: 4.3780, val_acc: 0.5903\n",
      "Epoch [368], train_loss: 0.0000, val_loss: 4.6630, val_acc: 0.5929\n",
      "Epoch [369], train_loss: 0.0000, val_loss: 4.6672, val_acc: 0.6063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [370], train_loss: 0.0000, val_loss: 4.6716, val_acc: 0.5851\n",
      "Epoch [371], train_loss: 0.0000, val_loss: 4.6203, val_acc: 0.5955\n",
      "Epoch [372], train_loss: 0.0000, val_loss: 4.6573, val_acc: 0.5825\n",
      "Epoch [373], train_loss: 0.0000, val_loss: 4.5749, val_acc: 0.5929\n",
      "Epoch [374], train_loss: 0.0000, val_loss: 4.6517, val_acc: 0.5929\n",
      "Epoch [375], train_loss: 0.0000, val_loss: 4.8068, val_acc: 0.5958\n",
      "Epoch [376], train_loss: 0.0000, val_loss: 4.7636, val_acc: 0.5877\n",
      "Epoch [377], train_loss: 0.0000, val_loss: 4.6607, val_acc: 0.5929\n",
      "Epoch [378], train_loss: 0.0001, val_loss: 4.7795, val_acc: 0.5958\n",
      "Epoch [379], train_loss: 0.0057, val_loss: 8.2566, val_acc: 0.5428\n",
      "Epoch [380], train_loss: 0.0745, val_loss: 1.5744, val_acc: 0.5568\n",
      "Epoch [381], train_loss: 0.1089, val_loss: 2.5463, val_acc: 0.6261\n",
      "Epoch [382], train_loss: 0.0874, val_loss: 4.7785, val_acc: 0.5994\n",
      "Epoch [383], train_loss: 0.0801, val_loss: 2.0121, val_acc: 0.5646\n",
      "Epoch [384], train_loss: 0.0479, val_loss: 3.3132, val_acc: 0.5945\n",
      "Epoch [385], train_loss: 0.1118, val_loss: 2.2543, val_acc: 0.6049\n",
      "Epoch [386], train_loss: 0.0604, val_loss: 2.4527, val_acc: 0.5916\n",
      "Epoch [387], train_loss: 0.0239, val_loss: 2.4774, val_acc: 0.6254\n",
      "Epoch [388], train_loss: 0.0107, val_loss: 3.2169, val_acc: 0.6316\n",
      "Epoch [389], train_loss: 0.0065, val_loss: 5.5245, val_acc: 0.6160\n",
      "Epoch [390], train_loss: 0.0407, val_loss: 1.9941, val_acc: 0.6401\n",
      "Epoch [391], train_loss: 0.1080, val_loss: 2.3405, val_acc: 0.6310\n",
      "Epoch [392], train_loss: 0.0187, val_loss: 3.1206, val_acc: 0.6264\n",
      "Epoch [393], train_loss: 0.0108, val_loss: 3.6898, val_acc: 0.6391\n",
      "Epoch [394], train_loss: 0.0310, val_loss: 2.9815, val_acc: 0.5910\n",
      "Epoch [395], train_loss: 0.0071, val_loss: 3.9769, val_acc: 0.6046\n",
      "Epoch [396], train_loss: 0.0082, val_loss: 3.7893, val_acc: 0.6186\n",
      "Epoch [397], train_loss: 0.0183, val_loss: 3.3301, val_acc: 0.6339\n",
      "Epoch [398], train_loss: 0.0086, val_loss: 3.1325, val_acc: 0.5994\n",
      "Epoch [399], train_loss: 0.0009, val_loss: 3.6353, val_acc: 0.6017\n",
      "Epoch [400], train_loss: 0.0002, val_loss: 3.7865, val_acc: 0.5910\n",
      "Epoch [401], train_loss: 0.0001, val_loss: 3.8865, val_acc: 0.5910\n",
      "Epoch [402], train_loss: 0.0001, val_loss: 3.9824, val_acc: 0.5962\n",
      "Epoch [403], train_loss: 0.0001, val_loss: 4.0256, val_acc: 0.5991\n",
      "Epoch [404], train_loss: 0.0000, val_loss: 4.2729, val_acc: 0.5910\n",
      "Epoch [405], train_loss: 0.0000, val_loss: 4.1102, val_acc: 0.5884\n",
      "Epoch [406], train_loss: 0.0000, val_loss: 4.3128, val_acc: 0.5884\n",
      "Epoch [407], train_loss: 0.0000, val_loss: 4.1472, val_acc: 0.5884\n",
      "Epoch [408], train_loss: 0.0000, val_loss: 4.2746, val_acc: 0.5884\n",
      "Epoch [409], train_loss: 0.0000, val_loss: 4.2885, val_acc: 0.5884\n",
      "Epoch [410], train_loss: 0.0000, val_loss: 4.3160, val_acc: 0.5910\n",
      "Epoch [411], train_loss: 0.0000, val_loss: 4.3466, val_acc: 0.5884\n",
      "Epoch [412], train_loss: 0.0000, val_loss: 4.4451, val_acc: 0.5884\n",
      "Epoch [413], train_loss: 0.0000, val_loss: 4.4023, val_acc: 0.5910\n",
      "Epoch [414], train_loss: 0.0000, val_loss: 4.6799, val_acc: 0.5936\n",
      "Epoch [415], train_loss: 0.0000, val_loss: 4.5427, val_acc: 0.5910\n",
      "Epoch [416], train_loss: 0.0000, val_loss: 4.4982, val_acc: 0.5880\n",
      "Epoch [417], train_loss: 0.0000, val_loss: 4.6487, val_acc: 0.5932\n",
      "Epoch [418], train_loss: 0.0000, val_loss: 4.4861, val_acc: 0.5825\n",
      "Epoch [419], train_loss: 0.0000, val_loss: 4.6255, val_acc: 0.5988\n",
      "Epoch [420], train_loss: 0.0000, val_loss: 4.6390, val_acc: 0.5880\n",
      "Epoch [421], train_loss: 0.0000, val_loss: 4.6805, val_acc: 0.5936\n",
      "Epoch [422], train_loss: 0.0000, val_loss: 4.6518, val_acc: 0.5936\n",
      "Epoch [423], train_loss: 0.0000, val_loss: 4.6690, val_acc: 0.5936\n",
      "Epoch [424], train_loss: 0.0000, val_loss: 4.8575, val_acc: 0.5962\n",
      "Epoch [425], train_loss: 0.0000, val_loss: 4.8345, val_acc: 0.5828\n",
      "Epoch [426], train_loss: 0.0000, val_loss: 4.6674, val_acc: 0.5910\n",
      "Epoch [427], train_loss: 0.0000, val_loss: 4.7530, val_acc: 0.5936\n",
      "Epoch [428], train_loss: 0.0000, val_loss: 4.8900, val_acc: 0.5936\n",
      "Epoch [429], train_loss: 0.0000, val_loss: 4.7424, val_acc: 0.5962\n",
      "Epoch [430], train_loss: 0.0000, val_loss: 4.8399, val_acc: 0.5962\n",
      "Epoch [431], train_loss: 0.0000, val_loss: 4.8462, val_acc: 0.5962\n",
      "Epoch [432], train_loss: 0.0000, val_loss: 5.1080, val_acc: 0.5936\n",
      "Epoch [433], train_loss: 0.0000, val_loss: 4.8686, val_acc: 0.5884\n",
      "Epoch [434], train_loss: 0.0000, val_loss: 4.9832, val_acc: 0.5936\n",
      "Epoch [435], train_loss: 0.0000, val_loss: 4.8393, val_acc: 0.5910\n",
      "Epoch [436], train_loss: 0.0000, val_loss: 4.8181, val_acc: 0.5939\n",
      "Epoch [437], train_loss: 0.0000, val_loss: 5.0892, val_acc: 0.5936\n",
      "Epoch [438], train_loss: 0.0000, val_loss: 4.9182, val_acc: 0.5991\n",
      "Epoch [439], train_loss: 0.0000, val_loss: 4.9783, val_acc: 0.5991\n",
      "Epoch [440], train_loss: 0.0000, val_loss: 5.0165, val_acc: 0.5857\n",
      "Epoch [441], train_loss: 0.0000, val_loss: 4.9072, val_acc: 0.5910\n",
      "Epoch [442], train_loss: 0.0000, val_loss: 4.9763, val_acc: 0.5965\n",
      "Epoch [443], train_loss: 0.0000, val_loss: 5.0128, val_acc: 0.5910\n",
      "Epoch [444], train_loss: 0.0000, val_loss: 5.0000, val_acc: 0.5910\n",
      "Epoch [445], train_loss: 0.0007, val_loss: 5.0938, val_acc: 0.5861\n",
      "Epoch [446], train_loss: 0.2004, val_loss: 1.3744, val_acc: 0.5490\n",
      "Epoch [447], train_loss: 0.1410, val_loss: 2.3946, val_acc: 0.5565\n",
      "Epoch [448], train_loss: 0.0685, val_loss: 2.4605, val_acc: 0.5867\n",
      "Epoch [449], train_loss: 0.1722, val_loss: 1.6018, val_acc: 0.5597\n",
      "Epoch [450], train_loss: 0.0922, val_loss: 2.4686, val_acc: 0.5948\n",
      "Epoch [451], train_loss: 0.0524, val_loss: 2.7394, val_acc: 0.6235\n",
      "Epoch [452], train_loss: 0.0507, val_loss: 2.6422, val_acc: 0.5809\n",
      "Epoch [453], train_loss: 0.0378, val_loss: 3.8228, val_acc: 0.6264\n",
      "Epoch [454], train_loss: 0.0576, val_loss: 2.8189, val_acc: 0.6153\n",
      "Epoch [455], train_loss: 0.0393, val_loss: 3.6223, val_acc: 0.6049\n",
      "Epoch [456], train_loss: 0.0413, val_loss: 2.9687, val_acc: 0.5910\n",
      "Epoch [457], train_loss: 0.0104, val_loss: 3.3799, val_acc: 0.6235\n",
      "Epoch [458], train_loss: 0.0040, val_loss: 3.4009, val_acc: 0.6339\n",
      "Epoch [459], train_loss: 0.0049, val_loss: 4.0217, val_acc: 0.6342\n",
      "Epoch [460], train_loss: 0.0196, val_loss: 2.7426, val_acc: 0.6206\n",
      "Epoch [461], train_loss: 0.0116, val_loss: 3.2941, val_acc: 0.6127\n",
      "Epoch [462], train_loss: 0.0207, val_loss: 3.2707, val_acc: 0.6049\n",
      "Epoch [463], train_loss: 0.0165, val_loss: 3.5054, val_acc: 0.6502\n",
      "Epoch [464], train_loss: 0.0054, val_loss: 3.8577, val_acc: 0.6554\n",
      "Epoch [465], train_loss: 0.0018, val_loss: 4.0271, val_acc: 0.6420\n",
      "Epoch [466], train_loss: 0.0069, val_loss: 3.7411, val_acc: 0.6124\n",
      "Epoch [467], train_loss: 0.0572, val_loss: 2.1872, val_acc: 0.6232\n",
      "Epoch [468], train_loss: 0.1717, val_loss: 1.8521, val_acc: 0.6899\n",
      "Epoch [469], train_loss: 0.0528, val_loss: 2.7561, val_acc: 0.6072\n",
      "Epoch [470], train_loss: 0.0403, val_loss: 3.0491, val_acc: 0.6206\n",
      "Epoch [471], train_loss: 0.0157, val_loss: 3.2631, val_acc: 0.6554\n",
      "Epoch [472], train_loss: 0.0070, val_loss: 3.4741, val_acc: 0.6254\n",
      "Epoch [473], train_loss: 0.0037, val_loss: 3.6132, val_acc: 0.6420\n",
      "Epoch [474], train_loss: 0.0093, val_loss: 2.8404, val_acc: 0.6414\n",
      "Epoch [475], train_loss: 0.0092, val_loss: 3.7601, val_acc: 0.6524\n",
      "Epoch [476], train_loss: 0.0098, val_loss: 3.9866, val_acc: 0.6554\n",
      "Epoch [477], train_loss: 0.0791, val_loss: 1.8369, val_acc: 0.6472\n",
      "Epoch [478], train_loss: 0.0292, val_loss: 2.6410, val_acc: 0.6443\n",
      "Epoch [479], train_loss: 0.0023, val_loss: 2.7864, val_acc: 0.6342\n",
      "Epoch [480], train_loss: 0.0006, val_loss: 2.8709, val_acc: 0.6371\n",
      "Epoch [481], train_loss: 0.0003, val_loss: 2.9937, val_acc: 0.6206\n",
      "Epoch [482], train_loss: 0.0002, val_loss: 3.0345, val_acc: 0.6449\n",
      "Epoch [483], train_loss: 0.0002, val_loss: 3.1414, val_acc: 0.6342\n",
      "Epoch [484], train_loss: 0.0001, val_loss: 3.1796, val_acc: 0.6313\n",
      "Epoch [485], train_loss: 0.0001, val_loss: 3.1729, val_acc: 0.6342\n",
      "Epoch [486], train_loss: 0.0001, val_loss: 3.2023, val_acc: 0.6342\n",
      "Epoch [487], train_loss: 0.0001, val_loss: 3.2392, val_acc: 0.6290\n",
      "Epoch [488], train_loss: 0.0001, val_loss: 3.2988, val_acc: 0.6368\n",
      "Epoch [489], train_loss: 0.0036, val_loss: 3.1534, val_acc: 0.6254\n",
      "Epoch [490], train_loss: 0.1250, val_loss: 1.5514, val_acc: 0.6179\n",
      "Epoch [491], train_loss: 0.0311, val_loss: 3.9108, val_acc: 0.6020\n",
      "Epoch [492], train_loss: 0.0483, val_loss: 3.1575, val_acc: 0.5932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [493], train_loss: 0.0685, val_loss: 1.6092, val_acc: 0.5591\n",
      "Epoch [494], train_loss: 0.0169, val_loss: 2.9847, val_acc: 0.6157\n",
      "Epoch [495], train_loss: 0.0214, val_loss: 3.0938, val_acc: 0.6179\n",
      "Epoch [496], train_loss: 0.0074, val_loss: 3.5336, val_acc: 0.6206\n",
      "Epoch [497], train_loss: 0.0015, val_loss: 3.6368, val_acc: 0.6209\n",
      "Epoch [498], train_loss: 0.0005, val_loss: 3.6033, val_acc: 0.6261\n",
      "Epoch [499], train_loss: 0.0004, val_loss: 3.8703, val_acc: 0.6287\n",
      "Epoch [500], train_loss: 0.0002, val_loss: 3.9470, val_acc: 0.6206\n",
      "Epoch [501], train_loss: 0.0001, val_loss: 3.8629, val_acc: 0.6313\n",
      "Epoch [502], train_loss: 0.0001, val_loss: 4.0135, val_acc: 0.6206\n",
      "Epoch [503], train_loss: 0.0001, val_loss: 3.9691, val_acc: 0.6206\n",
      "Epoch [504], train_loss: 0.0001, val_loss: 4.1485, val_acc: 0.6179\n",
      "Epoch [505], train_loss: 0.0001, val_loss: 4.1511, val_acc: 0.6124\n",
      "Epoch [506], train_loss: 0.0001, val_loss: 4.1432, val_acc: 0.6098\n",
      "Epoch [507], train_loss: 0.0001, val_loss: 4.1424, val_acc: 0.6179\n",
      "Epoch [508], train_loss: 0.0000, val_loss: 4.2322, val_acc: 0.6124\n",
      "Epoch [509], train_loss: 0.0000, val_loss: 4.2600, val_acc: 0.6098\n",
      "Epoch [510], train_loss: 0.0000, val_loss: 4.3109, val_acc: 0.6072\n",
      "Epoch [511], train_loss: 0.0000, val_loss: 4.1881, val_acc: 0.6124\n",
      "Epoch [512], train_loss: 0.0000, val_loss: 4.3038, val_acc: 0.6150\n",
      "Epoch [513], train_loss: 0.0001, val_loss: 4.3623, val_acc: 0.6176\n",
      "Epoch [514], train_loss: 0.0001, val_loss: 4.4076, val_acc: 0.6095\n",
      "Epoch [515], train_loss: 0.0000, val_loss: 4.3720, val_acc: 0.6176\n",
      "Epoch [516], train_loss: 0.0000, val_loss: 4.4450, val_acc: 0.6124\n",
      "Epoch [517], train_loss: 0.0000, val_loss: 4.3858, val_acc: 0.6124\n",
      "Epoch [518], train_loss: 0.0000, val_loss: 4.5134, val_acc: 0.6098\n",
      "Epoch [519], train_loss: 0.0000, val_loss: 4.4102, val_acc: 0.6150\n",
      "Epoch [520], train_loss: 0.0000, val_loss: 4.4775, val_acc: 0.6150\n",
      "Epoch [521], train_loss: 0.0000, val_loss: 4.5122, val_acc: 0.6206\n",
      "Epoch [522], train_loss: 0.0000, val_loss: 4.4598, val_acc: 0.6232\n",
      "Epoch [523], train_loss: 0.0000, val_loss: 4.5856, val_acc: 0.6206\n",
      "Epoch [524], train_loss: 0.0000, val_loss: 4.6570, val_acc: 0.6206\n",
      "Epoch [525], train_loss: 0.0000, val_loss: 4.7081, val_acc: 0.6150\n",
      "Epoch [526], train_loss: 0.0000, val_loss: 4.5615, val_acc: 0.6313\n",
      "Epoch [527], train_loss: 0.0000, val_loss: 4.7916, val_acc: 0.6232\n",
      "Epoch [528], train_loss: 0.0000, val_loss: 4.6401, val_acc: 0.6313\n",
      "Epoch [529], train_loss: 0.0000, val_loss: 4.5196, val_acc: 0.6206\n",
      "Epoch [530], train_loss: 0.0000, val_loss: 4.7962, val_acc: 0.6232\n",
      "Epoch [531], train_loss: 0.0000, val_loss: 4.7668, val_acc: 0.6232\n",
      "Epoch [532], train_loss: 0.0000, val_loss: 4.8079, val_acc: 0.6258\n",
      "Epoch [533], train_loss: 0.0000, val_loss: 4.7855, val_acc: 0.6232\n",
      "Epoch [534], train_loss: 0.0000, val_loss: 4.8402, val_acc: 0.6365\n",
      "Epoch [535], train_loss: 0.0001, val_loss: 4.6946, val_acc: 0.6176\n",
      "Epoch [536], train_loss: 0.0000, val_loss: 4.7647, val_acc: 0.6342\n",
      "Epoch [537], train_loss: 0.0000, val_loss: 4.7878, val_acc: 0.6290\n",
      "Epoch [538], train_loss: 0.0000, val_loss: 4.7933, val_acc: 0.6316\n",
      "Epoch [539], train_loss: 0.0005, val_loss: 4.5098, val_acc: 0.6186\n",
      "Epoch [540], train_loss: 0.1586, val_loss: 1.6886, val_acc: 0.5809\n",
      "Epoch [541], train_loss: 0.1071, val_loss: 3.4226, val_acc: 0.5861\n",
      "Epoch [542], train_loss: 0.0706, val_loss: 1.7919, val_acc: 0.5724\n",
      "Epoch [543], train_loss: 0.0296, val_loss: 3.2787, val_acc: 0.5747\n",
      "Epoch [544], train_loss: 0.0210, val_loss: 2.2073, val_acc: 0.6235\n",
      "Epoch [545], train_loss: 0.0266, val_loss: 1.6989, val_acc: 0.6092\n",
      "Epoch [546], train_loss: 0.0136, val_loss: 3.3668, val_acc: 0.5857\n",
      "Epoch [547], train_loss: 0.0043, val_loss: 4.0336, val_acc: 0.6127\n",
      "Epoch [548], train_loss: 0.0736, val_loss: 1.5388, val_acc: 0.6020\n",
      "Epoch [549], train_loss: 0.1210, val_loss: 2.3694, val_acc: 0.6179\n",
      "Epoch [550], train_loss: 0.0566, val_loss: 1.4411, val_acc: 0.6023\n",
      "Epoch [551], train_loss: 0.0251, val_loss: 3.0079, val_acc: 0.5988\n",
      "Epoch [552], train_loss: 0.0319, val_loss: 2.5466, val_acc: 0.5962\n",
      "Epoch [553], train_loss: 0.0049, val_loss: 3.0458, val_acc: 0.6199\n",
      "Epoch [554], train_loss: 0.0009, val_loss: 3.3635, val_acc: 0.5955\n",
      "Epoch [555], train_loss: 0.0004, val_loss: 3.4625, val_acc: 0.5985\n",
      "Epoch [556], train_loss: 0.0002, val_loss: 3.5978, val_acc: 0.5877\n",
      "Epoch [557], train_loss: 0.0001, val_loss: 3.6182, val_acc: 0.5877\n",
      "Epoch [558], train_loss: 0.0001, val_loss: 3.5734, val_acc: 0.5851\n",
      "Epoch [559], train_loss: 0.0001, val_loss: 3.7807, val_acc: 0.5851\n",
      "Epoch [560], train_loss: 0.0001, val_loss: 3.7369, val_acc: 0.5796\n",
      "Epoch [561], train_loss: 0.0001, val_loss: 3.8528, val_acc: 0.6011\n",
      "Epoch [562], train_loss: 0.0000, val_loss: 3.9278, val_acc: 0.5985\n",
      "Epoch [563], train_loss: 0.0001, val_loss: 3.8696, val_acc: 0.5955\n",
      "Epoch [564], train_loss: 0.0001, val_loss: 3.9169, val_acc: 0.6173\n",
      "Epoch [565], train_loss: 0.0000, val_loss: 4.0152, val_acc: 0.5877\n",
      "Epoch [566], train_loss: 0.0025, val_loss: 4.3634, val_acc: 0.6118\n",
      "Epoch [567], train_loss: 0.1009, val_loss: 1.7720, val_acc: 0.5779\n",
      "Epoch [568], train_loss: 0.0206, val_loss: 2.8349, val_acc: 0.6176\n",
      "Epoch [569], train_loss: 0.0221, val_loss: 2.7476, val_acc: 0.5750\n",
      "Epoch [570], train_loss: 0.0232, val_loss: 2.5539, val_acc: 0.6339\n",
      "Epoch [571], train_loss: 0.0032, val_loss: 2.9261, val_acc: 0.6310\n",
      "Epoch [572], train_loss: 0.0071, val_loss: 2.4425, val_acc: 0.6280\n",
      "Epoch [573], train_loss: 0.0083, val_loss: 2.9878, val_acc: 0.6043\n",
      "Epoch [574], train_loss: 0.0014, val_loss: 3.1082, val_acc: 0.5776\n",
      "Epoch [575], train_loss: 0.0026, val_loss: 3.2743, val_acc: 0.5779\n",
      "Epoch [576], train_loss: 0.0482, val_loss: 2.2969, val_acc: 0.6072\n",
      "Epoch [577], train_loss: 0.0154, val_loss: 2.2793, val_acc: 0.6469\n",
      "Epoch [578], train_loss: 0.0029, val_loss: 3.0306, val_acc: 0.6040\n",
      "Epoch [579], train_loss: 0.0006, val_loss: 3.1965, val_acc: 0.6150\n",
      "Epoch [580], train_loss: 0.0001, val_loss: 3.2152, val_acc: 0.6150\n",
      "Epoch [581], train_loss: 0.0002, val_loss: 3.1043, val_acc: 0.6095\n",
      "Epoch [582], train_loss: 0.0001, val_loss: 3.2146, val_acc: 0.6095\n",
      "Epoch [583], train_loss: 0.0002, val_loss: 3.3229, val_acc: 0.6310\n",
      "Epoch [584], train_loss: 0.0001, val_loss: 3.3087, val_acc: 0.6362\n",
      "Epoch [585], train_loss: 0.0000, val_loss: 3.4176, val_acc: 0.6310\n",
      "Epoch [586], train_loss: 0.0000, val_loss: 3.4378, val_acc: 0.6173\n",
      "Epoch [587], train_loss: 0.0000, val_loss: 3.4681, val_acc: 0.6202\n",
      "Epoch [588], train_loss: 0.0000, val_loss: 3.4996, val_acc: 0.6336\n",
      "Epoch [589], train_loss: 0.0000, val_loss: 3.4541, val_acc: 0.6121\n",
      "Epoch [590], train_loss: 0.0000, val_loss: 3.4375, val_acc: 0.6228\n",
      "Epoch [591], train_loss: 0.0000, val_loss: 3.4560, val_acc: 0.6310\n",
      "Epoch [592], train_loss: 0.0000, val_loss: 3.5455, val_acc: 0.6417\n",
      "Epoch [593], train_loss: 0.0000, val_loss: 3.4438, val_acc: 0.6284\n",
      "Epoch [594], train_loss: 0.0000, val_loss: 3.4870, val_acc: 0.6284\n",
      "Epoch [595], train_loss: 0.0000, val_loss: 3.6277, val_acc: 0.6310\n",
      "Epoch [596], train_loss: 0.0000, val_loss: 3.5474, val_acc: 0.6258\n",
      "Epoch [597], train_loss: 0.0000, val_loss: 3.6795, val_acc: 0.6284\n",
      "Epoch [598], train_loss: 0.0000, val_loss: 3.5599, val_acc: 0.6254\n",
      "Epoch [599], train_loss: 0.0000, val_loss: 3.5972, val_acc: 0.6150\n",
      "Epoch [600], train_loss: 0.0000, val_loss: 3.6187, val_acc: 0.6284\n",
      "Epoch [601], train_loss: 0.0000, val_loss: 3.6175, val_acc: 0.6258\n",
      "Epoch [602], train_loss: 0.0000, val_loss: 3.6639, val_acc: 0.6336\n",
      "Epoch [603], train_loss: 0.0000, val_loss: 3.6292, val_acc: 0.6228\n",
      "Epoch [604], train_loss: 0.0000, val_loss: 3.7272, val_acc: 0.6336\n",
      "Epoch [605], train_loss: 0.0000, val_loss: 3.7195, val_acc: 0.6258\n",
      "Epoch [606], train_loss: 0.0000, val_loss: 3.7537, val_acc: 0.6121\n",
      "Epoch [607], train_loss: 0.0000, val_loss: 3.7122, val_acc: 0.6232\n",
      "Epoch [608], train_loss: 0.0000, val_loss: 3.7257, val_acc: 0.6258\n",
      "Epoch [609], train_loss: 0.0000, val_loss: 3.7788, val_acc: 0.6284\n",
      "Epoch [610], train_loss: 0.0000, val_loss: 3.7997, val_acc: 0.6206\n",
      "Epoch [611], train_loss: 0.0000, val_loss: 3.8103, val_acc: 0.6150\n",
      "Epoch [612], train_loss: 0.0000, val_loss: 3.7497, val_acc: 0.6176\n",
      "Epoch [613], train_loss: 0.0000, val_loss: 3.7921, val_acc: 0.6310\n",
      "Epoch [614], train_loss: 0.0000, val_loss: 3.8327, val_acc: 0.6176\n",
      "Epoch [615], train_loss: 0.0000, val_loss: 3.7272, val_acc: 0.6310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [616], train_loss: 0.0000, val_loss: 3.8040, val_acc: 0.6254\n",
      "Epoch [617], train_loss: 0.0000, val_loss: 3.8757, val_acc: 0.6284\n",
      "Epoch [618], train_loss: 0.0000, val_loss: 3.8640, val_acc: 0.6254\n",
      "Epoch [619], train_loss: 0.0000, val_loss: 3.8606, val_acc: 0.6232\n",
      "Epoch [620], train_loss: 0.0106, val_loss: 4.8758, val_acc: 0.6017\n",
      "Epoch [621], train_loss: 0.1626, val_loss: 1.5722, val_acc: 0.6101\n",
      "Epoch [622], train_loss: 0.0809, val_loss: 2.7436, val_acc: 0.6020\n",
      "Epoch [623], train_loss: 0.1468, val_loss: 1.9640, val_acc: 0.6124\n",
      "Epoch [624], train_loss: 0.0565, val_loss: 2.3300, val_acc: 0.6023\n",
      "Epoch [625], train_loss: 0.0284, val_loss: 1.8372, val_acc: 0.5965\n",
      "Epoch [626], train_loss: 0.0278, val_loss: 3.3600, val_acc: 0.6258\n",
      "Epoch [627], train_loss: 0.0239, val_loss: 2.9261, val_acc: 0.5968\n",
      "Epoch [628], train_loss: 0.0058, val_loss: 2.8077, val_acc: 0.6371\n",
      "Epoch [629], train_loss: 0.0009, val_loss: 3.0108, val_acc: 0.6394\n",
      "Epoch [630], train_loss: 0.0002, val_loss: 3.1157, val_acc: 0.6446\n",
      "Epoch [631], train_loss: 0.0005, val_loss: 2.4962, val_acc: 0.6287\n",
      "Epoch [632], train_loss: 0.0034, val_loss: 3.3774, val_acc: 0.6339\n",
      "Epoch [633], train_loss: 0.0054, val_loss: 2.8107, val_acc: 0.6440\n",
      "Epoch [634], train_loss: 0.0012, val_loss: 3.2614, val_acc: 0.6254\n",
      "Epoch [635], train_loss: 0.0002, val_loss: 3.4457, val_acc: 0.6362\n",
      "Epoch [636], train_loss: 0.0001, val_loss: 3.4115, val_acc: 0.6443\n",
      "Epoch [637], train_loss: 0.0001, val_loss: 3.5943, val_acc: 0.6388\n",
      "Epoch [638], train_loss: 0.0001, val_loss: 3.5559, val_acc: 0.6414\n",
      "Epoch [639], train_loss: 0.0001, val_loss: 3.6957, val_acc: 0.6417\n",
      "Epoch [640], train_loss: 0.0000, val_loss: 3.6249, val_acc: 0.6443\n",
      "Epoch [641], train_loss: 0.0000, val_loss: 3.6125, val_acc: 0.6391\n",
      "Epoch [642], train_loss: 0.0001, val_loss: 3.6770, val_acc: 0.6417\n",
      "Epoch [643], train_loss: 0.0001, val_loss: 3.7420, val_acc: 0.6469\n",
      "Epoch [644], train_loss: 0.0000, val_loss: 3.7756, val_acc: 0.6469\n",
      "Epoch [645], train_loss: 0.0014, val_loss: 3.9784, val_acc: 0.6443\n",
      "Epoch [646], train_loss: 0.1040, val_loss: 2.2646, val_acc: 0.6075\n",
      "Epoch [647], train_loss: 0.0521, val_loss: 2.5442, val_acc: 0.6238\n",
      "Epoch [648], train_loss: 0.0109, val_loss: 3.7683, val_acc: 0.6232\n",
      "Epoch [649], train_loss: 0.0135, val_loss: 2.2195, val_acc: 0.6209\n",
      "Epoch [650], train_loss: 0.0055, val_loss: 2.5419, val_acc: 0.6267\n",
      "Epoch [651], train_loss: 0.0090, val_loss: 2.4099, val_acc: 0.6264\n",
      "Epoch [652], train_loss: 0.0301, val_loss: 2.5525, val_acc: 0.6339\n",
      "Epoch [653], train_loss: 0.0033, val_loss: 2.7895, val_acc: 0.6524\n",
      "Epoch [654], train_loss: 0.0005, val_loss: 2.9680, val_acc: 0.6394\n",
      "Epoch [655], train_loss: 0.0002, val_loss: 3.1442, val_acc: 0.6420\n",
      "Epoch [656], train_loss: 0.0002, val_loss: 3.0706, val_acc: 0.6232\n",
      "Epoch [657], train_loss: 0.0001, val_loss: 3.2281, val_acc: 0.6420\n",
      "Epoch [658], train_loss: 0.0001, val_loss: 3.2845, val_acc: 0.6368\n",
      "Epoch [659], train_loss: 0.0001, val_loss: 3.4274, val_acc: 0.6342\n",
      "Epoch [660], train_loss: 0.0001, val_loss: 3.3266, val_acc: 0.6368\n",
      "Epoch [661], train_loss: 0.0001, val_loss: 3.4161, val_acc: 0.6368\n",
      "Epoch [662], train_loss: 0.0000, val_loss: 3.3840, val_acc: 0.6394\n",
      "Epoch [663], train_loss: 0.0001, val_loss: 3.5842, val_acc: 0.6316\n",
      "Epoch [664], train_loss: 0.0000, val_loss: 3.5677, val_acc: 0.6423\n",
      "Epoch [665], train_loss: 0.0000, val_loss: 3.5999, val_acc: 0.6475\n",
      "Epoch [666], train_loss: 0.0000, val_loss: 3.6609, val_acc: 0.6423\n",
      "Epoch [667], train_loss: 0.0000, val_loss: 3.5729, val_acc: 0.6502\n",
      "Epoch [668], train_loss: 0.0000, val_loss: 3.7752, val_acc: 0.6449\n",
      "Epoch [669], train_loss: 0.0000, val_loss: 3.6915, val_acc: 0.6423\n",
      "Epoch [670], train_loss: 0.0000, val_loss: 3.6967, val_acc: 0.6475\n",
      "Epoch [671], train_loss: 0.0000, val_loss: 3.7386, val_acc: 0.6423\n",
      "Epoch [672], train_loss: 0.0000, val_loss: 3.6899, val_acc: 0.6475\n",
      "Epoch [673], train_loss: 0.0000, val_loss: 3.7279, val_acc: 0.6475\n",
      "Epoch [674], train_loss: 0.0000, val_loss: 3.7324, val_acc: 0.6502\n",
      "Epoch [675], train_loss: 0.0000, val_loss: 3.7312, val_acc: 0.6423\n",
      "Epoch [676], train_loss: 0.0000, val_loss: 3.8184, val_acc: 0.6449\n",
      "Epoch [677], train_loss: 0.0000, val_loss: 3.8905, val_acc: 0.6397\n",
      "Epoch [678], train_loss: 0.0000, val_loss: 3.9145, val_acc: 0.6423\n",
      "Epoch [679], train_loss: 0.0000, val_loss: 3.8175, val_acc: 0.6475\n",
      "Epoch [680], train_loss: 0.0000, val_loss: 3.8850, val_acc: 0.6449\n",
      "Epoch [681], train_loss: 0.0015, val_loss: 4.3668, val_acc: 0.6319\n",
      "Epoch [682], train_loss: 0.0907, val_loss: 0.8491, val_acc: 0.5763\n",
      "Epoch [683], train_loss: 0.0871, val_loss: 2.9135, val_acc: 0.6258\n",
      "Epoch [684], train_loss: 0.0374, val_loss: 2.3387, val_acc: 0.6339\n",
      "Epoch [685], train_loss: 0.0266, val_loss: 2.9557, val_acc: 0.5727\n",
      "Epoch [686], train_loss: 0.0436, val_loss: 1.5620, val_acc: 0.6179\n",
      "Epoch [687], train_loss: 0.0082, val_loss: 3.4002, val_acc: 0.6124\n",
      "Epoch [688], train_loss: 0.0033, val_loss: 3.3816, val_acc: 0.6121\n",
      "Epoch [689], train_loss: 0.0047, val_loss: 2.8382, val_acc: 0.6284\n",
      "Epoch [690], train_loss: 0.0011, val_loss: 3.3479, val_acc: 0.6280\n",
      "Epoch [691], train_loss: 0.0010, val_loss: 3.8203, val_acc: 0.6254\n",
      "Epoch [692], train_loss: 0.0051, val_loss: 3.0049, val_acc: 0.6313\n",
      "Epoch [693], train_loss: 0.0115, val_loss: 4.4944, val_acc: 0.5994\n",
      "Epoch [694], train_loss: 0.0618, val_loss: 2.3488, val_acc: 0.6391\n",
      "Epoch [695], train_loss: 0.0273, val_loss: 3.3568, val_acc: 0.6017\n",
      "Epoch [696], train_loss: 0.0240, val_loss: 4.8622, val_acc: 0.5835\n",
      "Epoch [697], train_loss: 0.0839, val_loss: 2.0809, val_acc: 0.6095\n",
      "Epoch [698], train_loss: 0.0362, val_loss: 3.2982, val_acc: 0.6469\n",
      "Epoch [699], train_loss: 0.0123, val_loss: 2.7910, val_acc: 0.6502\n",
      "Epoch [700], train_loss: 0.0031, val_loss: 2.2755, val_acc: 0.6287\n",
      "Epoch [701], train_loss: 0.0022, val_loss: 2.7454, val_acc: 0.6557\n",
      "Epoch [702], train_loss: 0.0059, val_loss: 3.3504, val_acc: 0.6583\n",
      "Epoch [703], train_loss: 0.0021, val_loss: 3.3736, val_acc: 0.6420\n",
      "Epoch [704], train_loss: 0.0040, val_loss: 2.9148, val_acc: 0.6557\n",
      "Epoch [705], train_loss: 0.0005, val_loss: 3.1763, val_acc: 0.6449\n",
      "Epoch [706], train_loss: 0.0002, val_loss: 3.3830, val_acc: 0.6475\n",
      "Epoch [707], train_loss: 0.0001, val_loss: 3.3043, val_acc: 0.6531\n",
      "Epoch [708], train_loss: 0.0001, val_loss: 3.5312, val_acc: 0.6423\n",
      "Epoch [709], train_loss: 0.0001, val_loss: 3.5534, val_acc: 0.6475\n",
      "Epoch [710], train_loss: 0.0002, val_loss: 3.6236, val_acc: 0.6502\n",
      "Epoch [711], train_loss: 0.0001, val_loss: 3.5804, val_acc: 0.6502\n",
      "Epoch [712], train_loss: 0.0000, val_loss: 3.6713, val_acc: 0.6449\n",
      "Epoch [713], train_loss: 0.0000, val_loss: 3.7268, val_acc: 0.6475\n",
      "Epoch [714], train_loss: 0.0000, val_loss: 3.7465, val_acc: 0.6557\n",
      "Epoch [715], train_loss: 0.0001, val_loss: 3.7457, val_acc: 0.6505\n",
      "Epoch [716], train_loss: 0.0000, val_loss: 3.8454, val_acc: 0.6557\n",
      "Epoch [717], train_loss: 0.0000, val_loss: 3.8791, val_acc: 0.6531\n",
      "Epoch [718], train_loss: 0.0043, val_loss: 4.0003, val_acc: 0.5942\n",
      "Epoch [719], train_loss: 0.0365, val_loss: 1.9415, val_acc: 0.6228\n",
      "Epoch [720], train_loss: 0.0321, val_loss: 2.1779, val_acc: 0.6261\n",
      "Epoch [721], train_loss: 0.0279, val_loss: 2.4717, val_acc: 0.6017\n",
      "Epoch [722], train_loss: 0.0088, val_loss: 2.5608, val_acc: 0.6310\n",
      "Epoch [723], train_loss: 0.0019, val_loss: 3.1168, val_acc: 0.6209\n",
      "Epoch [724], train_loss: 0.0002, val_loss: 3.2491, val_acc: 0.6235\n",
      "Epoch [725], train_loss: 0.0001, val_loss: 3.3255, val_acc: 0.6235\n",
      "Epoch [726], train_loss: 0.0001, val_loss: 3.4628, val_acc: 0.6258\n",
      "Epoch [727], train_loss: 0.0001, val_loss: 3.5182, val_acc: 0.6235\n",
      "Epoch [728], train_loss: 0.0001, val_loss: 3.5002, val_acc: 0.6284\n",
      "Epoch [729], train_loss: 0.0001, val_loss: 3.5121, val_acc: 0.6258\n",
      "Epoch [730], train_loss: 0.0002, val_loss: 3.6351, val_acc: 0.6339\n",
      "Epoch [731], train_loss: 0.0001, val_loss: 3.7616, val_acc: 0.6150\n",
      "Epoch [732], train_loss: 0.0000, val_loss: 3.8196, val_acc: 0.6179\n",
      "Epoch [733], train_loss: 0.0000, val_loss: 3.7679, val_acc: 0.6206\n",
      "Epoch [734], train_loss: 0.0000, val_loss: 3.8503, val_acc: 0.6206\n",
      "Epoch [735], train_loss: 0.0000, val_loss: 3.8563, val_acc: 0.6232\n",
      "Epoch [736], train_loss: 0.0000, val_loss: 3.9217, val_acc: 0.6232\n",
      "Epoch [737], train_loss: 0.0000, val_loss: 3.9292, val_acc: 0.6098\n",
      "Epoch [738], train_loss: 0.0000, val_loss: 4.0020, val_acc: 0.6206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [739], train_loss: 0.0000, val_loss: 4.0573, val_acc: 0.6176\n",
      "Epoch [740], train_loss: 0.0000, val_loss: 4.0185, val_acc: 0.6124\n",
      "Epoch [741], train_loss: 0.0000, val_loss: 4.1100, val_acc: 0.6150\n",
      "Epoch [742], train_loss: 0.0000, val_loss: 3.9904, val_acc: 0.6098\n",
      "Epoch [743], train_loss: 0.0000, val_loss: 3.9741, val_acc: 0.6179\n",
      "Epoch [744], train_loss: 0.0023, val_loss: 5.6311, val_acc: 0.5991\n",
      "Epoch [745], train_loss: 0.0697, val_loss: 3.0302, val_acc: 0.5838\n",
      "Epoch [746], train_loss: 0.1129, val_loss: 2.1246, val_acc: 0.6228\n",
      "Epoch [747], train_loss: 0.0504, val_loss: 2.2392, val_acc: 0.5854\n",
      "Epoch [748], train_loss: 0.0463, val_loss: 2.9280, val_acc: 0.6098\n",
      "Epoch [749], train_loss: 0.0162, val_loss: 2.8942, val_acc: 0.6098\n",
      "Epoch [750], train_loss: 0.0038, val_loss: 2.7405, val_acc: 0.5910\n",
      "Epoch [751], train_loss: 0.0008, val_loss: 3.4505, val_acc: 0.6313\n",
      "Epoch [752], train_loss: 0.0011, val_loss: 3.8241, val_acc: 0.6098\n",
      "Epoch [753], train_loss: 0.0018, val_loss: 4.1521, val_acc: 0.6342\n",
      "Epoch [754], train_loss: 0.0012, val_loss: 4.5330, val_acc: 0.6290\n",
      "Epoch [755], train_loss: 0.0092, val_loss: 2.5877, val_acc: 0.6362\n",
      "Epoch [756], train_loss: 0.0393, val_loss: 2.7252, val_acc: 0.6017\n",
      "Epoch [757], train_loss: 0.0102, val_loss: 2.6720, val_acc: 0.6235\n",
      "Epoch [758], train_loss: 0.0082, val_loss: 2.9761, val_acc: 0.6310\n",
      "Epoch [759], train_loss: 0.0014, val_loss: 3.2778, val_acc: 0.6342\n",
      "Epoch [760], train_loss: 0.0005, val_loss: 3.1755, val_acc: 0.6183\n",
      "Epoch [761], train_loss: 0.0002, val_loss: 3.3228, val_acc: 0.6264\n",
      "Epoch [762], train_loss: 0.0001, val_loss: 3.3594, val_acc: 0.6235\n",
      "Epoch [763], train_loss: 0.0001, val_loss: 3.4090, val_acc: 0.6290\n",
      "Epoch [764], train_loss: 0.0001, val_loss: 3.5404, val_acc: 0.6264\n",
      "Epoch [765], train_loss: 0.0001, val_loss: 3.4331, val_acc: 0.6209\n",
      "Epoch [766], train_loss: 0.0000, val_loss: 3.4479, val_acc: 0.6313\n",
      "Epoch [767], train_loss: 0.0000, val_loss: 3.5307, val_acc: 0.6316\n",
      "Epoch [768], train_loss: 0.0001, val_loss: 3.5893, val_acc: 0.6209\n",
      "Epoch [769], train_loss: 0.0000, val_loss: 3.6153, val_acc: 0.6342\n",
      "Epoch [770], train_loss: 0.0000, val_loss: 3.5560, val_acc: 0.6290\n",
      "Epoch [771], train_loss: 0.0002, val_loss: 3.5983, val_acc: 0.6316\n",
      "Epoch [772], train_loss: 0.0004, val_loss: 3.7045, val_acc: 0.6183\n",
      "Epoch [773], train_loss: 0.0002, val_loss: 3.9299, val_acc: 0.6316\n",
      "Epoch [774], train_loss: 0.0001, val_loss: 3.8836, val_acc: 0.6183\n",
      "Epoch [775], train_loss: 0.0000, val_loss: 4.0178, val_acc: 0.6209\n",
      "Epoch [776], train_loss: 0.0000, val_loss: 3.9931, val_acc: 0.6261\n",
      "Epoch [777], train_loss: 0.0000, val_loss: 3.9694, val_acc: 0.6261\n",
      "Epoch [778], train_loss: 0.0000, val_loss: 3.9716, val_acc: 0.6423\n",
      "Epoch [779], train_loss: 0.0000, val_loss: 4.1659, val_acc: 0.6124\n",
      "Epoch [780], train_loss: 0.0000, val_loss: 4.0864, val_acc: 0.6124\n",
      "Epoch [781], train_loss: 0.0000, val_loss: 4.1025, val_acc: 0.6475\n",
      "Epoch [782], train_loss: 0.0000, val_loss: 4.0600, val_acc: 0.6449\n",
      "Epoch [783], train_loss: 0.0000, val_loss: 4.1657, val_acc: 0.6313\n",
      "Epoch [784], train_loss: 0.0000, val_loss: 4.1078, val_acc: 0.6313\n",
      "Epoch [785], train_loss: 0.0000, val_loss: 4.2693, val_acc: 0.6313\n",
      "Epoch [786], train_loss: 0.0000, val_loss: 4.2644, val_acc: 0.6287\n",
      "Epoch [787], train_loss: 0.0000, val_loss: 4.1211, val_acc: 0.6339\n",
      "Epoch [788], train_loss: 0.0000, val_loss: 4.2020, val_acc: 0.6287\n",
      "Epoch [789], train_loss: 0.0000, val_loss: 4.2095, val_acc: 0.6206\n",
      "Epoch [790], train_loss: 0.0000, val_loss: 4.2182, val_acc: 0.6232\n",
      "Epoch [791], train_loss: 0.0000, val_loss: 4.2790, val_acc: 0.6232\n",
      "Epoch [792], train_loss: 0.0000, val_loss: 4.3341, val_acc: 0.6098\n",
      "Epoch [793], train_loss: 0.0000, val_loss: 4.2719, val_acc: 0.6206\n",
      "Epoch [794], train_loss: 0.0000, val_loss: 4.1534, val_acc: 0.6261\n",
      "Epoch [795], train_loss: 0.0000, val_loss: 4.3635, val_acc: 0.6179\n",
      "Epoch [796], train_loss: 0.0000, val_loss: 4.3519, val_acc: 0.6206\n",
      "Epoch [797], train_loss: 0.0000, val_loss: 4.3478, val_acc: 0.6206\n",
      "Epoch [798], train_loss: 0.0000, val_loss: 4.3088, val_acc: 0.6046\n",
      "Epoch [799], train_loss: 0.0000, val_loss: 4.4924, val_acc: 0.6098\n",
      "Epoch [800], train_loss: 0.0000, val_loss: 4.4569, val_acc: 0.5991\n",
      "Epoch [801], train_loss: 0.0000, val_loss: 4.3301, val_acc: 0.6206\n",
      "Epoch [802], train_loss: 0.0000, val_loss: 4.3251, val_acc: 0.6179\n",
      "Epoch [803], train_loss: 0.0000, val_loss: 4.3156, val_acc: 0.6017\n",
      "Epoch [804], train_loss: 0.0000, val_loss: 4.3836, val_acc: 0.6124\n",
      "Epoch [805], train_loss: 0.0000, val_loss: 4.4656, val_acc: 0.6043\n",
      "Epoch [806], train_loss: 0.0000, val_loss: 4.2998, val_acc: 0.6098\n",
      "Epoch [807], train_loss: 0.0000, val_loss: 4.3809, val_acc: 0.6232\n",
      "Epoch [808], train_loss: 0.0000, val_loss: 4.3973, val_acc: 0.6179\n",
      "Epoch [809], train_loss: 0.0000, val_loss: 4.4160, val_acc: 0.6043\n",
      "Epoch [810], train_loss: 0.0000, val_loss: 4.5150, val_acc: 0.6153\n",
      "Epoch [811], train_loss: 0.0000, val_loss: 4.3508, val_acc: 0.6258\n",
      "Epoch [812], train_loss: 0.0000, val_loss: 4.4704, val_acc: 0.6261\n",
      "Epoch [813], train_loss: 0.0000, val_loss: 4.4391, val_acc: 0.6179\n",
      "Epoch [814], train_loss: 0.0000, val_loss: 4.4335, val_acc: 0.6179\n",
      "Epoch [815], train_loss: 0.0000, val_loss: 4.3520, val_acc: 0.6313\n",
      "Epoch [816], train_loss: 0.0000, val_loss: 4.4604, val_acc: 0.6202\n",
      "Epoch [817], train_loss: 0.0001, val_loss: 4.3162, val_acc: 0.6098\n",
      "Epoch [818], train_loss: 0.0000, val_loss: 4.3139, val_acc: 0.6153\n",
      "Epoch [819], train_loss: 0.0000, val_loss: 4.4256, val_acc: 0.6017\n",
      "Epoch [820], train_loss: 0.0000, val_loss: 4.4303, val_acc: 0.6235\n",
      "Epoch [821], train_loss: 0.0000, val_loss: 4.3419, val_acc: 0.6261\n",
      "Epoch [822], train_loss: 0.0000, val_loss: 4.4550, val_acc: 0.6098\n",
      "Epoch [823], train_loss: 0.0000, val_loss: 4.4408, val_acc: 0.6206\n",
      "Epoch [824], train_loss: 0.0000, val_loss: 4.4061, val_acc: 0.6258\n",
      "Epoch [825], train_loss: 0.0000, val_loss: 4.4928, val_acc: 0.6069\n",
      "Epoch [826], train_loss: 0.0000, val_loss: 4.5247, val_acc: 0.6127\n",
      "Epoch [827], train_loss: 0.0000, val_loss: 4.4510, val_acc: 0.6179\n",
      "Epoch [828], train_loss: 0.0000, val_loss: 4.4886, val_acc: 0.6043\n",
      "Epoch [829], train_loss: 0.0000, val_loss: 4.5296, val_acc: 0.6206\n",
      "Epoch [830], train_loss: 0.0000, val_loss: 4.4530, val_acc: 0.6365\n",
      "Epoch [831], train_loss: 0.0000, val_loss: 4.5551, val_acc: 0.6284\n",
      "Epoch [832], train_loss: 0.0000, val_loss: 4.5607, val_acc: 0.6150\n",
      "Epoch [833], train_loss: 0.0000, val_loss: 4.5736, val_acc: 0.6284\n",
      "Epoch [834], train_loss: 0.0000, val_loss: 4.5555, val_acc: 0.6098\n",
      "Epoch [835], train_loss: 0.0000, val_loss: 4.5679, val_acc: 0.6176\n",
      "Epoch [836], train_loss: 0.0000, val_loss: 4.6134, val_acc: 0.6176\n",
      "Epoch [837], train_loss: 0.0000, val_loss: 4.6125, val_acc: 0.6206\n",
      "Epoch [838], train_loss: 0.0000, val_loss: 4.5898, val_acc: 0.6179\n",
      "Epoch [839], train_loss: 0.0000, val_loss: 4.6667, val_acc: 0.6258\n",
      "Epoch [840], train_loss: 0.0000, val_loss: 4.5814, val_acc: 0.6235\n",
      "Epoch [841], train_loss: 0.0000, val_loss: 4.6322, val_acc: 0.6206\n",
      "Epoch [842], train_loss: 0.0000, val_loss: 4.6164, val_acc: 0.6420\n",
      "Epoch [843], train_loss: 0.0000, val_loss: 4.5940, val_acc: 0.6176\n",
      "Epoch [844], train_loss: 0.0000, val_loss: 4.6596, val_acc: 0.6232\n",
      "Epoch [845], train_loss: 0.0000, val_loss: 4.6177, val_acc: 0.6232\n",
      "Epoch [846], train_loss: 0.0000, val_loss: 4.6706, val_acc: 0.6072\n",
      "Epoch [847], train_loss: 0.0000, val_loss: 4.5901, val_acc: 0.6261\n",
      "Epoch [848], train_loss: 0.0000, val_loss: 4.6522, val_acc: 0.6313\n",
      "Epoch [849], train_loss: 0.0000, val_loss: 4.7613, val_acc: 0.6232\n",
      "Epoch [850], train_loss: 0.0000, val_loss: 4.6199, val_acc: 0.6098\n",
      "Epoch [851], train_loss: 0.0000, val_loss: 4.6812, val_acc: 0.6232\n",
      "Epoch [852], train_loss: 0.0000, val_loss: 4.5246, val_acc: 0.6232\n",
      "Epoch [853], train_loss: 0.0000, val_loss: 4.5994, val_acc: 0.6365\n",
      "Epoch [854], train_loss: 0.0000, val_loss: 4.7804, val_acc: 0.6284\n",
      "Epoch [855], train_loss: 0.0000, val_loss: 4.8227, val_acc: 0.6284\n",
      "Epoch [856], train_loss: 0.0000, val_loss: 4.5818, val_acc: 0.6150\n",
      "Epoch [857], train_loss: 0.0000, val_loss: 4.7301, val_acc: 0.6339\n",
      "Epoch [858], train_loss: 0.0000, val_loss: 4.7075, val_acc: 0.6206\n",
      "Epoch [859], train_loss: 0.0000, val_loss: 4.8616, val_acc: 0.6179\n",
      "Epoch [860], train_loss: 0.0000, val_loss: 4.7163, val_acc: 0.6232\n",
      "Epoch [861], train_loss: 0.0000, val_loss: 4.7666, val_acc: 0.6258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [862], train_loss: 0.0000, val_loss: 4.8153, val_acc: 0.6232\n",
      "Epoch [863], train_loss: 0.0000, val_loss: 4.7991, val_acc: 0.6261\n",
      "Epoch [864], train_loss: 0.0000, val_loss: 4.6913, val_acc: 0.6342\n",
      "Epoch [865], train_loss: 0.0000, val_loss: 4.6806, val_acc: 0.6313\n",
      "Epoch [866], train_loss: 0.0000, val_loss: 4.7787, val_acc: 0.6284\n",
      "Epoch [867], train_loss: 0.0000, val_loss: 4.7236, val_acc: 0.6206\n",
      "Epoch [868], train_loss: 0.0003, val_loss: 4.8140, val_acc: 0.6127\n",
      "Epoch [869], train_loss: 0.2391, val_loss: 1.1264, val_acc: 0.5646\n",
      "Epoch [870], train_loss: 0.1880, val_loss: 5.5308, val_acc: 0.5483\n",
      "Epoch [871], train_loss: 0.1492, val_loss: 1.9165, val_acc: 0.5779\n",
      "Epoch [872], train_loss: 0.0757, val_loss: 2.5225, val_acc: 0.6528\n",
      "Epoch [873], train_loss: 0.0448, val_loss: 2.7510, val_acc: 0.6206\n",
      "Epoch [874], train_loss: 0.1353, val_loss: 1.1025, val_acc: 0.6105\n",
      "Epoch [875], train_loss: 0.0617, val_loss: 2.2933, val_acc: 0.6176\n",
      "Epoch [876], train_loss: 0.0344, val_loss: 1.4071, val_acc: 0.6284\n",
      "Epoch [877], train_loss: 0.0233, val_loss: 2.4613, val_acc: 0.6153\n",
      "Epoch [878], train_loss: 0.0060, val_loss: 2.6332, val_acc: 0.6469\n",
      "Epoch [879], train_loss: 0.0076, val_loss: 2.8195, val_acc: 0.6176\n",
      "Epoch [880], train_loss: 0.0148, val_loss: 4.2494, val_acc: 0.6554\n",
      "Epoch [881], train_loss: 0.0321, val_loss: 2.0866, val_acc: 0.6443\n",
      "Epoch [882], train_loss: 0.0111, val_loss: 3.6635, val_acc: 0.5913\n",
      "Epoch [883], train_loss: 0.0084, val_loss: 3.0770, val_acc: 0.6287\n",
      "Epoch [884], train_loss: 0.0013, val_loss: 3.2544, val_acc: 0.6075\n",
      "Epoch [885], train_loss: 0.0003, val_loss: 3.5394, val_acc: 0.6235\n",
      "Epoch [886], train_loss: 0.0002, val_loss: 3.5325, val_acc: 0.6131\n",
      "Epoch [887], train_loss: 0.0001, val_loss: 3.7033, val_acc: 0.6105\n",
      "Epoch [888], train_loss: 0.0001, val_loss: 3.7036, val_acc: 0.6049\n",
      "Epoch [889], train_loss: 0.0001, val_loss: 3.7099, val_acc: 0.6105\n",
      "Epoch [890], train_loss: 0.0000, val_loss: 3.6708, val_acc: 0.6212\n",
      "Epoch [891], train_loss: 0.0001, val_loss: 3.7061, val_acc: 0.6157\n",
      "Epoch [892], train_loss: 0.0000, val_loss: 3.8220, val_acc: 0.6105\n",
      "Epoch [893], train_loss: 0.0000, val_loss: 3.8722, val_acc: 0.6105\n",
      "Epoch [894], train_loss: 0.0000, val_loss: 3.9231, val_acc: 0.6131\n",
      "Epoch [895], train_loss: 0.0000, val_loss: 3.9165, val_acc: 0.6079\n",
      "Epoch [896], train_loss: 0.0000, val_loss: 3.8847, val_acc: 0.6105\n",
      "Epoch [897], train_loss: 0.0000, val_loss: 4.0435, val_acc: 0.6131\n",
      "Epoch [898], train_loss: 0.0000, val_loss: 3.8635, val_acc: 0.6134\n",
      "Epoch [899], train_loss: 0.0000, val_loss: 3.9876, val_acc: 0.6131\n",
      "Epoch [900], train_loss: 0.0000, val_loss: 3.9292, val_acc: 0.6238\n",
      "Epoch [901], train_loss: 0.0007, val_loss: 4.0885, val_acc: 0.6183\n",
      "Epoch [902], train_loss: 0.0425, val_loss: 2.1050, val_acc: 0.6023\n",
      "Epoch [903], train_loss: 0.0258, val_loss: 4.1021, val_acc: 0.5857\n",
      "Epoch [904], train_loss: 0.0135, val_loss: 4.6545, val_acc: 0.6417\n",
      "Epoch [905], train_loss: 0.0099, val_loss: 3.4285, val_acc: 0.6179\n",
      "Epoch [906], train_loss: 0.0583, val_loss: 1.8543, val_acc: 0.5767\n",
      "Epoch [907], train_loss: 0.0451, val_loss: 1.7614, val_acc: 0.6147\n",
      "Epoch [908], train_loss: 0.0101, val_loss: 3.0986, val_acc: 0.5620\n",
      "Epoch [909], train_loss: 0.0023, val_loss: 3.2024, val_acc: 0.5831\n",
      "Epoch [910], train_loss: 0.0006, val_loss: 3.4047, val_acc: 0.5913\n",
      "Epoch [911], train_loss: 0.0005, val_loss: 3.2941, val_acc: 0.5802\n",
      "Epoch [912], train_loss: 0.0004, val_loss: 3.6387, val_acc: 0.6095\n",
      "Epoch [913], train_loss: 0.0001, val_loss: 3.7066, val_acc: 0.6121\n",
      "Epoch [914], train_loss: 0.0001, val_loss: 3.8602, val_acc: 0.6069\n",
      "Epoch [915], train_loss: 0.0000, val_loss: 3.7687, val_acc: 0.6069\n",
      "Epoch [916], train_loss: 0.0001, val_loss: 3.7979, val_acc: 0.6095\n",
      "Epoch [917], train_loss: 0.0000, val_loss: 3.9733, val_acc: 0.6147\n",
      "Epoch [918], train_loss: 0.0000, val_loss: 3.7710, val_acc: 0.6121\n",
      "Epoch [919], train_loss: 0.0000, val_loss: 4.0097, val_acc: 0.6121\n",
      "Epoch [920], train_loss: 0.0000, val_loss: 3.8495, val_acc: 0.6043\n",
      "Epoch [921], train_loss: 0.0047, val_loss: 3.7619, val_acc: 0.6124\n",
      "Epoch [922], train_loss: 0.0465, val_loss: 2.6066, val_acc: 0.5971\n",
      "Epoch [923], train_loss: 0.0609, val_loss: 2.7123, val_acc: 0.6095\n",
      "Epoch [924], train_loss: 0.0139, val_loss: 6.6870, val_acc: 0.5730\n",
      "Epoch [925], train_loss: 0.0088, val_loss: 4.9069, val_acc: 0.5968\n",
      "Epoch [926], train_loss: 0.0085, val_loss: 5.4173, val_acc: 0.5939\n",
      "Epoch [927], train_loss: 0.0458, val_loss: 3.3725, val_acc: 0.5994\n",
      "Epoch [928], train_loss: 0.0316, val_loss: 3.2723, val_acc: 0.6287\n",
      "Epoch [929], train_loss: 0.0043, val_loss: 3.6852, val_acc: 0.5916\n",
      "Epoch [930], train_loss: 0.0039, val_loss: 3.2446, val_acc: 0.6238\n",
      "Epoch [931], train_loss: 0.0163, val_loss: 4.3970, val_acc: 0.6105\n",
      "Epoch [932], train_loss: 0.0012, val_loss: 3.6353, val_acc: 0.6212\n",
      "Epoch [933], train_loss: 0.0003, val_loss: 3.8242, val_acc: 0.6131\n",
      "Epoch [934], train_loss: 0.0001, val_loss: 3.8969, val_acc: 0.6160\n",
      "Epoch [935], train_loss: 0.0002, val_loss: 4.1291, val_acc: 0.6079\n",
      "Epoch [936], train_loss: 0.0001, val_loss: 4.1099, val_acc: 0.6023\n",
      "Epoch [937], train_loss: 0.0001, val_loss: 4.1815, val_acc: 0.6023\n",
      "Epoch [938], train_loss: 0.0001, val_loss: 4.2687, val_acc: 0.6049\n",
      "Epoch [939], train_loss: 0.0000, val_loss: 4.2582, val_acc: 0.6131\n",
      "Epoch [940], train_loss: 0.0001, val_loss: 4.3444, val_acc: 0.6079\n",
      "Epoch [941], train_loss: 0.0000, val_loss: 4.2355, val_acc: 0.6079\n",
      "Epoch [942], train_loss: 0.0000, val_loss: 4.3895, val_acc: 0.6131\n",
      "Epoch [943], train_loss: 0.0000, val_loss: 4.4279, val_acc: 0.6023\n",
      "Epoch [944], train_loss: 0.0000, val_loss: 4.3578, val_acc: 0.6157\n",
      "Epoch [945], train_loss: 0.0000, val_loss: 4.5226, val_acc: 0.6079\n",
      "Epoch [946], train_loss: 0.0000, val_loss: 4.4554, val_acc: 0.6079\n",
      "Epoch [947], train_loss: 0.0000, val_loss: 4.5780, val_acc: 0.6183\n",
      "Epoch [948], train_loss: 0.0000, val_loss: 4.5629, val_acc: 0.6101\n",
      "Epoch [949], train_loss: 0.0000, val_loss: 4.7375, val_acc: 0.6105\n",
      "Epoch [950], train_loss: 0.0000, val_loss: 4.6856, val_acc: 0.6131\n",
      "Epoch [951], train_loss: 0.0000, val_loss: 4.6922, val_acc: 0.6075\n",
      "Epoch [952], train_loss: 0.0000, val_loss: 4.6123, val_acc: 0.6131\n",
      "Epoch [953], train_loss: 0.0000, val_loss: 4.6834, val_acc: 0.6183\n",
      "Epoch [954], train_loss: 0.0001, val_loss: 4.7434, val_acc: 0.6023\n",
      "Epoch [955], train_loss: 0.0000, val_loss: 4.7577, val_acc: 0.6026\n",
      "Epoch [956], train_loss: 0.0000, val_loss: 4.7085, val_acc: 0.6000\n",
      "Epoch [957], train_loss: 0.0000, val_loss: 4.8238, val_acc: 0.6052\n",
      "Epoch [958], train_loss: 0.0001, val_loss: 4.8051, val_acc: 0.6079\n",
      "Epoch [959], train_loss: 0.0000, val_loss: 4.9456, val_acc: 0.6020\n",
      "Epoch [960], train_loss: 0.0000, val_loss: 5.0581, val_acc: 0.5913\n",
      "Epoch [961], train_loss: 0.0000, val_loss: 5.1296, val_acc: 0.5965\n",
      "Epoch [962], train_loss: 0.0000, val_loss: 5.0531, val_acc: 0.6075\n",
      "Epoch [963], train_loss: 0.0000, val_loss: 4.9751, val_acc: 0.6049\n",
      "Epoch [964], train_loss: 0.0000, val_loss: 5.0062, val_acc: 0.5968\n",
      "Epoch [965], train_loss: 0.0000, val_loss: 5.1167, val_acc: 0.5994\n",
      "Epoch [966], train_loss: 0.0000, val_loss: 5.0677, val_acc: 0.6101\n",
      "Epoch [967], train_loss: 0.0000, val_loss: 5.0803, val_acc: 0.5994\n",
      "Epoch [968], train_loss: 0.0000, val_loss: 5.1236, val_acc: 0.5994\n",
      "Epoch [969], train_loss: 0.0000, val_loss: 4.9975, val_acc: 0.6023\n",
      "Epoch [970], train_loss: 0.0000, val_loss: 5.0789, val_acc: 0.6075\n",
      "Epoch [971], train_loss: 0.0000, val_loss: 5.1757, val_acc: 0.6020\n",
      "Epoch [972], train_loss: 0.0000, val_loss: 5.1491, val_acc: 0.6157\n",
      "Epoch [973], train_loss: 0.0000, val_loss: 5.1458, val_acc: 0.5997\n",
      "Epoch [974], train_loss: 0.0000, val_loss: 5.1206, val_acc: 0.6075\n",
      "Epoch [975], train_loss: 0.0000, val_loss: 5.2807, val_acc: 0.6020\n",
      "Epoch [976], train_loss: 0.0000, val_loss: 5.1158, val_acc: 0.5971\n",
      "Epoch [977], train_loss: 0.0000, val_loss: 5.2806, val_acc: 0.6049\n",
      "Epoch [978], train_loss: 0.0000, val_loss: 5.2289, val_acc: 0.6101\n",
      "Epoch [979], train_loss: 0.0000, val_loss: 5.1673, val_acc: 0.5968\n",
      "Epoch [980], train_loss: 0.0000, val_loss: 5.2635, val_acc: 0.6020\n",
      "Epoch [981], train_loss: 0.0000, val_loss: 5.2492, val_acc: 0.6049\n",
      "Epoch [982], train_loss: 0.0000, val_loss: 5.1824, val_acc: 0.6101\n",
      "Epoch [983], train_loss: 0.0000, val_loss: 5.2962, val_acc: 0.5997\n",
      "Epoch [984], train_loss: 0.0000, val_loss: 5.2220, val_acc: 0.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [985], train_loss: 0.0000, val_loss: 5.3557, val_acc: 0.6049\n",
      "Epoch [986], train_loss: 0.0000, val_loss: 5.3748, val_acc: 0.6052\n",
      "Epoch [987], train_loss: 0.0000, val_loss: 5.3144, val_acc: 0.6075\n",
      "Epoch [988], train_loss: 0.0000, val_loss: 5.2277, val_acc: 0.6075\n",
      "Epoch [989], train_loss: 0.0000, val_loss: 5.4076, val_acc: 0.6157\n",
      "Epoch [990], train_loss: 0.0000, val_loss: 5.5005, val_acc: 0.6049\n",
      "Epoch [991], train_loss: 0.0000, val_loss: 5.3161, val_acc: 0.6075\n",
      "Epoch [992], train_loss: 0.0000, val_loss: 5.4196, val_acc: 0.5971\n",
      "Epoch [993], train_loss: 0.0000, val_loss: 5.3777, val_acc: 0.5994\n",
      "Epoch [994], train_loss: 0.0000, val_loss: 5.4585, val_acc: 0.6049\n",
      "Epoch [995], train_loss: 0.0000, val_loss: 5.2581, val_acc: 0.6049\n",
      "Epoch [996], train_loss: 0.0000, val_loss: 5.4610, val_acc: 0.6157\n",
      "Epoch [997], train_loss: 0.0004, val_loss: 5.8270, val_acc: 0.6157\n",
      "Epoch [998], train_loss: 0.1513, val_loss: 1.7686, val_acc: 0.5838\n",
      "Epoch [999], train_loss: 0.0923, val_loss: 2.5897, val_acc: 0.5805\n",
      "Epoch [1000], train_loss: 0.0466, val_loss: 2.5490, val_acc: 0.5756\n",
      "Epoch [1001], train_loss: 0.0084, val_loss: 3.8675, val_acc: 0.6049\n",
      "Epoch [1002], train_loss: 0.0254, val_loss: 2.6298, val_acc: 0.6258\n",
      "Epoch [1003], train_loss: 0.0705, val_loss: 2.7052, val_acc: 0.5539\n",
      "Epoch [1004], train_loss: 0.0474, val_loss: 1.5491, val_acc: 0.6000\n",
      "Epoch [1005], train_loss: 0.0290, val_loss: 2.7243, val_acc: 0.5809\n",
      "Epoch [1006], train_loss: 0.0030, val_loss: 2.6250, val_acc: 0.6000\n",
      "Epoch [1007], train_loss: 0.0006, val_loss: 2.7381, val_acc: 0.5916\n",
      "Epoch [1008], train_loss: 0.0003, val_loss: 2.9843, val_acc: 0.5861\n",
      "Epoch [1009], train_loss: 0.0002, val_loss: 3.0072, val_acc: 0.5835\n",
      "Epoch [1010], train_loss: 0.0001, val_loss: 3.1225, val_acc: 0.5835\n",
      "Epoch [1011], train_loss: 0.0001, val_loss: 3.1507, val_acc: 0.5809\n",
      "Epoch [1012], train_loss: 0.0001, val_loss: 3.2281, val_acc: 0.5809\n",
      "Epoch [1013], train_loss: 0.0001, val_loss: 3.2214, val_acc: 0.5809\n",
      "Epoch [1014], train_loss: 0.0001, val_loss: 3.3048, val_acc: 0.5809\n",
      "Epoch [1015], train_loss: 0.0001, val_loss: 3.3018, val_acc: 0.5809\n",
      "Epoch [1016], train_loss: 0.0001, val_loss: 3.3797, val_acc: 0.5812\n",
      "Epoch [1017], train_loss: 0.0000, val_loss: 3.4317, val_acc: 0.5890\n",
      "Epoch [1018], train_loss: 0.0001, val_loss: 3.4618, val_acc: 0.5890\n",
      "Epoch [1019], train_loss: 0.0001, val_loss: 3.4730, val_acc: 0.5890\n",
      "Epoch [1020], train_loss: 0.0001, val_loss: 3.5550, val_acc: 0.5701\n",
      "Epoch [1021], train_loss: 0.0000, val_loss: 3.6052, val_acc: 0.5783\n",
      "Epoch [1022], train_loss: 0.0000, val_loss: 3.5911, val_acc: 0.5835\n",
      "Epoch [1023], train_loss: 0.0000, val_loss: 3.6961, val_acc: 0.5809\n",
      "Epoch [1024], train_loss: 0.0000, val_loss: 3.7431, val_acc: 0.5812\n",
      "Epoch [1025], train_loss: 0.0000, val_loss: 3.7218, val_acc: 0.5890\n",
      "Epoch [1026], train_loss: 0.0000, val_loss: 3.8075, val_acc: 0.5890\n",
      "Epoch [1027], train_loss: 0.0000, val_loss: 3.6866, val_acc: 0.5835\n",
      "Epoch [1028], train_loss: 0.0000, val_loss: 3.7829, val_acc: 0.5942\n",
      "Epoch [1029], train_loss: 0.0000, val_loss: 3.8628, val_acc: 0.5835\n",
      "Epoch [1030], train_loss: 0.0000, val_loss: 3.7430, val_acc: 0.5783\n",
      "Epoch [1031], train_loss: 0.0000, val_loss: 3.9250, val_acc: 0.5864\n",
      "Epoch [1032], train_loss: 0.0000, val_loss: 3.8657, val_acc: 0.5890\n",
      "Epoch [1033], train_loss: 0.0000, val_loss: 3.8803, val_acc: 0.5864\n",
      "Epoch [1034], train_loss: 0.0000, val_loss: 3.8285, val_acc: 0.5864\n",
      "Epoch [1035], train_loss: 0.0000, val_loss: 3.7982, val_acc: 0.5864\n",
      "Epoch [1036], train_loss: 0.0000, val_loss: 3.8659, val_acc: 0.5916\n",
      "Epoch [1037], train_loss: 0.0000, val_loss: 3.9072, val_acc: 0.5890\n",
      "Epoch [1038], train_loss: 0.0000, val_loss: 3.9718, val_acc: 0.5916\n",
      "Epoch [1039], train_loss: 0.0000, val_loss: 3.8791, val_acc: 0.5864\n",
      "Epoch [1040], train_loss: 0.0000, val_loss: 3.9321, val_acc: 0.5890\n",
      "Epoch [1041], train_loss: 0.0000, val_loss: 4.0326, val_acc: 0.5916\n",
      "Epoch [1042], train_loss: 0.0000, val_loss: 4.0680, val_acc: 0.5864\n",
      "Epoch [1043], train_loss: 0.0000, val_loss: 4.0951, val_acc: 0.5890\n",
      "Epoch [1044], train_loss: 0.0000, val_loss: 4.0630, val_acc: 0.5916\n",
      "Epoch [1045], train_loss: 0.0000, val_loss: 4.0453, val_acc: 0.5890\n",
      "Epoch [1046], train_loss: 0.0000, val_loss: 4.0965, val_acc: 0.5890\n",
      "Epoch [1047], train_loss: 0.0000, val_loss: 4.0312, val_acc: 0.5890\n",
      "Epoch [1048], train_loss: 0.0000, val_loss: 4.0753, val_acc: 0.5890\n",
      "Epoch [1049], train_loss: 0.0000, val_loss: 4.1069, val_acc: 0.5864\n",
      "Epoch [1050], train_loss: 0.0000, val_loss: 4.1542, val_acc: 0.5864\n",
      "Epoch [1051], train_loss: 0.0000, val_loss: 4.1121, val_acc: 0.5864\n",
      "Epoch [1052], train_loss: 0.0000, val_loss: 4.0769, val_acc: 0.5916\n",
      "Epoch [1053], train_loss: 0.0000, val_loss: 4.2183, val_acc: 0.5864\n",
      "Epoch [1054], train_loss: 0.0000, val_loss: 4.1880, val_acc: 0.5809\n",
      "Epoch [1055], train_loss: 0.0000, val_loss: 4.2620, val_acc: 0.5916\n",
      "Epoch [1056], train_loss: 0.0000, val_loss: 4.1185, val_acc: 0.5890\n",
      "Epoch [1057], train_loss: 0.0000, val_loss: 4.3129, val_acc: 0.5809\n",
      "Epoch [1058], train_loss: 0.0000, val_loss: 4.2324, val_acc: 0.5864\n",
      "Epoch [1059], train_loss: 0.0000, val_loss: 4.2389, val_acc: 0.5890\n",
      "Epoch [1060], train_loss: 0.0000, val_loss: 4.2394, val_acc: 0.5916\n",
      "Epoch [1061], train_loss: 0.0035, val_loss: 2.9845, val_acc: 0.6108\n",
      "Epoch [1062], train_loss: 0.1978, val_loss: 2.3334, val_acc: 0.5968\n",
      "Epoch [1063], train_loss: 0.0873, val_loss: 2.1974, val_acc: 0.5672\n",
      "Epoch [1064], train_loss: 0.0534, val_loss: 2.9285, val_acc: 0.5913\n",
      "Epoch [1065], train_loss: 0.0713, val_loss: 2.0738, val_acc: 0.5939\n",
      "Epoch [1066], train_loss: 0.0134, val_loss: 3.6497, val_acc: 0.5913\n",
      "Epoch [1067], train_loss: 0.1167, val_loss: 1.3501, val_acc: 0.5919\n",
      "Epoch [1068], train_loss: 0.0471, val_loss: 2.2737, val_acc: 0.5730\n",
      "Epoch [1069], train_loss: 0.0353, val_loss: 2.8472, val_acc: 0.6026\n",
      "Epoch [1070], train_loss: 0.0143, val_loss: 2.7669, val_acc: 0.6147\n",
      "Epoch [1071], train_loss: 0.0026, val_loss: 3.0329, val_acc: 0.5887\n",
      "Epoch [1072], train_loss: 0.0009, val_loss: 3.3028, val_acc: 0.6017\n",
      "Epoch [1073], train_loss: 0.0002, val_loss: 3.2946, val_acc: 0.5991\n",
      "Epoch [1074], train_loss: 0.0002, val_loss: 3.3045, val_acc: 0.5965\n",
      "Epoch [1075], train_loss: 0.0006, val_loss: 3.3902, val_acc: 0.5884\n",
      "Epoch [1076], train_loss: 0.0004, val_loss: 3.4617, val_acc: 0.5936\n",
      "Epoch [1077], train_loss: 0.0005, val_loss: 3.6416, val_acc: 0.5936\n",
      "Epoch [1078], train_loss: 0.0001, val_loss: 3.5998, val_acc: 0.5857\n",
      "Epoch [1079], train_loss: 0.0001, val_loss: 3.7230, val_acc: 0.5884\n",
      "Epoch [1080], train_loss: 0.0001, val_loss: 3.7609, val_acc: 0.5776\n",
      "Epoch [1081], train_loss: 0.0001, val_loss: 3.8128, val_acc: 0.5802\n",
      "Epoch [1082], train_loss: 0.0001, val_loss: 3.8619, val_acc: 0.5965\n",
      "Epoch [1083], train_loss: 0.0000, val_loss: 3.8366, val_acc: 0.5884\n",
      "Epoch [1084], train_loss: 0.0001, val_loss: 3.7922, val_acc: 0.5910\n",
      "Epoch [1085], train_loss: 0.0000, val_loss: 3.9073, val_acc: 0.5831\n",
      "Epoch [1086], train_loss: 0.0000, val_loss: 3.9555, val_acc: 0.5857\n",
      "Epoch [1087], train_loss: 0.0000, val_loss: 3.9639, val_acc: 0.5936\n",
      "Epoch [1088], train_loss: 0.0000, val_loss: 4.1101, val_acc: 0.5965\n",
      "Epoch [1089], train_loss: 0.0000, val_loss: 4.0561, val_acc: 0.5939\n",
      "Epoch [1090], train_loss: 0.0000, val_loss: 4.0636, val_acc: 0.5884\n",
      "Epoch [1091], train_loss: 0.0000, val_loss: 4.0284, val_acc: 0.5776\n",
      "Epoch [1092], train_loss: 0.0000, val_loss: 4.0357, val_acc: 0.5910\n",
      "Epoch [1093], train_loss: 0.0000, val_loss: 4.0976, val_acc: 0.5991\n",
      "Epoch [1094], train_loss: 0.0000, val_loss: 4.1707, val_acc: 0.5857\n",
      "Epoch [1095], train_loss: 0.0000, val_loss: 4.2624, val_acc: 0.5965\n",
      "Epoch [1096], train_loss: 0.0000, val_loss: 4.2727, val_acc: 0.5857\n",
      "Epoch [1097], train_loss: 0.0000, val_loss: 4.2842, val_acc: 0.5884\n",
      "Epoch [1098], train_loss: 0.0000, val_loss: 4.3138, val_acc: 0.5884\n",
      "Epoch [1099], train_loss: 0.0000, val_loss: 4.3231, val_acc: 0.5884\n",
      "Epoch [1100], train_loss: 0.0000, val_loss: 4.2268, val_acc: 0.5910\n",
      "Epoch [1101], train_loss: 0.0000, val_loss: 4.2890, val_acc: 0.5910\n",
      "Epoch [1102], train_loss: 0.0000, val_loss: 4.3151, val_acc: 0.5884\n",
      "Epoch [1103], train_loss: 0.0000, val_loss: 4.3983, val_acc: 0.5939\n",
      "Epoch [1104], train_loss: 0.0000, val_loss: 4.3784, val_acc: 0.5857\n",
      "Epoch [1105], train_loss: 0.0000, val_loss: 4.4427, val_acc: 0.5965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1106], train_loss: 0.0000, val_loss: 4.4433, val_acc: 0.5939\n",
      "Epoch [1107], train_loss: 0.0000, val_loss: 4.4737, val_acc: 0.5965\n",
      "Epoch [1108], train_loss: 0.0000, val_loss: 4.4851, val_acc: 0.5939\n",
      "Epoch [1109], train_loss: 0.0000, val_loss: 4.4556, val_acc: 0.5965\n",
      "Epoch [1110], train_loss: 0.0000, val_loss: 4.5088, val_acc: 0.5965\n",
      "Epoch [1111], train_loss: 0.0000, val_loss: 4.5019, val_acc: 0.5939\n",
      "Epoch [1112], train_loss: 0.0000, val_loss: 4.5037, val_acc: 0.5831\n",
      "Epoch [1113], train_loss: 0.0001, val_loss: 4.4923, val_acc: 0.5884\n",
      "Epoch [1114], train_loss: 0.0001, val_loss: 4.7034, val_acc: 0.5854\n",
      "Epoch [1115], train_loss: 0.0000, val_loss: 4.7100, val_acc: 0.5991\n",
      "Epoch [1116], train_loss: 0.0000, val_loss: 4.8681, val_acc: 0.5936\n",
      "Epoch [1117], train_loss: 0.0000, val_loss: 4.6689, val_acc: 0.5965\n",
      "Epoch [1118], train_loss: 0.0000, val_loss: 4.8355, val_acc: 0.5936\n",
      "Epoch [1119], train_loss: 0.0000, val_loss: 4.7747, val_acc: 0.5939\n",
      "Epoch [1120], train_loss: 0.0000, val_loss: 4.6754, val_acc: 0.5884\n",
      "Epoch [1121], train_loss: 0.0000, val_loss: 4.7788, val_acc: 0.5884\n",
      "Epoch [1122], train_loss: 0.0000, val_loss: 4.6741, val_acc: 0.6046\n",
      "Epoch [1123], train_loss: 0.0000, val_loss: 4.7691, val_acc: 0.5884\n",
      "Epoch [1124], train_loss: 0.0000, val_loss: 4.8547, val_acc: 0.5936\n",
      "Epoch [1125], train_loss: 0.0000, val_loss: 4.8085, val_acc: 0.5991\n",
      "Epoch [1126], train_loss: 0.0000, val_loss: 4.9549, val_acc: 0.5936\n",
      "Epoch [1127], train_loss: 0.0000, val_loss: 4.9245, val_acc: 0.5991\n",
      "Epoch [1128], train_loss: 0.0000, val_loss: 4.8483, val_acc: 0.5939\n",
      "Epoch [1129], train_loss: 0.0000, val_loss: 4.9061, val_acc: 0.5991\n",
      "Epoch [1130], train_loss: 0.0000, val_loss: 4.7874, val_acc: 0.5962\n",
      "Epoch [1131], train_loss: 0.0000, val_loss: 4.9978, val_acc: 0.6046\n",
      "Epoch [1132], train_loss: 0.0000, val_loss: 4.9480, val_acc: 0.5965\n",
      "Epoch [1133], train_loss: 0.0000, val_loss: 4.9216, val_acc: 0.6046\n",
      "Epoch [1134], train_loss: 0.0000, val_loss: 4.9346, val_acc: 0.6017\n",
      "Epoch [1135], train_loss: 0.0000, val_loss: 4.9380, val_acc: 0.6127\n",
      "Epoch [1136], train_loss: 0.0000, val_loss: 4.9002, val_acc: 0.6098\n",
      "Epoch [1137], train_loss: 0.0000, val_loss: 4.9672, val_acc: 0.6072\n",
      "Epoch [1138], train_loss: 0.0000, val_loss: 5.1144, val_acc: 0.5965\n",
      "Epoch [1139], train_loss: 0.0000, val_loss: 5.0436, val_acc: 0.6046\n",
      "Epoch [1140], train_loss: 0.0000, val_loss: 5.0203, val_acc: 0.6072\n",
      "Epoch [1141], train_loss: 0.0000, val_loss: 4.9666, val_acc: 0.5965\n",
      "Epoch [1142], train_loss: 0.0000, val_loss: 5.0749, val_acc: 0.6046\n",
      "Epoch [1143], train_loss: 0.0000, val_loss: 5.1603, val_acc: 0.5965\n",
      "Epoch [1144], train_loss: 0.0000, val_loss: 5.0146, val_acc: 0.6020\n",
      "Epoch [1145], train_loss: 0.0000, val_loss: 5.1328, val_acc: 0.5910\n",
      "Epoch [1146], train_loss: 0.0000, val_loss: 5.1749, val_acc: 0.5965\n",
      "Epoch [1147], train_loss: 0.0000, val_loss: 5.2837, val_acc: 0.5939\n",
      "Epoch [1148], train_loss: 0.0000, val_loss: 5.0875, val_acc: 0.5857\n",
      "Epoch [1149], train_loss: 0.0000, val_loss: 5.2069, val_acc: 0.5965\n",
      "Epoch [1150], train_loss: 0.0000, val_loss: 5.2143, val_acc: 0.6046\n",
      "Epoch [1151], train_loss: 0.0000, val_loss: 5.2247, val_acc: 0.5913\n",
      "Epoch [1152], train_loss: 0.0143, val_loss: 6.5879, val_acc: 0.6179\n",
      "Epoch [1153], train_loss: 0.2995, val_loss: 1.3773, val_acc: 0.5910\n",
      "Epoch [1154], train_loss: 0.0622, val_loss: 2.2154, val_acc: 0.6023\n",
      "Epoch [1155], train_loss: 0.0342, val_loss: 2.4256, val_acc: 0.5971\n",
      "Epoch [1156], train_loss: 0.0358, val_loss: 3.4032, val_acc: 0.6394\n",
      "Epoch [1157], train_loss: 0.0148, val_loss: 3.4242, val_acc: 0.5916\n",
      "Epoch [1158], train_loss: 0.0436, val_loss: 2.1403, val_acc: 0.6017\n",
      "Epoch [1159], train_loss: 0.0154, val_loss: 4.2182, val_acc: 0.5991\n",
      "Epoch [1160], train_loss: 0.0099, val_loss: 2.8576, val_acc: 0.5864\n",
      "Epoch [1161], train_loss: 0.0014, val_loss: 4.0077, val_acc: 0.5704\n",
      "Epoch [1162], train_loss: 0.0041, val_loss: 3.5744, val_acc: 0.6046\n",
      "Epoch [1163], train_loss: 0.0006, val_loss: 3.6617, val_acc: 0.5753\n",
      "Epoch [1164], train_loss: 0.0005, val_loss: 3.9677, val_acc: 0.5968\n",
      "Epoch [1165], train_loss: 0.0001, val_loss: 3.9496, val_acc: 0.5968\n",
      "Epoch [1166], train_loss: 0.0001, val_loss: 3.9909, val_acc: 0.5942\n",
      "Epoch [1167], train_loss: 0.0001, val_loss: 4.0116, val_acc: 0.5861\n",
      "Epoch [1168], train_loss: 0.0001, val_loss: 4.0112, val_acc: 0.5968\n",
      "Epoch [1169], train_loss: 0.0000, val_loss: 4.2547, val_acc: 0.5887\n",
      "Epoch [1170], train_loss: 0.0000, val_loss: 4.1568, val_acc: 0.5968\n",
      "Epoch [1171], train_loss: 0.0000, val_loss: 4.1930, val_acc: 0.5942\n",
      "Epoch [1172], train_loss: 0.0000, val_loss: 4.2275, val_acc: 0.5942\n",
      "Epoch [1173], train_loss: 0.0001, val_loss: 4.2305, val_acc: 0.5835\n",
      "Epoch [1174], train_loss: 0.0000, val_loss: 4.2343, val_acc: 0.5942\n",
      "Epoch [1175], train_loss: 0.0000, val_loss: 4.3166, val_acc: 0.5805\n",
      "Epoch [1176], train_loss: 0.0000, val_loss: 4.3842, val_acc: 0.5942\n",
      "Epoch [1177], train_loss: 0.0000, val_loss: 4.4057, val_acc: 0.5942\n",
      "Epoch [1178], train_loss: 0.0000, val_loss: 4.3715, val_acc: 0.5861\n",
      "Epoch [1179], train_loss: 0.0000, val_loss: 4.3440, val_acc: 0.5887\n",
      "Epoch [1180], train_loss: 0.0000, val_loss: 4.5187, val_acc: 0.5942\n",
      "Epoch [1181], train_loss: 0.0000, val_loss: 4.3966, val_acc: 0.5753\n",
      "Epoch [1182], train_loss: 0.0000, val_loss: 4.3811, val_acc: 0.5887\n",
      "Epoch [1183], train_loss: 0.0000, val_loss: 4.5049, val_acc: 0.5887\n",
      "Epoch [1184], train_loss: 0.0000, val_loss: 4.5842, val_acc: 0.5835\n",
      "Epoch [1185], train_loss: 0.0000, val_loss: 4.5621, val_acc: 0.5942\n",
      "Epoch [1186], train_loss: 0.0000, val_loss: 4.5436, val_acc: 0.5916\n",
      "Epoch [1187], train_loss: 0.0000, val_loss: 4.5831, val_acc: 0.5835\n",
      "Epoch [1188], train_loss: 0.0000, val_loss: 4.4427, val_acc: 0.5887\n",
      "Epoch [1189], train_loss: 0.0000, val_loss: 4.6339, val_acc: 0.5994\n",
      "Epoch [1190], train_loss: 0.0000, val_loss: 4.6405, val_acc: 0.5916\n",
      "Epoch [1191], train_loss: 0.0000, val_loss: 4.5998, val_acc: 0.5942\n",
      "Epoch [1192], train_loss: 0.0051, val_loss: 4.1763, val_acc: 0.6105\n",
      "Epoch [1193], train_loss: 0.0611, val_loss: 2.8043, val_acc: 0.5730\n",
      "Epoch [1194], train_loss: 0.0447, val_loss: 2.0521, val_acc: 0.5962\n",
      "Epoch [1195], train_loss: 0.0236, val_loss: 2.7211, val_acc: 0.6124\n",
      "Epoch [1196], train_loss: 0.0125, val_loss: 3.5579, val_acc: 0.6287\n",
      "Epoch [1197], train_loss: 0.0076, val_loss: 3.6686, val_acc: 0.6287\n",
      "Epoch [1198], train_loss: 0.0026, val_loss: 3.8671, val_acc: 0.6235\n",
      "Epoch [1199], train_loss: 0.0005, val_loss: 3.9350, val_acc: 0.6420\n",
      "Epoch [1200], train_loss: 0.0001, val_loss: 4.0896, val_acc: 0.6206\n",
      "Epoch [1201], train_loss: 0.0004, val_loss: 4.0048, val_acc: 0.6287\n",
      "Epoch [1202], train_loss: 0.0318, val_loss: 3.6681, val_acc: 0.5809\n",
      "Epoch [1203], train_loss: 0.0704, val_loss: 3.9900, val_acc: 0.5884\n",
      "Epoch [1204], train_loss: 0.0290, val_loss: 2.6724, val_acc: 0.6046\n",
      "Epoch [1205], train_loss: 0.0460, val_loss: 3.3371, val_acc: 0.5773\n",
      "Epoch [1206], train_loss: 0.0420, val_loss: 2.3065, val_acc: 0.5994\n",
      "Epoch [1207], train_loss: 0.0149, val_loss: 3.1610, val_acc: 0.6209\n",
      "Epoch [1208], train_loss: 0.0230, val_loss: 2.4380, val_acc: 0.6209\n",
      "Epoch [1209], train_loss: 0.0024, val_loss: 3.2860, val_acc: 0.6342\n",
      "Epoch [1210], train_loss: 0.0004, val_loss: 3.5732, val_acc: 0.6394\n",
      "Epoch [1211], train_loss: 0.0001, val_loss: 3.6907, val_acc: 0.6368\n",
      "Epoch [1212], train_loss: 0.0001, val_loss: 3.6467, val_acc: 0.6368\n",
      "Epoch [1213], train_loss: 0.0001, val_loss: 3.7096, val_acc: 0.6502\n",
      "Epoch [1214], train_loss: 0.0000, val_loss: 3.7425, val_acc: 0.6502\n",
      "Epoch [1215], train_loss: 0.0000, val_loss: 3.8444, val_acc: 0.6449\n",
      "Epoch [1216], train_loss: 0.0001, val_loss: 3.8547, val_acc: 0.6502\n",
      "Epoch [1217], train_loss: 0.0000, val_loss: 3.8259, val_acc: 0.6449\n",
      "Epoch [1218], train_loss: 0.0000, val_loss: 3.8788, val_acc: 0.6502\n",
      "Epoch [1219], train_loss: 0.0000, val_loss: 4.0237, val_acc: 0.6475\n",
      "Epoch [1220], train_loss: 0.0000, val_loss: 3.9265, val_acc: 0.6554\n",
      "Epoch [1221], train_loss: 0.0000, val_loss: 3.9827, val_acc: 0.6475\n",
      "Epoch [1222], train_loss: 0.0000, val_loss: 3.9210, val_acc: 0.6475\n",
      "Epoch [1223], train_loss: 0.0000, val_loss: 3.9910, val_acc: 0.6502\n",
      "Epoch [1224], train_loss: 0.0000, val_loss: 3.9054, val_acc: 0.6528\n",
      "Epoch [1225], train_loss: 0.0077, val_loss: 3.3785, val_acc: 0.6290\n",
      "Epoch [1226], train_loss: 0.1015, val_loss: 2.5949, val_acc: 0.6293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1227], train_loss: 0.0325, val_loss: 2.8391, val_acc: 0.6371\n",
      "Epoch [1228], train_loss: 0.0127, val_loss: 3.0928, val_acc: 0.6479\n",
      "Epoch [1229], train_loss: 0.0015, val_loss: 3.9355, val_acc: 0.6316\n",
      "Epoch [1230], train_loss: 0.0011, val_loss: 4.3341, val_acc: 0.6241\n",
      "Epoch [1231], train_loss: 0.0003, val_loss: 4.4226, val_acc: 0.6267\n",
      "Epoch [1232], train_loss: 0.0001, val_loss: 4.4766, val_acc: 0.6293\n",
      "Epoch [1233], train_loss: 0.0001, val_loss: 4.7561, val_acc: 0.6267\n",
      "Epoch [1234], train_loss: 0.0000, val_loss: 4.7221, val_acc: 0.6293\n",
      "Epoch [1235], train_loss: 0.0001, val_loss: 4.9328, val_acc: 0.6267\n",
      "Epoch [1236], train_loss: 0.0001, val_loss: 4.8740, val_acc: 0.6319\n",
      "Epoch [1237], train_loss: 0.0000, val_loss: 4.9220, val_acc: 0.6215\n",
      "Epoch [1238], train_loss: 0.0000, val_loss: 4.9835, val_acc: 0.6189\n",
      "Epoch [1239], train_loss: 0.0000, val_loss: 4.8980, val_acc: 0.6186\n",
      "Epoch [1240], train_loss: 0.0000, val_loss: 5.0230, val_acc: 0.6267\n",
      "Epoch [1241], train_loss: 0.0000, val_loss: 5.1862, val_acc: 0.6293\n",
      "Epoch [1242], train_loss: 0.0001, val_loss: 5.0120, val_acc: 0.6108\n",
      "Epoch [1243], train_loss: 0.0000, val_loss: 5.3512, val_acc: 0.6186\n",
      "Epoch [1244], train_loss: 0.0000, val_loss: 5.2465, val_acc: 0.6186\n",
      "Epoch [1245], train_loss: 0.0000, val_loss: 5.1092, val_acc: 0.6134\n",
      "Epoch [1246], train_loss: 0.0000, val_loss: 5.0772, val_acc: 0.6264\n",
      "Epoch [1247], train_loss: 0.0000, val_loss: 5.2308, val_acc: 0.6212\n",
      "Epoch [1248], train_loss: 0.0001, val_loss: 5.3691, val_acc: 0.6371\n",
      "Epoch [1249], train_loss: 0.0000, val_loss: 5.5611, val_acc: 0.6368\n",
      "Epoch [1250], train_loss: 0.0000, val_loss: 5.5658, val_acc: 0.6316\n",
      "Epoch [1251], train_loss: 0.0000, val_loss: 5.4477, val_acc: 0.6238\n",
      "Epoch [1252], train_loss: 0.0000, val_loss: 5.4811, val_acc: 0.6371\n",
      "Epoch [1253], train_loss: 0.0000, val_loss: 5.4176, val_acc: 0.6345\n",
      "Epoch [1254], train_loss: 0.0000, val_loss: 5.5183, val_acc: 0.6397\n",
      "Epoch [1255], train_loss: 0.0000, val_loss: 5.5854, val_acc: 0.6397\n",
      "Epoch [1256], train_loss: 0.0000, val_loss: 5.6412, val_acc: 0.6423\n",
      "Epoch [1257], train_loss: 0.0000, val_loss: 5.5080, val_acc: 0.6319\n",
      "Epoch [1258], train_loss: 0.0000, val_loss: 5.5830, val_acc: 0.6345\n",
      "Epoch [1259], train_loss: 0.0000, val_loss: 5.7413, val_acc: 0.6319\n",
      "Epoch [1260], train_loss: 0.0000, val_loss: 5.7434, val_acc: 0.6345\n",
      "Epoch [1261], train_loss: 0.0000, val_loss: 5.5643, val_acc: 0.6290\n",
      "Epoch [1262], train_loss: 0.0000, val_loss: 5.7013, val_acc: 0.6319\n",
      "Epoch [1263], train_loss: 0.0000, val_loss: 5.8762, val_acc: 0.6371\n",
      "Epoch [1264], train_loss: 0.0000, val_loss: 5.8548, val_acc: 0.6319\n",
      "Epoch [1265], train_loss: 0.0000, val_loss: 5.7193, val_acc: 0.6345\n",
      "Epoch [1266], train_loss: 0.0000, val_loss: 5.6015, val_acc: 0.6371\n",
      "Epoch [1267], train_loss: 0.0000, val_loss: 5.7165, val_acc: 0.6264\n",
      "Epoch [1268], train_loss: 0.0000, val_loss: 5.9686, val_acc: 0.6345\n",
      "Epoch [1269], train_loss: 0.0000, val_loss: 5.8899, val_acc: 0.6371\n",
      "Epoch [1270], train_loss: 0.0000, val_loss: 5.7321, val_acc: 0.6264\n",
      "Epoch [1271], train_loss: 0.0000, val_loss: 5.9359, val_acc: 0.6345\n",
      "Epoch [1272], train_loss: 0.0000, val_loss: 5.9437, val_acc: 0.6371\n",
      "Epoch [1273], train_loss: 0.0000, val_loss: 5.8685, val_acc: 0.6316\n",
      "Epoch [1274], train_loss: 0.0000, val_loss: 6.0111, val_acc: 0.6319\n",
      "Epoch [1275], train_loss: 0.0000, val_loss: 5.9875, val_acc: 0.6287\n",
      "Epoch [1276], train_loss: 0.0000, val_loss: 5.9944, val_acc: 0.6316\n",
      "Epoch [1277], train_loss: 0.0000, val_loss: 6.0553, val_acc: 0.6394\n",
      "Epoch [1278], train_loss: 0.0000, val_loss: 5.9427, val_acc: 0.6368\n",
      "Epoch [1279], train_loss: 0.0000, val_loss: 6.0411, val_acc: 0.6290\n",
      "Epoch [1280], train_loss: 0.0000, val_loss: 6.0519, val_acc: 0.6342\n",
      "Epoch [1281], train_loss: 0.0000, val_loss: 5.9478, val_acc: 0.6316\n",
      "Epoch [1282], train_loss: 0.0000, val_loss: 5.7994, val_acc: 0.6290\n",
      "Epoch [1283], train_loss: 0.0000, val_loss: 6.0191, val_acc: 0.6290\n",
      "Epoch [1284], train_loss: 0.0000, val_loss: 6.0126, val_acc: 0.6316\n",
      "Epoch [1285], train_loss: 0.0000, val_loss: 6.1369, val_acc: 0.6342\n",
      "Epoch [1286], train_loss: 0.0000, val_loss: 6.1872, val_acc: 0.6342\n",
      "Epoch [1287], train_loss: 0.0000, val_loss: 5.9478, val_acc: 0.6342\n",
      "Epoch [1288], train_loss: 0.0000, val_loss: 6.1376, val_acc: 0.6290\n",
      "Epoch [1289], train_loss: 0.0000, val_loss: 6.0766, val_acc: 0.6316\n",
      "Epoch [1290], train_loss: 0.0000, val_loss: 5.9980, val_acc: 0.6316\n",
      "Epoch [1291], train_loss: 0.0000, val_loss: 6.1037, val_acc: 0.6316\n",
      "Epoch [1292], train_loss: 0.0000, val_loss: 6.1729, val_acc: 0.6290\n",
      "Epoch [1293], train_loss: 0.0000, val_loss: 6.2340, val_acc: 0.6316\n",
      "Epoch [1294], train_loss: 0.0000, val_loss: 6.1269, val_acc: 0.6290\n",
      "Epoch [1295], train_loss: 0.0000, val_loss: 6.1249, val_acc: 0.6316\n",
      "Epoch [1296], train_loss: 0.0000, val_loss: 6.0942, val_acc: 0.6316\n",
      "Epoch [1297], train_loss: 0.0000, val_loss: 6.0944, val_acc: 0.6264\n",
      "Epoch [1298], train_loss: 0.0000, val_loss: 6.1321, val_acc: 0.6342\n",
      "Epoch [1299], train_loss: 0.0000, val_loss: 6.3580, val_acc: 0.6342\n",
      "Epoch [1300], train_loss: 0.0000, val_loss: 6.3393, val_acc: 0.6342\n",
      "Epoch [1301], train_loss: 0.0000, val_loss: 6.4152, val_acc: 0.6290\n",
      "Epoch [1302], train_loss: 0.0000, val_loss: 6.3119, val_acc: 0.6316\n",
      "Epoch [1303], train_loss: 0.0000, val_loss: 6.3088, val_acc: 0.6368\n",
      "Epoch [1304], train_loss: 0.0000, val_loss: 6.2756, val_acc: 0.6290\n",
      "Epoch [1305], train_loss: 0.0000, val_loss: 6.3123, val_acc: 0.6290\n",
      "Epoch [1306], train_loss: 0.0000, val_loss: 6.2915, val_acc: 0.6316\n",
      "Epoch [1307], train_loss: 0.0000, val_loss: 6.3975, val_acc: 0.6290\n",
      "Epoch [1308], train_loss: 0.0000, val_loss: 6.3489, val_acc: 0.6342\n",
      "Epoch [1309], train_loss: 0.0000, val_loss: 6.2969, val_acc: 0.6290\n",
      "Epoch [1310], train_loss: 0.0000, val_loss: 6.3340, val_acc: 0.6290\n",
      "Epoch [1311], train_loss: 0.0000, val_loss: 6.4025, val_acc: 0.6316\n",
      "Epoch [1312], train_loss: 0.0000, val_loss: 6.4557, val_acc: 0.6290\n",
      "Epoch [1313], train_loss: 0.0000, val_loss: 6.4733, val_acc: 0.6290\n",
      "Epoch [1314], train_loss: 0.0000, val_loss: 6.3158, val_acc: 0.6290\n",
      "Epoch [1315], train_loss: 0.0000, val_loss: 6.7413, val_acc: 0.6209\n",
      "Epoch [1316], train_loss: 0.0000, val_loss: 6.5491, val_acc: 0.6313\n",
      "Epoch [1317], train_loss: 0.0000, val_loss: 6.6328, val_acc: 0.6316\n",
      "Epoch [1318], train_loss: 0.0000, val_loss: 6.5835, val_acc: 0.6316\n",
      "Epoch [1319], train_loss: 0.0000, val_loss: 6.8318, val_acc: 0.6342\n",
      "Epoch [1320], train_loss: 0.0000, val_loss: 6.6543, val_acc: 0.6342\n",
      "Epoch [1321], train_loss: 0.0000, val_loss: 6.5432, val_acc: 0.6342\n",
      "Epoch [1322], train_loss: 0.0000, val_loss: 6.6265, val_acc: 0.6342\n",
      "Epoch [1323], train_loss: 0.0000, val_loss: 6.5162, val_acc: 0.6368\n",
      "Epoch [1324], train_loss: 0.0000, val_loss: 6.5565, val_acc: 0.6423\n",
      "Epoch [1325], train_loss: 0.0000, val_loss: 6.7032, val_acc: 0.6290\n",
      "Epoch [1326], train_loss: 0.0000, val_loss: 6.5997, val_acc: 0.6290\n",
      "Epoch [1327], train_loss: 0.0000, val_loss: 6.7946, val_acc: 0.6345\n",
      "Epoch [1328], train_loss: 0.0000, val_loss: 6.6504, val_acc: 0.6423\n",
      "Epoch [1329], train_loss: 0.0000, val_loss: 6.8995, val_acc: 0.6368\n",
      "Epoch [1330], train_loss: 0.0000, val_loss: 6.7460, val_acc: 0.6342\n",
      "Epoch [1331], train_loss: 0.0000, val_loss: 6.8758, val_acc: 0.6316\n",
      "Epoch [1332], train_loss: 0.0000, val_loss: 6.7957, val_acc: 0.6290\n",
      "Epoch [1333], train_loss: 0.0000, val_loss: 6.6838, val_acc: 0.6316\n",
      "Epoch [1334], train_loss: 0.0000, val_loss: 6.7583, val_acc: 0.6316\n",
      "Epoch [1335], train_loss: 0.0000, val_loss: 6.5099, val_acc: 0.6316\n",
      "Epoch [1336], train_loss: 0.0000, val_loss: 6.6186, val_acc: 0.6371\n",
      "Epoch [1337], train_loss: 0.0000, val_loss: 6.6836, val_acc: 0.6423\n",
      "Epoch [1338], train_loss: 0.0000, val_loss: 6.6483, val_acc: 0.6316\n",
      "Epoch [1339], train_loss: 0.0000, val_loss: 6.7471, val_acc: 0.6316\n",
      "Epoch [1340], train_loss: 0.0000, val_loss: 6.7864, val_acc: 0.6397\n",
      "Epoch [1341], train_loss: 0.0000, val_loss: 6.8306, val_acc: 0.6316\n",
      "Epoch [1342], train_loss: 0.0000, val_loss: 6.6870, val_acc: 0.6342\n",
      "Epoch [1343], train_loss: 0.0000, val_loss: 6.7759, val_acc: 0.6345\n",
      "Epoch [1344], train_loss: 0.0000, val_loss: 6.8565, val_acc: 0.6316\n",
      "Epoch [1345], train_loss: 0.0000, val_loss: 6.6869, val_acc: 0.6316\n",
      "Epoch [1346], train_loss: 0.0000, val_loss: 6.7234, val_acc: 0.6290\n",
      "Epoch [1347], train_loss: 0.0000, val_loss: 6.9234, val_acc: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1348], train_loss: 0.0000, val_loss: 6.7440, val_acc: 0.6397\n",
      "Epoch [1349], train_loss: 0.0000, val_loss: 6.8713, val_acc: 0.6290\n",
      "Epoch [1350], train_loss: 0.0000, val_loss: 7.1025, val_acc: 0.6423\n",
      "Epoch [1351], train_loss: 0.0000, val_loss: 6.6824, val_acc: 0.6423\n",
      "Epoch [1352], train_loss: 0.0000, val_loss: 6.8582, val_acc: 0.6290\n",
      "Epoch [1353], train_loss: 0.0000, val_loss: 6.9018, val_acc: 0.6423\n",
      "Epoch [1354], train_loss: 0.0000, val_loss: 6.9264, val_acc: 0.6423\n",
      "Epoch [1355], train_loss: 0.0000, val_loss: 6.7518, val_acc: 0.6345\n",
      "Epoch [1356], train_loss: 0.0000, val_loss: 7.0288, val_acc: 0.6397\n",
      "Epoch [1357], train_loss: 0.0000, val_loss: 6.9532, val_acc: 0.6371\n",
      "Epoch [1358], train_loss: 0.0000, val_loss: 6.8748, val_acc: 0.6449\n",
      "Epoch [1359], train_loss: 0.0000, val_loss: 6.9664, val_acc: 0.6342\n",
      "Epoch [1360], train_loss: 0.0000, val_loss: 6.8045, val_acc: 0.6423\n",
      "Epoch [1361], train_loss: 0.0000, val_loss: 7.0360, val_acc: 0.6449\n",
      "Epoch [1362], train_loss: 0.0000, val_loss: 6.9745, val_acc: 0.6371\n",
      "Epoch [1363], train_loss: 0.0000, val_loss: 7.0660, val_acc: 0.6316\n",
      "Epoch [1364], train_loss: 0.0000, val_loss: 6.8025, val_acc: 0.6371\n",
      "Epoch [1365], train_loss: 0.0000, val_loss: 6.9431, val_acc: 0.6316\n",
      "Epoch [1366], train_loss: 0.0000, val_loss: 7.0936, val_acc: 0.6371\n",
      "Epoch [1367], train_loss: 0.0000, val_loss: 7.1989, val_acc: 0.6423\n",
      "Epoch [1368], train_loss: 0.0000, val_loss: 7.0196, val_acc: 0.6397\n",
      "Epoch [1369], train_loss: 0.0000, val_loss: 7.0857, val_acc: 0.6316\n",
      "Epoch [1370], train_loss: 0.0000, val_loss: 6.9461, val_acc: 0.6397\n",
      "Epoch [1371], train_loss: 0.0000, val_loss: 7.0829, val_acc: 0.6423\n",
      "Epoch [1372], train_loss: 0.0000, val_loss: 7.1376, val_acc: 0.6423\n",
      "Epoch [1373], train_loss: 0.0000, val_loss: 6.9929, val_acc: 0.6290\n",
      "Epoch [1374], train_loss: 0.0000, val_loss: 7.2093, val_acc: 0.6371\n",
      "Epoch [1375], train_loss: 0.0000, val_loss: 7.2113, val_acc: 0.6475\n",
      "Epoch [1376], train_loss: 0.0000, val_loss: 7.0484, val_acc: 0.6342\n",
      "Epoch [1377], train_loss: 0.0000, val_loss: 7.1431, val_acc: 0.6371\n",
      "Epoch [1378], train_loss: 0.0000, val_loss: 7.1950, val_acc: 0.6397\n",
      "Epoch [1379], train_loss: 0.0000, val_loss: 7.3421, val_acc: 0.6316\n",
      "Epoch [1380], train_loss: 0.0000, val_loss: 7.2724, val_acc: 0.6342\n",
      "Epoch [1381], train_loss: 0.0000, val_loss: 7.2777, val_acc: 0.6316\n",
      "Epoch [1382], train_loss: 0.0000, val_loss: 7.2175, val_acc: 0.6423\n",
      "Epoch [1383], train_loss: 0.0000, val_loss: 7.2760, val_acc: 0.6371\n",
      "Epoch [1384], train_loss: 0.0000, val_loss: 7.1910, val_acc: 0.6475\n",
      "Epoch [1385], train_loss: 0.0000, val_loss: 7.1001, val_acc: 0.6397\n",
      "Epoch [1386], train_loss: 0.0000, val_loss: 7.2212, val_acc: 0.6371\n",
      "Epoch [1387], train_loss: 0.0000, val_loss: 7.1994, val_acc: 0.6316\n",
      "Epoch [1388], train_loss: 0.0000, val_loss: 7.3348, val_acc: 0.6316\n",
      "Epoch [1389], train_loss: 0.0000, val_loss: 7.2901, val_acc: 0.6397\n",
      "Epoch [1390], train_loss: 0.0000, val_loss: 7.1025, val_acc: 0.6397\n",
      "Epoch [1391], train_loss: 0.0000, val_loss: 7.3351, val_acc: 0.6342\n",
      "Epoch [1392], train_loss: 0.0000, val_loss: 7.4017, val_acc: 0.6397\n",
      "Epoch [1393], train_loss: 0.0000, val_loss: 7.3017, val_acc: 0.6264\n",
      "Epoch [1394], train_loss: 0.0000, val_loss: 7.2901, val_acc: 0.6423\n",
      "Epoch [1395], train_loss: 0.0000, val_loss: 7.2432, val_acc: 0.6371\n",
      "Epoch [1396], train_loss: 0.0000, val_loss: 7.3811, val_acc: 0.6475\n",
      "Epoch [1397], train_loss: 0.0000, val_loss: 7.3250, val_acc: 0.6371\n",
      "Epoch [1398], train_loss: 0.0000, val_loss: 7.0252, val_acc: 0.6423\n",
      "Epoch [1399], train_loss: 0.0000, val_loss: 7.1169, val_acc: 0.6397\n",
      "Epoch [1400], train_loss: 0.0000, val_loss: 7.3608, val_acc: 0.6345\n",
      "Epoch [1401], train_loss: 0.0000, val_loss: 7.3836, val_acc: 0.6397\n",
      "Epoch [1402], train_loss: 0.0000, val_loss: 7.4250, val_acc: 0.6342\n",
      "Epoch [1403], train_loss: 0.0000, val_loss: 7.5370, val_acc: 0.6261\n",
      "Epoch [1404], train_loss: 0.0000, val_loss: 7.4364, val_acc: 0.6371\n",
      "Epoch [1405], train_loss: 0.0137, val_loss: 7.7973, val_acc: 0.5939\n",
      "Epoch [1406], train_loss: 0.1991, val_loss: 2.7097, val_acc: 0.5574\n",
      "Epoch [1407], train_loss: 0.1004, val_loss: 2.1276, val_acc: 0.6056\n",
      "Epoch [1408], train_loss: 0.0397, val_loss: 2.7323, val_acc: 0.5649\n",
      "Epoch [1409], train_loss: 0.0092, val_loss: 2.9765, val_acc: 0.6287\n",
      "Epoch [1410], train_loss: 0.0276, val_loss: 2.9767, val_acc: 0.5997\n",
      "Epoch [1411], train_loss: 0.0329, val_loss: 2.9650, val_acc: 0.6131\n",
      "Epoch [1412], train_loss: 0.0081, val_loss: 3.7223, val_acc: 0.6020\n",
      "Epoch [1413], train_loss: 0.0116, val_loss: 3.0394, val_acc: 0.6319\n",
      "Epoch [1414], train_loss: 0.0038, val_loss: 3.7382, val_acc: 0.5835\n",
      "Epoch [1415], train_loss: 0.0171, val_loss: 3.0436, val_acc: 0.6026\n",
      "Epoch [1416], train_loss: 0.1309, val_loss: 1.9865, val_acc: 0.6215\n",
      "Epoch [1417], train_loss: 0.0256, val_loss: 2.2363, val_acc: 0.6049\n",
      "Epoch [1418], train_loss: 0.0037, val_loss: 2.8569, val_acc: 0.6475\n",
      "Epoch [1419], train_loss: 0.0010, val_loss: 3.2421, val_acc: 0.6261\n",
      "Epoch [1420], train_loss: 0.0004, val_loss: 3.3306, val_acc: 0.6449\n",
      "Epoch [1421], train_loss: 0.0002, val_loss: 3.5176, val_acc: 0.6475\n",
      "Epoch [1422], train_loss: 0.0002, val_loss: 3.5916, val_acc: 0.6475\n",
      "Epoch [1423], train_loss: 0.0001, val_loss: 3.6267, val_acc: 0.6368\n",
      "Epoch [1424], train_loss: 0.0001, val_loss: 3.6930, val_acc: 0.6423\n",
      "Epoch [1425], train_loss: 0.0001, val_loss: 3.5822, val_acc: 0.6342\n",
      "Epoch [1426], train_loss: 0.0003, val_loss: 3.8490, val_acc: 0.6475\n",
      "Epoch [1427], train_loss: 0.0003, val_loss: 3.7607, val_acc: 0.6397\n",
      "Epoch [1428], train_loss: 0.0002, val_loss: 3.6982, val_acc: 0.6397\n",
      "Epoch [1429], train_loss: 0.0001, val_loss: 3.9729, val_acc: 0.6479\n",
      "Epoch [1430], train_loss: 0.0001, val_loss: 3.8286, val_acc: 0.6528\n",
      "Epoch [1431], train_loss: 0.0001, val_loss: 4.0668, val_acc: 0.6528\n",
      "Epoch [1432], train_loss: 0.0001, val_loss: 3.9443, val_acc: 0.6528\n",
      "Epoch [1433], train_loss: 0.0001, val_loss: 4.0648, val_acc: 0.6505\n",
      "Epoch [1434], train_loss: 0.0000, val_loss: 4.1503, val_acc: 0.6505\n",
      "Epoch [1435], train_loss: 0.0000, val_loss: 4.1204, val_acc: 0.6505\n",
      "Epoch [1436], train_loss: 0.0001, val_loss: 4.1221, val_acc: 0.6531\n",
      "Epoch [1437], train_loss: 0.0000, val_loss: 4.2057, val_acc: 0.6505\n",
      "Epoch [1438], train_loss: 0.0000, val_loss: 4.1085, val_acc: 0.6345\n",
      "Epoch [1439], train_loss: 0.0000, val_loss: 4.1284, val_acc: 0.6423\n",
      "Epoch [1440], train_loss: 0.0000, val_loss: 4.1173, val_acc: 0.6449\n",
      "Epoch [1441], train_loss: 0.0000, val_loss: 4.2704, val_acc: 0.6449\n",
      "Epoch [1442], train_loss: 0.0000, val_loss: 4.3457, val_acc: 0.6449\n",
      "Epoch [1443], train_loss: 0.0000, val_loss: 4.2794, val_acc: 0.6475\n",
      "Epoch [1444], train_loss: 0.0000, val_loss: 4.2286, val_acc: 0.6449\n",
      "Epoch [1445], train_loss: 0.0000, val_loss: 4.3672, val_acc: 0.6479\n",
      "Epoch [1446], train_loss: 0.0000, val_loss: 4.3284, val_acc: 0.6449\n",
      "Epoch [1447], train_loss: 0.0020, val_loss: 6.7288, val_acc: 0.6153\n",
      "Epoch [1448], train_loss: 0.0263, val_loss: 2.8009, val_acc: 0.6127\n",
      "Epoch [1449], train_loss: 0.0009, val_loss: 3.0299, val_acc: 0.6212\n",
      "Epoch [1450], train_loss: 0.0005, val_loss: 3.2110, val_acc: 0.6238\n",
      "Epoch [1451], train_loss: 0.0002, val_loss: 3.3615, val_acc: 0.6345\n",
      "Epoch [1452], train_loss: 0.0001, val_loss: 3.3913, val_acc: 0.6345\n",
      "Epoch [1453], train_loss: 0.0001, val_loss: 3.4848, val_acc: 0.6345\n",
      "Epoch [1454], train_loss: 0.0002, val_loss: 3.4821, val_acc: 0.6290\n",
      "Epoch [1455], train_loss: 0.0001, val_loss: 3.6249, val_acc: 0.6238\n",
      "Epoch [1456], train_loss: 0.0001, val_loss: 3.7112, val_acc: 0.6319\n",
      "Epoch [1457], train_loss: 0.0001, val_loss: 3.7690, val_acc: 0.6397\n",
      "Epoch [1458], train_loss: 0.0000, val_loss: 3.7056, val_acc: 0.6212\n",
      "Epoch [1459], train_loss: 0.0000, val_loss: 3.8447, val_acc: 0.6319\n",
      "Epoch [1460], train_loss: 0.0003, val_loss: 3.7597, val_acc: 0.6319\n",
      "Epoch [1461], train_loss: 0.0136, val_loss: 3.6646, val_acc: 0.6209\n",
      "Epoch [1462], train_loss: 0.0290, val_loss: 2.7098, val_acc: 0.6183\n",
      "Epoch [1463], train_loss: 0.0021, val_loss: 2.8440, val_acc: 0.6316\n",
      "Epoch [1464], train_loss: 0.0005, val_loss: 3.1269, val_acc: 0.6235\n",
      "Epoch [1465], train_loss: 0.0002, val_loss: 3.2965, val_acc: 0.6235\n",
      "Epoch [1466], train_loss: 0.0001, val_loss: 3.3678, val_acc: 0.6423\n",
      "Epoch [1467], train_loss: 0.0001, val_loss: 3.4130, val_acc: 0.6313\n",
      "Epoch [1468], train_loss: 0.0001, val_loss: 3.4554, val_acc: 0.6368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1469], train_loss: 0.0001, val_loss: 3.5653, val_acc: 0.6316\n",
      "Epoch [1470], train_loss: 0.0001, val_loss: 3.6781, val_acc: 0.6423\n",
      "Epoch [1471], train_loss: 0.0001, val_loss: 3.6434, val_acc: 0.6342\n",
      "Epoch [1472], train_loss: 0.0000, val_loss: 3.7715, val_acc: 0.6449\n",
      "Epoch [1473], train_loss: 0.0000, val_loss: 3.7088, val_acc: 0.6394\n",
      "Epoch [1474], train_loss: 0.0000, val_loss: 3.7906, val_acc: 0.6368\n",
      "Epoch [1475], train_loss: 0.0000, val_loss: 3.7802, val_acc: 0.6423\n",
      "Epoch [1476], train_loss: 0.0000, val_loss: 3.8584, val_acc: 0.6261\n",
      "Epoch [1477], train_loss: 0.0000, val_loss: 3.8901, val_acc: 0.6368\n",
      "Epoch [1478], train_loss: 0.0000, val_loss: 3.8864, val_acc: 0.6342\n",
      "Epoch [1479], train_loss: 0.0000, val_loss: 3.8910, val_acc: 0.6261\n",
      "Epoch [1480], train_loss: 0.0000, val_loss: 3.9665, val_acc: 0.6368\n",
      "Epoch [1481], train_loss: 0.0026, val_loss: 3.9154, val_acc: 0.6212\n",
      "Epoch [1482], train_loss: 0.0667, val_loss: 1.9236, val_acc: 0.6212\n",
      "Epoch [1483], train_loss: 0.0464, val_loss: 3.4183, val_acc: 0.6134\n",
      "Epoch [1484], train_loss: 0.0186, val_loss: 3.8434, val_acc: 0.5727\n",
      "Epoch [1485], train_loss: 0.0128, val_loss: 3.5905, val_acc: 0.6075\n",
      "Epoch [1486], train_loss: 0.0233, val_loss: 2.4688, val_acc: 0.5942\n",
      "Epoch [1487], train_loss: 0.0158, val_loss: 4.7100, val_acc: 0.6072\n",
      "Epoch [1488], train_loss: 0.0361, val_loss: 3.3090, val_acc: 0.6020\n",
      "Epoch [1489], train_loss: 0.0192, val_loss: 3.5997, val_acc: 0.6134\n",
      "Epoch [1490], train_loss: 0.0488, val_loss: 3.3809, val_acc: 0.5786\n",
      "Epoch [1491], train_loss: 0.0124, val_loss: 5.4150, val_acc: 0.5864\n",
      "Epoch [1492], train_loss: 0.1606, val_loss: 1.6741, val_acc: 0.5997\n",
      "Epoch [1493], train_loss: 0.0649, val_loss: 3.9217, val_acc: 0.5763\n",
      "Epoch [1494], train_loss: 0.0406, val_loss: 3.6908, val_acc: 0.6186\n",
      "Epoch [1495], train_loss: 0.0119, val_loss: 4.7811, val_acc: 0.5838\n",
      "Epoch [1496], train_loss: 0.0023, val_loss: 5.4146, val_acc: 0.5945\n",
      "Epoch [1497], train_loss: 0.0005, val_loss: 5.7686, val_acc: 0.5922\n",
      "Epoch [1498], train_loss: 0.0002, val_loss: 6.3111, val_acc: 0.5974\n",
      "Epoch [1499], train_loss: 0.0001, val_loss: 6.1415, val_acc: 0.6000\n",
      "Epoch [1500], train_loss: 0.0001, val_loss: 6.4101, val_acc: 0.6000\n",
      "Epoch [1501], train_loss: 0.0001, val_loss: 6.5885, val_acc: 0.5974\n",
      "Epoch [1502], train_loss: 0.0001, val_loss: 6.7273, val_acc: 0.5893\n",
      "Epoch [1503], train_loss: 0.0001, val_loss: 6.5222, val_acc: 0.5974\n",
      "Epoch [1504], train_loss: 0.0001, val_loss: 6.9746, val_acc: 0.5919\n",
      "Epoch [1505], train_loss: 0.0000, val_loss: 6.9522, val_acc: 0.5945\n",
      "Epoch [1506], train_loss: 0.0000, val_loss: 7.1493, val_acc: 0.5945\n",
      "Epoch [1507], train_loss: 0.0412, val_loss: 9.0968, val_acc: 0.5893\n",
      "Epoch [1508], train_loss: 0.1502, val_loss: 1.3728, val_acc: 0.5786\n",
      "Epoch [1509], train_loss: 0.0568, val_loss: 3.3156, val_acc: 0.5623\n",
      "Epoch [1510], train_loss: 0.0120, val_loss: 3.4858, val_acc: 0.5786\n",
      "Epoch [1511], train_loss: 0.0108, val_loss: 3.9615, val_acc: 0.5997\n",
      "Epoch [1512], train_loss: 0.0062, val_loss: 3.9344, val_acc: 0.6079\n",
      "Epoch [1513], train_loss: 0.0024, val_loss: 5.0840, val_acc: 0.6108\n",
      "Epoch [1514], train_loss: 0.0018, val_loss: 5.2560, val_acc: 0.6131\n",
      "Epoch [1515], train_loss: 0.0011, val_loss: 4.6786, val_acc: 0.5994\n",
      "Epoch [1516], train_loss: 0.0063, val_loss: 4.1609, val_acc: 0.6157\n",
      "Epoch [1517], train_loss: 0.0044, val_loss: 3.6817, val_acc: 0.6160\n",
      "Epoch [1518], train_loss: 0.0016, val_loss: 4.6717, val_acc: 0.6049\n",
      "Epoch [1519], train_loss: 0.0012, val_loss: 4.9547, val_acc: 0.6183\n",
      "Epoch [1520], train_loss: 0.0074, val_loss: 4.0923, val_acc: 0.6134\n",
      "Epoch [1521], train_loss: 0.0420, val_loss: 4.2266, val_acc: 0.6186\n",
      "Epoch [1522], train_loss: 0.0029, val_loss: 3.3853, val_acc: 0.6079\n",
      "Epoch [1523], train_loss: 0.0007, val_loss: 3.4630, val_acc: 0.6131\n",
      "Epoch [1524], train_loss: 0.0002, val_loss: 3.6042, val_acc: 0.6131\n",
      "Epoch [1525], train_loss: 0.0001, val_loss: 3.6319, val_acc: 0.6212\n",
      "Epoch [1526], train_loss: 0.0001, val_loss: 3.7906, val_acc: 0.6131\n",
      "Epoch [1527], train_loss: 0.0001, val_loss: 3.9941, val_acc: 0.6157\n",
      "Epoch [1528], train_loss: 0.0003, val_loss: 3.9365, val_acc: 0.5831\n",
      "Epoch [1529], train_loss: 0.0003, val_loss: 4.4350, val_acc: 0.6131\n",
      "Epoch [1530], train_loss: 0.0001, val_loss: 4.5580, val_acc: 0.6186\n",
      "Epoch [1531], train_loss: 0.0001, val_loss: 4.5098, val_acc: 0.6186\n",
      "Epoch [1532], train_loss: 0.0001, val_loss: 4.5684, val_acc: 0.6049\n",
      "Epoch [1533], train_loss: 0.0000, val_loss: 4.5282, val_acc: 0.6079\n",
      "Epoch [1534], train_loss: 0.0000, val_loss: 4.5446, val_acc: 0.6049\n",
      "Epoch [1535], train_loss: 0.0000, val_loss: 4.5665, val_acc: 0.6079\n",
      "Epoch [1536], train_loss: 0.0000, val_loss: 4.5170, val_acc: 0.6157\n",
      "Epoch [1537], train_loss: 0.0000, val_loss: 4.6814, val_acc: 0.6075\n",
      "Epoch [1538], train_loss: 0.0000, val_loss: 4.6688, val_acc: 0.6183\n",
      "Epoch [1539], train_loss: 0.0000, val_loss: 4.7791, val_acc: 0.6153\n",
      "Epoch [1540], train_loss: 0.0000, val_loss: 4.6717, val_acc: 0.6131\n",
      "Epoch [1541], train_loss: 0.0001, val_loss: 4.8669, val_acc: 0.6131\n",
      "Epoch [1542], train_loss: 0.0000, val_loss: 4.8451, val_acc: 0.6049\n",
      "Epoch [1543], train_loss: 0.0000, val_loss: 4.9725, val_acc: 0.6183\n",
      "Epoch [1544], train_loss: 0.0000, val_loss: 4.8461, val_acc: 0.6049\n",
      "Epoch [1545], train_loss: 0.0000, val_loss: 5.0139, val_acc: 0.6023\n",
      "Epoch [1546], train_loss: 0.0230, val_loss: 7.1245, val_acc: 0.6322\n",
      "Epoch [1547], train_loss: 0.1240, val_loss: 2.1166, val_acc: 0.5939\n",
      "Epoch [1548], train_loss: 0.0794, val_loss: 1.5931, val_acc: 0.5965\n",
      "Epoch [1549], train_loss: 0.0939, val_loss: 3.2801, val_acc: 0.5568\n",
      "Epoch [1550], train_loss: 0.0830, val_loss: 1.6492, val_acc: 0.6287\n",
      "Epoch [1551], train_loss: 0.0106, val_loss: 2.3326, val_acc: 0.6206\n",
      "Epoch [1552], train_loss: 0.0029, val_loss: 2.8317, val_acc: 0.6258\n",
      "Epoch [1553], train_loss: 0.0006, val_loss: 2.9647, val_acc: 0.6313\n",
      "Epoch [1554], train_loss: 0.0006, val_loss: 3.1074, val_acc: 0.6209\n",
      "Epoch [1555], train_loss: 0.0003, val_loss: 3.3461, val_acc: 0.6153\n",
      "Epoch [1556], train_loss: 0.0002, val_loss: 3.3574, val_acc: 0.6235\n",
      "Epoch [1557], train_loss: 0.0002, val_loss: 3.4758, val_acc: 0.6313\n",
      "Epoch [1558], train_loss: 0.0002, val_loss: 3.4631, val_acc: 0.6261\n",
      "Epoch [1559], train_loss: 0.0001, val_loss: 3.5203, val_acc: 0.6261\n",
      "Epoch [1560], train_loss: 0.0001, val_loss: 3.6747, val_acc: 0.6232\n",
      "Epoch [1561], train_loss: 0.0001, val_loss: 3.6946, val_acc: 0.6313\n",
      "Epoch [1562], train_loss: 0.0001, val_loss: 3.7149, val_acc: 0.6287\n",
      "Epoch [1563], train_loss: 0.0000, val_loss: 3.8050, val_acc: 0.6313\n",
      "Epoch [1564], train_loss: 0.0001, val_loss: 3.7943, val_acc: 0.6287\n",
      "Epoch [1565], train_loss: 0.0001, val_loss: 3.9162, val_acc: 0.6287\n",
      "Epoch [1566], train_loss: 0.0000, val_loss: 3.9663, val_acc: 0.6287\n",
      "Epoch [1567], train_loss: 0.0000, val_loss: 3.9431, val_acc: 0.6287\n",
      "Epoch [1568], train_loss: 0.0000, val_loss: 3.8745, val_acc: 0.6287\n",
      "Epoch [1569], train_loss: 0.0000, val_loss: 3.9700, val_acc: 0.6313\n",
      "Epoch [1570], train_loss: 0.0001, val_loss: 4.0443, val_acc: 0.6287\n",
      "Epoch [1571], train_loss: 0.0000, val_loss: 4.2799, val_acc: 0.6313\n",
      "Epoch [1572], train_loss: 0.0000, val_loss: 4.1929, val_acc: 0.6261\n",
      "Epoch [1573], train_loss: 0.0000, val_loss: 4.3050, val_acc: 0.6365\n",
      "Epoch [1574], train_loss: 0.0000, val_loss: 4.2317, val_acc: 0.6287\n",
      "Epoch [1575], train_loss: 0.0001, val_loss: 4.2991, val_acc: 0.6365\n",
      "Epoch [1576], train_loss: 0.0001, val_loss: 4.2977, val_acc: 0.6261\n",
      "Epoch [1577], train_loss: 0.0000, val_loss: 4.1594, val_acc: 0.6287\n",
      "Epoch [1578], train_loss: 0.0000, val_loss: 4.3731, val_acc: 0.6235\n",
      "Epoch [1579], train_loss: 0.0000, val_loss: 4.4069, val_acc: 0.6287\n",
      "Epoch [1580], train_loss: 0.0001, val_loss: 4.3555, val_acc: 0.6206\n",
      "Epoch [1581], train_loss: 0.0001, val_loss: 4.4835, val_acc: 0.6101\n",
      "Epoch [1582], train_loss: 0.0000, val_loss: 4.6666, val_acc: 0.6209\n",
      "Epoch [1583], train_loss: 0.0000, val_loss: 4.5880, val_acc: 0.6179\n",
      "Epoch [1584], train_loss: 0.0001, val_loss: 4.6521, val_acc: 0.6232\n",
      "Epoch [1585], train_loss: 0.0000, val_loss: 4.6211, val_acc: 0.6258\n",
      "Epoch [1586], train_loss: 0.0000, val_loss: 4.7737, val_acc: 0.6258\n",
      "Epoch [1587], train_loss: 0.0000, val_loss: 4.8397, val_acc: 0.6206\n",
      "Epoch [1588], train_loss: 0.0000, val_loss: 4.7000, val_acc: 0.6417\n",
      "Epoch [1589], train_loss: 0.0000, val_loss: 4.6863, val_acc: 0.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1590], train_loss: 0.0000, val_loss: 4.7040, val_acc: 0.6339\n",
      "Epoch [1591], train_loss: 0.0000, val_loss: 4.8937, val_acc: 0.6232\n",
      "Epoch [1592], train_loss: 0.0000, val_loss: 4.7314, val_acc: 0.6365\n",
      "Epoch [1593], train_loss: 0.0000, val_loss: 4.9158, val_acc: 0.6258\n",
      "Epoch [1594], train_loss: 0.0000, val_loss: 4.8461, val_acc: 0.6232\n",
      "Epoch [1595], train_loss: 0.0000, val_loss: 4.8642, val_acc: 0.6258\n",
      "Epoch [1596], train_loss: 0.0000, val_loss: 4.9493, val_acc: 0.6206\n",
      "Epoch [1597], train_loss: 0.0000, val_loss: 4.9626, val_acc: 0.6179\n",
      "Epoch [1598], train_loss: 0.0000, val_loss: 5.0216, val_acc: 0.6258\n",
      "Epoch [1599], train_loss: 0.0000, val_loss: 4.8600, val_acc: 0.6365\n",
      "Epoch [1600], train_loss: 0.0000, val_loss: 4.9469, val_acc: 0.6339\n",
      "Epoch [1601], train_loss: 0.0000, val_loss: 5.0845, val_acc: 0.6258\n",
      "Epoch [1602], train_loss: 0.0000, val_loss: 4.8018, val_acc: 0.6339\n",
      "Epoch [1603], train_loss: 0.0000, val_loss: 5.1485, val_acc: 0.6206\n",
      "Epoch [1604], train_loss: 0.0000, val_loss: 4.9668, val_acc: 0.6339\n",
      "Epoch [1605], train_loss: 0.0000, val_loss: 5.1862, val_acc: 0.6153\n",
      "Epoch [1606], train_loss: 0.0000, val_loss: 5.1595, val_acc: 0.6339\n",
      "Epoch [1607], train_loss: 0.0000, val_loss: 5.3363, val_acc: 0.6339\n",
      "Epoch [1608], train_loss: 0.0000, val_loss: 5.0945, val_acc: 0.6232\n",
      "Epoch [1609], train_loss: 0.0000, val_loss: 5.2279, val_acc: 0.6258\n",
      "Epoch [1610], train_loss: 0.0000, val_loss: 5.2020, val_acc: 0.6098\n",
      "Epoch [1611], train_loss: 0.0000, val_loss: 5.2868, val_acc: 0.6313\n",
      "Epoch [1612], train_loss: 0.0000, val_loss: 5.1555, val_acc: 0.6472\n",
      "Epoch [1613], train_loss: 0.0000, val_loss: 5.2847, val_acc: 0.6232\n",
      "Epoch [1614], train_loss: 0.0000, val_loss: 5.4607, val_acc: 0.6179\n",
      "Epoch [1615], train_loss: 0.0000, val_loss: 5.2296, val_acc: 0.6179\n",
      "Epoch [1616], train_loss: 0.0000, val_loss: 5.3718, val_acc: 0.6287\n",
      "Epoch [1617], train_loss: 0.0000, val_loss: 5.2403, val_acc: 0.6339\n",
      "Epoch [1618], train_loss: 0.0000, val_loss: 5.2982, val_acc: 0.6287\n",
      "Epoch [1619], train_loss: 0.0000, val_loss: 5.3001, val_acc: 0.6261\n",
      "Epoch [1620], train_loss: 0.0000, val_loss: 5.3499, val_acc: 0.6232\n",
      "Epoch [1621], train_loss: 0.0000, val_loss: 5.3528, val_acc: 0.6258\n",
      "Epoch [1622], train_loss: 0.0000, val_loss: 5.1739, val_acc: 0.6232\n",
      "Epoch [1623], train_loss: 0.0000, val_loss: 5.1993, val_acc: 0.6232\n",
      "Epoch [1624], train_loss: 0.0000, val_loss: 5.3379, val_acc: 0.6098\n",
      "Epoch [1625], train_loss: 0.0000, val_loss: 5.1613, val_acc: 0.6206\n",
      "Epoch [1626], train_loss: 0.0000, val_loss: 5.2419, val_acc: 0.6124\n",
      "Epoch [1627], train_loss: 0.0000, val_loss: 5.4310, val_acc: 0.6206\n",
      "Epoch [1628], train_loss: 0.0000, val_loss: 5.3822, val_acc: 0.6206\n",
      "Epoch [1629], train_loss: 0.0000, val_loss: 5.2869, val_acc: 0.6232\n",
      "Epoch [1630], train_loss: 0.0000, val_loss: 5.3311, val_acc: 0.6232\n",
      "Epoch [1631], train_loss: 0.0000, val_loss: 5.4348, val_acc: 0.6206\n",
      "Epoch [1632], train_loss: 0.0000, val_loss: 5.2879, val_acc: 0.6206\n",
      "Epoch [1633], train_loss: 0.0000, val_loss: 5.2901, val_acc: 0.6232\n",
      "Epoch [1634], train_loss: 0.0000, val_loss: 5.3411, val_acc: 0.6232\n",
      "Epoch [1635], train_loss: 0.0000, val_loss: 5.3346, val_acc: 0.6206\n",
      "Epoch [1636], train_loss: 0.0000, val_loss: 5.3240, val_acc: 0.6232\n",
      "Epoch [1637], train_loss: 0.0000, val_loss: 5.3820, val_acc: 0.6232\n",
      "Epoch [1638], train_loss: 0.0000, val_loss: 5.4923, val_acc: 0.6258\n",
      "Epoch [1639], train_loss: 0.0000, val_loss: 5.4933, val_acc: 0.6313\n",
      "Epoch [1640], train_loss: 0.0000, val_loss: 5.5633, val_acc: 0.6339\n",
      "Epoch [1641], train_loss: 0.0000, val_loss: 5.4390, val_acc: 0.6153\n",
      "Epoch [1642], train_loss: 0.0000, val_loss: 5.4975, val_acc: 0.6313\n",
      "Epoch [1643], train_loss: 0.0000, val_loss: 5.5256, val_acc: 0.6258\n",
      "Epoch [1644], train_loss: 0.0000, val_loss: 5.4209, val_acc: 0.6284\n",
      "Epoch [1645], train_loss: 0.0000, val_loss: 5.4208, val_acc: 0.6258\n",
      "Epoch [1646], train_loss: 0.0000, val_loss: 5.3019, val_acc: 0.6206\n",
      "Epoch [1647], train_loss: 0.0000, val_loss: 5.2570, val_acc: 0.6157\n",
      "Epoch [1648], train_loss: 0.0000, val_loss: 5.6222, val_acc: 0.6261\n",
      "Epoch [1649], train_loss: 0.0000, val_loss: 5.4526, val_acc: 0.6072\n",
      "Epoch [1650], train_loss: 0.0000, val_loss: 5.7063, val_acc: 0.6313\n",
      "Epoch [1651], train_loss: 0.0000, val_loss: 5.6037, val_acc: 0.6206\n",
      "Epoch [1652], train_loss: 0.0000, val_loss: 5.8737, val_acc: 0.6127\n",
      "Epoch [1653], train_loss: 0.0000, val_loss: 5.7402, val_acc: 0.6287\n",
      "Epoch [1654], train_loss: 0.0000, val_loss: 5.7705, val_acc: 0.6179\n",
      "Epoch [1655], train_loss: 0.0000, val_loss: 5.8621, val_acc: 0.6179\n",
      "Epoch [1656], train_loss: 0.0000, val_loss: 5.9873, val_acc: 0.6206\n",
      "Epoch [1657], train_loss: 0.0000, val_loss: 5.8693, val_acc: 0.6206\n",
      "Epoch [1658], train_loss: 0.0000, val_loss: 5.7819, val_acc: 0.6150\n",
      "Epoch [1659], train_loss: 0.0169, val_loss: 5.7520, val_acc: 0.5812\n",
      "Epoch [1660], train_loss: 0.2500, val_loss: 1.5944, val_acc: 0.5753\n",
      "Epoch [1661], train_loss: 0.0533, val_loss: 2.1554, val_acc: 0.6179\n",
      "Epoch [1662], train_loss: 0.1320, val_loss: 1.5937, val_acc: 0.6479\n",
      "Epoch [1663], train_loss: 0.0253, val_loss: 1.9872, val_acc: 0.6368\n",
      "Epoch [1664], train_loss: 0.0078, val_loss: 2.4461, val_acc: 0.6241\n",
      "Epoch [1665], train_loss: 0.0091, val_loss: 2.7002, val_acc: 0.6056\n",
      "Epoch [1666], train_loss: 0.0039, val_loss: 2.8493, val_acc: 0.6186\n",
      "Epoch [1667], train_loss: 0.0010, val_loss: 2.8608, val_acc: 0.6238\n",
      "Epoch [1668], train_loss: 0.0006, val_loss: 2.9308, val_acc: 0.6241\n",
      "Epoch [1669], train_loss: 0.0241, val_loss: 2.6485, val_acc: 0.6101\n",
      "Epoch [1670], train_loss: 0.1273, val_loss: 1.5600, val_acc: 0.6232\n",
      "Epoch [1671], train_loss: 0.0373, val_loss: 1.9455, val_acc: 0.6183\n",
      "Epoch [1672], train_loss: 0.0244, val_loss: 3.0331, val_acc: 0.6420\n",
      "Epoch [1673], train_loss: 0.0726, val_loss: 2.3570, val_acc: 0.6108\n",
      "Epoch [1674], train_loss: 0.0353, val_loss: 7.3740, val_acc: 0.5685\n",
      "Epoch [1675], train_loss: 0.0972, val_loss: 5.8326, val_acc: 0.5571\n",
      "Epoch [1676], train_loss: 0.0777, val_loss: 2.2258, val_acc: 0.6322\n",
      "Epoch [1677], train_loss: 0.0082, val_loss: 3.0695, val_acc: 0.6241\n",
      "Epoch [1678], train_loss: 0.0058, val_loss: 3.7848, val_acc: 0.6075\n",
      "Epoch [1679], train_loss: 0.0012, val_loss: 3.6450, val_acc: 0.6293\n",
      "Epoch [1680], train_loss: 0.0006, val_loss: 3.6404, val_acc: 0.6241\n",
      "Epoch [1681], train_loss: 0.0003, val_loss: 3.6479, val_acc: 0.6186\n",
      "Epoch [1682], train_loss: 0.0005, val_loss: 3.8275, val_acc: 0.6404\n",
      "Epoch [1683], train_loss: 0.0002, val_loss: 3.8721, val_acc: 0.6378\n",
      "Epoch [1684], train_loss: 0.0002, val_loss: 3.9088, val_acc: 0.6352\n",
      "Epoch [1685], train_loss: 0.0001, val_loss: 3.9517, val_acc: 0.6352\n",
      "Epoch [1686], train_loss: 0.0002, val_loss: 4.0113, val_acc: 0.6189\n",
      "Epoch [1687], train_loss: 0.0006, val_loss: 4.1482, val_acc: 0.6270\n",
      "Epoch [1688], train_loss: 0.0002, val_loss: 4.1360, val_acc: 0.6348\n",
      "Epoch [1689], train_loss: 0.0001, val_loss: 4.2437, val_acc: 0.6322\n",
      "Epoch [1690], train_loss: 0.0001, val_loss: 4.2701, val_acc: 0.6244\n",
      "Epoch [1691], train_loss: 0.0001, val_loss: 4.3696, val_acc: 0.6134\n",
      "Epoch [1692], train_loss: 0.0001, val_loss: 4.2785, val_acc: 0.6244\n",
      "Epoch [1693], train_loss: 0.0001, val_loss: 4.2998, val_acc: 0.6322\n",
      "Epoch [1694], train_loss: 0.0001, val_loss: 4.5247, val_acc: 0.6352\n",
      "Epoch [1695], train_loss: 0.0228, val_loss: 3.7508, val_acc: 0.6241\n",
      "Epoch [1696], train_loss: 0.0494, val_loss: 3.5153, val_acc: 0.5812\n",
      "Epoch [1697], train_loss: 0.0119, val_loss: 3.0248, val_acc: 0.6052\n",
      "Epoch [1698], train_loss: 0.0016, val_loss: 3.1365, val_acc: 0.6374\n",
      "Epoch [1699], train_loss: 0.0008, val_loss: 3.4132, val_acc: 0.6105\n",
      "Epoch [1700], train_loss: 0.0004, val_loss: 3.4270, val_acc: 0.6105\n",
      "Epoch [1701], train_loss: 0.0002, val_loss: 3.4460, val_acc: 0.6238\n",
      "Epoch [1702], train_loss: 0.0001, val_loss: 3.5332, val_acc: 0.6105\n",
      "Epoch [1703], train_loss: 0.0001, val_loss: 3.3956, val_acc: 0.6131\n",
      "Epoch [1704], train_loss: 0.0001, val_loss: 3.5830, val_acc: 0.5997\n",
      "Epoch [1705], train_loss: 0.0001, val_loss: 3.6441, val_acc: 0.6131\n",
      "Epoch [1706], train_loss: 0.0001, val_loss: 3.6721, val_acc: 0.6049\n",
      "Epoch [1707], train_loss: 0.0001, val_loss: 3.6790, val_acc: 0.6105\n",
      "Epoch [1708], train_loss: 0.0001, val_loss: 3.7282, val_acc: 0.6049\n",
      "Epoch [1709], train_loss: 0.0001, val_loss: 3.6391, val_acc: 0.6075\n",
      "Epoch [1710], train_loss: 0.0000, val_loss: 3.7221, val_acc: 0.6105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1711], train_loss: 0.0001, val_loss: 3.7925, val_acc: 0.6049\n",
      "Epoch [1712], train_loss: 0.0000, val_loss: 3.8419, val_acc: 0.6023\n",
      "Epoch [1713], train_loss: 0.0000, val_loss: 3.7636, val_acc: 0.6131\n",
      "Epoch [1714], train_loss: 0.0038, val_loss: 3.4868, val_acc: 0.6212\n",
      "Epoch [1715], train_loss: 0.0566, val_loss: 2.9982, val_acc: 0.6212\n",
      "Epoch [1716], train_loss: 0.0153, val_loss: 2.4751, val_acc: 0.6394\n",
      "Epoch [1717], train_loss: 0.0390, val_loss: 2.2023, val_acc: 0.5962\n",
      "Epoch [1718], train_loss: 0.0019, val_loss: 2.6978, val_acc: 0.6206\n",
      "Epoch [1719], train_loss: 0.0006, val_loss: 2.8766, val_acc: 0.6232\n",
      "Epoch [1720], train_loss: 0.0006, val_loss: 2.9250, val_acc: 0.6313\n",
      "Epoch [1721], train_loss: 0.0003, val_loss: 2.8961, val_acc: 0.6261\n",
      "Epoch [1722], train_loss: 0.0004, val_loss: 2.9082, val_acc: 0.6287\n",
      "Epoch [1723], train_loss: 0.0017, val_loss: 3.5866, val_acc: 0.5857\n",
      "Epoch [1724], train_loss: 0.0020, val_loss: 3.1511, val_acc: 0.6342\n",
      "Epoch [1725], train_loss: 0.0007, val_loss: 3.1944, val_acc: 0.6342\n",
      "Epoch [1726], train_loss: 0.0001, val_loss: 3.1962, val_acc: 0.6394\n",
      "Epoch [1727], train_loss: 0.0001, val_loss: 3.2279, val_acc: 0.6342\n",
      "Epoch [1728], train_loss: 0.0002, val_loss: 3.4769, val_acc: 0.6449\n",
      "Epoch [1729], train_loss: 0.0001, val_loss: 3.3999, val_acc: 0.6290\n",
      "Epoch [1730], train_loss: 0.0002, val_loss: 3.3735, val_acc: 0.6423\n",
      "Epoch [1731], train_loss: 0.0001, val_loss: 3.4995, val_acc: 0.6449\n",
      "Epoch [1732], train_loss: 0.0001, val_loss: 3.4743, val_acc: 0.6475\n",
      "Epoch [1733], train_loss: 0.0001, val_loss: 3.5510, val_acc: 0.6449\n",
      "Epoch [1734], train_loss: 0.0003, val_loss: 3.5422, val_acc: 0.6345\n",
      "Epoch [1735], train_loss: 0.0005, val_loss: 3.7660, val_acc: 0.6293\n",
      "Epoch [1736], train_loss: 0.0005, val_loss: 3.5395, val_acc: 0.6475\n",
      "Epoch [1737], train_loss: 0.0001, val_loss: 3.6971, val_acc: 0.6264\n",
      "Epoch [1738], train_loss: 0.0000, val_loss: 3.7301, val_acc: 0.6316\n",
      "Epoch [1739], train_loss: 0.0000, val_loss: 3.7978, val_acc: 0.6394\n",
      "Epoch [1740], train_loss: 0.0000, val_loss: 3.8481, val_acc: 0.6342\n",
      "Epoch [1741], train_loss: 0.0000, val_loss: 3.8187, val_acc: 0.6261\n",
      "Epoch [1742], train_loss: 0.0000, val_loss: 3.7194, val_acc: 0.6313\n",
      "Epoch [1743], train_loss: 0.0000, val_loss: 3.9283, val_acc: 0.6290\n",
      "Epoch [1744], train_loss: 0.0000, val_loss: 3.7637, val_acc: 0.6316\n",
      "Epoch [1745], train_loss: 0.0000, val_loss: 3.9090, val_acc: 0.6290\n",
      "Epoch [1746], train_loss: 0.0000, val_loss: 3.9176, val_acc: 0.6235\n",
      "Epoch [1747], train_loss: 0.0000, val_loss: 3.8795, val_acc: 0.6316\n",
      "Epoch [1748], train_loss: 0.0000, val_loss: 3.8978, val_acc: 0.6316\n",
      "Epoch [1749], train_loss: 0.0000, val_loss: 3.9278, val_acc: 0.6261\n",
      "Epoch [1750], train_loss: 0.0000, val_loss: 3.9940, val_acc: 0.6290\n",
      "Epoch [1751], train_loss: 0.0000, val_loss: 4.0135, val_acc: 0.6264\n",
      "Epoch [1752], train_loss: 0.0000, val_loss: 3.9611, val_acc: 0.6264\n",
      "Epoch [1753], train_loss: 0.0000, val_loss: 3.9768, val_acc: 0.6290\n",
      "Epoch [1754], train_loss: 0.0000, val_loss: 3.9870, val_acc: 0.6316\n",
      "Epoch [1755], train_loss: 0.0000, val_loss: 4.0019, val_acc: 0.6238\n",
      "Epoch [1756], train_loss: 0.0000, val_loss: 4.1049, val_acc: 0.6238\n",
      "Epoch [1757], train_loss: 0.0000, val_loss: 4.0180, val_acc: 0.6264\n",
      "Epoch [1758], train_loss: 0.0000, val_loss: 4.0732, val_acc: 0.6264\n",
      "Epoch [1759], train_loss: 0.0000, val_loss: 4.1121, val_acc: 0.6183\n",
      "Epoch [1760], train_loss: 0.0000, val_loss: 4.0960, val_acc: 0.6264\n",
      "Epoch [1761], train_loss: 0.0000, val_loss: 4.0660, val_acc: 0.6235\n",
      "Epoch [1762], train_loss: 0.0000, val_loss: 4.0683, val_acc: 0.6316\n",
      "Epoch [1763], train_loss: 0.0000, val_loss: 4.1284, val_acc: 0.6342\n",
      "Epoch [1764], train_loss: 0.0000, val_loss: 4.1034, val_acc: 0.6342\n",
      "Epoch [1765], train_loss: 0.0000, val_loss: 4.1768, val_acc: 0.6342\n",
      "Epoch [1766], train_loss: 0.0000, val_loss: 4.1989, val_acc: 0.6238\n",
      "Epoch [1767], train_loss: 0.0000, val_loss: 4.2137, val_acc: 0.6290\n",
      "Epoch [1768], train_loss: 0.0000, val_loss: 4.2007, val_acc: 0.6264\n",
      "Epoch [1769], train_loss: 0.0000, val_loss: 4.1180, val_acc: 0.6209\n",
      "Epoch [1770], train_loss: 0.0000, val_loss: 4.3006, val_acc: 0.6209\n",
      "Epoch [1771], train_loss: 0.0000, val_loss: 4.2170, val_acc: 0.6238\n",
      "Epoch [1772], train_loss: 0.0000, val_loss: 4.3218, val_acc: 0.6290\n",
      "Epoch [1773], train_loss: 0.0000, val_loss: 4.1399, val_acc: 0.6316\n",
      "Epoch [1774], train_loss: 0.0000, val_loss: 4.2507, val_acc: 0.6316\n",
      "Epoch [1775], train_loss: 0.0000, val_loss: 4.2963, val_acc: 0.6238\n",
      "Epoch [1776], train_loss: 0.0000, val_loss: 4.4156, val_acc: 0.6209\n",
      "Epoch [1777], train_loss: 0.0000, val_loss: 4.2681, val_acc: 0.6235\n",
      "Epoch [1778], train_loss: 0.0000, val_loss: 4.2305, val_acc: 0.6368\n",
      "Epoch [1779], train_loss: 0.0000, val_loss: 4.2988, val_acc: 0.6316\n",
      "Epoch [1780], train_loss: 0.0000, val_loss: 4.4049, val_acc: 0.6290\n",
      "Epoch [1781], train_loss: 0.0000, val_loss: 4.3802, val_acc: 0.6290\n",
      "Epoch [1782], train_loss: 0.0000, val_loss: 4.4134, val_acc: 0.6209\n",
      "Epoch [1783], train_loss: 0.0000, val_loss: 4.4751, val_acc: 0.6316\n",
      "Epoch [1784], train_loss: 0.0000, val_loss: 4.4057, val_acc: 0.6209\n",
      "Epoch [1785], train_loss: 0.0000, val_loss: 4.4260, val_acc: 0.6290\n",
      "Epoch [1786], train_loss: 0.0000, val_loss: 4.4135, val_acc: 0.6290\n",
      "Epoch [1787], train_loss: 0.0000, val_loss: 4.4238, val_acc: 0.6287\n",
      "Epoch [1788], train_loss: 0.0000, val_loss: 4.4696, val_acc: 0.6235\n",
      "Epoch [1789], train_loss: 0.0000, val_loss: 4.4950, val_acc: 0.6153\n",
      "Epoch [1790], train_loss: 0.0000, val_loss: 4.5078, val_acc: 0.6235\n",
      "Epoch [1791], train_loss: 0.0000, val_loss: 4.4340, val_acc: 0.6287\n",
      "Epoch [1792], train_loss: 0.0000, val_loss: 4.5742, val_acc: 0.6261\n",
      "Epoch [1793], train_loss: 0.0000, val_loss: 4.5424, val_acc: 0.6209\n",
      "Epoch [1794], train_loss: 0.0000, val_loss: 4.4789, val_acc: 0.6316\n",
      "Epoch [1795], train_loss: 0.0000, val_loss: 4.6195, val_acc: 0.6316\n",
      "Epoch [1796], train_loss: 0.0000, val_loss: 4.7725, val_acc: 0.6153\n",
      "Epoch [1797], train_loss: 0.0000, val_loss: 4.5855, val_acc: 0.6261\n",
      "Epoch [1798], train_loss: 0.0001, val_loss: 4.5057, val_acc: 0.6261\n",
      "Epoch [1799], train_loss: 0.0012, val_loss: 4.8758, val_acc: 0.6209\n",
      "Epoch [1800], train_loss: 0.1160, val_loss: 2.3493, val_acc: 0.5962\n",
      "Epoch [1801], train_loss: 0.0632, val_loss: 2.6890, val_acc: 0.6127\n",
      "Epoch [1802], train_loss: 0.0236, val_loss: 4.8714, val_acc: 0.5916\n",
      "Epoch [1803], train_loss: 0.0763, val_loss: 2.5973, val_acc: 0.5838\n",
      "Epoch [1804], train_loss: 0.0102, val_loss: 3.3598, val_acc: 0.6134\n",
      "Epoch [1805], train_loss: 0.0038, val_loss: 5.1334, val_acc: 0.6075\n",
      "Epoch [1806], train_loss: 0.0080, val_loss: 3.2315, val_acc: 0.6339\n",
      "Epoch [1807], train_loss: 0.0017, val_loss: 3.3149, val_acc: 0.6368\n",
      "Epoch [1808], train_loss: 0.0010, val_loss: 4.1939, val_acc: 0.6290\n",
      "Epoch [1809], train_loss: 0.0002, val_loss: 4.2686, val_acc: 0.6049\n",
      "Epoch [1810], train_loss: 0.0001, val_loss: 4.2888, val_acc: 0.6183\n",
      "Epoch [1811], train_loss: 0.0001, val_loss: 4.2630, val_acc: 0.6023\n",
      "Epoch [1812], train_loss: 0.0000, val_loss: 4.3216, val_acc: 0.6023\n",
      "Epoch [1813], train_loss: 0.0000, val_loss: 4.3461, val_acc: 0.6075\n",
      "Epoch [1814], train_loss: 0.0001, val_loss: 4.5161, val_acc: 0.6209\n",
      "Epoch [1815], train_loss: 0.0000, val_loss: 4.4372, val_acc: 0.6264\n",
      "Epoch [1816], train_loss: 0.0000, val_loss: 4.4291, val_acc: 0.6127\n",
      "Epoch [1817], train_loss: 0.0000, val_loss: 4.5033, val_acc: 0.6153\n",
      "Epoch [1818], train_loss: 0.0000, val_loss: 4.4951, val_acc: 0.6235\n",
      "Epoch [1819], train_loss: 0.0000, val_loss: 4.6068, val_acc: 0.6157\n",
      "Epoch [1820], train_loss: 0.0000, val_loss: 4.5852, val_acc: 0.6127\n",
      "Epoch [1821], train_loss: 0.0000, val_loss: 4.5744, val_acc: 0.6316\n",
      "Epoch [1822], train_loss: 0.0000, val_loss: 4.6090, val_acc: 0.6316\n",
      "Epoch [1823], train_loss: 0.0000, val_loss: 4.5875, val_acc: 0.6316\n",
      "Epoch [1824], train_loss: 0.0000, val_loss: 4.6880, val_acc: 0.6316\n",
      "Epoch [1825], train_loss: 0.0000, val_loss: 4.7392, val_acc: 0.6183\n",
      "Epoch [1826], train_loss: 0.0000, val_loss: 4.6787, val_acc: 0.6290\n",
      "Epoch [1827], train_loss: 0.0000, val_loss: 4.7775, val_acc: 0.6209\n",
      "Epoch [1828], train_loss: 0.0000, val_loss: 4.8003, val_acc: 0.6183\n",
      "Epoch [1829], train_loss: 0.0000, val_loss: 4.7238, val_acc: 0.6316\n",
      "Epoch [1830], train_loss: 0.0000, val_loss: 4.7720, val_acc: 0.6316\n",
      "Epoch [1831], train_loss: 0.0000, val_loss: 4.6867, val_acc: 0.6183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1832], train_loss: 0.0000, val_loss: 4.7308, val_acc: 0.6316\n",
      "Epoch [1833], train_loss: 0.0000, val_loss: 4.8310, val_acc: 0.6290\n",
      "Epoch [1834], train_loss: 0.0000, val_loss: 4.9708, val_acc: 0.6397\n",
      "Epoch [1835], train_loss: 0.0000, val_loss: 4.9282, val_acc: 0.6183\n",
      "Epoch [1836], train_loss: 0.0000, val_loss: 4.9313, val_acc: 0.6290\n",
      "Epoch [1837], train_loss: 0.0000, val_loss: 4.8863, val_acc: 0.6209\n",
      "Epoch [1838], train_loss: 0.0000, val_loss: 4.9635, val_acc: 0.6209\n",
      "Epoch [1839], train_loss: 0.0000, val_loss: 5.0811, val_acc: 0.6183\n",
      "Epoch [1840], train_loss: 0.0000, val_loss: 5.0387, val_acc: 0.6235\n",
      "Epoch [1841], train_loss: 0.0000, val_loss: 5.0031, val_acc: 0.6290\n",
      "Epoch [1842], train_loss: 0.0000, val_loss: 4.9415, val_acc: 0.6290\n",
      "Epoch [1843], train_loss: 0.0000, val_loss: 4.9005, val_acc: 0.6264\n",
      "Epoch [1844], train_loss: 0.0000, val_loss: 5.0933, val_acc: 0.6238\n",
      "Epoch [1845], train_loss: 0.0000, val_loss: 5.0536, val_acc: 0.6183\n",
      "Epoch [1846], train_loss: 0.0000, val_loss: 5.1304, val_acc: 0.6290\n",
      "Epoch [1847], train_loss: 0.0000, val_loss: 5.0416, val_acc: 0.6290\n",
      "Epoch [1848], train_loss: 0.0000, val_loss: 5.1637, val_acc: 0.6316\n",
      "Epoch [1849], train_loss: 0.0000, val_loss: 5.0160, val_acc: 0.6316\n",
      "Epoch [1850], train_loss: 0.0000, val_loss: 5.1673, val_acc: 0.6290\n",
      "Epoch [1851], train_loss: 0.0000, val_loss: 5.1592, val_acc: 0.6290\n",
      "Epoch [1852], train_loss: 0.0000, val_loss: 5.0832, val_acc: 0.6316\n",
      "Epoch [1853], train_loss: 0.0000, val_loss: 5.1212, val_acc: 0.6316\n",
      "Epoch [1854], train_loss: 0.0000, val_loss: 5.0973, val_acc: 0.6290\n",
      "Epoch [1855], train_loss: 0.0000, val_loss: 5.1737, val_acc: 0.6290\n",
      "Epoch [1856], train_loss: 0.0000, val_loss: 5.1672, val_acc: 0.6290\n",
      "Epoch [1857], train_loss: 0.0000, val_loss: 5.1193, val_acc: 0.6049\n",
      "Epoch [1858], train_loss: 0.0000, val_loss: 5.1513, val_acc: 0.6157\n",
      "Epoch [1859], train_loss: 0.0000, val_loss: 5.1449, val_acc: 0.6183\n",
      "Epoch [1860], train_loss: 0.0000, val_loss: 5.1703, val_acc: 0.6183\n",
      "Epoch [1861], train_loss: 0.0000, val_loss: 5.0660, val_acc: 0.6316\n",
      "Epoch [1862], train_loss: 0.0000, val_loss: 5.3014, val_acc: 0.6290\n",
      "Epoch [1863], train_loss: 0.0000, val_loss: 5.1356, val_acc: 0.6316\n",
      "Epoch [1864], train_loss: 0.0000, val_loss: 5.2905, val_acc: 0.6290\n",
      "Epoch [1865], train_loss: 0.0000, val_loss: 5.3842, val_acc: 0.6212\n",
      "Epoch [1866], train_loss: 0.0000, val_loss: 5.3090, val_acc: 0.6238\n",
      "Epoch [1867], train_loss: 0.0000, val_loss: 5.2937, val_acc: 0.6238\n",
      "Epoch [1868], train_loss: 0.0000, val_loss: 5.3229, val_acc: 0.6264\n",
      "Epoch [1869], train_loss: 0.0000, val_loss: 5.2239, val_acc: 0.6397\n",
      "Epoch [1870], train_loss: 0.0000, val_loss: 5.3404, val_acc: 0.6290\n",
      "Epoch [1871], train_loss: 0.0000, val_loss: 5.4379, val_acc: 0.6290\n",
      "Epoch [1872], train_loss: 0.0000, val_loss: 5.1935, val_acc: 0.6397\n",
      "Epoch [1873], train_loss: 0.0000, val_loss: 5.3715, val_acc: 0.6345\n",
      "Epoch [1874], train_loss: 0.0000, val_loss: 5.5218, val_acc: 0.6238\n",
      "Epoch [1875], train_loss: 0.0000, val_loss: 5.2565, val_acc: 0.6371\n",
      "Epoch [1876], train_loss: 0.0000, val_loss: 5.3931, val_acc: 0.6423\n",
      "Epoch [1877], train_loss: 0.0000, val_loss: 5.2205, val_acc: 0.6345\n",
      "Epoch [1878], train_loss: 0.0000, val_loss: 5.5439, val_acc: 0.6423\n",
      "Epoch [1879], train_loss: 0.0001, val_loss: 5.3800, val_acc: 0.6371\n",
      "Epoch [1880], train_loss: 0.0776, val_loss: 2.1349, val_acc: 0.6534\n",
      "Epoch [1881], train_loss: 0.1034, val_loss: 2.8249, val_acc: 0.5783\n",
      "Epoch [1882], train_loss: 0.0571, val_loss: 2.4829, val_acc: 0.5867\n",
      "Epoch [1883], train_loss: 0.0603, val_loss: 1.8372, val_acc: 0.6143\n",
      "Epoch [1884], train_loss: 0.0449, val_loss: 2.1017, val_acc: 0.6345\n",
      "Epoch [1885], train_loss: 0.0119, val_loss: 3.0399, val_acc: 0.6293\n",
      "Epoch [1886], train_loss: 0.0067, val_loss: 3.4425, val_acc: 0.6589\n",
      "Epoch [1887], train_loss: 0.0078, val_loss: 2.9521, val_acc: 0.6238\n",
      "Epoch [1888], train_loss: 0.0034, val_loss: 3.6293, val_acc: 0.6267\n",
      "Epoch [1889], train_loss: 0.0005, val_loss: 3.7405, val_acc: 0.6401\n",
      "Epoch [1890], train_loss: 0.0001, val_loss: 3.8481, val_acc: 0.6374\n",
      "Epoch [1891], train_loss: 0.0001, val_loss: 3.9938, val_acc: 0.6511\n",
      "Epoch [1892], train_loss: 0.0001, val_loss: 4.1512, val_acc: 0.6482\n",
      "Epoch [1893], train_loss: 0.0000, val_loss: 4.1413, val_acc: 0.6508\n",
      "Epoch [1894], train_loss: 0.0001, val_loss: 4.0509, val_acc: 0.6615\n",
      "Epoch [1895], train_loss: 0.0000, val_loss: 4.1312, val_acc: 0.6560\n",
      "Epoch [1896], train_loss: 0.0000, val_loss: 4.2461, val_acc: 0.6589\n",
      "Epoch [1897], train_loss: 0.0000, val_loss: 4.2958, val_acc: 0.6615\n",
      "Epoch [1898], train_loss: 0.0000, val_loss: 4.2121, val_acc: 0.6534\n",
      "Epoch [1899], train_loss: 0.0000, val_loss: 4.4010, val_acc: 0.6641\n",
      "Epoch [1900], train_loss: 0.0000, val_loss: 4.5219, val_acc: 0.6534\n",
      "Epoch [1901], train_loss: 0.0000, val_loss: 4.5474, val_acc: 0.6534\n",
      "Epoch [1902], train_loss: 0.0000, val_loss: 4.5322, val_acc: 0.6508\n",
      "Epoch [1903], train_loss: 0.0000, val_loss: 4.5399, val_acc: 0.6508\n",
      "Epoch [1904], train_loss: 0.0000, val_loss: 4.5996, val_acc: 0.6508\n",
      "Epoch [1905], train_loss: 0.0000, val_loss: 4.6281, val_acc: 0.6482\n",
      "Epoch [1906], train_loss: 0.0000, val_loss: 4.6341, val_acc: 0.6534\n",
      "Epoch [1907], train_loss: 0.0000, val_loss: 4.7021, val_acc: 0.6586\n",
      "Epoch [1908], train_loss: 0.0000, val_loss: 4.5157, val_acc: 0.6508\n",
      "Epoch [1909], train_loss: 0.0000, val_loss: 4.6463, val_acc: 0.6427\n",
      "Epoch [1910], train_loss: 0.0000, val_loss: 4.7953, val_acc: 0.6482\n",
      "Epoch [1911], train_loss: 0.0000, val_loss: 4.9347, val_acc: 0.6534\n",
      "Epoch [1912], train_loss: 0.0000, val_loss: 4.7978, val_acc: 0.6534\n",
      "Epoch [1913], train_loss: 0.0000, val_loss: 4.8434, val_acc: 0.6427\n",
      "Epoch [1914], train_loss: 0.0000, val_loss: 4.7744, val_acc: 0.6537\n",
      "Epoch [1915], train_loss: 0.0000, val_loss: 4.9110, val_acc: 0.6534\n",
      "Epoch [1916], train_loss: 0.0000, val_loss: 4.8211, val_acc: 0.6534\n",
      "Epoch [1917], train_loss: 0.0000, val_loss: 4.9500, val_acc: 0.6482\n",
      "Epoch [1918], train_loss: 0.0000, val_loss: 5.0262, val_acc: 0.6508\n",
      "Epoch [1919], train_loss: 0.0000, val_loss: 4.8829, val_acc: 0.6482\n",
      "Epoch [1920], train_loss: 0.0000, val_loss: 4.9594, val_acc: 0.6401\n",
      "Epoch [1921], train_loss: 0.0000, val_loss: 5.1066, val_acc: 0.6427\n",
      "Epoch [1922], train_loss: 0.0000, val_loss: 5.1700, val_acc: 0.6401\n",
      "Epoch [1923], train_loss: 0.0000, val_loss: 5.0292, val_acc: 0.6479\n",
      "Epoch [1924], train_loss: 0.0000, val_loss: 4.9746, val_acc: 0.6401\n",
      "Epoch [1925], train_loss: 0.0000, val_loss: 5.0009, val_acc: 0.6456\n",
      "Epoch [1926], train_loss: 0.0000, val_loss: 5.1189, val_acc: 0.6482\n",
      "Epoch [1927], train_loss: 0.0000, val_loss: 5.2300, val_acc: 0.6319\n",
      "Epoch [1928], train_loss: 0.0000, val_loss: 5.1198, val_acc: 0.6319\n",
      "Epoch [1929], train_loss: 0.0000, val_loss: 5.2106, val_acc: 0.6401\n",
      "Epoch [1930], train_loss: 0.0000, val_loss: 5.0948, val_acc: 0.6453\n",
      "Epoch [1931], train_loss: 0.0000, val_loss: 5.2456, val_acc: 0.6401\n",
      "Epoch [1932], train_loss: 0.0000, val_loss: 5.2091, val_acc: 0.6534\n",
      "Epoch [1933], train_loss: 0.0000, val_loss: 5.1792, val_acc: 0.6560\n",
      "Epoch [1934], train_loss: 0.0000, val_loss: 5.4404, val_acc: 0.6479\n",
      "Epoch [1935], train_loss: 0.0000, val_loss: 5.3062, val_acc: 0.6401\n",
      "Epoch [1936], train_loss: 0.0000, val_loss: 5.1804, val_acc: 0.6453\n",
      "Epoch [1937], train_loss: 0.0000, val_loss: 5.3574, val_acc: 0.6401\n",
      "Epoch [1938], train_loss: 0.0000, val_loss: 5.2634, val_acc: 0.6453\n",
      "Epoch [1939], train_loss: 0.0000, val_loss: 5.4143, val_acc: 0.6371\n",
      "Epoch [1940], train_loss: 0.0000, val_loss: 5.1588, val_acc: 0.6560\n",
      "Epoch [1941], train_loss: 0.0000, val_loss: 5.3109, val_acc: 0.6401\n",
      "Epoch [1942], train_loss: 0.0000, val_loss: 5.2654, val_acc: 0.6453\n",
      "Epoch [1943], train_loss: 0.0000, val_loss: 5.4251, val_acc: 0.6427\n",
      "Epoch [1944], train_loss: 0.0000, val_loss: 5.5049, val_acc: 0.6401\n",
      "Epoch [1945], train_loss: 0.0000, val_loss: 5.3384, val_acc: 0.6482\n",
      "Epoch [1946], train_loss: 0.0000, val_loss: 5.3066, val_acc: 0.6427\n",
      "Epoch [1947], train_loss: 0.0000, val_loss: 5.4106, val_acc: 0.6534\n",
      "Epoch [1948], train_loss: 0.0000, val_loss: 5.3974, val_acc: 0.6482\n",
      "Epoch [1949], train_loss: 0.0000, val_loss: 5.3894, val_acc: 0.6401\n",
      "Epoch [1950], train_loss: 0.0000, val_loss: 5.5027, val_acc: 0.6508\n",
      "Epoch [1951], train_loss: 0.0000, val_loss: 5.5768, val_acc: 0.6482\n",
      "Epoch [1952], train_loss: 0.0000, val_loss: 5.5005, val_acc: 0.6453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1953], train_loss: 0.0000, val_loss: 5.5869, val_acc: 0.6427\n",
      "Epoch [1954], train_loss: 0.0000, val_loss: 5.5221, val_acc: 0.6427\n",
      "Epoch [1955], train_loss: 0.0000, val_loss: 5.5872, val_acc: 0.6505\n",
      "Epoch [1956], train_loss: 0.0000, val_loss: 5.6792, val_acc: 0.6508\n",
      "Epoch [1957], train_loss: 0.0000, val_loss: 5.4919, val_acc: 0.6371\n",
      "Epoch [1958], train_loss: 0.0000, val_loss: 5.7067, val_acc: 0.6345\n",
      "Epoch [1959], train_loss: 0.0000, val_loss: 5.6779, val_acc: 0.6238\n",
      "Epoch [1960], train_loss: 0.0000, val_loss: 5.5578, val_acc: 0.6427\n",
      "Epoch [1961], train_loss: 0.0000, val_loss: 5.7246, val_acc: 0.6374\n",
      "Epoch [1962], train_loss: 0.0000, val_loss: 5.4920, val_acc: 0.6479\n",
      "Epoch [1963], train_loss: 0.0000, val_loss: 5.7233, val_acc: 0.6427\n",
      "Epoch [1964], train_loss: 0.0000, val_loss: 5.7059, val_acc: 0.6508\n",
      "Epoch [1965], train_loss: 0.0000, val_loss: 5.7002, val_acc: 0.6505\n",
      "Epoch [1966], train_loss: 0.0000, val_loss: 5.6922, val_acc: 0.6534\n",
      "Epoch [1967], train_loss: 0.0000, val_loss: 5.8064, val_acc: 0.6401\n",
      "Epoch [1968], train_loss: 0.0000, val_loss: 5.7031, val_acc: 0.6479\n",
      "Epoch [1969], train_loss: 0.0000, val_loss: 5.8883, val_acc: 0.6371\n",
      "Epoch [1970], train_loss: 0.0000, val_loss: 5.8766, val_acc: 0.6508\n",
      "Epoch [1971], train_loss: 0.0000, val_loss: 5.7437, val_acc: 0.6479\n",
      "Epoch [1972], train_loss: 0.0000, val_loss: 5.7207, val_acc: 0.6508\n",
      "Epoch [1973], train_loss: 0.0000, val_loss: 5.7685, val_acc: 0.6560\n",
      "Epoch [1974], train_loss: 0.0000, val_loss: 5.5456, val_acc: 0.6560\n",
      "Epoch [1975], train_loss: 0.0000, val_loss: 5.8287, val_acc: 0.6427\n",
      "Epoch [1976], train_loss: 0.0000, val_loss: 5.8533, val_acc: 0.6453\n",
      "Epoch [1977], train_loss: 0.0000, val_loss: 5.6466, val_acc: 0.6560\n",
      "Epoch [1978], train_loss: 0.0000, val_loss: 5.8330, val_acc: 0.6586\n",
      "Epoch [1979], train_loss: 0.0000, val_loss: 5.8456, val_acc: 0.6453\n",
      "Epoch [1980], train_loss: 0.0000, val_loss: 5.7973, val_acc: 0.6453\n",
      "Epoch [1981], train_loss: 0.0000, val_loss: 5.7220, val_acc: 0.6453\n",
      "Epoch [1982], train_loss: 0.0000, val_loss: 5.8143, val_acc: 0.6479\n",
      "Epoch [1983], train_loss: 0.0000, val_loss: 5.9991, val_acc: 0.6427\n",
      "Epoch [1984], train_loss: 0.0000, val_loss: 5.9332, val_acc: 0.6453\n",
      "Epoch [1985], train_loss: 0.0000, val_loss: 6.0097, val_acc: 0.6319\n",
      "Epoch [1986], train_loss: 0.0000, val_loss: 5.9626, val_acc: 0.6371\n",
      "Epoch [1987], train_loss: 0.0000, val_loss: 6.1030, val_acc: 0.6397\n",
      "Epoch [1988], train_loss: 0.0000, val_loss: 5.9240, val_acc: 0.6345\n",
      "Epoch [1989], train_loss: 0.0000, val_loss: 5.9883, val_acc: 0.6264\n",
      "Epoch [1990], train_loss: 0.0000, val_loss: 5.9586, val_acc: 0.6427\n",
      "Epoch [1991], train_loss: 0.0000, val_loss: 6.0325, val_acc: 0.6479\n",
      "Epoch [1992], train_loss: 0.0000, val_loss: 6.2053, val_acc: 0.6427\n",
      "Epoch [1993], train_loss: 0.0000, val_loss: 6.2302, val_acc: 0.6427\n",
      "Epoch [1994], train_loss: 0.0000, val_loss: 5.9844, val_acc: 0.6560\n",
      "Epoch [1995], train_loss: 0.0000, val_loss: 6.1063, val_acc: 0.6508\n",
      "Epoch [1996], train_loss: 0.0000, val_loss: 6.0968, val_acc: 0.6508\n",
      "Epoch [1997], train_loss: 0.0000, val_loss: 6.2015, val_acc: 0.6560\n",
      "Epoch [1998], train_loss: 0.0000, val_loss: 6.0914, val_acc: 0.6401\n",
      "Epoch [1999], train_loss: 0.0000, val_loss: 6.2124, val_acc: 0.6453\n",
      "Epoch [2000], train_loss: 0.0000, val_loss: 6.1722, val_acc: 0.6427\n",
      "Epoch [2001], train_loss: 0.0000, val_loss: 6.1747, val_acc: 0.6264\n",
      "Epoch [2002], train_loss: 0.0000, val_loss: 6.0750, val_acc: 0.6479\n",
      "Epoch [2003], train_loss: 0.0000, val_loss: 6.3047, val_acc: 0.6508\n",
      "Epoch [2004], train_loss: 0.0000, val_loss: 6.2487, val_acc: 0.6397\n",
      "Epoch [2005], train_loss: 0.0000, val_loss: 7.7420, val_acc: 0.6212\n",
      "Epoch [2006], train_loss: 0.1881, val_loss: 4.5558, val_acc: 0.5356\n",
      "Epoch [2007], train_loss: 0.0845, val_loss: 2.3312, val_acc: 0.5588\n",
      "Epoch [2008], train_loss: 0.0239, val_loss: 2.4035, val_acc: 0.5854\n",
      "Epoch [2009], train_loss: 0.0483, val_loss: 2.2822, val_acc: 0.6069\n",
      "Epoch [2010], train_loss: 0.0093, val_loss: 2.1840, val_acc: 0.5971\n",
      "Epoch [2011], train_loss: 0.0041, val_loss: 2.8472, val_acc: 0.6101\n",
      "Epoch [2012], train_loss: 0.0013, val_loss: 2.9583, val_acc: 0.6043\n",
      "Epoch [2013], train_loss: 0.0002, val_loss: 3.1150, val_acc: 0.6127\n",
      "Epoch [2014], train_loss: 0.0002, val_loss: 3.2338, val_acc: 0.5991\n",
      "Epoch [2015], train_loss: 0.0001, val_loss: 3.2507, val_acc: 0.6124\n",
      "Epoch [2016], train_loss: 0.0001, val_loss: 3.3029, val_acc: 0.6069\n",
      "Epoch [2017], train_loss: 0.0001, val_loss: 3.3707, val_acc: 0.5991\n",
      "Epoch [2018], train_loss: 0.0001, val_loss: 3.4420, val_acc: 0.5962\n",
      "Epoch [2019], train_loss: 0.0001, val_loss: 3.4578, val_acc: 0.6124\n",
      "Epoch [2020], train_loss: 0.0001, val_loss: 3.4636, val_acc: 0.6017\n",
      "Epoch [2021], train_loss: 0.0000, val_loss: 3.5006, val_acc: 0.6098\n",
      "Epoch [2022], train_loss: 0.0000, val_loss: 3.5796, val_acc: 0.6179\n",
      "Epoch [2023], train_loss: 0.0000, val_loss: 3.5766, val_acc: 0.6124\n",
      "Epoch [2024], train_loss: 0.0000, val_loss: 3.6332, val_acc: 0.6095\n",
      "Epoch [2025], train_loss: 0.0000, val_loss: 3.6870, val_acc: 0.6072\n",
      "Epoch [2026], train_loss: 0.0000, val_loss: 3.6870, val_acc: 0.6258\n",
      "Epoch [2027], train_loss: 0.0000, val_loss: 3.7849, val_acc: 0.6232\n",
      "Epoch [2028], train_loss: 0.0000, val_loss: 3.7103, val_acc: 0.6043\n",
      "Epoch [2029], train_loss: 0.0000, val_loss: 3.7609, val_acc: 0.6206\n",
      "Epoch [2030], train_loss: 0.0000, val_loss: 3.8041, val_acc: 0.6150\n",
      "Epoch [2031], train_loss: 0.0000, val_loss: 3.8698, val_acc: 0.6232\n",
      "Epoch [2032], train_loss: 0.0000, val_loss: 3.7413, val_acc: 0.6069\n",
      "Epoch [2033], train_loss: 0.0000, val_loss: 3.7891, val_acc: 0.6043\n",
      "Epoch [2034], train_loss: 0.0000, val_loss: 3.8228, val_acc: 0.6069\n",
      "Epoch [2035], train_loss: 0.0000, val_loss: 3.8028, val_acc: 0.6043\n",
      "Epoch [2036], train_loss: 0.0000, val_loss: 3.9720, val_acc: 0.6095\n",
      "Epoch [2037], train_loss: 0.0000, val_loss: 3.9657, val_acc: 0.6095\n",
      "Epoch [2038], train_loss: 0.0000, val_loss: 4.0016, val_acc: 0.6176\n",
      "Epoch [2039], train_loss: 0.0000, val_loss: 4.0191, val_acc: 0.6069\n",
      "Epoch [2040], train_loss: 0.0000, val_loss: 4.0109, val_acc: 0.6124\n",
      "Epoch [2041], train_loss: 0.0000, val_loss: 4.0286, val_acc: 0.6095\n",
      "Epoch [2042], train_loss: 0.0000, val_loss: 4.1049, val_acc: 0.6069\n",
      "Epoch [2043], train_loss: 0.0000, val_loss: 4.0660, val_acc: 0.6098\n",
      "Epoch [2044], train_loss: 0.0000, val_loss: 4.1250, val_acc: 0.6069\n",
      "Epoch [2045], train_loss: 0.0000, val_loss: 4.0249, val_acc: 0.6043\n",
      "Epoch [2046], train_loss: 0.0000, val_loss: 4.1345, val_acc: 0.6069\n",
      "Epoch [2047], train_loss: 0.0000, val_loss: 3.9460, val_acc: 0.6176\n",
      "Epoch [2048], train_loss: 0.0000, val_loss: 4.1726, val_acc: 0.6176\n",
      "Epoch [2049], train_loss: 0.0000, val_loss: 4.1788, val_acc: 0.6124\n",
      "Epoch [2050], train_loss: 0.0000, val_loss: 4.1824, val_acc: 0.6095\n",
      "Epoch [2051], train_loss: 0.0000, val_loss: 4.1794, val_acc: 0.6150\n",
      "Epoch [2052], train_loss: 0.0000, val_loss: 4.3186, val_acc: 0.6095\n",
      "Epoch [2053], train_loss: 0.0000, val_loss: 4.3360, val_acc: 0.5988\n",
      "Epoch [2054], train_loss: 0.0000, val_loss: 4.3029, val_acc: 0.6069\n",
      "Epoch [2055], train_loss: 0.0000, val_loss: 4.2015, val_acc: 0.6043\n",
      "Epoch [2056], train_loss: 0.0000, val_loss: 4.3023, val_acc: 0.6176\n",
      "Epoch [2057], train_loss: 0.0000, val_loss: 4.2857, val_acc: 0.6095\n",
      "Epoch [2058], train_loss: 0.0000, val_loss: 4.1885, val_acc: 0.6043\n",
      "Epoch [2059], train_loss: 0.0000, val_loss: 4.3648, val_acc: 0.6095\n",
      "Epoch [2060], train_loss: 0.0000, val_loss: 4.4274, val_acc: 0.6095\n",
      "Epoch [2061], train_loss: 0.0000, val_loss: 4.3743, val_acc: 0.6043\n",
      "Epoch [2062], train_loss: 0.0000, val_loss: 4.3502, val_acc: 0.6043\n",
      "Epoch [2063], train_loss: 0.0000, val_loss: 4.2947, val_acc: 0.6069\n",
      "Epoch [2064], train_loss: 0.0000, val_loss: 4.2913, val_acc: 0.6153\n",
      "Epoch [2065], train_loss: 0.0000, val_loss: 4.3537, val_acc: 0.6069\n",
      "Epoch [2066], train_loss: 0.0000, val_loss: 4.2566, val_acc: 0.6043\n",
      "Epoch [2067], train_loss: 0.0000, val_loss: 4.3294, val_acc: 0.6095\n",
      "Epoch [2068], train_loss: 0.0000, val_loss: 4.4441, val_acc: 0.6095\n",
      "Epoch [2069], train_loss: 0.0000, val_loss: 4.4104, val_acc: 0.6043\n",
      "Epoch [2070], train_loss: 0.0000, val_loss: 4.3975, val_acc: 0.5991\n",
      "Epoch [2071], train_loss: 0.0000, val_loss: 4.2848, val_acc: 0.6095\n",
      "Epoch [2072], train_loss: 0.0000, val_loss: 4.3073, val_acc: 0.6043\n",
      "Epoch [2073], train_loss: 0.0000, val_loss: 4.4113, val_acc: 0.6043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2074], train_loss: 0.0000, val_loss: 4.5436, val_acc: 0.6069\n",
      "Epoch [2075], train_loss: 0.0000, val_loss: 4.4620, val_acc: 0.6069\n",
      "Epoch [2076], train_loss: 0.0000, val_loss: 4.4782, val_acc: 0.6098\n",
      "Epoch [2077], train_loss: 0.0000, val_loss: 4.5845, val_acc: 0.6043\n",
      "Epoch [2078], train_loss: 0.0000, val_loss: 4.4314, val_acc: 0.6072\n",
      "Epoch [2079], train_loss: 0.0000, val_loss: 4.4824, val_acc: 0.6043\n",
      "Epoch [2080], train_loss: 0.0000, val_loss: 4.5241, val_acc: 0.6043\n",
      "Epoch [2081], train_loss: 0.0000, val_loss: 4.5172, val_acc: 0.6069\n",
      "Epoch [2082], train_loss: 0.0000, val_loss: 4.5754, val_acc: 0.6069\n",
      "Epoch [2083], train_loss: 0.0000, val_loss: 4.4632, val_acc: 0.6017\n",
      "Epoch [2084], train_loss: 0.0000, val_loss: 4.6240, val_acc: 0.6043\n",
      "Epoch [2085], train_loss: 0.0000, val_loss: 4.4929, val_acc: 0.6017\n",
      "Epoch [2086], train_loss: 0.0000, val_loss: 4.3634, val_acc: 0.6017\n",
      "Epoch [2087], train_loss: 0.0000, val_loss: 4.5390, val_acc: 0.6017\n",
      "Epoch [2088], train_loss: 0.0000, val_loss: 4.4555, val_acc: 0.6179\n",
      "Epoch [2089], train_loss: 0.0000, val_loss: 4.5045, val_acc: 0.6043\n",
      "Epoch [2090], train_loss: 0.0000, val_loss: 4.5482, val_acc: 0.5913\n",
      "Epoch [2091], train_loss: 0.0000, val_loss: 4.5239, val_acc: 0.6179\n",
      "Epoch [2092], train_loss: 0.0000, val_loss: 4.6735, val_acc: 0.5991\n",
      "Epoch [2093], train_loss: 0.0000, val_loss: 4.6403, val_acc: 0.6124\n",
      "Epoch [2094], train_loss: 0.0000, val_loss: 4.6248, val_acc: 0.5991\n",
      "Epoch [2095], train_loss: 0.0000, val_loss: 4.6689, val_acc: 0.5991\n",
      "Epoch [2096], train_loss: 0.0000, val_loss: 4.5892, val_acc: 0.6043\n",
      "Epoch [2097], train_loss: 0.0000, val_loss: 4.6493, val_acc: 0.6017\n",
      "Epoch [2098], train_loss: 0.0000, val_loss: 4.6056, val_acc: 0.6043\n",
      "Epoch [2099], train_loss: 0.0000, val_loss: 4.5777, val_acc: 0.6069\n",
      "Epoch [2100], train_loss: 0.0000, val_loss: 4.6049, val_acc: 0.6043\n",
      "Epoch [2101], train_loss: 0.0000, val_loss: 4.7532, val_acc: 0.6069\n",
      "Epoch [2102], train_loss: 0.0000, val_loss: 4.7580, val_acc: 0.6069\n",
      "Epoch [2103], train_loss: 0.0000, val_loss: 4.6925, val_acc: 0.6017\n",
      "Epoch [2104], train_loss: 0.0000, val_loss: 4.7062, val_acc: 0.6017\n",
      "Epoch [2105], train_loss: 0.0000, val_loss: 4.6255, val_acc: 0.6043\n",
      "Epoch [2106], train_loss: 0.0000, val_loss: 4.8459, val_acc: 0.6043\n",
      "Epoch [2107], train_loss: 0.0000, val_loss: 4.9242, val_acc: 0.6017\n",
      "Epoch [2108], train_loss: 0.0000, val_loss: 4.9696, val_acc: 0.6124\n",
      "Epoch [2109], train_loss: 0.0000, val_loss: 4.8850, val_acc: 0.6017\n",
      "Epoch [2110], train_loss: 0.0000, val_loss: 4.8468, val_acc: 0.6069\n",
      "Epoch [2111], train_loss: 0.0000, val_loss: 4.5268, val_acc: 0.6072\n",
      "Epoch [2112], train_loss: 0.0000, val_loss: 4.5421, val_acc: 0.6017\n",
      "Epoch [2113], train_loss: 0.0006, val_loss: 5.1342, val_acc: 0.6040\n",
      "Epoch [2114], train_loss: 0.1984, val_loss: 1.4576, val_acc: 0.5760\n",
      "Epoch [2115], train_loss: 0.1011, val_loss: 2.1433, val_acc: 0.5887\n",
      "Epoch [2116], train_loss: 0.0635, val_loss: 2.6460, val_acc: 0.6072\n",
      "Epoch [2117], train_loss: 0.0268, val_loss: 2.3207, val_acc: 0.6173\n",
      "Epoch [2118], train_loss: 0.0486, val_loss: 3.2452, val_acc: 0.5809\n",
      "Epoch [2119], train_loss: 0.0236, val_loss: 3.1398, val_acc: 0.5910\n",
      "Epoch [2120], train_loss: 0.0088, val_loss: 3.0974, val_acc: 0.6131\n",
      "Epoch [2121], train_loss: 0.0056, val_loss: 3.0156, val_acc: 0.6176\n",
      "Epoch [2122], train_loss: 0.0025, val_loss: 3.9414, val_acc: 0.6287\n",
      "Epoch [2123], train_loss: 0.0031, val_loss: 4.0631, val_acc: 0.5936\n",
      "Epoch [2124], train_loss: 0.0106, val_loss: 3.5196, val_acc: 0.5835\n",
      "Epoch [2125], train_loss: 0.0247, val_loss: 3.5205, val_acc: 0.6179\n",
      "Epoch [2126], train_loss: 0.0081, val_loss: 3.9647, val_acc: 0.6020\n",
      "Epoch [2127], train_loss: 0.0154, val_loss: 3.5827, val_acc: 0.6124\n",
      "Epoch [2128], train_loss: 0.0182, val_loss: 3.4712, val_acc: 0.6336\n",
      "Epoch [2129], train_loss: 0.0099, val_loss: 2.4011, val_acc: 0.6118\n",
      "Epoch [2130], train_loss: 0.0081, val_loss: 2.6631, val_acc: 0.5884\n",
      "Epoch [2131], train_loss: 0.0018, val_loss: 3.2759, val_acc: 0.6072\n",
      "Epoch [2132], train_loss: 0.0005, val_loss: 3.2436, val_acc: 0.6153\n",
      "Epoch [2133], train_loss: 0.0003, val_loss: 3.3053, val_acc: 0.6150\n",
      "Epoch [2134], train_loss: 0.0002, val_loss: 3.6990, val_acc: 0.6072\n",
      "Epoch [2135], train_loss: 0.0001, val_loss: 3.4684, val_acc: 0.6017\n",
      "Epoch [2136], train_loss: 0.0001, val_loss: 3.8025, val_acc: 0.5991\n",
      "Epoch [2137], train_loss: 0.0001, val_loss: 3.7932, val_acc: 0.6098\n",
      "Epoch [2138], train_loss: 0.0001, val_loss: 3.7714, val_acc: 0.6072\n",
      "Epoch [2139], train_loss: 0.0000, val_loss: 3.8337, val_acc: 0.6072\n",
      "Epoch [2140], train_loss: 0.0000, val_loss: 3.9014, val_acc: 0.6043\n",
      "Epoch [2141], train_loss: 0.0000, val_loss: 4.0984, val_acc: 0.6014\n",
      "Epoch [2142], train_loss: 0.0000, val_loss: 3.9401, val_acc: 0.6098\n",
      "Epoch [2143], train_loss: 0.0033, val_loss: 5.0265, val_acc: 0.6394\n",
      "Epoch [2144], train_loss: 0.0895, val_loss: 2.6960, val_acc: 0.5802\n",
      "Epoch [2145], train_loss: 0.0290, val_loss: 2.6757, val_acc: 0.6020\n",
      "Epoch [2146], train_loss: 0.0058, val_loss: 3.0482, val_acc: 0.6043\n",
      "Epoch [2147], train_loss: 0.0012, val_loss: 3.4862, val_acc: 0.6017\n",
      "Epoch [2148], train_loss: 0.0005, val_loss: 3.6561, val_acc: 0.5988\n",
      "Epoch [2149], train_loss: 0.0002, val_loss: 3.7567, val_acc: 0.5910\n",
      "Epoch [2150], train_loss: 0.0001, val_loss: 3.7084, val_acc: 0.5910\n",
      "Epoch [2151], train_loss: 0.0001, val_loss: 3.8359, val_acc: 0.5854\n",
      "Epoch [2152], train_loss: 0.0001, val_loss: 4.0071, val_acc: 0.5828\n",
      "Epoch [2153], train_loss: 0.0002, val_loss: 4.1483, val_acc: 0.5936\n",
      "Epoch [2154], train_loss: 0.0002, val_loss: 4.5174, val_acc: 0.5828\n",
      "Epoch [2155], train_loss: 0.0001, val_loss: 4.4770, val_acc: 0.5854\n",
      "Epoch [2156], train_loss: 0.0000, val_loss: 4.3289, val_acc: 0.5776\n",
      "Epoch [2157], train_loss: 0.0000, val_loss: 4.3413, val_acc: 0.5721\n",
      "Epoch [2158], train_loss: 0.0000, val_loss: 4.4150, val_acc: 0.5750\n",
      "Epoch [2159], train_loss: 0.0000, val_loss: 4.3978, val_acc: 0.5802\n",
      "Epoch [2160], train_loss: 0.0000, val_loss: 4.4237, val_acc: 0.5831\n",
      "Epoch [2161], train_loss: 0.0000, val_loss: 4.4075, val_acc: 0.5695\n",
      "Epoch [2162], train_loss: 0.0000, val_loss: 4.3973, val_acc: 0.5750\n",
      "Epoch [2163], train_loss: 0.0000, val_loss: 4.3323, val_acc: 0.5750\n",
      "Epoch [2164], train_loss: 0.0000, val_loss: 4.5100, val_acc: 0.5776\n",
      "Epoch [2165], train_loss: 0.0000, val_loss: 4.5173, val_acc: 0.5831\n",
      "Epoch [2166], train_loss: 0.0000, val_loss: 4.4858, val_acc: 0.5831\n",
      "Epoch [2167], train_loss: 0.0000, val_loss: 4.4168, val_acc: 0.5750\n",
      "Epoch [2168], train_loss: 0.0000, val_loss: 4.6345, val_acc: 0.5831\n",
      "Epoch [2169], train_loss: 0.0000, val_loss: 4.6655, val_acc: 0.5750\n",
      "Epoch [2170], train_loss: 0.0000, val_loss: 4.4139, val_acc: 0.5857\n",
      "Epoch [2171], train_loss: 0.0000, val_loss: 4.5199, val_acc: 0.5857\n",
      "Epoch [2172], train_loss: 0.0000, val_loss: 4.7664, val_acc: 0.5857\n",
      "Epoch [2173], train_loss: 0.0000, val_loss: 4.4542, val_acc: 0.5802\n",
      "Epoch [2174], train_loss: 0.0000, val_loss: 4.8348, val_acc: 0.5831\n",
      "Epoch [2175], train_loss: 0.0001, val_loss: 4.7350, val_acc: 0.5750\n",
      "Epoch [2176], train_loss: 0.0000, val_loss: 4.7827, val_acc: 0.5802\n",
      "Epoch [2177], train_loss: 0.0000, val_loss: 4.5569, val_acc: 0.5802\n",
      "Epoch [2178], train_loss: 0.0000, val_loss: 4.6429, val_acc: 0.5854\n",
      "Epoch [2179], train_loss: 0.0000, val_loss: 4.7915, val_acc: 0.5776\n",
      "Epoch [2180], train_loss: 0.0000, val_loss: 4.9149, val_acc: 0.5854\n",
      "Epoch [2181], train_loss: 0.0000, val_loss: 4.9233, val_acc: 0.5828\n",
      "Epoch [2182], train_loss: 0.0000, val_loss: 4.8281, val_acc: 0.5802\n",
      "Epoch [2183], train_loss: 0.0000, val_loss: 4.8853, val_acc: 0.5802\n",
      "Epoch [2184], train_loss: 0.0000, val_loss: 4.7313, val_acc: 0.5802\n",
      "Epoch [2185], train_loss: 0.0000, val_loss: 4.8794, val_acc: 0.5857\n",
      "Epoch [2186], train_loss: 0.0000, val_loss: 4.9712, val_acc: 0.5857\n",
      "Epoch [2187], train_loss: 0.0000, val_loss: 5.0659, val_acc: 0.5857\n",
      "Epoch [2188], train_loss: 0.0000, val_loss: 4.8330, val_acc: 0.5802\n",
      "Epoch [2189], train_loss: 0.0000, val_loss: 4.9682, val_acc: 0.5854\n",
      "Epoch [2190], train_loss: 0.0000, val_loss: 5.0432, val_acc: 0.5750\n",
      "Epoch [2191], train_loss: 0.0000, val_loss: 4.8713, val_acc: 0.5857\n",
      "Epoch [2192], train_loss: 0.0000, val_loss: 4.7705, val_acc: 0.5802\n",
      "Epoch [2193], train_loss: 0.0000, val_loss: 5.0743, val_acc: 0.5802\n",
      "Epoch [2194], train_loss: 0.0000, val_loss: 4.9368, val_acc: 0.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2195], train_loss: 0.0000, val_loss: 5.0737, val_acc: 0.5776\n",
      "Epoch [2196], train_loss: 0.0000, val_loss: 5.0170, val_acc: 0.5854\n",
      "Epoch [2197], train_loss: 0.0000, val_loss: 5.0294, val_acc: 0.5828\n",
      "Epoch [2198], train_loss: 0.0000, val_loss: 5.2318, val_acc: 0.5828\n",
      "Epoch [2199], train_loss: 0.0000, val_loss: 4.9193, val_acc: 0.5776\n",
      "Epoch [2200], train_loss: 0.0000, val_loss: 4.8128, val_acc: 0.5802\n",
      "Epoch [2201], train_loss: 0.0000, val_loss: 4.9878, val_acc: 0.5776\n",
      "Epoch [2202], train_loss: 0.0000, val_loss: 5.0784, val_acc: 0.5802\n",
      "Epoch [2203], train_loss: 0.0000, val_loss: 5.0663, val_acc: 0.5750\n",
      "Epoch [2204], train_loss: 0.0000, val_loss: 5.0476, val_acc: 0.5828\n",
      "Epoch [2205], train_loss: 0.0000, val_loss: 5.2000, val_acc: 0.5828\n",
      "Epoch [2206], train_loss: 0.0000, val_loss: 5.1249, val_acc: 0.5802\n",
      "Epoch [2207], train_loss: 0.0000, val_loss: 4.9903, val_acc: 0.5776\n",
      "Epoch [2208], train_loss: 0.0000, val_loss: 5.1810, val_acc: 0.5802\n",
      "Epoch [2209], train_loss: 0.0000, val_loss: 5.0728, val_acc: 0.5828\n",
      "Epoch [2210], train_loss: 0.0000, val_loss: 5.1358, val_acc: 0.5857\n",
      "Epoch [2211], train_loss: 0.0000, val_loss: 5.0801, val_acc: 0.5750\n",
      "Epoch [2212], train_loss: 0.0000, val_loss: 5.1923, val_acc: 0.5750\n",
      "Epoch [2213], train_loss: 0.0000, val_loss: 5.1625, val_acc: 0.5910\n",
      "Epoch [2214], train_loss: 0.0000, val_loss: 5.1600, val_acc: 0.5721\n",
      "Epoch [2215], train_loss: 0.0000, val_loss: 5.0953, val_acc: 0.5776\n",
      "Epoch [2216], train_loss: 0.0000, val_loss: 5.2014, val_acc: 0.5854\n",
      "Epoch [2217], train_loss: 0.0000, val_loss: 4.9713, val_acc: 0.5802\n",
      "Epoch [2218], train_loss: 0.0000, val_loss: 5.1924, val_acc: 0.5802\n",
      "Epoch [2219], train_loss: 0.0000, val_loss: 5.3562, val_acc: 0.5828\n",
      "Epoch [2220], train_loss: 0.0000, val_loss: 5.1954, val_acc: 0.5776\n",
      "Epoch [2221], train_loss: 0.0000, val_loss: 5.4146, val_acc: 0.5802\n",
      "Epoch [2222], train_loss: 0.0000, val_loss: 5.2096, val_acc: 0.5802\n",
      "Epoch [2223], train_loss: 0.0000, val_loss: 5.3087, val_acc: 0.5802\n",
      "Epoch [2224], train_loss: 0.0000, val_loss: 5.4152, val_acc: 0.5991\n",
      "Epoch [2225], train_loss: 0.0000, val_loss: 5.4268, val_acc: 0.5991\n",
      "Epoch [2226], train_loss: 0.0000, val_loss: 5.5256, val_acc: 0.6017\n",
      "Epoch [2227], train_loss: 0.0000, val_loss: 5.4853, val_acc: 0.5828\n",
      "Epoch [2228], train_loss: 0.0000, val_loss: 5.4344, val_acc: 0.5828\n",
      "Epoch [2229], train_loss: 0.0000, val_loss: 5.3566, val_acc: 0.5802\n",
      "Epoch [2230], train_loss: 0.0000, val_loss: 5.3314, val_acc: 0.5802\n",
      "Epoch [2231], train_loss: 0.0000, val_loss: 5.4433, val_acc: 0.5802\n",
      "Epoch [2232], train_loss: 0.0000, val_loss: 5.4113, val_acc: 0.5828\n",
      "Epoch [2233], train_loss: 0.0000, val_loss: 5.4486, val_acc: 0.5802\n",
      "Epoch [2234], train_loss: 0.0000, val_loss: 5.4696, val_acc: 0.5776\n",
      "Epoch [2235], train_loss: 0.0000, val_loss: 5.5076, val_acc: 0.5802\n",
      "Epoch [2236], train_loss: 0.0000, val_loss: 5.5298, val_acc: 0.5802\n",
      "Epoch [2237], train_loss: 0.0000, val_loss: 5.5912, val_acc: 0.5880\n",
      "Epoch [2238], train_loss: 0.0000, val_loss: 5.6005, val_acc: 0.5854\n",
      "Epoch [2239], train_loss: 0.0000, val_loss: 5.5743, val_acc: 0.5854\n",
      "Epoch [2240], train_loss: 0.0000, val_loss: 5.6174, val_acc: 0.5988\n",
      "Epoch [2241], train_loss: 0.0000, val_loss: 5.4480, val_acc: 0.5880\n",
      "Epoch [2242], train_loss: 0.0000, val_loss: 5.4661, val_acc: 0.6017\n",
      "Epoch [2243], train_loss: 0.0000, val_loss: 5.7365, val_acc: 0.5962\n",
      "Epoch [2244], train_loss: 0.0000, val_loss: 5.6606, val_acc: 0.5910\n",
      "Epoch [2245], train_loss: 0.0000, val_loss: 5.5129, val_acc: 0.6017\n",
      "Epoch [2246], train_loss: 0.0000, val_loss: 5.4822, val_acc: 0.5936\n",
      "Epoch [2247], train_loss: 0.0000, val_loss: 5.6356, val_acc: 0.5991\n",
      "Epoch [2248], train_loss: 0.0000, val_loss: 5.7621, val_acc: 0.5854\n",
      "Epoch [2249], train_loss: 0.0000, val_loss: 5.6572, val_acc: 0.5910\n",
      "Epoch [2250], train_loss: 0.0000, val_loss: 5.8411, val_acc: 0.5962\n",
      "Epoch [2251], train_loss: 0.0000, val_loss: 5.8393, val_acc: 0.6017\n",
      "Epoch [2252], train_loss: 0.0000, val_loss: 5.6282, val_acc: 0.5936\n",
      "Epoch [2253], train_loss: 0.0000, val_loss: 5.3345, val_acc: 0.5936\n",
      "Epoch [2254], train_loss: 0.0000, val_loss: 5.6059, val_acc: 0.6017\n",
      "Epoch [2255], train_loss: 0.0000, val_loss: 5.6262, val_acc: 0.6017\n",
      "Epoch [2256], train_loss: 0.0000, val_loss: 5.6805, val_acc: 0.5854\n",
      "Epoch [2257], train_loss: 0.0000, val_loss: 5.6454, val_acc: 0.5991\n",
      "Epoch [2258], train_loss: 0.0000, val_loss: 5.5732, val_acc: 0.5910\n",
      "Epoch [2259], train_loss: 0.0000, val_loss: 5.8440, val_acc: 0.5991\n",
      "Epoch [2260], train_loss: 0.0000, val_loss: 5.7987, val_acc: 0.5936\n",
      "Epoch [2261], train_loss: 0.0000, val_loss: 5.8822, val_acc: 0.5910\n",
      "Epoch [2262], train_loss: 0.0000, val_loss: 5.7351, val_acc: 0.5884\n",
      "Epoch [2263], train_loss: 0.0000, val_loss: 5.6189, val_acc: 0.5910\n",
      "Epoch [2264], train_loss: 0.0000, val_loss: 5.6421, val_acc: 0.5910\n",
      "Epoch [2265], train_loss: 0.0000, val_loss: 5.7243, val_acc: 0.5910\n",
      "Epoch [2266], train_loss: 0.0000, val_loss: 5.7543, val_acc: 0.5910\n",
      "Epoch [2267], train_loss: 0.0000, val_loss: 5.8446, val_acc: 0.5910\n",
      "Epoch [2268], train_loss: 0.0000, val_loss: 5.8265, val_acc: 0.5828\n",
      "Epoch [2269], train_loss: 0.0000, val_loss: 5.5553, val_acc: 0.5991\n",
      "Epoch [2270], train_loss: 0.0000, val_loss: 5.9335, val_acc: 0.5828\n",
      "Epoch [2271], train_loss: 0.0000, val_loss: 5.7154, val_acc: 0.5884\n",
      "Epoch [2272], train_loss: 0.0000, val_loss: 5.6740, val_acc: 0.5910\n",
      "Epoch [2273], train_loss: 0.0000, val_loss: 5.8355, val_acc: 0.5910\n",
      "Epoch [2274], train_loss: 0.0000, val_loss: 5.9064, val_acc: 0.5910\n",
      "Epoch [2275], train_loss: 0.0000, val_loss: 5.8002, val_acc: 0.5828\n",
      "Epoch [2276], train_loss: 0.0000, val_loss: 5.7787, val_acc: 0.5884\n",
      "Epoch [2277], train_loss: 0.0000, val_loss: 5.7952, val_acc: 0.5828\n",
      "Epoch [2278], train_loss: 0.0000, val_loss: 6.1081, val_acc: 0.5884\n",
      "Epoch [2279], train_loss: 0.0000, val_loss: 5.7267, val_acc: 0.5910\n",
      "Epoch [2280], train_loss: 0.0000, val_loss: 6.0326, val_acc: 0.5828\n",
      "Epoch [2281], train_loss: 0.0000, val_loss: 5.6233, val_acc: 0.5910\n",
      "Epoch [2282], train_loss: 0.0000, val_loss: 6.0308, val_acc: 0.5965\n",
      "Epoch [2283], train_loss: 0.0000, val_loss: 5.8301, val_acc: 0.5884\n",
      "Epoch [2284], train_loss: 0.0000, val_loss: 5.9231, val_acc: 0.5857\n",
      "Epoch [2285], train_loss: 0.0000, val_loss: 5.9355, val_acc: 0.5936\n",
      "Epoch [2286], train_loss: 0.0000, val_loss: 6.0452, val_acc: 0.5884\n",
      "Epoch [2287], train_loss: 0.0000, val_loss: 6.0594, val_acc: 0.6017\n",
      "Epoch [2288], train_loss: 0.0000, val_loss: 5.8504, val_acc: 0.5991\n",
      "Epoch [2289], train_loss: 0.0000, val_loss: 5.6223, val_acc: 0.5906\n",
      "Epoch [2290], train_loss: 0.0000, val_loss: 5.6426, val_acc: 0.5936\n",
      "Epoch [2291], train_loss: 0.0000, val_loss: 5.7947, val_acc: 0.5854\n",
      "Epoch [2292], train_loss: 0.1048, val_loss: 2.3671, val_acc: 0.5672\n",
      "Epoch [2293], train_loss: 0.1250, val_loss: 2.3064, val_acc: 0.5890\n",
      "Epoch [2294], train_loss: 0.0845, val_loss: 7.7067, val_acc: 0.5945\n",
      "Epoch [2295], train_loss: 0.0607, val_loss: 2.8001, val_acc: 0.5887\n",
      "Epoch [2296], train_loss: 0.0469, val_loss: 1.7121, val_acc: 0.5939\n",
      "Epoch [2297], train_loss: 0.0266, val_loss: 2.2519, val_acc: 0.5649\n",
      "Epoch [2298], train_loss: 0.0030, val_loss: 3.0061, val_acc: 0.5887\n",
      "Epoch [2299], train_loss: 0.0069, val_loss: 3.0860, val_acc: 0.6017\n",
      "Epoch [2300], train_loss: 0.0078, val_loss: 3.4627, val_acc: 0.6066\n",
      "Epoch [2301], train_loss: 0.0015, val_loss: 3.3597, val_acc: 0.6098\n",
      "Epoch [2302], train_loss: 0.0004, val_loss: 3.5517, val_acc: 0.5880\n",
      "Epoch [2303], train_loss: 0.0002, val_loss: 3.5646, val_acc: 0.5962\n",
      "Epoch [2304], train_loss: 0.0001, val_loss: 3.6591, val_acc: 0.6014\n",
      "Epoch [2305], train_loss: 0.0001, val_loss: 3.6641, val_acc: 0.6043\n",
      "Epoch [2306], train_loss: 0.0000, val_loss: 3.7795, val_acc: 0.5962\n",
      "Epoch [2307], train_loss: 0.0000, val_loss: 3.7347, val_acc: 0.5962\n",
      "Epoch [2308], train_loss: 0.0000, val_loss: 3.7962, val_acc: 0.5854\n",
      "Epoch [2309], train_loss: 0.0000, val_loss: 3.6784, val_acc: 0.5880\n",
      "Epoch [2310], train_loss: 0.0001, val_loss: 3.8268, val_acc: 0.5988\n",
      "Epoch [2311], train_loss: 0.0000, val_loss: 3.8089, val_acc: 0.5965\n",
      "Epoch [2312], train_loss: 0.0000, val_loss: 3.8306, val_acc: 0.5936\n",
      "Epoch [2313], train_loss: 0.0000, val_loss: 3.7334, val_acc: 0.5962\n",
      "Epoch [2314], train_loss: 0.0000, val_loss: 3.8549, val_acc: 0.6017\n",
      "Epoch [2315], train_loss: 0.0008, val_loss: 3.8518, val_acc: 0.5825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2316], train_loss: 0.0663, val_loss: 3.0905, val_acc: 0.6118\n",
      "Epoch [2317], train_loss: 0.0560, val_loss: 2.1777, val_acc: 0.6124\n",
      "Epoch [2318], train_loss: 0.0083, val_loss: 2.5621, val_acc: 0.6069\n",
      "Epoch [2319], train_loss: 0.0026, val_loss: 3.1027, val_acc: 0.6098\n",
      "Epoch [2320], train_loss: 0.0005, val_loss: 3.3154, val_acc: 0.6020\n",
      "Epoch [2321], train_loss: 0.0002, val_loss: 3.5741, val_acc: 0.6046\n",
      "Epoch [2322], train_loss: 0.0002, val_loss: 3.6056, val_acc: 0.6046\n",
      "Epoch [2323], train_loss: 0.0001, val_loss: 3.7893, val_acc: 0.6020\n",
      "Epoch [2324], train_loss: 0.0001, val_loss: 3.9095, val_acc: 0.5991\n",
      "Epoch [2325], train_loss: 0.0000, val_loss: 3.8550, val_acc: 0.5887\n",
      "Epoch [2326], train_loss: 0.0000, val_loss: 3.8270, val_acc: 0.5994\n",
      "Epoch [2327], train_loss: 0.0000, val_loss: 3.9730, val_acc: 0.5861\n",
      "Epoch [2328], train_loss: 0.0000, val_loss: 3.8530, val_acc: 0.5887\n",
      "Epoch [2329], train_loss: 0.0000, val_loss: 3.9248, val_acc: 0.5991\n",
      "Epoch [2330], train_loss: 0.0000, val_loss: 3.9144, val_acc: 0.5913\n",
      "Epoch [2331], train_loss: 0.0000, val_loss: 4.0050, val_acc: 0.5913\n",
      "Epoch [2332], train_loss: 0.0000, val_loss: 4.0167, val_acc: 0.5861\n",
      "Epoch [2333], train_loss: 0.0000, val_loss: 4.0975, val_acc: 0.5991\n",
      "Epoch [2334], train_loss: 0.0000, val_loss: 4.0548, val_acc: 0.5965\n",
      "Epoch [2335], train_loss: 0.0000, val_loss: 4.1697, val_acc: 0.5991\n",
      "Epoch [2336], train_loss: 0.0000, val_loss: 4.1812, val_acc: 0.5994\n",
      "Epoch [2337], train_loss: 0.0000, val_loss: 4.1008, val_acc: 0.5994\n",
      "Epoch [2338], train_loss: 0.0007, val_loss: 4.4922, val_acc: 0.5864\n",
      "Epoch [2339], train_loss: 0.0070, val_loss: 4.9718, val_acc: 0.6098\n",
      "Epoch [2340], train_loss: 0.0075, val_loss: 4.3328, val_acc: 0.5835\n",
      "Epoch [2341], train_loss: 0.0500, val_loss: 1.8796, val_acc: 0.6238\n",
      "Epoch [2342], train_loss: 0.0333, val_loss: 3.4658, val_acc: 0.6072\n",
      "Epoch [2343], train_loss: 0.0025, val_loss: 3.2566, val_acc: 0.6505\n",
      "Epoch [2344], train_loss: 0.0003, val_loss: 3.6625, val_acc: 0.6319\n",
      "Epoch [2345], train_loss: 0.0002, val_loss: 3.8368, val_acc: 0.6397\n",
      "Epoch [2346], train_loss: 0.0001, val_loss: 3.9229, val_acc: 0.6371\n",
      "Epoch [2347], train_loss: 0.0001, val_loss: 4.0344, val_acc: 0.6238\n",
      "Epoch [2348], train_loss: 0.0001, val_loss: 4.2616, val_acc: 0.6345\n",
      "Epoch [2349], train_loss: 0.0000, val_loss: 4.2116, val_acc: 0.6264\n",
      "Epoch [2350], train_loss: 0.0000, val_loss: 4.1833, val_acc: 0.6345\n",
      "Epoch [2351], train_loss: 0.0000, val_loss: 4.3207, val_acc: 0.6345\n",
      "Epoch [2352], train_loss: 0.0000, val_loss: 4.1590, val_acc: 0.6157\n",
      "Epoch [2353], train_loss: 0.0000, val_loss: 4.1362, val_acc: 0.6371\n",
      "Epoch [2354], train_loss: 0.0000, val_loss: 4.3363, val_acc: 0.6371\n",
      "Epoch [2355], train_loss: 0.0000, val_loss: 4.3470, val_acc: 0.6235\n",
      "Epoch [2356], train_loss: 0.0000, val_loss: 4.4316, val_acc: 0.6345\n",
      "Epoch [2357], train_loss: 0.0000, val_loss: 4.4321, val_acc: 0.6209\n",
      "Epoch [2358], train_loss: 0.0000, val_loss: 4.4597, val_acc: 0.6345\n",
      "Epoch [2359], train_loss: 0.0000, val_loss: 4.5142, val_acc: 0.6371\n",
      "Epoch [2360], train_loss: 0.0000, val_loss: 4.6265, val_acc: 0.6319\n",
      "Epoch [2361], train_loss: 0.0000, val_loss: 4.5952, val_acc: 0.6316\n",
      "Epoch [2362], train_loss: 0.0000, val_loss: 4.6038, val_acc: 0.6397\n",
      "Epoch [2363], train_loss: 0.0000, val_loss: 4.6675, val_acc: 0.6345\n",
      "Epoch [2364], train_loss: 0.0000, val_loss: 4.7219, val_acc: 0.6316\n",
      "Epoch [2365], train_loss: 0.0000, val_loss: 4.7201, val_acc: 0.6209\n",
      "Epoch [2366], train_loss: 0.0000, val_loss: 4.7046, val_acc: 0.6264\n",
      "Epoch [2367], train_loss: 0.0000, val_loss: 4.7352, val_acc: 0.6290\n",
      "Epoch [2368], train_loss: 0.0000, val_loss: 4.6689, val_acc: 0.6290\n",
      "Epoch [2369], train_loss: 0.0000, val_loss: 4.7940, val_acc: 0.6345\n",
      "Epoch [2370], train_loss: 0.0000, val_loss: 4.8689, val_acc: 0.6209\n",
      "Epoch [2371], train_loss: 0.0000, val_loss: 4.7878, val_acc: 0.6157\n",
      "Epoch [2372], train_loss: 0.0000, val_loss: 4.8711, val_acc: 0.6131\n",
      "Epoch [2373], train_loss: 0.0000, val_loss: 4.7552, val_acc: 0.6319\n",
      "Epoch [2374], train_loss: 0.0000, val_loss: 4.9147, val_acc: 0.6209\n",
      "Epoch [2375], train_loss: 0.0000, val_loss: 4.9063, val_acc: 0.6238\n",
      "Epoch [2376], train_loss: 0.0000, val_loss: 4.9200, val_acc: 0.6183\n",
      "Epoch [2377], train_loss: 0.0000, val_loss: 4.9683, val_acc: 0.6238\n",
      "Epoch [2378], train_loss: 0.0000, val_loss: 4.8763, val_acc: 0.6183\n",
      "Epoch [2379], train_loss: 0.0000, val_loss: 4.9862, val_acc: 0.6212\n",
      "Epoch [2380], train_loss: 0.0000, val_loss: 5.0060, val_acc: 0.6319\n",
      "Epoch [2381], train_loss: 0.0000, val_loss: 4.9657, val_acc: 0.6290\n",
      "Epoch [2382], train_loss: 0.0001, val_loss: 4.8983, val_acc: 0.6371\n",
      "Epoch [2383], train_loss: 0.0000, val_loss: 4.8059, val_acc: 0.6241\n",
      "Epoch [2384], train_loss: 0.0000, val_loss: 5.2720, val_acc: 0.6316\n",
      "Epoch [2385], train_loss: 0.0000, val_loss: 5.4338, val_acc: 0.6206\n",
      "Epoch [2386], train_loss: 0.0000, val_loss: 5.3564, val_acc: 0.6261\n",
      "Epoch [2387], train_loss: 0.0000, val_loss: 5.4663, val_acc: 0.6235\n",
      "Epoch [2388], train_loss: 0.0000, val_loss: 5.3716, val_acc: 0.6342\n",
      "Epoch [2389], train_loss: 0.0000, val_loss: 5.2865, val_acc: 0.6313\n",
      "Epoch [2390], train_loss: 0.0528, val_loss: 2.3745, val_acc: 0.5695\n",
      "Epoch [2391], train_loss: 0.0577, val_loss: 3.1476, val_acc: 0.5698\n",
      "Epoch [2392], train_loss: 0.0301, val_loss: 1.8597, val_acc: 0.5890\n",
      "Epoch [2393], train_loss: 0.0357, val_loss: 2.8534, val_acc: 0.5675\n",
      "Epoch [2394], train_loss: 0.0018, val_loss: 3.4070, val_acc: 0.5884\n",
      "Epoch [2395], train_loss: 0.0005, val_loss: 3.7594, val_acc: 0.5854\n",
      "Epoch [2396], train_loss: 0.0001, val_loss: 3.9284, val_acc: 0.5776\n",
      "Epoch [2397], train_loss: 0.0001, val_loss: 4.1150, val_acc: 0.5750\n",
      "Epoch [2398], train_loss: 0.0001, val_loss: 4.1758, val_acc: 0.5802\n",
      "Epoch [2399], train_loss: 0.0001, val_loss: 3.9367, val_acc: 0.5750\n",
      "Epoch [2400], train_loss: 0.0001, val_loss: 3.9714, val_acc: 0.5802\n",
      "Epoch [2401], train_loss: 0.0001, val_loss: 4.1848, val_acc: 0.5695\n",
      "Epoch [2402], train_loss: 0.0000, val_loss: 4.3206, val_acc: 0.5773\n",
      "Epoch [2403], train_loss: 0.0000, val_loss: 4.2901, val_acc: 0.5802\n",
      "Epoch [2404], train_loss: 0.0000, val_loss: 4.2756, val_acc: 0.5828\n",
      "Epoch [2405], train_loss: 0.0010, val_loss: 4.4461, val_acc: 0.5805\n",
      "Epoch [2406], train_loss: 0.0451, val_loss: 2.3702, val_acc: 0.5913\n",
      "Epoch [2407], train_loss: 0.0150, val_loss: 3.0853, val_acc: 0.5669\n",
      "Epoch [2408], train_loss: 0.0308, val_loss: 3.3049, val_acc: 0.5939\n",
      "Epoch [2409], train_loss: 0.0017, val_loss: 3.8852, val_acc: 0.5913\n",
      "Epoch [2410], train_loss: 0.0004, val_loss: 4.3652, val_acc: 0.5698\n",
      "Epoch [2411], train_loss: 0.0003, val_loss: 4.3747, val_acc: 0.5831\n",
      "Epoch [2412], train_loss: 0.0001, val_loss: 4.3731, val_acc: 0.5805\n",
      "Epoch [2413], train_loss: 0.0001, val_loss: 4.3836, val_acc: 0.5779\n",
      "Epoch [2414], train_loss: 0.0001, val_loss: 4.5564, val_acc: 0.5939\n",
      "Epoch [2415], train_loss: 0.0001, val_loss: 4.9322, val_acc: 0.5887\n",
      "Epoch [2416], train_loss: 0.0001, val_loss: 4.8395, val_acc: 0.5805\n",
      "Epoch [2417], train_loss: 0.0001, val_loss: 4.8010, val_acc: 0.5756\n",
      "Epoch [2418], train_loss: 0.0000, val_loss: 4.9901, val_acc: 0.5890\n",
      "Epoch [2419], train_loss: 0.0000, val_loss: 4.8895, val_acc: 0.5890\n",
      "Epoch [2420], train_loss: 0.0000, val_loss: 4.8150, val_acc: 0.5838\n",
      "Epoch [2421], train_loss: 0.0000, val_loss: 4.8059, val_acc: 0.5783\n",
      "Epoch [2422], train_loss: 0.0000, val_loss: 4.8864, val_acc: 0.5916\n",
      "Epoch [2423], train_loss: 0.0000, val_loss: 4.9874, val_acc: 0.5890\n",
      "Epoch [2424], train_loss: 0.0000, val_loss: 4.9405, val_acc: 0.5887\n",
      "Epoch [2425], train_loss: 0.0000, val_loss: 5.0809, val_acc: 0.5864\n",
      "Epoch [2426], train_loss: 0.0000, val_loss: 4.9775, val_acc: 0.5942\n",
      "Epoch [2427], train_loss: 0.0000, val_loss: 5.0279, val_acc: 0.5916\n",
      "Epoch [2428], train_loss: 0.0000, val_loss: 5.0730, val_acc: 0.5916\n",
      "Epoch [2429], train_loss: 0.0000, val_loss: 5.1069, val_acc: 0.5942\n",
      "Epoch [2430], train_loss: 0.0000, val_loss: 5.0440, val_acc: 0.5890\n",
      "Epoch [2431], train_loss: 0.0000, val_loss: 4.9082, val_acc: 0.5864\n",
      "Epoch [2432], train_loss: 0.0000, val_loss: 5.0187, val_acc: 0.5783\n",
      "Epoch [2433], train_loss: 0.0000, val_loss: 5.1252, val_acc: 0.5835\n",
      "Epoch [2434], train_loss: 0.0000, val_loss: 5.0964, val_acc: 0.5835\n",
      "Epoch [2435], train_loss: 0.0000, val_loss: 5.1449, val_acc: 0.5887\n",
      "Epoch [2436], train_loss: 0.0000, val_loss: 5.2027, val_acc: 0.5861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2437], train_loss: 0.0000, val_loss: 5.2020, val_acc: 0.5835\n",
      "Epoch [2438], train_loss: 0.0000, val_loss: 5.2175, val_acc: 0.5809\n",
      "Epoch [2439], train_loss: 0.0000, val_loss: 5.2141, val_acc: 0.5916\n",
      "Epoch [2440], train_loss: 0.0000, val_loss: 5.2838, val_acc: 0.5942\n",
      "Epoch [2441], train_loss: 0.0000, val_loss: 5.2574, val_acc: 0.5887\n",
      "Epoch [2442], train_loss: 0.0000, val_loss: 5.3806, val_acc: 0.5861\n",
      "Epoch [2443], train_loss: 0.0000, val_loss: 5.2712, val_acc: 0.5861\n",
      "Epoch [2444], train_loss: 0.0000, val_loss: 5.3398, val_acc: 0.5968\n",
      "Epoch [2445], train_loss: 0.0000, val_loss: 5.3744, val_acc: 0.5942\n",
      "Epoch [2446], train_loss: 0.0000, val_loss: 5.1664, val_acc: 0.5887\n",
      "Epoch [2447], train_loss: 0.0000, val_loss: 5.4219, val_acc: 0.5861\n",
      "Epoch [2448], train_loss: 0.0000, val_loss: 5.3026, val_acc: 0.5861\n",
      "Epoch [2449], train_loss: 0.0000, val_loss: 5.5060, val_acc: 0.5942\n",
      "Epoch [2450], train_loss: 0.0000, val_loss: 5.3247, val_acc: 0.5942\n",
      "Epoch [2451], train_loss: 0.0000, val_loss: 5.5147, val_acc: 0.5861\n",
      "Epoch [2452], train_loss: 0.0000, val_loss: 5.3677, val_acc: 0.5994\n",
      "Epoch [2453], train_loss: 0.0000, val_loss: 5.3454, val_acc: 0.5887\n",
      "Epoch [2454], train_loss: 0.0000, val_loss: 5.4187, val_acc: 0.5939\n",
      "Epoch [2455], train_loss: 0.0000, val_loss: 5.3367, val_acc: 0.5942\n",
      "Epoch [2456], train_loss: 0.0000, val_loss: 4.8858, val_acc: 0.5968\n",
      "Epoch [2457], train_loss: 0.0000, val_loss: 5.2085, val_acc: 0.6101\n",
      "Epoch [2458], train_loss: 0.0000, val_loss: 5.2864, val_acc: 0.6049\n",
      "Epoch [2459], train_loss: 0.0000, val_loss: 5.4520, val_acc: 0.5968\n",
      "Epoch [2460], train_loss: 0.0000, val_loss: 5.5595, val_acc: 0.5968\n",
      "Epoch [2461], train_loss: 0.0000, val_loss: 5.4824, val_acc: 0.5994\n",
      "Epoch [2462], train_loss: 0.0000, val_loss: 5.4899, val_acc: 0.5994\n",
      "Epoch [2463], train_loss: 0.0000, val_loss: 5.5511, val_acc: 0.6101\n",
      "Epoch [2464], train_loss: 0.0000, val_loss: 5.5615, val_acc: 0.6101\n",
      "Epoch [2465], train_loss: 0.0000, val_loss: 5.6181, val_acc: 0.5994\n",
      "Epoch [2466], train_loss: 0.0000, val_loss: 5.5186, val_acc: 0.6049\n",
      "Epoch [2467], train_loss: 0.0000, val_loss: 5.4837, val_acc: 0.6075\n",
      "Epoch [2468], train_loss: 0.0000, val_loss: 5.7529, val_acc: 0.6049\n",
      "Epoch [2469], train_loss: 0.0000, val_loss: 5.6543, val_acc: 0.6049\n",
      "Epoch [2470], train_loss: 0.0000, val_loss: 5.6899, val_acc: 0.6023\n",
      "Epoch [2471], train_loss: 0.0000, val_loss: 5.8885, val_acc: 0.6101\n",
      "Epoch [2472], train_loss: 0.0000, val_loss: 5.6298, val_acc: 0.6049\n",
      "Epoch [2473], train_loss: 0.0000, val_loss: 5.6950, val_acc: 0.6101\n",
      "Epoch [2474], train_loss: 0.0000, val_loss: 5.7163, val_acc: 0.6049\n",
      "Epoch [2475], train_loss: 0.0000, val_loss: 5.8225, val_acc: 0.6101\n",
      "Epoch [2476], train_loss: 0.0000, val_loss: 5.9414, val_acc: 0.6049\n",
      "Epoch [2477], train_loss: 0.0000, val_loss: 5.7451, val_acc: 0.6049\n",
      "Epoch [2478], train_loss: 0.0000, val_loss: 5.7828, val_acc: 0.6049\n",
      "Epoch [2479], train_loss: 0.0000, val_loss: 5.6713, val_acc: 0.6049\n",
      "Epoch [2480], train_loss: 0.0000, val_loss: 5.6883, val_acc: 0.6075\n",
      "Epoch [2481], train_loss: 0.0016, val_loss: 4.8096, val_acc: 0.5890\n",
      "Epoch [2482], train_loss: 0.1039, val_loss: 2.2048, val_acc: 0.5698\n",
      "Epoch [2483], train_loss: 0.0403, val_loss: 2.3730, val_acc: 0.5626\n",
      "Epoch [2484], train_loss: 0.0241, val_loss: 3.5758, val_acc: 0.6209\n",
      "Epoch [2485], train_loss: 0.0082, val_loss: 4.1775, val_acc: 0.5965\n",
      "Epoch [2486], train_loss: 0.0019, val_loss: 4.2194, val_acc: 0.5597\n",
      "Epoch [2487], train_loss: 0.0005, val_loss: 4.6554, val_acc: 0.5887\n",
      "Epoch [2488], train_loss: 0.0002, val_loss: 4.3104, val_acc: 0.5542\n",
      "Epoch [2489], train_loss: 0.0001, val_loss: 4.6182, val_acc: 0.5568\n",
      "Epoch [2490], train_loss: 0.0001, val_loss: 4.4876, val_acc: 0.5756\n",
      "Epoch [2491], train_loss: 0.0000, val_loss: 4.8199, val_acc: 0.5594\n",
      "Epoch [2492], train_loss: 0.0000, val_loss: 4.6353, val_acc: 0.5675\n",
      "Epoch [2493], train_loss: 0.0000, val_loss: 4.7754, val_acc: 0.5649\n",
      "Epoch [2494], train_loss: 0.0000, val_loss: 4.7993, val_acc: 0.5675\n",
      "Epoch [2495], train_loss: 0.0000, val_loss: 4.8920, val_acc: 0.5675\n",
      "Epoch [2496], train_loss: 0.0000, val_loss: 4.9523, val_acc: 0.5727\n",
      "Epoch [2497], train_loss: 0.0000, val_loss: 4.9187, val_acc: 0.5568\n",
      "Epoch [2498], train_loss: 0.0000, val_loss: 4.7801, val_acc: 0.5646\n",
      "Epoch [2499], train_loss: 0.0000, val_loss: 5.0016, val_acc: 0.5727\n",
      "Epoch [2500], train_loss: 0.0000, val_loss: 5.0322, val_acc: 0.5701\n",
      "Epoch [2501], train_loss: 0.0000, val_loss: 5.1501, val_acc: 0.5727\n",
      "Epoch [2502], train_loss: 0.0000, val_loss: 5.1263, val_acc: 0.5809\n",
      "Epoch [2503], train_loss: 0.0000, val_loss: 5.0116, val_acc: 0.5861\n",
      "Epoch [2504], train_loss: 0.0000, val_loss: 5.1855, val_acc: 0.5809\n",
      "Epoch [2505], train_loss: 0.0000, val_loss: 5.2887, val_acc: 0.5753\n",
      "Epoch [2506], train_loss: 0.0002, val_loss: 5.0846, val_acc: 0.5887\n",
      "Epoch [2507], train_loss: 0.0004, val_loss: 5.6290, val_acc: 0.6049\n",
      "Epoch [2508], train_loss: 0.0001, val_loss: 5.5448, val_acc: 0.6075\n",
      "Epoch [2509], train_loss: 0.0000, val_loss: 5.7409, val_acc: 0.6020\n",
      "Epoch [2510], train_loss: 0.0000, val_loss: 5.7074, val_acc: 0.6020\n",
      "Epoch [2511], train_loss: 0.0000, val_loss: 6.0291, val_acc: 0.6049\n",
      "Epoch [2512], train_loss: 0.0000, val_loss: 6.0860, val_acc: 0.6023\n",
      "Epoch [2513], train_loss: 0.0000, val_loss: 5.9391, val_acc: 0.5968\n",
      "Epoch [2514], train_loss: 0.0000, val_loss: 5.8919, val_acc: 0.6020\n",
      "Epoch [2515], train_loss: 0.0000, val_loss: 5.9681, val_acc: 0.5968\n",
      "Epoch [2516], train_loss: 0.0000, val_loss: 6.0864, val_acc: 0.6049\n",
      "Epoch [2517], train_loss: 0.0000, val_loss: 6.1912, val_acc: 0.5916\n",
      "Epoch [2518], train_loss: 0.0000, val_loss: 6.0528, val_acc: 0.6020\n",
      "Epoch [2519], train_loss: 0.0000, val_loss: 6.0798, val_acc: 0.5968\n",
      "Epoch [2520], train_loss: 0.0000, val_loss: 6.2373, val_acc: 0.6049\n",
      "Epoch [2521], train_loss: 0.0000, val_loss: 5.8656, val_acc: 0.5994\n",
      "Epoch [2522], train_loss: 0.0000, val_loss: 6.0271, val_acc: 0.5916\n",
      "Epoch [2523], train_loss: 0.0000, val_loss: 6.2374, val_acc: 0.6023\n",
      "Epoch [2524], train_loss: 0.0000, val_loss: 6.1997, val_acc: 0.5727\n",
      "Epoch [2525], train_loss: 0.0000, val_loss: 6.0224, val_acc: 0.5805\n",
      "Epoch [2526], train_loss: 0.0000, val_loss: 6.1534, val_acc: 0.5857\n",
      "Epoch [2527], train_loss: 0.0000, val_loss: 6.2293, val_acc: 0.5835\n",
      "Epoch [2528], train_loss: 0.0000, val_loss: 6.2188, val_acc: 0.5884\n",
      "Epoch [2529], train_loss: 0.0000, val_loss: 6.1089, val_acc: 0.5861\n",
      "Epoch [2530], train_loss: 0.0000, val_loss: 6.3595, val_acc: 0.5831\n",
      "Epoch [2531], train_loss: 0.0000, val_loss: 6.5535, val_acc: 0.5913\n",
      "Epoch [2532], train_loss: 0.0000, val_loss: 6.3373, val_acc: 0.5887\n",
      "Epoch [2533], train_loss: 0.0000, val_loss: 6.3374, val_acc: 0.5779\n",
      "Epoch [2534], train_loss: 0.0000, val_loss: 6.2122, val_acc: 0.5887\n",
      "Epoch [2535], train_loss: 0.0000, val_loss: 6.4114, val_acc: 0.5861\n",
      "Epoch [2536], train_loss: 0.0000, val_loss: 6.4254, val_acc: 0.5779\n",
      "Epoch [2537], train_loss: 0.0000, val_loss: 6.4217, val_acc: 0.5727\n",
      "Epoch [2538], train_loss: 0.0000, val_loss: 6.4285, val_acc: 0.5701\n",
      "Epoch [2539], train_loss: 0.0000, val_loss: 6.4467, val_acc: 0.5727\n",
      "Epoch [2540], train_loss: 0.0000, val_loss: 6.5611, val_acc: 0.5809\n",
      "Epoch [2541], train_loss: 0.0000, val_loss: 6.3773, val_acc: 0.5727\n",
      "Epoch [2542], train_loss: 0.0000, val_loss: 6.3895, val_acc: 0.5805\n",
      "Epoch [2543], train_loss: 0.0000, val_loss: 6.4930, val_acc: 0.5779\n",
      "Epoch [2544], train_loss: 0.0000, val_loss: 6.3544, val_acc: 0.5753\n",
      "Epoch [2545], train_loss: 0.0000, val_loss: 6.4546, val_acc: 0.5753\n",
      "Epoch [2546], train_loss: 0.0000, val_loss: 6.5767, val_acc: 0.5779\n",
      "Epoch [2547], train_loss: 0.0000, val_loss: 6.5802, val_acc: 0.5727\n",
      "Epoch [2548], train_loss: 0.0000, val_loss: 6.6912, val_acc: 0.5809\n",
      "Epoch [2549], train_loss: 0.0000, val_loss: 6.5016, val_acc: 0.5942\n",
      "Epoch [2550], train_loss: 0.0000, val_loss: 6.6402, val_acc: 0.5805\n",
      "Epoch [2551], train_loss: 0.0000, val_loss: 6.6350, val_acc: 0.5779\n",
      "Epoch [2552], train_loss: 0.0000, val_loss: 6.6216, val_acc: 0.5724\n",
      "Epoch [2553], train_loss: 0.0000, val_loss: 6.5172, val_acc: 0.5779\n",
      "Epoch [2554], train_loss: 0.0000, val_loss: 6.4352, val_acc: 0.5727\n",
      "Epoch [2555], train_loss: 0.0000, val_loss: 6.6726, val_acc: 0.5727\n",
      "Epoch [2556], train_loss: 0.0000, val_loss: 6.7100, val_acc: 0.5753\n",
      "Epoch [2557], train_loss: 0.0000, val_loss: 6.5435, val_acc: 0.5779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2558], train_loss: 0.0000, val_loss: 6.5830, val_acc: 0.5698\n",
      "Epoch [2559], train_loss: 0.0000, val_loss: 6.6518, val_acc: 0.5779\n",
      "Epoch [2560], train_loss: 0.0000, val_loss: 6.5934, val_acc: 0.5698\n",
      "Epoch [2561], train_loss: 0.0001, val_loss: 5.9945, val_acc: 0.5727\n",
      "Epoch [2562], train_loss: 0.0761, val_loss: 2.3443, val_acc: 0.6052\n",
      "Epoch [2563], train_loss: 0.1162, val_loss: 1.6791, val_acc: 0.6121\n",
      "Epoch [2564], train_loss: 0.0392, val_loss: 1.8241, val_acc: 0.6023\n",
      "Epoch [2565], train_loss: 0.0428, val_loss: 2.3327, val_acc: 0.6127\n",
      "Epoch [2566], train_loss: 0.0033, val_loss: 3.1395, val_acc: 0.6072\n",
      "Epoch [2567], train_loss: 0.0002, val_loss: 3.2009, val_acc: 0.6046\n",
      "Epoch [2568], train_loss: 0.0001, val_loss: 3.3087, val_acc: 0.6183\n",
      "Epoch [2569], train_loss: 0.0001, val_loss: 3.5085, val_acc: 0.6209\n",
      "Epoch [2570], train_loss: 0.0001, val_loss: 3.4047, val_acc: 0.6049\n",
      "Epoch [2571], train_loss: 0.0001, val_loss: 3.5337, val_acc: 0.6264\n",
      "Epoch [2572], train_loss: 0.0000, val_loss: 3.6286, val_acc: 0.6131\n",
      "Epoch [2573], train_loss: 0.0000, val_loss: 3.4785, val_acc: 0.6131\n",
      "Epoch [2574], train_loss: 0.0000, val_loss: 3.6478, val_acc: 0.6157\n",
      "Epoch [2575], train_loss: 0.0000, val_loss: 3.7512, val_acc: 0.6290\n",
      "Epoch [2576], train_loss: 0.0000, val_loss: 3.7574, val_acc: 0.6212\n",
      "Epoch [2577], train_loss: 0.0000, val_loss: 3.8715, val_acc: 0.6157\n",
      "Epoch [2578], train_loss: 0.0000, val_loss: 3.8299, val_acc: 0.6157\n",
      "Epoch [2579], train_loss: 0.0000, val_loss: 3.7906, val_acc: 0.6023\n",
      "Epoch [2580], train_loss: 0.0000, val_loss: 3.8616, val_acc: 0.6049\n",
      "Epoch [2581], train_loss: 0.0001, val_loss: 3.8305, val_acc: 0.6183\n",
      "Epoch [2582], train_loss: 0.0001, val_loss: 3.8268, val_acc: 0.6101\n",
      "Epoch [2583], train_loss: 0.0000, val_loss: 3.9033, val_acc: 0.6235\n",
      "Epoch [2584], train_loss: 0.0000, val_loss: 3.9339, val_acc: 0.6101\n",
      "Epoch [2585], train_loss: 0.0000, val_loss: 4.0177, val_acc: 0.6209\n",
      "Epoch [2586], train_loss: 0.0000, val_loss: 3.8918, val_acc: 0.6238\n",
      "Epoch [2587], train_loss: 0.0001, val_loss: 4.3302, val_acc: 0.6261\n",
      "Epoch [2588], train_loss: 0.0000, val_loss: 4.3424, val_acc: 0.6179\n",
      "Epoch [2589], train_loss: 0.0000, val_loss: 4.3902, val_acc: 0.6153\n",
      "Epoch [2590], train_loss: 0.0000, val_loss: 4.4255, val_acc: 0.6179\n",
      "Epoch [2591], train_loss: 0.0000, val_loss: 4.2945, val_acc: 0.6127\n",
      "Epoch [2592], train_loss: 0.0000, val_loss: 4.4131, val_acc: 0.6127\n",
      "Epoch [2593], train_loss: 0.0000, val_loss: 4.3057, val_acc: 0.6127\n",
      "Epoch [2594], train_loss: 0.0000, val_loss: 4.3685, val_acc: 0.6046\n",
      "Epoch [2595], train_loss: 0.0000, val_loss: 4.3109, val_acc: 0.6072\n",
      "Epoch [2596], train_loss: 0.0000, val_loss: 4.3694, val_acc: 0.6153\n",
      "Epoch [2597], train_loss: 0.0000, val_loss: 4.3723, val_acc: 0.6209\n",
      "Epoch [2598], train_loss: 0.0000, val_loss: 4.4180, val_acc: 0.6153\n",
      "Epoch [2599], train_loss: 0.0000, val_loss: 4.4496, val_acc: 0.6179\n",
      "Epoch [2600], train_loss: 0.0000, val_loss: 4.4616, val_acc: 0.6098\n",
      "Epoch [2601], train_loss: 0.0000, val_loss: 4.3803, val_acc: 0.6046\n",
      "Epoch [2602], train_loss: 0.0000, val_loss: 4.6142, val_acc: 0.6020\n",
      "Epoch [2603], train_loss: 0.0000, val_loss: 4.6513, val_acc: 0.6179\n",
      "Epoch [2604], train_loss: 0.0000, val_loss: 4.4478, val_acc: 0.6179\n",
      "Epoch [2605], train_loss: 0.0000, val_loss: 4.4913, val_acc: 0.6072\n",
      "Epoch [2606], train_loss: 0.0000, val_loss: 4.6048, val_acc: 0.6098\n",
      "Epoch [2607], train_loss: 0.0000, val_loss: 4.5111, val_acc: 0.6046\n",
      "Epoch [2608], train_loss: 0.0000, val_loss: 4.6205, val_acc: 0.6072\n",
      "Epoch [2609], train_loss: 0.0000, val_loss: 4.5051, val_acc: 0.6046\n",
      "Epoch [2610], train_loss: 0.0000, val_loss: 4.5740, val_acc: 0.6046\n",
      "Epoch [2611], train_loss: 0.0000, val_loss: 4.6322, val_acc: 0.6179\n",
      "Epoch [2612], train_loss: 0.0000, val_loss: 4.5331, val_acc: 0.6072\n",
      "Epoch [2613], train_loss: 0.0000, val_loss: 4.7274, val_acc: 0.6098\n",
      "Epoch [2614], train_loss: 0.0000, val_loss: 4.6615, val_acc: 0.6127\n",
      "Epoch [2615], train_loss: 0.0000, val_loss: 4.7372, val_acc: 0.6153\n",
      "Epoch [2616], train_loss: 0.0002, val_loss: 4.6361, val_acc: 0.6183\n",
      "Epoch [2617], train_loss: 0.0159, val_loss: 5.2583, val_acc: 0.6124\n",
      "Epoch [2618], train_loss: 0.0683, val_loss: 2.3590, val_acc: 0.6365\n",
      "Epoch [2619], train_loss: 0.0132, val_loss: 3.9400, val_acc: 0.6153\n",
      "Epoch [2620], train_loss: 0.0100, val_loss: 2.4645, val_acc: 0.6098\n",
      "Epoch [2621], train_loss: 0.0204, val_loss: 3.3819, val_acc: 0.6131\n",
      "Epoch [2622], train_loss: 0.0133, val_loss: 4.6874, val_acc: 0.6023\n",
      "Epoch [2623], train_loss: 0.0209, val_loss: 2.6761, val_acc: 0.5942\n",
      "Epoch [2624], train_loss: 0.0117, val_loss: 2.3481, val_acc: 0.6258\n",
      "Epoch [2625], train_loss: 0.0353, val_loss: 3.1860, val_acc: 0.5913\n",
      "Epoch [2626], train_loss: 0.0237, val_loss: 3.2707, val_acc: 0.5994\n",
      "Epoch [2627], train_loss: 0.0025, val_loss: 3.0524, val_acc: 0.6017\n",
      "Epoch [2628], train_loss: 0.0005, val_loss: 3.6320, val_acc: 0.6043\n",
      "Epoch [2629], train_loss: 0.0002, val_loss: 3.7357, val_acc: 0.5910\n",
      "Epoch [2630], train_loss: 0.0001, val_loss: 3.7499, val_acc: 0.6017\n",
      "Epoch [2631], train_loss: 0.0001, val_loss: 3.7851, val_acc: 0.5962\n",
      "Epoch [2632], train_loss: 0.0001, val_loss: 3.9561, val_acc: 0.6017\n",
      "Epoch [2633], train_loss: 0.0000, val_loss: 3.9693, val_acc: 0.6121\n",
      "Epoch [2634], train_loss: 0.0001, val_loss: 3.9925, val_acc: 0.6095\n",
      "Epoch [2635], train_loss: 0.0000, val_loss: 4.1725, val_acc: 0.6043\n",
      "Epoch [2636], train_loss: 0.0001, val_loss: 4.1320, val_acc: 0.6017\n",
      "Epoch [2637], train_loss: 0.0000, val_loss: 4.0899, val_acc: 0.6017\n",
      "Epoch [2638], train_loss: 0.0000, val_loss: 4.1503, val_acc: 0.6121\n",
      "Epoch [2639], train_loss: 0.0000, val_loss: 4.2844, val_acc: 0.6147\n",
      "Epoch [2640], train_loss: 0.0000, val_loss: 4.0976, val_acc: 0.5991\n",
      "Epoch [2641], train_loss: 0.0000, val_loss: 4.2271, val_acc: 0.6095\n",
      "Epoch [2642], train_loss: 0.0000, val_loss: 4.2996, val_acc: 0.6069\n",
      "Epoch [2643], train_loss: 0.0000, val_loss: 4.2306, val_acc: 0.6121\n",
      "Epoch [2644], train_loss: 0.0000, val_loss: 4.2138, val_acc: 0.6069\n",
      "Epoch [2645], train_loss: 0.0000, val_loss: 4.2939, val_acc: 0.6095\n",
      "Epoch [2646], train_loss: 0.0000, val_loss: 4.3199, val_acc: 0.6095\n",
      "Epoch [2647], train_loss: 0.0000, val_loss: 4.3282, val_acc: 0.6095\n",
      "Epoch [2648], train_loss: 0.0000, val_loss: 4.3942, val_acc: 0.6069\n",
      "Epoch [2649], train_loss: 0.0000, val_loss: 4.6178, val_acc: 0.5880\n",
      "Epoch [2650], train_loss: 0.0000, val_loss: 4.4697, val_acc: 0.6095\n",
      "Epoch [2651], train_loss: 0.0000, val_loss: 4.4558, val_acc: 0.6176\n",
      "Epoch [2652], train_loss: 0.0000, val_loss: 4.4960, val_acc: 0.5962\n",
      "Epoch [2653], train_loss: 0.0000, val_loss: 4.6127, val_acc: 0.6121\n",
      "Epoch [2654], train_loss: 0.0000, val_loss: 4.5791, val_acc: 0.6014\n",
      "Epoch [2655], train_loss: 0.0000, val_loss: 4.6208, val_acc: 0.6069\n",
      "Epoch [2656], train_loss: 0.0000, val_loss: 4.6638, val_acc: 0.6124\n",
      "Epoch [2657], train_loss: 0.0000, val_loss: 4.5434, val_acc: 0.6121\n",
      "Epoch [2658], train_loss: 0.0000, val_loss: 4.6626, val_acc: 0.6069\n",
      "Epoch [2659], train_loss: 0.0000, val_loss: 4.6936, val_acc: 0.6043\n",
      "Epoch [2660], train_loss: 0.0000, val_loss: 4.7767, val_acc: 0.6150\n",
      "Epoch [2661], train_loss: 0.0000, val_loss: 4.5899, val_acc: 0.6176\n",
      "Epoch [2662], train_loss: 0.0000, val_loss: 4.7481, val_acc: 0.6069\n",
      "Epoch [2663], train_loss: 0.0000, val_loss: 4.7031, val_acc: 0.6043\n",
      "Epoch [2664], train_loss: 0.0000, val_loss: 4.7811, val_acc: 0.6095\n",
      "Epoch [2665], train_loss: 0.0000, val_loss: 4.8127, val_acc: 0.5936\n",
      "Epoch [2666], train_loss: 0.0000, val_loss: 4.9587, val_acc: 0.5988\n",
      "Epoch [2667], train_loss: 0.0000, val_loss: 4.6473, val_acc: 0.6095\n",
      "Epoch [2668], train_loss: 0.0000, val_loss: 4.7828, val_acc: 0.6017\n",
      "Epoch [2669], train_loss: 0.0000, val_loss: 4.7445, val_acc: 0.6069\n",
      "Epoch [2670], train_loss: 0.0000, val_loss: 4.9355, val_acc: 0.5988\n",
      "Epoch [2671], train_loss: 0.0000, val_loss: 4.9898, val_acc: 0.5962\n",
      "Epoch [2672], train_loss: 0.0000, val_loss: 4.8216, val_acc: 0.5988\n",
      "Epoch [2673], train_loss: 0.0000, val_loss: 4.7584, val_acc: 0.6017\n",
      "Epoch [2674], train_loss: 0.0000, val_loss: 4.9733, val_acc: 0.5988\n",
      "Epoch [2675], train_loss: 0.0000, val_loss: 4.8946, val_acc: 0.6043\n",
      "Epoch [2676], train_loss: 0.0000, val_loss: 4.8606, val_acc: 0.5936\n",
      "Epoch [2677], train_loss: 0.0000, val_loss: 4.8208, val_acc: 0.5936\n",
      "Epoch [2678], train_loss: 0.0000, val_loss: 4.8952, val_acc: 0.5962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2679], train_loss: 0.0000, val_loss: 4.8346, val_acc: 0.5962\n",
      "Epoch [2680], train_loss: 0.0000, val_loss: 5.0829, val_acc: 0.5962\n",
      "Epoch [2681], train_loss: 0.0000, val_loss: 5.0591, val_acc: 0.5962\n",
      "Epoch [2682], train_loss: 0.0000, val_loss: 4.8773, val_acc: 0.5910\n",
      "Epoch [2683], train_loss: 0.0000, val_loss: 4.9660, val_acc: 0.6043\n",
      "Epoch [2684], train_loss: 0.0000, val_loss: 4.9549, val_acc: 0.6017\n",
      "Epoch [2685], train_loss: 0.0000, val_loss: 5.0763, val_acc: 0.6017\n",
      "Epoch [2686], train_loss: 0.0000, val_loss: 5.0182, val_acc: 0.6043\n",
      "Epoch [2687], train_loss: 0.0000, val_loss: 5.1658, val_acc: 0.6069\n",
      "Epoch [2688], train_loss: 0.0000, val_loss: 4.9317, val_acc: 0.6069\n",
      "Epoch [2689], train_loss: 0.0000, val_loss: 5.0231, val_acc: 0.6043\n",
      "Epoch [2690], train_loss: 0.0000, val_loss: 5.1163, val_acc: 0.5991\n",
      "Epoch [2691], train_loss: 0.0000, val_loss: 5.2658, val_acc: 0.6069\n",
      "Epoch [2692], train_loss: 0.0000, val_loss: 5.0325, val_acc: 0.6069\n",
      "Epoch [2693], train_loss: 0.0000, val_loss: 5.2407, val_acc: 0.6043\n",
      "Epoch [2694], train_loss: 0.0000, val_loss: 5.2262, val_acc: 0.6069\n",
      "Epoch [2695], train_loss: 0.0000, val_loss: 5.2401, val_acc: 0.6043\n",
      "Epoch [2696], train_loss: 0.0000, val_loss: 5.0591, val_acc: 0.6043\n",
      "Epoch [2697], train_loss: 0.0000, val_loss: 5.2249, val_acc: 0.6043\n",
      "Epoch [2698], train_loss: 0.0000, val_loss: 5.1899, val_acc: 0.5991\n",
      "Epoch [2699], train_loss: 0.0000, val_loss: 5.4025, val_acc: 0.6043\n",
      "Epoch [2700], train_loss: 0.0000, val_loss: 5.3294, val_acc: 0.6017\n",
      "Epoch [2701], train_loss: 0.0000, val_loss: 5.1974, val_acc: 0.5965\n",
      "Epoch [2702], train_loss: 0.0000, val_loss: 5.1694, val_acc: 0.5991\n",
      "Epoch [2703], train_loss: 0.0000, val_loss: 5.2918, val_acc: 0.6098\n",
      "Epoch [2704], train_loss: 0.0000, val_loss: 5.3211, val_acc: 0.6124\n",
      "Epoch [2705], train_loss: 0.0000, val_loss: 5.2673, val_acc: 0.5991\n",
      "Epoch [2706], train_loss: 0.0000, val_loss: 5.1682, val_acc: 0.5939\n",
      "Epoch [2707], train_loss: 0.0000, val_loss: 5.3207, val_acc: 0.5965\n",
      "Epoch [2708], train_loss: 0.0000, val_loss: 5.3100, val_acc: 0.6017\n",
      "Epoch [2709], train_loss: 0.0000, val_loss: 5.2231, val_acc: 0.6017\n",
      "Epoch [2710], train_loss: 0.0000, val_loss: 5.4527, val_acc: 0.5965\n",
      "Epoch [2711], train_loss: 0.0000, val_loss: 5.3548, val_acc: 0.5965\n",
      "Epoch [2712], train_loss: 0.0037, val_loss: 11.4460, val_acc: 0.5698\n",
      "Epoch [2713], train_loss: 0.0863, val_loss: 2.3633, val_acc: 0.6046\n",
      "Epoch [2714], train_loss: 0.0708, val_loss: 5.1628, val_acc: 0.5880\n",
      "Epoch [2715], train_loss: 0.0620, val_loss: 2.7130, val_acc: 0.5854\n",
      "Epoch [2716], train_loss: 0.0086, val_loss: 3.2228, val_acc: 0.5936\n",
      "Epoch [2717], train_loss: 0.0016, val_loss: 4.0977, val_acc: 0.6017\n",
      "Epoch [2718], train_loss: 0.0007, val_loss: 3.8306, val_acc: 0.5854\n",
      "Epoch [2719], train_loss: 0.0003, val_loss: 3.9701, val_acc: 0.5724\n",
      "Epoch [2720], train_loss: 0.0001, val_loss: 4.0286, val_acc: 0.5776\n",
      "Epoch [2721], train_loss: 0.0001, val_loss: 4.0470, val_acc: 0.5724\n",
      "Epoch [2722], train_loss: 0.0001, val_loss: 3.9230, val_acc: 0.5776\n",
      "Epoch [2723], train_loss: 0.0000, val_loss: 4.0598, val_acc: 0.5724\n",
      "Epoch [2724], train_loss: 0.0001, val_loss: 4.1478, val_acc: 0.5724\n",
      "Epoch [2725], train_loss: 0.0000, val_loss: 4.1770, val_acc: 0.5698\n",
      "Epoch [2726], train_loss: 0.0000, val_loss: 4.2765, val_acc: 0.5750\n",
      "Epoch [2727], train_loss: 0.0000, val_loss: 4.1459, val_acc: 0.5724\n",
      "Epoch [2728], train_loss: 0.0000, val_loss: 4.2403, val_acc: 0.5724\n",
      "Epoch [2729], train_loss: 0.0000, val_loss: 4.4026, val_acc: 0.5750\n",
      "Epoch [2730], train_loss: 0.0000, val_loss: 4.5012, val_acc: 0.5750\n",
      "Epoch [2731], train_loss: 0.0000, val_loss: 4.3784, val_acc: 0.5698\n",
      "Epoch [2732], train_loss: 0.0000, val_loss: 4.3587, val_acc: 0.5750\n",
      "Epoch [2733], train_loss: 0.0000, val_loss: 4.4756, val_acc: 0.5724\n",
      "Epoch [2734], train_loss: 0.0000, val_loss: 4.4834, val_acc: 0.5750\n",
      "Epoch [2735], train_loss: 0.0000, val_loss: 4.3668, val_acc: 0.5698\n",
      "Epoch [2736], train_loss: 0.0000, val_loss: 4.4540, val_acc: 0.5750\n",
      "Epoch [2737], train_loss: 0.0000, val_loss: 4.5461, val_acc: 0.5724\n",
      "Epoch [2738], train_loss: 0.0000, val_loss: 4.4734, val_acc: 0.5724\n",
      "Epoch [2739], train_loss: 0.0000, val_loss: 4.4680, val_acc: 0.5802\n",
      "Epoch [2740], train_loss: 0.0001, val_loss: 4.8677, val_acc: 0.6069\n",
      "Epoch [2741], train_loss: 0.0000, val_loss: 4.5924, val_acc: 0.5936\n",
      "Epoch [2742], train_loss: 0.0000, val_loss: 4.8100, val_acc: 0.5828\n",
      "Epoch [2743], train_loss: 0.0000, val_loss: 4.7748, val_acc: 0.5854\n",
      "Epoch [2744], train_loss: 0.0000, val_loss: 4.8587, val_acc: 0.5880\n",
      "Epoch [2745], train_loss: 0.0000, val_loss: 4.8550, val_acc: 0.5936\n",
      "Epoch [2746], train_loss: 0.0000, val_loss: 4.9666, val_acc: 0.5936\n",
      "Epoch [2747], train_loss: 0.0000, val_loss: 4.8205, val_acc: 0.5936\n",
      "Epoch [2748], train_loss: 0.0000, val_loss: 4.7499, val_acc: 0.5962\n",
      "Epoch [2749], train_loss: 0.0000, val_loss: 4.7122, val_acc: 0.5828\n",
      "Epoch [2750], train_loss: 0.0000, val_loss: 4.8519, val_acc: 0.5776\n",
      "Epoch [2751], train_loss: 0.0000, val_loss: 4.9202, val_acc: 0.5936\n",
      "Epoch [2752], train_loss: 0.0000, val_loss: 4.7672, val_acc: 0.5936\n",
      "Epoch [2753], train_loss: 0.0000, val_loss: 4.8623, val_acc: 0.5936\n",
      "Epoch [2754], train_loss: 0.0000, val_loss: 5.0340, val_acc: 0.5910\n",
      "Epoch [2755], train_loss: 0.0000, val_loss: 4.8731, val_acc: 0.5884\n",
      "Epoch [2756], train_loss: 0.0000, val_loss: 4.8136, val_acc: 0.5936\n",
      "Epoch [2757], train_loss: 0.0000, val_loss: 4.8743, val_acc: 0.5884\n",
      "Epoch [2758], train_loss: 0.0000, val_loss: 4.8638, val_acc: 0.5910\n",
      "Epoch [2759], train_loss: 0.0000, val_loss: 4.9211, val_acc: 0.5857\n",
      "Epoch [2760], train_loss: 0.0000, val_loss: 4.7339, val_acc: 0.5910\n",
      "Epoch [2761], train_loss: 0.0000, val_loss: 4.9471, val_acc: 0.5884\n",
      "Epoch [2762], train_loss: 0.0000, val_loss: 4.8424, val_acc: 0.5910\n",
      "Epoch [2763], train_loss: 0.0000, val_loss: 5.0130, val_acc: 0.5857\n",
      "Epoch [2764], train_loss: 0.0000, val_loss: 4.9515, val_acc: 0.5857\n",
      "Epoch [2765], train_loss: 0.0000, val_loss: 4.8635, val_acc: 0.5854\n",
      "Epoch [2766], train_loss: 0.0000, val_loss: 4.7080, val_acc: 0.5802\n",
      "Epoch [2767], train_loss: 0.0000, val_loss: 4.8759, val_acc: 0.5802\n",
      "Epoch [2768], train_loss: 0.0000, val_loss: 4.7707, val_acc: 0.5802\n",
      "Epoch [2769], train_loss: 0.0000, val_loss: 4.8835, val_acc: 0.5776\n",
      "Epoch [2770], train_loss: 0.0000, val_loss: 4.8718, val_acc: 0.5724\n",
      "Epoch [2771], train_loss: 0.0000, val_loss: 4.8207, val_acc: 0.5884\n",
      "Epoch [2772], train_loss: 0.0000, val_loss: 5.0176, val_acc: 0.5884\n",
      "Epoch [2773], train_loss: 0.0000, val_loss: 4.9141, val_acc: 0.6043\n",
      "Epoch [2774], train_loss: 0.0000, val_loss: 4.9162, val_acc: 0.6017\n",
      "Epoch [2775], train_loss: 0.0000, val_loss: 4.9712, val_acc: 0.5884\n",
      "Epoch [2776], train_loss: 0.0000, val_loss: 5.1153, val_acc: 0.5857\n",
      "Epoch [2777], train_loss: 0.0000, val_loss: 4.9772, val_acc: 0.5910\n",
      "Epoch [2778], train_loss: 0.0000, val_loss: 5.0364, val_acc: 0.5884\n",
      "Epoch [2779], train_loss: 0.0000, val_loss: 5.1666, val_acc: 0.5936\n",
      "Epoch [2780], train_loss: 0.0000, val_loss: 5.0138, val_acc: 0.5750\n",
      "Epoch [2781], train_loss: 0.0000, val_loss: 5.0618, val_acc: 0.5962\n",
      "Epoch [2782], train_loss: 0.0000, val_loss: 5.1519, val_acc: 0.5910\n",
      "Epoch [2783], train_loss: 0.0000, val_loss: 5.1326, val_acc: 0.5884\n",
      "Epoch [2784], train_loss: 0.0000, val_loss: 5.0888, val_acc: 0.5884\n",
      "Epoch [2785], train_loss: 0.0000, val_loss: 5.1573, val_acc: 0.5936\n",
      "Epoch [2786], train_loss: 0.0000, val_loss: 5.0689, val_acc: 0.5828\n",
      "Epoch [2787], train_loss: 0.0000, val_loss: 5.1662, val_acc: 0.5828\n",
      "Epoch [2788], train_loss: 0.0000, val_loss: 5.1253, val_acc: 0.5857\n",
      "Epoch [2789], train_loss: 0.0000, val_loss: 5.1763, val_acc: 0.5910\n",
      "Epoch [2790], train_loss: 0.0000, val_loss: 5.0033, val_acc: 0.5910\n",
      "Epoch [2791], train_loss: 0.0000, val_loss: 5.1873, val_acc: 0.5831\n",
      "Epoch [2792], train_loss: 0.0000, val_loss: 5.1225, val_acc: 0.5805\n",
      "Epoch [2793], train_loss: 0.0000, val_loss: 5.1448, val_acc: 0.5779\n",
      "Epoch [2794], train_loss: 0.0000, val_loss: 5.2574, val_acc: 0.5884\n",
      "Epoch [2795], train_loss: 0.0000, val_loss: 5.1488, val_acc: 0.5910\n",
      "Epoch [2796], train_loss: 0.0000, val_loss: 5.1513, val_acc: 0.5750\n",
      "Epoch [2797], train_loss: 0.0000, val_loss: 5.1729, val_acc: 0.5805\n",
      "Epoch [2798], train_loss: 0.0000, val_loss: 5.0618, val_acc: 0.5831\n",
      "Epoch [2799], train_loss: 0.0000, val_loss: 5.2711, val_acc: 0.5805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2800], train_loss: 0.0000, val_loss: 5.2968, val_acc: 0.5910\n",
      "Epoch [2801], train_loss: 0.0000, val_loss: 5.2787, val_acc: 0.5910\n",
      "Epoch [2802], train_loss: 0.0000, val_loss: 5.2740, val_acc: 0.5831\n",
      "Epoch [2803], train_loss: 0.0000, val_loss: 5.2560, val_acc: 0.5831\n",
      "Epoch [2804], train_loss: 0.0000, val_loss: 5.3932, val_acc: 0.5857\n",
      "Epoch [2805], train_loss: 0.0000, val_loss: 5.1762, val_acc: 0.5776\n",
      "Epoch [2806], train_loss: 0.0000, val_loss: 5.4238, val_acc: 0.5988\n",
      "Epoch [2807], train_loss: 0.0000, val_loss: 5.3602, val_acc: 0.5776\n",
      "Epoch [2808], train_loss: 0.0000, val_loss: 5.2746, val_acc: 0.5831\n",
      "Epoch [2809], train_loss: 0.0000, val_loss: 5.5408, val_acc: 0.5936\n",
      "Epoch [2810], train_loss: 0.0000, val_loss: 5.5449, val_acc: 0.5936\n",
      "Epoch [2811], train_loss: 0.0000, val_loss: 5.5043, val_acc: 0.5936\n",
      "Epoch [2812], train_loss: 0.0000, val_loss: 5.5712, val_acc: 0.5962\n",
      "Epoch [2813], train_loss: 0.0000, val_loss: 5.4849, val_acc: 0.5910\n",
      "Epoch [2814], train_loss: 0.0000, val_loss: 5.5501, val_acc: 0.5910\n",
      "Epoch [2815], train_loss: 0.0000, val_loss: 5.5991, val_acc: 0.5910\n",
      "Epoch [2816], train_loss: 0.0000, val_loss: 5.3712, val_acc: 0.5857\n",
      "Epoch [2817], train_loss: 0.0000, val_loss: 5.4733, val_acc: 0.5910\n",
      "Epoch [2818], train_loss: 0.0000, val_loss: 5.5261, val_acc: 0.5910\n",
      "Epoch [2819], train_loss: 0.0000, val_loss: 5.3601, val_acc: 0.5884\n",
      "Epoch [2820], train_loss: 0.0000, val_loss: 5.5426, val_acc: 0.5779\n",
      "Epoch [2821], train_loss: 0.0000, val_loss: 5.5579, val_acc: 0.5805\n",
      "Epoch [2822], train_loss: 0.0000, val_loss: 5.4362, val_acc: 0.5805\n",
      "Epoch [2823], train_loss: 0.0000, val_loss: 5.4255, val_acc: 0.5884\n",
      "Epoch [2824], train_loss: 0.0000, val_loss: 5.4727, val_acc: 0.5779\n",
      "Epoch [2825], train_loss: 0.0000, val_loss: 5.5962, val_acc: 0.5831\n",
      "Epoch [2826], train_loss: 0.0000, val_loss: 5.6522, val_acc: 0.5831\n",
      "Epoch [2827], train_loss: 0.0000, val_loss: 5.5456, val_acc: 0.5831\n",
      "Epoch [2828], train_loss: 0.0000, val_loss: 5.7235, val_acc: 0.5831\n",
      "Epoch [2829], train_loss: 0.0000, val_loss: 5.6189, val_acc: 0.5724\n",
      "Epoch [2830], train_loss: 0.0000, val_loss: 5.5636, val_acc: 0.5854\n",
      "Epoch [2831], train_loss: 0.0000, val_loss: 5.6916, val_acc: 0.5828\n",
      "Epoch [2832], train_loss: 0.0000, val_loss: 5.7928, val_acc: 0.5828\n",
      "Epoch [2833], train_loss: 0.0000, val_loss: 5.7830, val_acc: 0.5828\n",
      "Epoch [2834], train_loss: 0.0000, val_loss: 5.6837, val_acc: 0.5828\n",
      "Epoch [2835], train_loss: 0.0000, val_loss: 5.7108, val_acc: 0.5854\n",
      "Epoch [2836], train_loss: 0.0000, val_loss: 5.7940, val_acc: 0.5802\n",
      "Epoch [2837], train_loss: 0.0000, val_loss: 5.8768, val_acc: 0.5828\n",
      "Epoch [2838], train_loss: 0.0000, val_loss: 5.9421, val_acc: 0.5828\n",
      "Epoch [2839], train_loss: 0.0000, val_loss: 5.9125, val_acc: 0.5802\n",
      "Epoch [2840], train_loss: 0.0000, val_loss: 5.7928, val_acc: 0.5802\n",
      "Epoch [2841], train_loss: 0.0000, val_loss: 5.7590, val_acc: 0.5828\n",
      "Epoch [2842], train_loss: 0.0000, val_loss: 5.7494, val_acc: 0.5828\n",
      "Epoch [2843], train_loss: 0.0000, val_loss: 5.9540, val_acc: 0.5828\n",
      "Epoch [2844], train_loss: 0.0000, val_loss: 5.9988, val_acc: 0.5880\n",
      "Epoch [2845], train_loss: 0.0000, val_loss: 6.0093, val_acc: 0.5962\n",
      "Epoch [2846], train_loss: 0.0000, val_loss: 5.9128, val_acc: 0.5750\n",
      "Epoch [2847], train_loss: 0.0000, val_loss: 5.7923, val_acc: 0.5880\n",
      "Epoch [2848], train_loss: 0.0000, val_loss: 5.9208, val_acc: 0.5802\n",
      "Epoch [2849], train_loss: 0.0000, val_loss: 5.8198, val_acc: 0.5854\n",
      "Epoch [2850], train_loss: 0.0000, val_loss: 5.9698, val_acc: 0.5802\n",
      "Epoch [2851], train_loss: 0.0000, val_loss: 6.0821, val_acc: 0.5828\n",
      "Epoch [2852], train_loss: 0.0000, val_loss: 5.8171, val_acc: 0.5854\n",
      "Epoch [2853], train_loss: 0.0000, val_loss: 5.8369, val_acc: 0.5828\n",
      "Epoch [2854], train_loss: 0.0000, val_loss: 5.9717, val_acc: 0.5854\n",
      "Epoch [2855], train_loss: 0.0000, val_loss: 5.9842, val_acc: 0.5776\n",
      "Epoch [2856], train_loss: 0.0000, val_loss: 6.0524, val_acc: 0.5880\n",
      "Epoch [2857], train_loss: 0.0000, val_loss: 5.9925, val_acc: 0.5880\n",
      "Epoch [2858], train_loss: 0.0000, val_loss: 6.0318, val_acc: 0.5802\n",
      "Epoch [2859], train_loss: 0.0000, val_loss: 5.9849, val_acc: 0.5828\n",
      "Epoch [2860], train_loss: 0.0000, val_loss: 5.9324, val_acc: 0.5828\n",
      "Epoch [2861], train_loss: 0.0000, val_loss: 5.9537, val_acc: 0.5854\n",
      "Epoch [2862], train_loss: 0.0001, val_loss: 5.8403, val_acc: 0.5805\n",
      "Epoch [2863], train_loss: 0.1235, val_loss: 2.0187, val_acc: 0.6209\n",
      "Epoch [2864], train_loss: 0.1378, val_loss: 2.2700, val_acc: 0.6017\n",
      "Epoch [2865], train_loss: 0.0117, val_loss: 3.1601, val_acc: 0.5773\n",
      "Epoch [2866], train_loss: 0.0040, val_loss: 3.0894, val_acc: 0.6020\n",
      "Epoch [2867], train_loss: 0.0022, val_loss: 3.5709, val_acc: 0.6127\n",
      "Epoch [2868], train_loss: 0.0008, val_loss: 3.9026, val_acc: 0.5913\n",
      "Epoch [2869], train_loss: 0.0002, val_loss: 4.2014, val_acc: 0.5916\n",
      "Epoch [2870], train_loss: 0.0001, val_loss: 4.1297, val_acc: 0.5913\n",
      "Epoch [2871], train_loss: 0.0001, val_loss: 3.9785, val_acc: 0.5942\n",
      "Epoch [2872], train_loss: 0.0000, val_loss: 4.0620, val_acc: 0.5887\n",
      "Epoch [2873], train_loss: 0.0001, val_loss: 4.1231, val_acc: 0.5835\n",
      "Epoch [2874], train_loss: 0.0001, val_loss: 4.2618, val_acc: 0.5913\n",
      "Epoch [2875], train_loss: 0.0000, val_loss: 4.2121, val_acc: 0.5835\n",
      "Epoch [2876], train_loss: 0.0000, val_loss: 4.3083, val_acc: 0.5887\n",
      "Epoch [2877], train_loss: 0.0000, val_loss: 4.1481, val_acc: 0.5939\n",
      "Epoch [2878], train_loss: 0.0008, val_loss: 4.3166, val_acc: 0.5887\n",
      "Epoch [2879], train_loss: 0.0175, val_loss: 4.4863, val_acc: 0.5887\n",
      "Epoch [2880], train_loss: 0.0119, val_loss: 3.2439, val_acc: 0.5884\n",
      "Epoch [2881], train_loss: 0.0503, val_loss: 4.2798, val_acc: 0.5997\n",
      "Epoch [2882], train_loss: 0.0098, val_loss: 3.1977, val_acc: 0.5942\n",
      "Epoch [2883], train_loss: 0.0055, val_loss: 2.7870, val_acc: 0.5906\n",
      "Epoch [2884], train_loss: 0.0014, val_loss: 3.2966, val_acc: 0.6131\n",
      "Epoch [2885], train_loss: 0.0028, val_loss: 3.8359, val_acc: 0.6131\n",
      "Epoch [2886], train_loss: 0.0020, val_loss: 3.7368, val_acc: 0.6069\n",
      "Epoch [2887], train_loss: 0.0002, val_loss: 3.7334, val_acc: 0.5991\n",
      "Epoch [2888], train_loss: 0.0001, val_loss: 3.8761, val_acc: 0.6043\n",
      "Epoch [2889], train_loss: 0.0001, val_loss: 3.9936, val_acc: 0.6043\n",
      "Epoch [2890], train_loss: 0.0001, val_loss: 3.9945, val_acc: 0.6098\n",
      "Epoch [2891], train_loss: 0.0001, val_loss: 4.1994, val_acc: 0.6124\n",
      "Epoch [2892], train_loss: 0.0001, val_loss: 4.1347, val_acc: 0.6124\n",
      "Epoch [2893], train_loss: 0.0001, val_loss: 4.2083, val_acc: 0.6206\n",
      "Epoch [2894], train_loss: 0.0000, val_loss: 4.1346, val_acc: 0.6098\n",
      "Epoch [2895], train_loss: 0.0000, val_loss: 4.2511, val_acc: 0.6098\n",
      "Epoch [2896], train_loss: 0.0000, val_loss: 4.2974, val_acc: 0.6150\n",
      "Epoch [2897], train_loss: 0.0001, val_loss: 4.1730, val_acc: 0.6179\n",
      "Epoch [2898], train_loss: 0.0000, val_loss: 4.3208, val_acc: 0.6232\n",
      "Epoch [2899], train_loss: 0.0000, val_loss: 4.3719, val_acc: 0.6206\n",
      "Epoch [2900], train_loss: 0.0000, val_loss: 4.5094, val_acc: 0.6179\n",
      "Epoch [2901], train_loss: 0.0000, val_loss: 4.4547, val_acc: 0.6150\n",
      "Epoch [2902], train_loss: 0.0000, val_loss: 4.5199, val_acc: 0.6124\n",
      "Epoch [2903], train_loss: 0.0000, val_loss: 4.3617, val_acc: 0.6150\n",
      "Epoch [2904], train_loss: 0.0000, val_loss: 4.5372, val_acc: 0.6150\n",
      "Epoch [2905], train_loss: 0.0000, val_loss: 4.5220, val_acc: 0.6043\n",
      "Epoch [2906], train_loss: 0.0000, val_loss: 4.5498, val_acc: 0.6124\n",
      "Epoch [2907], train_loss: 0.0000, val_loss: 4.4477, val_acc: 0.6232\n",
      "Epoch [2908], train_loss: 0.0000, val_loss: 4.4603, val_acc: 0.6098\n",
      "Epoch [2909], train_loss: 0.0000, val_loss: 4.5959, val_acc: 0.6124\n",
      "Epoch [2910], train_loss: 0.0000, val_loss: 4.5806, val_acc: 0.6124\n",
      "Epoch [2911], train_loss: 0.0000, val_loss: 4.4239, val_acc: 0.6150\n",
      "Epoch [2912], train_loss: 0.0000, val_loss: 4.6199, val_acc: 0.6150\n",
      "Epoch [2913], train_loss: 0.0000, val_loss: 4.7445, val_acc: 0.6072\n",
      "Epoch [2914], train_loss: 0.0000, val_loss: 4.7120, val_acc: 0.6098\n",
      "Epoch [2915], train_loss: 0.0000, val_loss: 4.6445, val_acc: 0.6124\n",
      "Epoch [2916], train_loss: 0.0000, val_loss: 4.7566, val_acc: 0.6206\n",
      "Epoch [2917], train_loss: 0.0000, val_loss: 4.7501, val_acc: 0.6098\n",
      "Epoch [2918], train_loss: 0.0000, val_loss: 4.8112, val_acc: 0.6017\n",
      "Epoch [2919], train_loss: 0.0000, val_loss: 4.7976, val_acc: 0.6124\n",
      "Epoch [2920], train_loss: 0.0000, val_loss: 4.7599, val_acc: 0.6098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2921], train_loss: 0.0000, val_loss: 4.7729, val_acc: 0.6124\n",
      "Epoch [2922], train_loss: 0.0000, val_loss: 5.0093, val_acc: 0.6124\n",
      "Epoch [2923], train_loss: 0.0000, val_loss: 4.8359, val_acc: 0.6098\n",
      "Epoch [2924], train_loss: 0.0000, val_loss: 5.0158, val_acc: 0.6072\n",
      "Epoch [2925], train_loss: 0.0000, val_loss: 4.9952, val_acc: 0.6098\n",
      "Epoch [2926], train_loss: 0.0000, val_loss: 4.8403, val_acc: 0.6150\n",
      "Epoch [2927], train_loss: 0.0000, val_loss: 4.9472, val_acc: 0.6150\n",
      "Epoch [2928], train_loss: 0.0000, val_loss: 4.9139, val_acc: 0.6124\n",
      "Epoch [2929], train_loss: 0.0000, val_loss: 4.8982, val_acc: 0.6098\n",
      "Epoch [2930], train_loss: 0.0000, val_loss: 5.0391, val_acc: 0.6098\n",
      "Epoch [2931], train_loss: 0.0000, val_loss: 5.0441, val_acc: 0.6150\n",
      "Epoch [2932], train_loss: 0.0000, val_loss: 5.0606, val_acc: 0.6098\n",
      "Epoch [2933], train_loss: 0.0000, val_loss: 5.0603, val_acc: 0.6150\n",
      "Epoch [2934], train_loss: 0.0000, val_loss: 5.0298, val_acc: 0.6124\n",
      "Epoch [2935], train_loss: 0.0000, val_loss: 4.8876, val_acc: 0.6124\n",
      "Epoch [2936], train_loss: 0.0000, val_loss: 4.9871, val_acc: 0.6124\n",
      "Epoch [2937], train_loss: 0.0000, val_loss: 5.1090, val_acc: 0.6124\n",
      "Epoch [2938], train_loss: 0.0000, val_loss: 5.0907, val_acc: 0.6098\n",
      "Epoch [2939], train_loss: 0.0000, val_loss: 5.0202, val_acc: 0.6150\n",
      "Epoch [2940], train_loss: 0.0000, val_loss: 5.1416, val_acc: 0.6098\n",
      "Epoch [2941], train_loss: 0.0000, val_loss: 5.0879, val_acc: 0.6124\n",
      "Epoch [2942], train_loss: 0.0000, val_loss: 5.0776, val_acc: 0.6124\n",
      "Epoch [2943], train_loss: 0.0000, val_loss: 4.9424, val_acc: 0.6124\n",
      "Epoch [2944], train_loss: 0.0000, val_loss: 5.0026, val_acc: 0.6098\n",
      "Epoch [2945], train_loss: 0.0000, val_loss: 5.2405, val_acc: 0.6124\n",
      "Epoch [2946], train_loss: 0.0000, val_loss: 5.1351, val_acc: 0.6150\n",
      "Epoch [2947], train_loss: 0.0000, val_loss: 5.0186, val_acc: 0.6150\n",
      "Epoch [2948], train_loss: 0.0000, val_loss: 5.1263, val_acc: 0.6124\n",
      "Epoch [2949], train_loss: 0.0000, val_loss: 5.1020, val_acc: 0.6150\n",
      "Epoch [2950], train_loss: 0.0000, val_loss: 5.1961, val_acc: 0.6069\n",
      "Epoch [2951], train_loss: 0.0000, val_loss: 5.4180, val_acc: 0.6098\n",
      "Epoch [2952], train_loss: 0.0000, val_loss: 5.0071, val_acc: 0.6150\n",
      "Epoch [2953], train_loss: 0.0000, val_loss: 5.0119, val_acc: 0.6150\n",
      "Epoch [2954], train_loss: 0.0000, val_loss: 5.1163, val_acc: 0.6098\n",
      "Epoch [2955], train_loss: 0.0000, val_loss: 4.9884, val_acc: 0.6069\n",
      "Epoch [2956], train_loss: 0.0000, val_loss: 5.2175, val_acc: 0.6098\n",
      "Epoch [2957], train_loss: 0.0000, val_loss: 5.2575, val_acc: 0.6098\n",
      "Epoch [2958], train_loss: 0.0000, val_loss: 5.1417, val_acc: 0.6098\n",
      "Epoch [2959], train_loss: 0.0000, val_loss: 5.2462, val_acc: 0.6098\n",
      "Epoch [2960], train_loss: 0.0000, val_loss: 5.2839, val_acc: 0.6017\n",
      "Epoch [2961], train_loss: 0.0000, val_loss: 5.1777, val_acc: 0.6098\n",
      "Epoch [2962], train_loss: 0.0000, val_loss: 5.3079, val_acc: 0.6150\n",
      "Epoch [2963], train_loss: 0.0000, val_loss: 5.3570, val_acc: 0.6017\n",
      "Epoch [2964], train_loss: 0.0000, val_loss: 5.2618, val_acc: 0.6098\n",
      "Epoch [2965], train_loss: 0.0000, val_loss: 5.4142, val_acc: 0.6098\n",
      "Epoch [2966], train_loss: 0.0000, val_loss: 5.3854, val_acc: 0.6072\n",
      "Epoch [2967], train_loss: 0.0000, val_loss: 5.5637, val_acc: 0.6043\n",
      "Epoch [2968], train_loss: 0.0000, val_loss: 5.3766, val_acc: 0.5991\n",
      "Epoch [2969], train_loss: 0.0000, val_loss: 5.4969, val_acc: 0.6072\n",
      "Epoch [2970], train_loss: 0.0000, val_loss: 5.5474, val_acc: 0.6043\n",
      "Epoch [2971], train_loss: 0.0000, val_loss: 5.3254, val_acc: 0.6017\n",
      "Epoch [2972], train_loss: 0.0000, val_loss: 5.2941, val_acc: 0.6176\n",
      "Epoch [2973], train_loss: 0.0000, val_loss: 5.5649, val_acc: 0.6124\n",
      "Epoch [2974], train_loss: 0.0000, val_loss: 5.3500, val_acc: 0.6124\n",
      "Epoch [2975], train_loss: 0.0000, val_loss: 5.3342, val_acc: 0.5991\n",
      "Epoch [2976], train_loss: 0.0000, val_loss: 5.3477, val_acc: 0.6098\n",
      "Epoch [2977], train_loss: 0.0000, val_loss: 5.3167, val_acc: 0.6043\n",
      "Epoch [2978], train_loss: 0.0000, val_loss: 5.3843, val_acc: 0.6069\n",
      "Epoch [2979], train_loss: 0.0000, val_loss: 5.4445, val_acc: 0.6017\n",
      "Epoch [2980], train_loss: 0.0000, val_loss: 5.5457, val_acc: 0.6017\n",
      "Epoch [2981], train_loss: 0.0000, val_loss: 5.4270, val_acc: 0.6043\n",
      "Epoch [2982], train_loss: 0.0000, val_loss: 5.4762, val_acc: 0.6072\n",
      "Epoch [2983], train_loss: 0.0000, val_loss: 5.6688, val_acc: 0.6017\n",
      "Epoch [2984], train_loss: 0.0000, val_loss: 5.5619, val_acc: 0.6043\n",
      "Epoch [2985], train_loss: 0.0000, val_loss: 5.4044, val_acc: 0.6069\n",
      "Epoch [2986], train_loss: 0.0000, val_loss: 5.5393, val_acc: 0.5991\n",
      "Epoch [2987], train_loss: 0.0000, val_loss: 5.5250, val_acc: 0.6043\n",
      "Epoch [2988], train_loss: 0.0000, val_loss: 5.5953, val_acc: 0.6043\n",
      "Epoch [2989], train_loss: 0.0000, val_loss: 5.4648, val_acc: 0.6017\n",
      "Epoch [2990], train_loss: 0.0000, val_loss: 5.5447, val_acc: 0.6017\n",
      "Epoch [2991], train_loss: 0.0000, val_loss: 5.5724, val_acc: 0.6150\n",
      "Epoch [2992], train_loss: 0.0000, val_loss: 5.7553, val_acc: 0.6017\n",
      "Epoch [2993], train_loss: 0.0000, val_loss: 5.5540, val_acc: 0.6017\n",
      "Epoch [2994], train_loss: 0.0000, val_loss: 5.5011, val_acc: 0.5991\n",
      "Epoch [2995], train_loss: 0.0000, val_loss: 5.7241, val_acc: 0.6098\n",
      "Epoch [2996], train_loss: 0.0000, val_loss: 5.6972, val_acc: 0.6043\n",
      "Epoch [2997], train_loss: 0.0000, val_loss: 5.7056, val_acc: 0.6017\n",
      "Epoch [2998], train_loss: 0.0000, val_loss: 5.7825, val_acc: 0.5910\n",
      "Epoch [2999], train_loss: 0.0000, val_loss: 5.7668, val_acc: 0.5991\n",
      "Epoch [3000], train_loss: 0.0000, val_loss: 5.8448, val_acc: 0.6017\n",
      "Epoch [3001], train_loss: 0.0000, val_loss: 5.6956, val_acc: 0.6150\n",
      "Epoch [3002], train_loss: 0.0000, val_loss: 5.7458, val_acc: 0.5991\n",
      "Epoch [3003], train_loss: 0.0000, val_loss: 5.8703, val_acc: 0.6098\n",
      "Epoch [3004], train_loss: 0.0000, val_loss: 5.8552, val_acc: 0.6043\n",
      "Epoch [3005], train_loss: 0.0000, val_loss: 5.8405, val_acc: 0.6098\n",
      "Epoch [3006], train_loss: 0.0000, val_loss: 5.8885, val_acc: 0.6124\n",
      "Epoch [3007], train_loss: 0.0000, val_loss: 5.7864, val_acc: 0.6043\n",
      "Epoch [3008], train_loss: 0.0000, val_loss: 5.9047, val_acc: 0.5991\n",
      "Epoch [3009], train_loss: 0.0000, val_loss: 5.8737, val_acc: 0.6098\n",
      "Epoch [3010], train_loss: 0.0000, val_loss: 5.8970, val_acc: 0.6043\n",
      "Epoch [3011], train_loss: 0.0000, val_loss: 5.9084, val_acc: 0.6043\n",
      "Epoch [3012], train_loss: 0.0000, val_loss: 5.7929, val_acc: 0.6043\n",
      "Epoch [3013], train_loss: 0.0000, val_loss: 5.8502, val_acc: 0.6043\n",
      "Epoch [3014], train_loss: 0.0000, val_loss: 5.7163, val_acc: 0.6043\n",
      "Epoch [3015], train_loss: 0.0000, val_loss: 5.9470, val_acc: 0.5936\n",
      "Epoch [3016], train_loss: 0.0000, val_loss: 6.0594, val_acc: 0.6043\n",
      "Epoch [3017], train_loss: 0.0000, val_loss: 6.0120, val_acc: 0.6098\n",
      "Epoch [3018], train_loss: 0.0000, val_loss: 5.9960, val_acc: 0.5991\n",
      "Epoch [3019], train_loss: 0.0000, val_loss: 5.8410, val_acc: 0.5936\n",
      "Epoch [3020], train_loss: 0.0000, val_loss: 5.7777, val_acc: 0.6043\n",
      "Epoch [3021], train_loss: 0.0000, val_loss: 5.8832, val_acc: 0.5936\n",
      "Epoch [3022], train_loss: 0.0000, val_loss: 6.0307, val_acc: 0.6017\n",
      "Epoch [3023], train_loss: 0.0000, val_loss: 6.0181, val_acc: 0.5991\n",
      "Epoch [3024], train_loss: 0.0000, val_loss: 5.9007, val_acc: 0.6043\n",
      "Epoch [3025], train_loss: 0.0000, val_loss: 5.8599, val_acc: 0.6069\n",
      "Epoch [3026], train_loss: 0.0000, val_loss: 6.2451, val_acc: 0.6098\n",
      "Epoch [3027], train_loss: 0.0000, val_loss: 6.4876, val_acc: 0.5988\n",
      "Epoch [3028], train_loss: 0.0000, val_loss: 6.3516, val_acc: 0.6124\n",
      "Epoch [3029], train_loss: 0.0000, val_loss: 6.2001, val_acc: 0.6043\n",
      "Epoch [3030], train_loss: 0.0000, val_loss: 6.2761, val_acc: 0.6150\n",
      "Epoch [3031], train_loss: 0.0000, val_loss: 6.4205, val_acc: 0.6150\n",
      "Epoch [3032], train_loss: 0.0000, val_loss: 6.0358, val_acc: 0.6043\n",
      "Epoch [3033], train_loss: 0.0000, val_loss: 6.0473, val_acc: 0.6124\n",
      "Epoch [3034], train_loss: 0.0000, val_loss: 6.1997, val_acc: 0.6124\n",
      "Epoch [3035], train_loss: 0.0000, val_loss: 6.1575, val_acc: 0.6069\n",
      "Epoch [3036], train_loss: 0.0000, val_loss: 7.4304, val_acc: 0.6072\n",
      "Epoch [3037], train_loss: 0.1097, val_loss: 6.0689, val_acc: 0.5971\n",
      "Epoch [3038], train_loss: 0.0373, val_loss: 3.1008, val_acc: 0.5880\n",
      "Epoch [3039], train_loss: 0.0421, val_loss: 2.1005, val_acc: 0.6072\n",
      "Epoch [3040], train_loss: 0.0244, val_loss: 2.1822, val_acc: 0.6095\n",
      "Epoch [3041], train_loss: 0.0027, val_loss: 3.1149, val_acc: 0.5962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3042], train_loss: 0.0003, val_loss: 3.3630, val_acc: 0.5939\n",
      "Epoch [3043], train_loss: 0.0003, val_loss: 3.3395, val_acc: 0.6020\n",
      "Epoch [3044], train_loss: 0.0001, val_loss: 3.5801, val_acc: 0.6069\n",
      "Epoch [3045], train_loss: 0.0001, val_loss: 3.6353, val_acc: 0.5991\n",
      "Epoch [3046], train_loss: 0.0000, val_loss: 3.5257, val_acc: 0.5991\n",
      "Epoch [3047], train_loss: 0.0001, val_loss: 3.5450, val_acc: 0.6017\n",
      "Epoch [3048], train_loss: 0.0001, val_loss: 3.7067, val_acc: 0.5991\n",
      "Epoch [3049], train_loss: 0.0001, val_loss: 3.6580, val_acc: 0.6017\n",
      "Epoch [3050], train_loss: 0.0000, val_loss: 3.8186, val_acc: 0.6043\n",
      "Epoch [3051], train_loss: 0.0000, val_loss: 3.8428, val_acc: 0.6017\n",
      "Epoch [3052], train_loss: 0.0000, val_loss: 3.7774, val_acc: 0.5962\n",
      "Epoch [3053], train_loss: 0.0000, val_loss: 3.8664, val_acc: 0.5936\n",
      "Epoch [3054], train_loss: 0.0000, val_loss: 3.9634, val_acc: 0.5936\n",
      "Epoch [3055], train_loss: 0.0000, val_loss: 3.7762, val_acc: 0.5936\n",
      "Epoch [3056], train_loss: 0.0000, val_loss: 3.9059, val_acc: 0.5988\n",
      "Epoch [3057], train_loss: 0.0000, val_loss: 3.9451, val_acc: 0.5936\n",
      "Epoch [3058], train_loss: 0.0000, val_loss: 3.9442, val_acc: 0.6043\n",
      "Epoch [3059], train_loss: 0.0000, val_loss: 4.0216, val_acc: 0.6043\n",
      "Epoch [3060], train_loss: 0.0000, val_loss: 4.0385, val_acc: 0.6017\n",
      "Epoch [3061], train_loss: 0.0000, val_loss: 4.0615, val_acc: 0.5910\n",
      "Epoch [3062], train_loss: 0.0000, val_loss: 4.1151, val_acc: 0.5962\n",
      "Epoch [3063], train_loss: 0.0000, val_loss: 4.2495, val_acc: 0.6043\n",
      "Epoch [3064], train_loss: 0.0000, val_loss: 4.2082, val_acc: 0.5936\n",
      "Epoch [3065], train_loss: 0.0001, val_loss: 3.8081, val_acc: 0.5910\n",
      "Epoch [3066], train_loss: 0.0010, val_loss: 4.1111, val_acc: 0.6313\n",
      "Epoch [3067], train_loss: 0.0006, val_loss: 4.2978, val_acc: 0.6179\n",
      "Epoch [3068], train_loss: 0.0001, val_loss: 4.3482, val_acc: 0.6173\n",
      "Epoch [3069], train_loss: 0.0000, val_loss: 4.2583, val_acc: 0.6014\n",
      "Epoch [3070], train_loss: 0.0000, val_loss: 4.3277, val_acc: 0.6066\n",
      "Epoch [3071], train_loss: 0.0000, val_loss: 4.3253, val_acc: 0.6066\n",
      "Epoch [3072], train_loss: 0.0000, val_loss: 4.4266, val_acc: 0.5988\n",
      "Epoch [3073], train_loss: 0.0000, val_loss: 4.3860, val_acc: 0.6014\n",
      "Epoch [3074], train_loss: 0.0000, val_loss: 4.3241, val_acc: 0.6121\n",
      "Epoch [3075], train_loss: 0.0000, val_loss: 4.5024, val_acc: 0.6014\n",
      "Epoch [3076], train_loss: 0.0000, val_loss: 4.5172, val_acc: 0.6040\n",
      "Epoch [3077], train_loss: 0.0000, val_loss: 4.4965, val_acc: 0.6040\n",
      "Epoch [3078], train_loss: 0.0000, val_loss: 4.5874, val_acc: 0.6040\n",
      "Epoch [3079], train_loss: 0.0000, val_loss: 4.4507, val_acc: 0.6040\n",
      "Epoch [3080], train_loss: 0.0001, val_loss: 4.4660, val_acc: 0.6014\n",
      "Epoch [3081], train_loss: 0.0003, val_loss: 4.7501, val_acc: 0.5965\n",
      "Epoch [3082], train_loss: 0.0002, val_loss: 4.4182, val_acc: 0.6014\n",
      "Epoch [3083], train_loss: 0.0005, val_loss: 4.6520, val_acc: 0.5727\n",
      "Epoch [3084], train_loss: 0.0124, val_loss: 10.7055, val_acc: 0.5962\n",
      "Epoch [3085], train_loss: 0.0648, val_loss: 2.5236, val_acc: 0.5835\n",
      "Epoch [3086], train_loss: 0.0281, val_loss: 2.4918, val_acc: 0.6157\n",
      "Epoch [3087], train_loss: 0.0028, val_loss: 3.5839, val_acc: 0.5968\n",
      "Epoch [3088], train_loss: 0.0003, val_loss: 3.7213, val_acc: 0.5965\n",
      "Epoch [3089], train_loss: 0.0001, val_loss: 3.7888, val_acc: 0.5831\n",
      "Epoch [3090], train_loss: 0.0001, val_loss: 3.9705, val_acc: 0.5831\n",
      "Epoch [3091], train_loss: 0.0001, val_loss: 3.8641, val_acc: 0.5857\n",
      "Epoch [3092], train_loss: 0.0001, val_loss: 4.1017, val_acc: 0.5939\n",
      "Epoch [3093], train_loss: 0.0001, val_loss: 4.3344, val_acc: 0.5913\n",
      "Epoch [3094], train_loss: 0.0000, val_loss: 4.4665, val_acc: 0.5913\n",
      "Epoch [3095], train_loss: 0.0000, val_loss: 4.2352, val_acc: 0.5805\n",
      "Epoch [3096], train_loss: 0.0000, val_loss: 4.3946, val_acc: 0.5913\n",
      "Epoch [3097], train_loss: 0.0000, val_loss: 4.5313, val_acc: 0.5913\n",
      "Epoch [3098], train_loss: 0.0001, val_loss: 4.6477, val_acc: 0.5962\n",
      "Epoch [3099], train_loss: 0.0000, val_loss: 4.6841, val_acc: 0.5991\n",
      "Epoch [3100], train_loss: 0.0003, val_loss: 5.0737, val_acc: 0.5861\n",
      "Epoch [3101], train_loss: 0.0312, val_loss: 2.0171, val_acc: 0.6319\n",
      "Epoch [3102], train_loss: 0.0351, val_loss: 4.8991, val_acc: 0.5971\n",
      "Epoch [3103], train_loss: 0.0200, val_loss: 4.0085, val_acc: 0.6232\n",
      "Epoch [3104], train_loss: 0.0210, val_loss: 2.8132, val_acc: 0.6179\n",
      "Epoch [3105], train_loss: 0.0051, val_loss: 3.1588, val_acc: 0.5965\n",
      "Epoch [3106], train_loss: 0.0030, val_loss: 4.3795, val_acc: 0.5994\n",
      "Epoch [3107], train_loss: 0.0008, val_loss: 4.3962, val_acc: 0.5884\n",
      "Epoch [3108], train_loss: 0.0245, val_loss: 2.7397, val_acc: 0.6052\n",
      "Epoch [3109], train_loss: 0.0058, val_loss: 2.0498, val_acc: 0.6049\n",
      "Epoch [3110], train_loss: 0.0075, val_loss: 3.7790, val_acc: 0.5965\n",
      "Epoch [3111], train_loss: 0.0017, val_loss: 2.3394, val_acc: 0.5854\n",
      "Epoch [3112], train_loss: 0.0009, val_loss: 2.9861, val_acc: 0.5698\n",
      "Epoch [3113], train_loss: 0.0003, val_loss: 3.5572, val_acc: 0.5835\n",
      "Epoch [3114], train_loss: 0.0002, val_loss: 3.6697, val_acc: 0.5753\n",
      "Epoch [3115], train_loss: 0.0001, val_loss: 3.7573, val_acc: 0.5727\n",
      "Epoch [3116], train_loss: 0.0001, val_loss: 3.9419, val_acc: 0.5646\n",
      "Epoch [3117], train_loss: 0.0001, val_loss: 3.8058, val_acc: 0.5809\n",
      "Epoch [3118], train_loss: 0.0001, val_loss: 4.1236, val_acc: 0.5646\n",
      "Epoch [3119], train_loss: 0.0000, val_loss: 3.9922, val_acc: 0.5675\n",
      "Epoch [3120], train_loss: 0.0000, val_loss: 4.1602, val_acc: 0.5620\n",
      "Epoch [3121], train_loss: 0.0000, val_loss: 4.0785, val_acc: 0.5675\n",
      "Epoch [3122], train_loss: 0.0000, val_loss: 4.1692, val_acc: 0.5701\n",
      "Epoch [3123], train_loss: 0.0000, val_loss: 4.1762, val_acc: 0.5698\n",
      "Epoch [3124], train_loss: 0.0000, val_loss: 4.2805, val_acc: 0.5756\n",
      "Epoch [3125], train_loss: 0.0000, val_loss: 4.3797, val_acc: 0.5698\n",
      "Epoch [3126], train_loss: 0.0000, val_loss: 4.2026, val_acc: 0.5753\n",
      "Epoch [3127], train_loss: 0.0000, val_loss: 4.6358, val_acc: 0.5701\n",
      "Epoch [3128], train_loss: 0.0000, val_loss: 4.4194, val_acc: 0.5594\n",
      "Epoch [3129], train_loss: 0.0000, val_loss: 4.4522, val_acc: 0.5727\n",
      "Epoch [3130], train_loss: 0.0000, val_loss: 4.3628, val_acc: 0.5753\n",
      "Epoch [3131], train_loss: 0.0000, val_loss: 4.5007, val_acc: 0.5698\n",
      "Epoch [3132], train_loss: 0.0000, val_loss: 4.5023, val_acc: 0.5672\n",
      "Epoch [3133], train_loss: 0.0000, val_loss: 4.6403, val_acc: 0.5646\n",
      "Epoch [3134], train_loss: 0.0000, val_loss: 4.7460, val_acc: 0.5646\n",
      "Epoch [3135], train_loss: 0.0000, val_loss: 4.5904, val_acc: 0.5750\n",
      "Epoch [3136], train_loss: 0.0000, val_loss: 4.6786, val_acc: 0.5701\n",
      "Epoch [3137], train_loss: 0.0000, val_loss: 4.5316, val_acc: 0.5698\n",
      "Epoch [3138], train_loss: 0.0000, val_loss: 4.7941, val_acc: 0.5646\n",
      "Epoch [3139], train_loss: 0.0000, val_loss: 4.7180, val_acc: 0.5672\n",
      "Epoch [3140], train_loss: 0.0000, val_loss: 4.6310, val_acc: 0.5753\n",
      "Epoch [3141], train_loss: 0.0000, val_loss: 4.7719, val_acc: 0.5698\n",
      "Epoch [3142], train_loss: 0.0000, val_loss: 4.6463, val_acc: 0.5727\n",
      "Epoch [3143], train_loss: 0.0000, val_loss: 4.6861, val_acc: 0.5727\n",
      "Epoch [3144], train_loss: 0.0000, val_loss: 4.6970, val_acc: 0.5698\n",
      "Epoch [3145], train_loss: 0.0000, val_loss: 4.4566, val_acc: 0.5727\n",
      "Epoch [3146], train_loss: 0.0000, val_loss: 4.7052, val_acc: 0.5753\n",
      "Epoch [3147], train_loss: 0.0000, val_loss: 4.9281, val_acc: 0.5698\n",
      "Epoch [3148], train_loss: 0.0000, val_loss: 4.8709, val_acc: 0.5831\n",
      "Epoch [3149], train_loss: 0.0000, val_loss: 5.0297, val_acc: 0.5831\n",
      "Epoch [3150], train_loss: 0.0000, val_loss: 5.1182, val_acc: 0.5779\n",
      "Epoch [3151], train_loss: 0.0000, val_loss: 4.9510, val_acc: 0.5779\n",
      "Epoch [3152], train_loss: 0.0000, val_loss: 4.9178, val_acc: 0.5887\n",
      "Epoch [3153], train_loss: 0.0020, val_loss: 7.5129, val_acc: 0.5916\n",
      "Epoch [3154], train_loss: 0.0764, val_loss: 3.8850, val_acc: 0.5649\n",
      "Epoch [3155], train_loss: 0.0338, val_loss: 2.8456, val_acc: 0.5965\n",
      "Epoch [3156], train_loss: 0.0435, val_loss: 1.6195, val_acc: 0.5861\n",
      "Epoch [3157], train_loss: 0.0249, val_loss: 3.3577, val_acc: 0.6157\n",
      "Epoch [3158], train_loss: 0.0217, val_loss: 2.9703, val_acc: 0.6075\n",
      "Epoch [3159], train_loss: 0.0076, val_loss: 2.6919, val_acc: 0.6072\n",
      "Epoch [3160], train_loss: 0.0015, val_loss: 3.4216, val_acc: 0.6043\n",
      "Epoch [3161], train_loss: 0.0004, val_loss: 3.6658, val_acc: 0.5936\n",
      "Epoch [3162], train_loss: 0.0001, val_loss: 3.7686, val_acc: 0.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3163], train_loss: 0.0001, val_loss: 3.8839, val_acc: 0.5988\n",
      "Epoch [3164], train_loss: 0.0002, val_loss: 4.0030, val_acc: 0.6147\n",
      "Epoch [3165], train_loss: 0.0001, val_loss: 3.9393, val_acc: 0.6147\n",
      "Epoch [3166], train_loss: 0.0000, val_loss: 3.9865, val_acc: 0.6095\n",
      "Epoch [3167], train_loss: 0.0001, val_loss: 4.0474, val_acc: 0.6121\n",
      "Epoch [3168], train_loss: 0.0001, val_loss: 4.0932, val_acc: 0.6228\n",
      "Epoch [3169], train_loss: 0.0000, val_loss: 4.1711, val_acc: 0.6043\n",
      "Epoch [3170], train_loss: 0.0001, val_loss: 4.2778, val_acc: 0.6095\n",
      "Epoch [3171], train_loss: 0.0002, val_loss: 4.2475, val_acc: 0.6095\n",
      "Epoch [3172], train_loss: 0.0196, val_loss: 5.2117, val_acc: 0.6131\n",
      "Epoch [3173], train_loss: 0.0893, val_loss: 4.1953, val_acc: 0.6453\n",
      "Epoch [3174], train_loss: 0.0501, val_loss: 4.0859, val_acc: 0.5939\n",
      "Epoch [3175], train_loss: 0.0061, val_loss: 4.8171, val_acc: 0.6046\n",
      "Epoch [3176], train_loss: 0.0025, val_loss: 4.9629, val_acc: 0.6072\n",
      "Epoch [3177], train_loss: 0.0024, val_loss: 5.3636, val_acc: 0.5802\n",
      "Epoch [3178], train_loss: 0.0014, val_loss: 6.2341, val_acc: 0.5939\n",
      "Epoch [3179], train_loss: 0.0053, val_loss: 4.6634, val_acc: 0.5890\n",
      "Epoch [3180], train_loss: 0.0013, val_loss: 5.4401, val_acc: 0.6046\n",
      "Epoch [3181], train_loss: 0.0258, val_loss: 3.7377, val_acc: 0.6095\n",
      "Epoch [3182], train_loss: 0.0054, val_loss: 3.7888, val_acc: 0.6280\n",
      "Epoch [3183], train_loss: 0.0004, val_loss: 4.1533, val_acc: 0.6124\n",
      "Epoch [3184], train_loss: 0.0002, val_loss: 4.3705, val_acc: 0.6153\n",
      "Epoch [3185], train_loss: 0.0001, val_loss: 4.4342, val_acc: 0.6287\n",
      "Epoch [3186], train_loss: 0.0001, val_loss: 4.2779, val_acc: 0.6287\n",
      "Epoch [3187], train_loss: 0.0001, val_loss: 4.3723, val_acc: 0.6153\n",
      "Epoch [3188], train_loss: 0.0001, val_loss: 4.6307, val_acc: 0.6153\n",
      "Epoch [3189], train_loss: 0.0001, val_loss: 4.4696, val_acc: 0.6150\n",
      "Epoch [3190], train_loss: 0.0000, val_loss: 4.3947, val_acc: 0.6072\n",
      "Epoch [3191], train_loss: 0.0000, val_loss: 4.5846, val_acc: 0.6179\n",
      "Epoch [3192], train_loss: 0.0000, val_loss: 4.4883, val_acc: 0.6072\n",
      "Epoch [3193], train_loss: 0.0001, val_loss: 4.4147, val_acc: 0.6017\n",
      "Epoch [3194], train_loss: 0.0000, val_loss: 4.5639, val_acc: 0.6049\n",
      "Epoch [3195], train_loss: 0.0000, val_loss: 4.5081, val_acc: 0.6020\n",
      "Epoch [3196], train_loss: 0.0000, val_loss: 4.7415, val_acc: 0.5939\n",
      "Epoch [3197], train_loss: 0.0000, val_loss: 4.7270, val_acc: 0.5913\n",
      "Epoch [3198], train_loss: 0.0000, val_loss: 4.5606, val_acc: 0.5965\n",
      "Epoch [3199], train_loss: 0.0001, val_loss: 5.0033, val_acc: 0.6153\n",
      "Epoch [3200], train_loss: 0.0000, val_loss: 4.6721, val_acc: 0.6020\n",
      "Epoch [3201], train_loss: 0.0000, val_loss: 4.9733, val_acc: 0.6127\n",
      "Epoch [3202], train_loss: 0.0100, val_loss: 6.3318, val_acc: 0.6124\n",
      "Epoch [3203], train_loss: 0.0615, val_loss: 4.3694, val_acc: 0.6023\n",
      "Epoch [3204], train_loss: 0.0054, val_loss: 3.6614, val_acc: 0.6557\n",
      "Epoch [3205], train_loss: 0.0053, val_loss: 4.6785, val_acc: 0.6371\n",
      "Epoch [3206], train_loss: 0.0031, val_loss: 4.3292, val_acc: 0.5913\n",
      "Epoch [3207], train_loss: 0.0003, val_loss: 4.9861, val_acc: 0.6124\n",
      "Epoch [3208], train_loss: 0.0002, val_loss: 5.1374, val_acc: 0.6150\n",
      "Epoch [3209], train_loss: 0.0001, val_loss: 4.9406, val_acc: 0.6020\n",
      "Epoch [3210], train_loss: 0.0001, val_loss: 5.0246, val_acc: 0.5965\n",
      "Epoch [3211], train_loss: 0.0001, val_loss: 5.1741, val_acc: 0.5991\n",
      "Epoch [3212], train_loss: 0.0000, val_loss: 5.3869, val_acc: 0.6069\n",
      "Epoch [3213], train_loss: 0.0001, val_loss: 5.5005, val_acc: 0.6046\n",
      "Epoch [3214], train_loss: 0.0000, val_loss: 5.5717, val_acc: 0.6017\n",
      "Epoch [3215], train_loss: 0.0000, val_loss: 5.6073, val_acc: 0.6043\n",
      "Epoch [3216], train_loss: 0.0000, val_loss: 5.5914, val_acc: 0.6043\n",
      "Epoch [3217], train_loss: 0.0000, val_loss: 5.5749, val_acc: 0.6072\n",
      "Epoch [3218], train_loss: 0.0000, val_loss: 5.8565, val_acc: 0.6017\n",
      "Epoch [3219], train_loss: 0.0000, val_loss: 5.8290, val_acc: 0.6017\n",
      "Epoch [3220], train_loss: 0.0000, val_loss: 5.6956, val_acc: 0.6072\n",
      "Epoch [3221], train_loss: 0.0000, val_loss: 5.7125, val_acc: 0.6046\n",
      "Epoch [3222], train_loss: 0.0000, val_loss: 5.7727, val_acc: 0.6046\n",
      "Epoch [3223], train_loss: 0.0000, val_loss: 6.1661, val_acc: 0.6017\n",
      "Epoch [3224], train_loss: 0.0000, val_loss: 5.9257, val_acc: 0.5991\n",
      "Epoch [3225], train_loss: 0.0000, val_loss: 5.7175, val_acc: 0.6046\n",
      "Epoch [3226], train_loss: 0.0000, val_loss: 5.8758, val_acc: 0.6043\n",
      "Epoch [3227], train_loss: 0.0000, val_loss: 6.2602, val_acc: 0.6121\n",
      "Epoch [3228], train_loss: 0.0000, val_loss: 6.2379, val_acc: 0.6043\n",
      "Epoch [3229], train_loss: 0.0000, val_loss: 6.1655, val_acc: 0.6043\n",
      "Epoch [3230], train_loss: 0.0000, val_loss: 5.9240, val_acc: 0.6069\n",
      "Epoch [3231], train_loss: 0.0000, val_loss: 6.4704, val_acc: 0.6124\n",
      "Epoch [3232], train_loss: 0.0000, val_loss: 6.0705, val_acc: 0.6069\n",
      "Epoch [3233], train_loss: 0.0000, val_loss: 6.3453, val_acc: 0.6179\n",
      "Epoch [3234], train_loss: 0.0000, val_loss: 6.3331, val_acc: 0.6121\n",
      "Epoch [3235], train_loss: 0.0023, val_loss: 6.5929, val_acc: 0.5997\n",
      "Epoch [3236], train_loss: 0.1034, val_loss: 5.3585, val_acc: 0.6206\n",
      "Epoch [3237], train_loss: 0.0334, val_loss: 4.6611, val_acc: 0.6284\n",
      "Epoch [3238], train_loss: 0.0058, val_loss: 5.1909, val_acc: 0.6202\n",
      "Epoch [3239], train_loss: 0.0009, val_loss: 5.7039, val_acc: 0.6043\n",
      "Epoch [3240], train_loss: 0.0004, val_loss: 6.1148, val_acc: 0.5936\n",
      "Epoch [3241], train_loss: 0.0002, val_loss: 6.3269, val_acc: 0.5936\n",
      "Epoch [3242], train_loss: 0.0002, val_loss: 6.3910, val_acc: 0.6017\n",
      "Epoch [3243], train_loss: 0.0001, val_loss: 6.9896, val_acc: 0.5910\n",
      "Epoch [3244], train_loss: 0.0001, val_loss: 6.5689, val_acc: 0.5910\n",
      "Epoch [3245], train_loss: 0.0001, val_loss: 6.7391, val_acc: 0.5991\n",
      "Epoch [3246], train_loss: 0.0000, val_loss: 6.9418, val_acc: 0.5991\n",
      "Epoch [3247], train_loss: 0.0001, val_loss: 7.0662, val_acc: 0.6072\n",
      "Epoch [3248], train_loss: 0.0001, val_loss: 7.2706, val_acc: 0.6098\n",
      "Epoch [3249], train_loss: 0.0000, val_loss: 7.0276, val_acc: 0.6043\n",
      "Epoch [3250], train_loss: 0.0002, val_loss: 6.7766, val_acc: 0.5965\n",
      "Epoch [3251], train_loss: 0.0001, val_loss: 6.9907, val_acc: 0.5991\n",
      "Epoch [3252], train_loss: 0.0005, val_loss: 7.4435, val_acc: 0.5991\n",
      "Epoch [3253], train_loss: 0.0409, val_loss: 2.5613, val_acc: 0.6023\n",
      "Epoch [3254], train_loss: 0.0204, val_loss: 4.4908, val_acc: 0.5968\n",
      "Epoch [3255], train_loss: 0.0261, val_loss: 4.1759, val_acc: 0.6388\n",
      "Epoch [3256], train_loss: 0.0032, val_loss: 4.1506, val_acc: 0.6391\n",
      "Epoch [3257], train_loss: 0.0010, val_loss: 4.6172, val_acc: 0.6150\n",
      "Epoch [3258], train_loss: 0.0027, val_loss: 4.6753, val_acc: 0.6202\n",
      "Epoch [3259], train_loss: 0.0005, val_loss: 4.7152, val_acc: 0.6254\n",
      "Epoch [3260], train_loss: 0.0002, val_loss: 5.1906, val_acc: 0.6443\n",
      "Epoch [3261], train_loss: 0.0002, val_loss: 5.4575, val_acc: 0.6443\n",
      "Epoch [3262], train_loss: 0.0001, val_loss: 5.6399, val_acc: 0.6417\n",
      "Epoch [3263], train_loss: 0.0001, val_loss: 5.6650, val_acc: 0.6417\n",
      "Epoch [3264], train_loss: 0.0001, val_loss: 5.8574, val_acc: 0.6391\n",
      "Epoch [3265], train_loss: 0.0001, val_loss: 5.8727, val_acc: 0.6443\n",
      "Epoch [3266], train_loss: 0.0001, val_loss: 6.1161, val_acc: 0.6313\n",
      "Epoch [3267], train_loss: 0.0001, val_loss: 6.0929, val_acc: 0.6443\n",
      "Epoch [3268], train_loss: 0.0001, val_loss: 6.0845, val_acc: 0.6443\n",
      "Epoch [3269], train_loss: 0.0000, val_loss: 6.2913, val_acc: 0.6362\n",
      "Epoch [3270], train_loss: 0.0001, val_loss: 6.5144, val_acc: 0.6495\n",
      "Epoch [3271], train_loss: 0.0000, val_loss: 6.4523, val_acc: 0.6443\n",
      "Epoch [3272], train_loss: 0.0001, val_loss: 6.2429, val_acc: 0.6469\n",
      "Epoch [3273], train_loss: 0.0000, val_loss: 6.5604, val_acc: 0.6443\n",
      "Epoch [3274], train_loss: 0.0000, val_loss: 6.4590, val_acc: 0.6469\n",
      "Epoch [3275], train_loss: 0.0000, val_loss: 6.7480, val_acc: 0.6469\n",
      "Epoch [3276], train_loss: 0.0000, val_loss: 6.5728, val_acc: 0.6495\n",
      "Epoch [3277], train_loss: 0.0000, val_loss: 6.5561, val_acc: 0.6443\n",
      "Epoch [3278], train_loss: 0.0001, val_loss: 6.3355, val_acc: 0.6495\n",
      "Epoch [3279], train_loss: 0.0000, val_loss: 6.7753, val_acc: 0.6417\n",
      "Epoch [3280], train_loss: 0.0000, val_loss: 6.8863, val_acc: 0.6524\n",
      "Epoch [3281], train_loss: 0.0000, val_loss: 6.6644, val_acc: 0.6524\n",
      "Epoch [3282], train_loss: 0.0000, val_loss: 7.1361, val_acc: 0.6391\n",
      "Epoch [3283], train_loss: 0.0000, val_loss: 6.9632, val_acc: 0.6524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3284], train_loss: 0.0000, val_loss: 6.6694, val_acc: 0.6524\n",
      "Epoch [3285], train_loss: 0.0000, val_loss: 7.0796, val_acc: 0.6524\n",
      "Epoch [3286], train_loss: 0.0000, val_loss: 7.1316, val_acc: 0.6498\n",
      "Epoch [3287], train_loss: 0.0000, val_loss: 7.0926, val_acc: 0.6443\n",
      "Epoch [3288], train_loss: 0.0000, val_loss: 7.0898, val_acc: 0.6603\n",
      "Epoch [3289], train_loss: 0.0000, val_loss: 6.9180, val_acc: 0.6469\n",
      "Epoch [3290], train_loss: 0.0000, val_loss: 6.7936, val_acc: 0.6603\n",
      "Epoch [3291], train_loss: 0.0000, val_loss: 7.1258, val_acc: 0.6417\n",
      "Epoch [3292], train_loss: 0.0000, val_loss: 7.1161, val_acc: 0.6443\n",
      "Epoch [3293], train_loss: 0.0000, val_loss: 7.2996, val_acc: 0.6443\n",
      "Epoch [3294], train_loss: 0.0000, val_loss: 7.0625, val_acc: 0.6495\n",
      "Epoch [3295], train_loss: 0.0000, val_loss: 7.2791, val_acc: 0.6469\n",
      "Epoch [3296], train_loss: 0.0000, val_loss: 7.6313, val_acc: 0.6417\n",
      "Epoch [3297], train_loss: 0.0000, val_loss: 7.4173, val_acc: 0.6550\n",
      "Epoch [3298], train_loss: 0.0000, val_loss: 7.5569, val_acc: 0.6443\n",
      "Epoch [3299], train_loss: 0.0000, val_loss: 7.1233, val_acc: 0.6417\n",
      "Epoch [3300], train_loss: 0.0000, val_loss: 7.1849, val_acc: 0.6469\n",
      "Epoch [3301], train_loss: 0.0000, val_loss: 7.2546, val_acc: 0.6550\n",
      "Epoch [3302], train_loss: 0.0000, val_loss: 7.5115, val_acc: 0.6443\n",
      "Epoch [3303], train_loss: 0.0000, val_loss: 7.5217, val_acc: 0.6443\n",
      "Epoch [3304], train_loss: 0.0021, val_loss: 7.1687, val_acc: 0.6391\n",
      "Epoch [3305], train_loss: 0.1840, val_loss: 4.4081, val_acc: 0.5962\n",
      "Epoch [3306], train_loss: 0.0822, val_loss: 1.8589, val_acc: 0.6254\n",
      "Epoch [3307], train_loss: 0.0085, val_loss: 3.2208, val_acc: 0.6254\n",
      "Epoch [3308], train_loss: 0.0015, val_loss: 3.3764, val_acc: 0.6303\n",
      "Epoch [3309], train_loss: 0.0015, val_loss: 4.1628, val_acc: 0.6466\n",
      "Epoch [3310], train_loss: 0.0004, val_loss: 3.8764, val_acc: 0.6385\n",
      "Epoch [3311], train_loss: 0.0002, val_loss: 4.1079, val_acc: 0.6359\n",
      "Epoch [3312], train_loss: 0.0002, val_loss: 4.0615, val_acc: 0.6307\n",
      "Epoch [3313], train_loss: 0.0002, val_loss: 3.9615, val_acc: 0.6385\n",
      "Epoch [3314], train_loss: 0.0005, val_loss: 3.8828, val_acc: 0.6254\n",
      "Epoch [3315], train_loss: 0.0002, val_loss: 3.9787, val_acc: 0.6440\n",
      "Epoch [3316], train_loss: 0.0004, val_loss: 4.0493, val_acc: 0.6414\n",
      "Epoch [3317], train_loss: 0.0003, val_loss: 4.3442, val_acc: 0.6466\n",
      "Epoch [3318], train_loss: 0.0001, val_loss: 4.3530, val_acc: 0.6440\n",
      "Epoch [3319], train_loss: 0.0001, val_loss: 4.3867, val_acc: 0.6388\n",
      "Epoch [3320], train_loss: 0.0001, val_loss: 4.3646, val_acc: 0.6440\n",
      "Epoch [3321], train_loss: 0.0002, val_loss: 4.0645, val_acc: 0.6411\n",
      "Epoch [3322], train_loss: 0.0001, val_loss: 4.3015, val_acc: 0.6385\n",
      "Epoch [3323], train_loss: 0.0000, val_loss: 4.3824, val_acc: 0.6414\n",
      "Epoch [3324], train_loss: 0.0000, val_loss: 4.4702, val_acc: 0.6414\n",
      "Epoch [3325], train_loss: 0.0000, val_loss: 4.5160, val_acc: 0.6388\n",
      "Epoch [3326], train_loss: 0.0001, val_loss: 4.5068, val_acc: 0.6388\n",
      "Epoch [3327], train_loss: 0.0000, val_loss: 4.5760, val_acc: 0.6280\n",
      "Epoch [3328], train_loss: 0.0000, val_loss: 4.3955, val_acc: 0.6359\n",
      "Epoch [3329], train_loss: 0.0000, val_loss: 4.4266, val_acc: 0.6388\n",
      "Epoch [3330], train_loss: 0.0000, val_loss: 4.6017, val_acc: 0.6440\n",
      "Epoch [3331], train_loss: 0.0000, val_loss: 4.5175, val_acc: 0.6388\n",
      "Epoch [3332], train_loss: 0.0000, val_loss: 4.5696, val_acc: 0.6414\n",
      "Epoch [3333], train_loss: 0.0000, val_loss: 4.6845, val_acc: 0.6333\n",
      "Epoch [3334], train_loss: 0.0000, val_loss: 4.4070, val_acc: 0.6362\n",
      "Epoch [3335], train_loss: 0.0000, val_loss: 4.5635, val_acc: 0.6414\n",
      "Epoch [3336], train_loss: 0.0000, val_loss: 4.6087, val_acc: 0.6414\n",
      "Epoch [3337], train_loss: 0.0000, val_loss: 4.6922, val_acc: 0.6440\n",
      "Epoch [3338], train_loss: 0.0000, val_loss: 4.6129, val_acc: 0.6414\n",
      "Epoch [3339], train_loss: 0.0000, val_loss: 4.5863, val_acc: 0.6362\n",
      "Epoch [3340], train_loss: 0.0000, val_loss: 4.6675, val_acc: 0.6414\n",
      "Epoch [3341], train_loss: 0.0000, val_loss: 4.7298, val_acc: 0.6440\n",
      "Epoch [3342], train_loss: 0.0000, val_loss: 4.7245, val_acc: 0.6414\n",
      "Epoch [3343], train_loss: 0.0000, val_loss: 4.7206, val_acc: 0.6388\n",
      "Epoch [3344], train_loss: 0.0000, val_loss: 4.8133, val_acc: 0.6414\n",
      "Epoch [3345], train_loss: 0.0000, val_loss: 4.6854, val_acc: 0.6388\n",
      "Epoch [3346], train_loss: 0.0000, val_loss: 4.7801, val_acc: 0.6414\n",
      "Epoch [3347], train_loss: 0.0000, val_loss: 4.5953, val_acc: 0.6440\n",
      "Epoch [3348], train_loss: 0.0000, val_loss: 4.6056, val_acc: 0.6440\n",
      "Epoch [3349], train_loss: 0.0000, val_loss: 4.7546, val_acc: 0.6440\n",
      "Epoch [3350], train_loss: 0.0000, val_loss: 4.7109, val_acc: 0.6440\n",
      "Epoch [3351], train_loss: 0.0002, val_loss: 3.8090, val_acc: 0.6362\n",
      "Epoch [3352], train_loss: 0.0001, val_loss: 4.2257, val_acc: 0.6310\n",
      "Epoch [3353], train_loss: 0.0001, val_loss: 4.2429, val_acc: 0.6365\n",
      "Epoch [3354], train_loss: 0.0001, val_loss: 4.3657, val_acc: 0.6258\n",
      "Epoch [3355], train_loss: 0.0000, val_loss: 4.2882, val_acc: 0.6284\n",
      "Epoch [3356], train_loss: 0.0000, val_loss: 4.4770, val_acc: 0.6336\n",
      "Epoch [3357], train_loss: 0.0000, val_loss: 4.4903, val_acc: 0.6258\n",
      "Epoch [3358], train_loss: 0.0000, val_loss: 4.6545, val_acc: 0.6362\n",
      "Epoch [3359], train_loss: 0.0000, val_loss: 4.6136, val_acc: 0.6388\n",
      "Epoch [3360], train_loss: 0.0000, val_loss: 4.5073, val_acc: 0.6388\n",
      "Epoch [3361], train_loss: 0.0000, val_loss: 4.6223, val_acc: 0.6336\n",
      "Epoch [3362], train_loss: 0.0000, val_loss: 4.5987, val_acc: 0.6336\n",
      "Epoch [3363], train_loss: 0.0000, val_loss: 4.6599, val_acc: 0.6362\n",
      "Epoch [3364], train_loss: 0.0000, val_loss: 4.5454, val_acc: 0.6336\n",
      "Epoch [3365], train_loss: 0.0000, val_loss: 4.7309, val_acc: 0.6362\n",
      "Epoch [3366], train_loss: 0.0000, val_loss: 4.6542, val_acc: 0.6362\n",
      "Epoch [3367], train_loss: 0.0000, val_loss: 4.6526, val_acc: 0.6362\n",
      "Epoch [3368], train_loss: 0.0000, val_loss: 4.7845, val_acc: 0.6228\n",
      "Epoch [3369], train_loss: 0.0000, val_loss: 4.6652, val_acc: 0.6388\n",
      "Epoch [3370], train_loss: 0.0000, val_loss: 4.8917, val_acc: 0.6228\n",
      "Epoch [3371], train_loss: 0.0000, val_loss: 4.5426, val_acc: 0.6414\n",
      "Epoch [3372], train_loss: 0.0000, val_loss: 4.6956, val_acc: 0.6440\n",
      "Epoch [3373], train_loss: 0.0000, val_loss: 4.6952, val_acc: 0.6310\n",
      "Epoch [3374], train_loss: 0.0000, val_loss: 4.8167, val_acc: 0.6359\n",
      "Epoch [3375], train_loss: 0.0000, val_loss: 4.9370, val_acc: 0.6280\n",
      "Epoch [3376], train_loss: 0.0000, val_loss: 4.6862, val_acc: 0.6228\n",
      "Epoch [3377], train_loss: 0.0000, val_loss: 4.6622, val_acc: 0.6228\n",
      "Epoch [3378], train_loss: 0.0000, val_loss: 4.8073, val_acc: 0.6254\n",
      "Epoch [3379], train_loss: 0.0000, val_loss: 4.9624, val_acc: 0.6199\n",
      "Epoch [3380], train_loss: 0.0000, val_loss: 4.9089, val_acc: 0.6333\n",
      "Epoch [3381], train_loss: 0.0000, val_loss: 4.9123, val_acc: 0.6307\n",
      "Epoch [3382], train_loss: 0.0000, val_loss: 4.9543, val_acc: 0.6359\n",
      "Epoch [3383], train_loss: 0.0000, val_loss: 4.8122, val_acc: 0.6307\n",
      "Epoch [3384], train_loss: 0.0000, val_loss: 4.9193, val_acc: 0.6280\n",
      "Epoch [3385], train_loss: 0.0000, val_loss: 4.9988, val_acc: 0.6225\n",
      "Epoch [3386], train_loss: 0.0000, val_loss: 4.8232, val_acc: 0.6225\n",
      "Epoch [3387], train_loss: 0.0000, val_loss: 5.0591, val_acc: 0.6333\n",
      "Epoch [3388], train_loss: 0.0000, val_loss: 4.9588, val_acc: 0.6280\n",
      "Epoch [3389], train_loss: 0.0000, val_loss: 4.9548, val_acc: 0.6225\n",
      "Epoch [3390], train_loss: 0.0000, val_loss: 5.0175, val_acc: 0.6333\n",
      "Epoch [3391], train_loss: 0.0000, val_loss: 4.9837, val_acc: 0.6225\n",
      "Epoch [3392], train_loss: 0.0000, val_loss: 4.9612, val_acc: 0.6359\n",
      "Epoch [3393], train_loss: 0.0000, val_loss: 4.9438, val_acc: 0.6254\n",
      "Epoch [3394], train_loss: 0.0000, val_loss: 4.8032, val_acc: 0.6333\n",
      "Epoch [3395], train_loss: 0.0000, val_loss: 4.9334, val_acc: 0.6307\n",
      "Epoch [3396], train_loss: 0.0000, val_loss: 4.9896, val_acc: 0.6333\n",
      "Epoch [3397], train_loss: 0.0000, val_loss: 5.0418, val_acc: 0.6385\n",
      "Epoch [3398], train_loss: 0.0000, val_loss: 5.0943, val_acc: 0.6333\n",
      "Epoch [3399], train_loss: 0.0000, val_loss: 5.0572, val_acc: 0.6385\n",
      "Epoch [3400], train_loss: 0.0000, val_loss: 5.1178, val_acc: 0.6359\n",
      "Epoch [3401], train_loss: 0.0000, val_loss: 5.1141, val_acc: 0.6225\n",
      "Epoch [3402], train_loss: 0.0000, val_loss: 5.1228, val_acc: 0.6333\n",
      "Epoch [3403], train_loss: 0.0000, val_loss: 5.0981, val_acc: 0.6359\n",
      "Epoch [3404], train_loss: 0.0000, val_loss: 5.0753, val_acc: 0.6307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3405], train_loss: 0.0000, val_loss: 5.1479, val_acc: 0.6359\n",
      "Epoch [3406], train_loss: 0.0000, val_loss: 5.0705, val_acc: 0.6385\n",
      "Epoch [3407], train_loss: 0.0000, val_loss: 5.1878, val_acc: 0.6307\n",
      "Epoch [3408], train_loss: 0.0000, val_loss: 4.8454, val_acc: 0.6280\n",
      "Epoch [3409], train_loss: 0.0000, val_loss: 5.0288, val_acc: 0.6359\n",
      "Epoch [3410], train_loss: 0.0000, val_loss: 5.3321, val_acc: 0.6333\n",
      "Epoch [3411], train_loss: 0.0000, val_loss: 5.1197, val_acc: 0.6359\n",
      "Epoch [3412], train_loss: 0.0000, val_loss: 5.1498, val_acc: 0.6333\n",
      "Epoch [3413], train_loss: 0.0000, val_loss: 5.1380, val_acc: 0.6280\n",
      "Epoch [3414], train_loss: 0.0000, val_loss: 5.0119, val_acc: 0.6147\n",
      "Epoch [3415], train_loss: 0.0000, val_loss: 5.3020, val_acc: 0.6333\n",
      "Epoch [3416], train_loss: 0.0000, val_loss: 5.3362, val_acc: 0.6303\n",
      "Epoch [3417], train_loss: 0.0000, val_loss: 5.3977, val_acc: 0.6277\n",
      "Epoch [3418], train_loss: 0.0000, val_loss: 5.1881, val_acc: 0.6277\n",
      "Epoch [3419], train_loss: 0.0000, val_loss: 5.3207, val_acc: 0.6303\n",
      "Epoch [3420], train_loss: 0.0000, val_loss: 5.5302, val_acc: 0.6303\n",
      "Epoch [3421], train_loss: 0.0000, val_loss: 5.2161, val_acc: 0.6303\n",
      "Epoch [3422], train_loss: 0.0000, val_loss: 5.4999, val_acc: 0.6303\n",
      "Epoch [3423], train_loss: 0.0000, val_loss: 5.3631, val_acc: 0.6303\n",
      "Epoch [3424], train_loss: 0.0000, val_loss: 5.8204, val_acc: 0.6118\n",
      "Epoch [3425], train_loss: 0.0000, val_loss: 5.7832, val_acc: 0.6307\n",
      "Epoch [3426], train_loss: 0.0001, val_loss: 5.7813, val_acc: 0.6277\n",
      "Epoch [3427], train_loss: 0.0648, val_loss: 2.9574, val_acc: 0.5936\n",
      "Epoch [3428], train_loss: 0.0918, val_loss: 3.6041, val_acc: 0.6254\n",
      "Epoch [3429], train_loss: 0.0512, val_loss: 2.2893, val_acc: 0.6127\n",
      "Epoch [3430], train_loss: 0.0421, val_loss: 3.2710, val_acc: 0.5646\n",
      "Epoch [3431], train_loss: 0.0057, val_loss: 4.5507, val_acc: 0.5884\n",
      "Epoch [3432], train_loss: 0.0041, val_loss: 3.9251, val_acc: 0.6183\n",
      "Epoch [3433], train_loss: 0.0010, val_loss: 4.2253, val_acc: 0.6261\n",
      "Epoch [3434], train_loss: 0.0004, val_loss: 4.4370, val_acc: 0.6075\n",
      "Epoch [3435], train_loss: 0.0001, val_loss: 4.7195, val_acc: 0.6235\n",
      "Epoch [3436], train_loss: 0.0001, val_loss: 4.6345, val_acc: 0.6131\n",
      "Epoch [3437], train_loss: 0.0001, val_loss: 4.7379, val_acc: 0.6183\n",
      "Epoch [3438], train_loss: 0.0001, val_loss: 4.7297, val_acc: 0.6209\n",
      "Epoch [3439], train_loss: 0.0000, val_loss: 4.9378, val_acc: 0.6209\n",
      "Epoch [3440], train_loss: 0.0001, val_loss: 4.8915, val_acc: 0.6020\n",
      "Epoch [3441], train_loss: 0.0002, val_loss: 4.9863, val_acc: 0.6101\n",
      "Epoch [3442], train_loss: 0.0019, val_loss: 4.9616, val_acc: 0.5939\n",
      "Epoch [3443], train_loss: 0.0319, val_loss: 2.3544, val_acc: 0.6310\n",
      "Epoch [3444], train_loss: 0.0029, val_loss: 2.9178, val_acc: 0.6254\n",
      "Epoch [3445], train_loss: 0.0008, val_loss: 3.2954, val_acc: 0.6280\n",
      "Epoch [3446], train_loss: 0.0001, val_loss: 3.3244, val_acc: 0.6391\n",
      "Epoch [3447], train_loss: 0.0001, val_loss: 3.3220, val_acc: 0.6417\n",
      "Epoch [3448], train_loss: 0.0001, val_loss: 3.4943, val_acc: 0.6336\n",
      "Epoch [3449], train_loss: 0.0001, val_loss: 3.4950, val_acc: 0.6495\n",
      "Epoch [3450], train_loss: 0.0001, val_loss: 3.4521, val_acc: 0.6443\n",
      "Epoch [3451], train_loss: 0.0001, val_loss: 3.6430, val_acc: 0.6417\n",
      "Epoch [3452], train_loss: 0.0000, val_loss: 3.6069, val_acc: 0.6576\n",
      "Epoch [3453], train_loss: 0.0000, val_loss: 3.6831, val_acc: 0.6417\n",
      "Epoch [3454], train_loss: 0.0000, val_loss: 3.6991, val_acc: 0.6388\n",
      "Epoch [3455], train_loss: 0.0000, val_loss: 3.6329, val_acc: 0.6417\n",
      "Epoch [3456], train_loss: 0.0000, val_loss: 3.7181, val_acc: 0.6391\n",
      "Epoch [3457], train_loss: 0.0000, val_loss: 3.6983, val_acc: 0.6307\n",
      "Epoch [3458], train_loss: 0.0000, val_loss: 3.6610, val_acc: 0.6254\n",
      "Epoch [3459], train_loss: 0.0000, val_loss: 3.6956, val_acc: 0.6284\n",
      "Epoch [3460], train_loss: 0.0000, val_loss: 3.7280, val_acc: 0.6310\n",
      "Epoch [3461], train_loss: 0.0000, val_loss: 3.6702, val_acc: 0.6310\n",
      "Epoch [3462], train_loss: 0.0000, val_loss: 3.6802, val_acc: 0.6336\n",
      "Epoch [3463], train_loss: 0.0000, val_loss: 3.8346, val_acc: 0.6310\n",
      "Epoch [3464], train_loss: 0.0000, val_loss: 3.8610, val_acc: 0.6391\n",
      "Epoch [3465], train_loss: 0.0000, val_loss: 3.8529, val_acc: 0.6391\n",
      "Epoch [3466], train_loss: 0.0000, val_loss: 3.9241, val_acc: 0.6336\n",
      "Epoch [3467], train_loss: 0.0000, val_loss: 3.9298, val_acc: 0.6310\n",
      "Epoch [3468], train_loss: 0.0000, val_loss: 3.9601, val_acc: 0.6336\n",
      "Epoch [3469], train_loss: 0.0000, val_loss: 3.8759, val_acc: 0.6202\n",
      "Epoch [3470], train_loss: 0.0000, val_loss: 3.9685, val_acc: 0.6310\n",
      "Epoch [3471], train_loss: 0.0000, val_loss: 3.9695, val_acc: 0.6310\n",
      "Epoch [3472], train_loss: 0.0000, val_loss: 4.0559, val_acc: 0.6336\n",
      "Epoch [3473], train_loss: 0.0000, val_loss: 3.9830, val_acc: 0.6284\n",
      "Epoch [3474], train_loss: 0.0000, val_loss: 4.1027, val_acc: 0.6284\n",
      "Epoch [3475], train_loss: 0.0000, val_loss: 4.1581, val_acc: 0.6228\n",
      "Epoch [3476], train_loss: 0.0000, val_loss: 4.0798, val_acc: 0.6280\n",
      "Epoch [3477], train_loss: 0.0000, val_loss: 4.0391, val_acc: 0.6284\n",
      "Epoch [3478], train_loss: 0.0000, val_loss: 4.1271, val_acc: 0.6310\n",
      "Epoch [3479], train_loss: 0.0000, val_loss: 4.0364, val_acc: 0.6232\n",
      "Epoch [3480], train_loss: 0.0000, val_loss: 4.2535, val_acc: 0.6232\n",
      "Epoch [3481], train_loss: 0.0000, val_loss: 4.2583, val_acc: 0.6254\n",
      "Epoch [3482], train_loss: 0.0000, val_loss: 4.2649, val_acc: 0.6202\n",
      "Epoch [3483], train_loss: 0.0000, val_loss: 3.8899, val_acc: 0.6150\n",
      "Epoch [3484], train_loss: 0.0000, val_loss: 4.2167, val_acc: 0.6202\n",
      "Epoch [3485], train_loss: 0.0000, val_loss: 4.1477, val_acc: 0.6228\n",
      "Epoch [3486], train_loss: 0.0000, val_loss: 4.2584, val_acc: 0.6228\n",
      "Epoch [3487], train_loss: 0.0000, val_loss: 4.3829, val_acc: 0.6150\n",
      "Epoch [3488], train_loss: 0.0000, val_loss: 4.1817, val_acc: 0.6284\n",
      "Epoch [3489], train_loss: 0.0000, val_loss: 4.1205, val_acc: 0.6310\n",
      "Epoch [3490], train_loss: 0.0000, val_loss: 4.3165, val_acc: 0.6232\n",
      "Epoch [3491], train_loss: 0.0000, val_loss: 4.2590, val_acc: 0.6258\n",
      "Epoch [3492], train_loss: 0.0000, val_loss: 4.3152, val_acc: 0.6336\n",
      "Epoch [3493], train_loss: 0.0000, val_loss: 4.3354, val_acc: 0.6284\n",
      "Epoch [3494], train_loss: 0.0000, val_loss: 4.2554, val_acc: 0.6258\n",
      "Epoch [3495], train_loss: 0.0000, val_loss: 4.4946, val_acc: 0.6362\n",
      "Epoch [3496], train_loss: 0.0000, val_loss: 4.4608, val_acc: 0.6310\n",
      "Epoch [3497], train_loss: 0.0000, val_loss: 4.4031, val_acc: 0.6310\n",
      "Epoch [3498], train_loss: 0.0000, val_loss: 4.3849, val_acc: 0.6232\n",
      "Epoch [3499], train_loss: 0.0000, val_loss: 4.3331, val_acc: 0.6258\n",
      "Epoch [3500], train_loss: 0.0000, val_loss: 4.5144, val_acc: 0.6284\n",
      "Epoch [3501], train_loss: 0.0000, val_loss: 4.4176, val_acc: 0.6284\n",
      "Epoch [3502], train_loss: 0.0000, val_loss: 4.6406, val_acc: 0.6284\n",
      "Epoch [3503], train_loss: 0.0000, val_loss: 4.3986, val_acc: 0.6258\n",
      "Epoch [3504], train_loss: 0.0000, val_loss: 4.5526, val_acc: 0.6284\n",
      "Epoch [3505], train_loss: 0.0000, val_loss: 4.4524, val_acc: 0.6284\n",
      "Epoch [3506], train_loss: 0.0000, val_loss: 4.5851, val_acc: 0.6179\n",
      "Epoch [3507], train_loss: 0.0000, val_loss: 4.6855, val_acc: 0.6202\n",
      "Epoch [3508], train_loss: 0.0001, val_loss: 4.4896, val_acc: 0.6228\n",
      "Epoch [3509], train_loss: 0.0046, val_loss: 3.7001, val_acc: 0.6183\n",
      "Epoch [3510], train_loss: 0.0644, val_loss: 2.5775, val_acc: 0.6075\n",
      "Epoch [3511], train_loss: 0.0497, val_loss: 2.0970, val_acc: 0.6293\n",
      "Epoch [3512], train_loss: 0.0169, val_loss: 2.8074, val_acc: 0.5861\n",
      "Epoch [3513], train_loss: 0.0110, val_loss: 2.9540, val_acc: 0.5887\n",
      "Epoch [3514], train_loss: 0.0005, val_loss: 3.7543, val_acc: 0.5890\n",
      "Epoch [3515], train_loss: 0.0002, val_loss: 3.8282, val_acc: 0.5838\n",
      "Epoch [3516], train_loss: 0.0001, val_loss: 3.9284, val_acc: 0.5893\n",
      "Epoch [3517], train_loss: 0.0001, val_loss: 4.0086, val_acc: 0.5997\n",
      "Epoch [3518], train_loss: 0.0000, val_loss: 4.0951, val_acc: 0.6052\n",
      "Epoch [3519], train_loss: 0.0000, val_loss: 3.8564, val_acc: 0.6079\n",
      "Epoch [3520], train_loss: 0.0000, val_loss: 4.2892, val_acc: 0.6052\n",
      "Epoch [3521], train_loss: 0.0000, val_loss: 4.1325, val_acc: 0.6079\n",
      "Epoch [3522], train_loss: 0.0000, val_loss: 4.0972, val_acc: 0.6079\n",
      "Epoch [3523], train_loss: 0.0000, val_loss: 4.3322, val_acc: 0.6023\n",
      "Epoch [3524], train_loss: 0.0000, val_loss: 4.1478, val_acc: 0.6131\n",
      "Epoch [3525], train_loss: 0.0000, val_loss: 4.2836, val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3526], train_loss: 0.0000, val_loss: 4.2317, val_acc: 0.6131\n",
      "Epoch [3527], train_loss: 0.0000, val_loss: 4.2471, val_acc: 0.6238\n",
      "Epoch [3528], train_loss: 0.0000, val_loss: 4.3178, val_acc: 0.6049\n",
      "Epoch [3529], train_loss: 0.0000, val_loss: 4.4417, val_acc: 0.6157\n",
      "Epoch [3530], train_loss: 0.0000, val_loss: 4.2844, val_acc: 0.6131\n",
      "Epoch [3531], train_loss: 0.0000, val_loss: 4.4286, val_acc: 0.6105\n",
      "Epoch [3532], train_loss: 0.0000, val_loss: 4.7020, val_acc: 0.6131\n",
      "Epoch [3533], train_loss: 0.0000, val_loss: 4.5529, val_acc: 0.6157\n",
      "Epoch [3534], train_loss: 0.0000, val_loss: 4.6712, val_acc: 0.6157\n",
      "Epoch [3535], train_loss: 0.0000, val_loss: 4.5968, val_acc: 0.5942\n",
      "Epoch [3536], train_loss: 0.0000, val_loss: 4.5738, val_acc: 0.6079\n",
      "Epoch [3537], train_loss: 0.0000, val_loss: 4.7975, val_acc: 0.6105\n",
      "Epoch [3538], train_loss: 0.0000, val_loss: 4.5672, val_acc: 0.6049\n",
      "Epoch [3539], train_loss: 0.0003, val_loss: 4.0573, val_acc: 0.6153\n",
      "Epoch [3540], train_loss: 0.0241, val_loss: 3.9101, val_acc: 0.6258\n",
      "Epoch [3541], train_loss: 0.0443, val_loss: 3.1094, val_acc: 0.6365\n",
      "Epoch [3542], train_loss: 0.0111, val_loss: 4.0662, val_acc: 0.6150\n",
      "Epoch [3543], train_loss: 0.0276, val_loss: 2.3925, val_acc: 0.5968\n",
      "Epoch [3544], train_loss: 0.0205, val_loss: 4.5394, val_acc: 0.6150\n",
      "Epoch [3545], train_loss: 0.0607, val_loss: 4.5114, val_acc: 0.6098\n",
      "Epoch [3546], train_loss: 0.0909, val_loss: 3.1802, val_acc: 0.5971\n",
      "Epoch [3547], train_loss: 0.0268, val_loss: 3.7116, val_acc: 0.6017\n",
      "Epoch [3548], train_loss: 0.0022, val_loss: 4.6012, val_acc: 0.5672\n",
      "Epoch [3549], train_loss: 0.0011, val_loss: 5.5189, val_acc: 0.5828\n",
      "Epoch [3550], train_loss: 0.0004, val_loss: 5.6180, val_acc: 0.5828\n",
      "Epoch [3551], train_loss: 0.0002, val_loss: 5.7674, val_acc: 0.5854\n",
      "Epoch [3552], train_loss: 0.0002, val_loss: 6.1441, val_acc: 0.5884\n",
      "Epoch [3553], train_loss: 0.0001, val_loss: 6.1450, val_acc: 0.5776\n",
      "Epoch [3554], train_loss: 0.0002, val_loss: 6.4712, val_acc: 0.5880\n",
      "Epoch [3555], train_loss: 0.0001, val_loss: 6.2866, val_acc: 0.5776\n",
      "Epoch [3556], train_loss: 0.0001, val_loss: 6.6452, val_acc: 0.5698\n",
      "Epoch [3557], train_loss: 0.0001, val_loss: 6.5996, val_acc: 0.5724\n",
      "Epoch [3558], train_loss: 0.0000, val_loss: 6.6629, val_acc: 0.5724\n",
      "Epoch [3559], train_loss: 0.0000, val_loss: 6.6742, val_acc: 0.5750\n",
      "Epoch [3560], train_loss: 0.0000, val_loss: 6.8038, val_acc: 0.5750\n",
      "Epoch [3561], train_loss: 0.0001, val_loss: 6.9532, val_acc: 0.5776\n",
      "Epoch [3562], train_loss: 0.0000, val_loss: 6.9093, val_acc: 0.5750\n",
      "Epoch [3563], train_loss: 0.0000, val_loss: 6.8749, val_acc: 0.5724\n",
      "Epoch [3564], train_loss: 0.0000, val_loss: 7.2931, val_acc: 0.5724\n",
      "Epoch [3565], train_loss: 0.0000, val_loss: 6.8982, val_acc: 0.5724\n",
      "Epoch [3566], train_loss: 0.0000, val_loss: 7.1562, val_acc: 0.5750\n",
      "Epoch [3567], train_loss: 0.0000, val_loss: 6.9216, val_acc: 0.5750\n",
      "Epoch [3568], train_loss: 0.0000, val_loss: 7.3810, val_acc: 0.5776\n",
      "Epoch [3569], train_loss: 0.0000, val_loss: 7.3561, val_acc: 0.5802\n",
      "Epoch [3570], train_loss: 0.0000, val_loss: 7.1195, val_acc: 0.5750\n",
      "Epoch [3571], train_loss: 0.0000, val_loss: 7.2431, val_acc: 0.5776\n",
      "Epoch [3572], train_loss: 0.0000, val_loss: 7.8531, val_acc: 0.5750\n",
      "Epoch [3573], train_loss: 0.0000, val_loss: 7.3786, val_acc: 0.5750\n",
      "Epoch [3574], train_loss: 0.0000, val_loss: 7.4285, val_acc: 0.5776\n",
      "Epoch [3575], train_loss: 0.0000, val_loss: 7.4224, val_acc: 0.5776\n",
      "Epoch [3576], train_loss: 0.0000, val_loss: 7.6141, val_acc: 0.5750\n",
      "Epoch [3577], train_loss: 0.0000, val_loss: 7.5993, val_acc: 0.5776\n",
      "Epoch [3578], train_loss: 0.0000, val_loss: 7.4518, val_acc: 0.5750\n",
      "Epoch [3579], train_loss: 0.0000, val_loss: 7.2626, val_acc: 0.5750\n",
      "Epoch [3580], train_loss: 0.0001, val_loss: 7.3110, val_acc: 0.5750\n",
      "Epoch [3581], train_loss: 0.0000, val_loss: 7.7195, val_acc: 0.5724\n",
      "Epoch [3582], train_loss: 0.0000, val_loss: 7.9440, val_acc: 0.5698\n",
      "Epoch [3583], train_loss: 0.0000, val_loss: 7.7948, val_acc: 0.5750\n",
      "Epoch [3584], train_loss: 0.0000, val_loss: 7.6318, val_acc: 0.5802\n",
      "Epoch [3585], train_loss: 0.0000, val_loss: 7.6729, val_acc: 0.5750\n",
      "Epoch [3586], train_loss: 0.0000, val_loss: 7.7824, val_acc: 0.5750\n",
      "Epoch [3587], train_loss: 0.0000, val_loss: 8.0789, val_acc: 0.5724\n",
      "Epoch [3588], train_loss: 0.0000, val_loss: 7.6515, val_acc: 0.5750\n",
      "Epoch [3589], train_loss: 0.0000, val_loss: 7.8602, val_acc: 0.5724\n",
      "Epoch [3590], train_loss: 0.0000, val_loss: 7.4982, val_acc: 0.5698\n",
      "Epoch [3591], train_loss: 0.0000, val_loss: 7.7045, val_acc: 0.5698\n",
      "Epoch [3592], train_loss: 0.0000, val_loss: 7.8580, val_acc: 0.5750\n",
      "Epoch [3593], train_loss: 0.0000, val_loss: 7.8215, val_acc: 0.5698\n",
      "Epoch [3594], train_loss: 0.0000, val_loss: 8.1667, val_acc: 0.5698\n",
      "Epoch [3595], train_loss: 0.0000, val_loss: 8.1243, val_acc: 0.5724\n",
      "Epoch [3596], train_loss: 0.0000, val_loss: 7.8483, val_acc: 0.5750\n",
      "Epoch [3597], train_loss: 0.0000, val_loss: 8.1909, val_acc: 0.5750\n",
      "Epoch [3598], train_loss: 0.0000, val_loss: 7.9671, val_acc: 0.5750\n",
      "Epoch [3599], train_loss: 0.0000, val_loss: 8.3965, val_acc: 0.5776\n",
      "Epoch [3600], train_loss: 0.0000, val_loss: 8.0931, val_acc: 0.5698\n",
      "Epoch [3601], train_loss: 0.0000, val_loss: 8.1598, val_acc: 0.5724\n",
      "Epoch [3602], train_loss: 0.0000, val_loss: 8.3800, val_acc: 0.5724\n",
      "Epoch [3603], train_loss: 0.0001, val_loss: 8.6483, val_acc: 0.5831\n",
      "Epoch [3604], train_loss: 0.0214, val_loss: 6.0448, val_acc: 0.6072\n",
      "Epoch [3605], train_loss: 0.0387, val_loss: 4.7228, val_acc: 0.5783\n",
      "Epoch [3606], train_loss: 0.0063, val_loss: 7.8022, val_acc: 0.5854\n",
      "Epoch [3607], train_loss: 0.0021, val_loss: 10.5855, val_acc: 0.5828\n",
      "Epoch [3608], train_loss: 0.0097, val_loss: 7.3956, val_acc: 0.6040\n",
      "Epoch [3609], train_loss: 0.0107, val_loss: 5.3510, val_acc: 0.6147\n",
      "Epoch [3610], train_loss: 0.0097, val_loss: 5.7066, val_acc: 0.6014\n",
      "Epoch [3611], train_loss: 0.0256, val_loss: 3.5370, val_acc: 0.5962\n",
      "Epoch [3612], train_loss: 0.0243, val_loss: 3.6069, val_acc: 0.6206\n",
      "Epoch [3613], train_loss: 0.0134, val_loss: 5.4597, val_acc: 0.6046\n",
      "Epoch [3614], train_loss: 0.0058, val_loss: 4.7773, val_acc: 0.5750\n",
      "Epoch [3615], train_loss: 0.0084, val_loss: 6.2550, val_acc: 0.5939\n",
      "Epoch [3616], train_loss: 0.0472, val_loss: 4.8617, val_acc: 0.6176\n",
      "Epoch [3617], train_loss: 0.0815, val_loss: 3.8160, val_acc: 0.6362\n",
      "Epoch [3618], train_loss: 0.0099, val_loss: 3.6769, val_acc: 0.6209\n",
      "Epoch [3619], train_loss: 0.0029, val_loss: 5.5362, val_acc: 0.6310\n",
      "Epoch [3620], train_loss: 0.0030, val_loss: 5.6323, val_acc: 0.6199\n",
      "Epoch [3621], train_loss: 0.0001, val_loss: 4.9870, val_acc: 0.6310\n",
      "Epoch [3622], train_loss: 0.0001, val_loss: 4.8722, val_acc: 0.6202\n",
      "Epoch [3623], train_loss: 0.0001, val_loss: 5.0152, val_acc: 0.6124\n",
      "Epoch [3624], train_loss: 0.0000, val_loss: 4.7082, val_acc: 0.6232\n",
      "Epoch [3625], train_loss: 0.0001, val_loss: 5.1304, val_acc: 0.6284\n",
      "Epoch [3626], train_loss: 0.0000, val_loss: 5.0181, val_acc: 0.6258\n",
      "Epoch [3627], train_loss: 0.0000, val_loss: 5.0933, val_acc: 0.6176\n",
      "Epoch [3628], train_loss: 0.0000, val_loss: 5.0229, val_acc: 0.6258\n",
      "Epoch [3629], train_loss: 0.0000, val_loss: 5.2316, val_acc: 0.6284\n",
      "Epoch [3630], train_loss: 0.0000, val_loss: 5.1644, val_acc: 0.6284\n",
      "Epoch [3631], train_loss: 0.0000, val_loss: 5.2312, val_acc: 0.6258\n",
      "Epoch [3632], train_loss: 0.0000, val_loss: 5.3707, val_acc: 0.6284\n",
      "Epoch [3633], train_loss: 0.0000, val_loss: 5.0854, val_acc: 0.6232\n",
      "Epoch [3634], train_loss: 0.0000, val_loss: 5.2225, val_acc: 0.6232\n",
      "Epoch [3635], train_loss: 0.0000, val_loss: 5.1610, val_acc: 0.6232\n",
      "Epoch [3636], train_loss: 0.0000, val_loss: 5.4268, val_acc: 0.6284\n",
      "Epoch [3637], train_loss: 0.0000, val_loss: 5.0946, val_acc: 0.6258\n",
      "Epoch [3638], train_loss: 0.0000, val_loss: 5.3278, val_acc: 0.6206\n",
      "Epoch [3639], train_loss: 0.0000, val_loss: 5.3666, val_acc: 0.6258\n",
      "Epoch [3640], train_loss: 0.0000, val_loss: 5.4760, val_acc: 0.6232\n",
      "Epoch [3641], train_loss: 0.0000, val_loss: 5.3661, val_acc: 0.6258\n",
      "Epoch [3642], train_loss: 0.0000, val_loss: 5.4815, val_acc: 0.6206\n",
      "Epoch [3643], train_loss: 0.0000, val_loss: 5.5081, val_acc: 0.6284\n",
      "Epoch [3644], train_loss: 0.0000, val_loss: 5.3481, val_acc: 0.6258\n",
      "Epoch [3645], train_loss: 0.0000, val_loss: 5.5957, val_acc: 0.6258\n",
      "Epoch [3646], train_loss: 0.0000, val_loss: 5.4225, val_acc: 0.6232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3647], train_loss: 0.0000, val_loss: 5.4261, val_acc: 0.6232\n",
      "Epoch [3648], train_loss: 0.0000, val_loss: 5.4788, val_acc: 0.6232\n",
      "Epoch [3649], train_loss: 0.0000, val_loss: 5.5885, val_acc: 0.6206\n",
      "Epoch [3650], train_loss: 0.0000, val_loss: 5.3820, val_acc: 0.6258\n",
      "Epoch [3651], train_loss: 0.0000, val_loss: 5.4507, val_acc: 0.6232\n",
      "Epoch [3652], train_loss: 0.0000, val_loss: 5.5753, val_acc: 0.6232\n",
      "Epoch [3653], train_loss: 0.0000, val_loss: 5.5968, val_acc: 0.6206\n",
      "Epoch [3654], train_loss: 0.0000, val_loss: 5.6250, val_acc: 0.6258\n",
      "Epoch [3655], train_loss: 0.0000, val_loss: 5.7225, val_acc: 0.6284\n",
      "Epoch [3656], train_loss: 0.0000, val_loss: 5.6242, val_acc: 0.6232\n",
      "Epoch [3657], train_loss: 0.0000, val_loss: 5.6501, val_acc: 0.6206\n",
      "Epoch [3658], train_loss: 0.0000, val_loss: 5.7027, val_acc: 0.6206\n",
      "Epoch [3659], train_loss: 0.0000, val_loss: 5.7635, val_acc: 0.6206\n",
      "Epoch [3660], train_loss: 0.0000, val_loss: 5.6057, val_acc: 0.6258\n",
      "Epoch [3661], train_loss: 0.0000, val_loss: 5.6448, val_acc: 0.6206\n",
      "Epoch [3662], train_loss: 0.0000, val_loss: 5.8499, val_acc: 0.6153\n",
      "Epoch [3663], train_loss: 0.0000, val_loss: 5.9322, val_acc: 0.6310\n",
      "Epoch [3664], train_loss: 0.0000, val_loss: 5.8189, val_acc: 0.6258\n",
      "Epoch [3665], train_loss: 0.0000, val_loss: 5.7164, val_acc: 0.6284\n",
      "Epoch [3666], train_loss: 0.0000, val_loss: 5.8442, val_acc: 0.6206\n",
      "Epoch [3667], train_loss: 0.0000, val_loss: 5.7260, val_acc: 0.6202\n",
      "Epoch [3668], train_loss: 0.0000, val_loss: 5.7213, val_acc: 0.6232\n",
      "Epoch [3669], train_loss: 0.0000, val_loss: 5.6617, val_acc: 0.6232\n",
      "Epoch [3670], train_loss: 0.0000, val_loss: 5.7176, val_acc: 0.6206\n",
      "Epoch [3671], train_loss: 0.0000, val_loss: 5.7975, val_acc: 0.6258\n",
      "Epoch [3672], train_loss: 0.0000, val_loss: 5.8314, val_acc: 0.6232\n",
      "Epoch [3673], train_loss: 0.0001, val_loss: 5.7861, val_acc: 0.6258\n",
      "Epoch [3674], train_loss: 0.0000, val_loss: 6.3436, val_acc: 0.6147\n",
      "Epoch [3675], train_loss: 0.0000, val_loss: 6.2556, val_acc: 0.6199\n",
      "Epoch [3676], train_loss: 0.0001, val_loss: 6.0371, val_acc: 0.6202\n",
      "Epoch [3677], train_loss: 0.0000, val_loss: 6.5509, val_acc: 0.6150\n",
      "Epoch [3678], train_loss: 0.0000, val_loss: 6.3999, val_acc: 0.6199\n",
      "Epoch [3679], train_loss: 0.0000, val_loss: 6.3349, val_acc: 0.6147\n",
      "Epoch [3680], train_loss: 0.0000, val_loss: 6.4754, val_acc: 0.6121\n",
      "Epoch [3681], train_loss: 0.0000, val_loss: 6.4333, val_acc: 0.6173\n",
      "Epoch [3682], train_loss: 0.0000, val_loss: 6.1915, val_acc: 0.6232\n",
      "Epoch [3683], train_loss: 0.0000, val_loss: 6.1784, val_acc: 0.6176\n",
      "Epoch [3684], train_loss: 0.0000, val_loss: 6.1878, val_acc: 0.6072\n",
      "Epoch [3685], train_loss: 0.0000, val_loss: 6.0050, val_acc: 0.6232\n",
      "Epoch [3686], train_loss: 0.0000, val_loss: 5.9580, val_acc: 0.6206\n",
      "Epoch [3687], train_loss: 0.0000, val_loss: 6.2405, val_acc: 0.6310\n",
      "Epoch [3688], train_loss: 0.0000, val_loss: 6.1816, val_acc: 0.6258\n",
      "Epoch [3689], train_loss: 0.0000, val_loss: 6.2536, val_acc: 0.6258\n",
      "Epoch [3690], train_loss: 0.0000, val_loss: 6.3912, val_acc: 0.6232\n",
      "Epoch [3691], train_loss: 0.0000, val_loss: 6.3056, val_acc: 0.6258\n",
      "Epoch [3692], train_loss: 0.0000, val_loss: 6.2675, val_acc: 0.6258\n",
      "Epoch [3693], train_loss: 0.0000, val_loss: 6.3475, val_acc: 0.6232\n",
      "Epoch [3694], train_loss: 0.0000, val_loss: 6.2278, val_acc: 0.6258\n",
      "Epoch [3695], train_loss: 0.0000, val_loss: 6.3336, val_acc: 0.6284\n",
      "Epoch [3696], train_loss: 0.0000, val_loss: 6.2262, val_acc: 0.6258\n",
      "Epoch [3697], train_loss: 0.0000, val_loss: 6.3028, val_acc: 0.6284\n",
      "Epoch [3698], train_loss: 0.0000, val_loss: 6.3778, val_acc: 0.6284\n",
      "Epoch [3699], train_loss: 0.0000, val_loss: 6.2711, val_acc: 0.6310\n",
      "Epoch [3700], train_loss: 0.0001, val_loss: 6.2780, val_acc: 0.6232\n",
      "Epoch [3701], train_loss: 0.0001, val_loss: 7.2726, val_acc: 0.5857\n",
      "Epoch [3702], train_loss: 0.0000, val_loss: 7.0216, val_acc: 0.5968\n",
      "Epoch [3703], train_loss: 0.0000, val_loss: 7.0793, val_acc: 0.5887\n",
      "Epoch [3704], train_loss: 0.0000, val_loss: 7.2080, val_acc: 0.5939\n",
      "Epoch [3705], train_loss: 0.0308, val_loss: 6.4155, val_acc: 0.6075\n",
      "Epoch [3706], train_loss: 0.1120, val_loss: 1.8383, val_acc: 0.6092\n",
      "Epoch [3707], train_loss: 0.0247, val_loss: 4.3173, val_acc: 0.5877\n",
      "Epoch [3708], train_loss: 0.0188, val_loss: 4.1916, val_acc: 0.6017\n",
      "Epoch [3709], train_loss: 0.0031, val_loss: 3.5796, val_acc: 0.5884\n",
      "Epoch [3710], train_loss: 0.0010, val_loss: 3.8828, val_acc: 0.6079\n",
      "Epoch [3711], train_loss: 0.0003, val_loss: 4.0133, val_acc: 0.6049\n",
      "Epoch [3712], train_loss: 0.0002, val_loss: 4.1166, val_acc: 0.6023\n",
      "Epoch [3713], train_loss: 0.0001, val_loss: 4.3431, val_acc: 0.5942\n",
      "Epoch [3714], train_loss: 0.0001, val_loss: 4.2521, val_acc: 0.6049\n",
      "Epoch [3715], train_loss: 0.0001, val_loss: 4.5894, val_acc: 0.6023\n",
      "Epoch [3716], train_loss: 0.0001, val_loss: 4.4683, val_acc: 0.6075\n",
      "Epoch [3717], train_loss: 0.0000, val_loss: 4.4848, val_acc: 0.6075\n",
      "Epoch [3718], train_loss: 0.0000, val_loss: 4.6603, val_acc: 0.6023\n",
      "Epoch [3719], train_loss: 0.0000, val_loss: 4.9022, val_acc: 0.5913\n",
      "Epoch [3720], train_loss: 0.0000, val_loss: 4.7824, val_acc: 0.6049\n",
      "Epoch [3721], train_loss: 0.0000, val_loss: 4.6984, val_acc: 0.6049\n",
      "Epoch [3722], train_loss: 0.0000, val_loss: 4.7616, val_acc: 0.5968\n",
      "Epoch [3723], train_loss: 0.0000, val_loss: 4.8347, val_acc: 0.5887\n",
      "Epoch [3724], train_loss: 0.0000, val_loss: 4.8001, val_acc: 0.5994\n",
      "Epoch [3725], train_loss: 0.0000, val_loss: 5.0012, val_acc: 0.6049\n",
      "Epoch [3726], train_loss: 0.0000, val_loss: 5.0954, val_acc: 0.5968\n",
      "Epoch [3727], train_loss: 0.0001, val_loss: 5.0004, val_acc: 0.6153\n",
      "Epoch [3728], train_loss: 0.0000, val_loss: 4.9935, val_acc: 0.5861\n",
      "Epoch [3729], train_loss: 0.0000, val_loss: 5.1493, val_acc: 0.5939\n",
      "Epoch [3730], train_loss: 0.0000, val_loss: 5.1170, val_acc: 0.6020\n",
      "Epoch [3731], train_loss: 0.0000, val_loss: 5.0837, val_acc: 0.6020\n",
      "Epoch [3732], train_loss: 0.0001, val_loss: 5.3315, val_acc: 0.5913\n",
      "Epoch [3733], train_loss: 0.0000, val_loss: 5.2221, val_acc: 0.5965\n",
      "Epoch [3734], train_loss: 0.0000, val_loss: 5.1831, val_acc: 0.5913\n",
      "Epoch [3735], train_loss: 0.0000, val_loss: 5.2414, val_acc: 0.5994\n",
      "Epoch [3736], train_loss: 0.0000, val_loss: 5.2959, val_acc: 0.5939\n",
      "Epoch [3737], train_loss: 0.0000, val_loss: 5.4400, val_acc: 0.5991\n",
      "Epoch [3738], train_loss: 0.0000, val_loss: 5.4417, val_acc: 0.5968\n",
      "Epoch [3739], train_loss: 0.0000, val_loss: 5.3871, val_acc: 0.5913\n",
      "Epoch [3740], train_loss: 0.0000, val_loss: 5.3039, val_acc: 0.5913\n",
      "Epoch [3741], train_loss: 0.0000, val_loss: 5.3818, val_acc: 0.5913\n",
      "Epoch [3742], train_loss: 0.0000, val_loss: 5.3641, val_acc: 0.5913\n",
      "Epoch [3743], train_loss: 0.0000, val_loss: 5.3334, val_acc: 0.5913\n",
      "Epoch [3744], train_loss: 0.0000, val_loss: 5.4873, val_acc: 0.5994\n",
      "Epoch [3745], train_loss: 0.0000, val_loss: 5.3419, val_acc: 0.6020\n",
      "Epoch [3746], train_loss: 0.0000, val_loss: 5.3061, val_acc: 0.5887\n",
      "Epoch [3747], train_loss: 0.0000, val_loss: 5.4507, val_acc: 0.5965\n",
      "Epoch [3748], train_loss: 0.0000, val_loss: 5.5292, val_acc: 0.5887\n",
      "Epoch [3749], train_loss: 0.0002, val_loss: 5.4217, val_acc: 0.5913\n",
      "Epoch [3750], train_loss: 0.0001, val_loss: 6.0278, val_acc: 0.6020\n",
      "Epoch [3751], train_loss: 0.0000, val_loss: 5.8337, val_acc: 0.6098\n",
      "Epoch [3752], train_loss: 0.0000, val_loss: 5.9070, val_acc: 0.5965\n",
      "Epoch [3753], train_loss: 0.0000, val_loss: 6.0050, val_acc: 0.6098\n",
      "Epoch [3754], train_loss: 0.0000, val_loss: 6.0064, val_acc: 0.6098\n",
      "Epoch [3755], train_loss: 0.0000, val_loss: 5.8542, val_acc: 0.6150\n",
      "Epoch [3756], train_loss: 0.0000, val_loss: 5.9262, val_acc: 0.5965\n",
      "Epoch [3757], train_loss: 0.0000, val_loss: 5.7942, val_acc: 0.6017\n",
      "Epoch [3758], train_loss: 0.0000, val_loss: 5.9496, val_acc: 0.6098\n",
      "Epoch [3759], train_loss: 0.0000, val_loss: 6.1312, val_acc: 0.5991\n",
      "Epoch [3760], train_loss: 0.0000, val_loss: 5.9098, val_acc: 0.6043\n",
      "Epoch [3761], train_loss: 0.0000, val_loss: 6.2697, val_acc: 0.6072\n",
      "Epoch [3762], train_loss: 0.0000, val_loss: 5.9948, val_acc: 0.6017\n",
      "Epoch [3763], train_loss: 0.0000, val_loss: 6.0937, val_acc: 0.6072\n",
      "Epoch [3764], train_loss: 0.0000, val_loss: 6.1505, val_acc: 0.6017\n",
      "Epoch [3765], train_loss: 0.0000, val_loss: 6.0817, val_acc: 0.5991\n",
      "Epoch [3766], train_loss: 0.0000, val_loss: 6.1573, val_acc: 0.6069\n",
      "Epoch [3767], train_loss: 0.0000, val_loss: 6.1074, val_acc: 0.6124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3768], train_loss: 0.0000, val_loss: 6.1804, val_acc: 0.5991\n",
      "Epoch [3769], train_loss: 0.0000, val_loss: 6.1368, val_acc: 0.6043\n",
      "Epoch [3770], train_loss: 0.0000, val_loss: 5.9880, val_acc: 0.6017\n",
      "Epoch [3771], train_loss: 0.0000, val_loss: 6.2873, val_acc: 0.6017\n",
      "Epoch [3772], train_loss: 0.0000, val_loss: 6.0626, val_acc: 0.6095\n",
      "Epoch [3773], train_loss: 0.0000, val_loss: 6.3292, val_acc: 0.5965\n",
      "Epoch [3774], train_loss: 0.0000, val_loss: 6.1636, val_acc: 0.6043\n",
      "Epoch [3775], train_loss: 0.0000, val_loss: 6.1792, val_acc: 0.6017\n",
      "Epoch [3776], train_loss: 0.0000, val_loss: 6.1193, val_acc: 0.6095\n",
      "Epoch [3777], train_loss: 0.0000, val_loss: 6.1394, val_acc: 0.6043\n",
      "Epoch [3778], train_loss: 0.0000, val_loss: 6.4667, val_acc: 0.5991\n",
      "Epoch [3779], train_loss: 0.0000, val_loss: 6.1300, val_acc: 0.5939\n",
      "Epoch [3780], train_loss: 0.0000, val_loss: 6.3106, val_acc: 0.5965\n",
      "Epoch [3781], train_loss: 0.0000, val_loss: 6.5089, val_acc: 0.5887\n",
      "Epoch [3782], train_loss: 0.0000, val_loss: 6.4945, val_acc: 0.5913\n",
      "Epoch [3783], train_loss: 0.0000, val_loss: 6.2733, val_acc: 0.5965\n",
      "Epoch [3784], train_loss: 0.0000, val_loss: 6.3656, val_acc: 0.5991\n",
      "Epoch [3785], train_loss: 0.0002, val_loss: 6.2773, val_acc: 0.5942\n",
      "Epoch [3786], train_loss: 0.0199, val_loss: 3.9638, val_acc: 0.5910\n",
      "Epoch [3787], train_loss: 0.0233, val_loss: 4.6037, val_acc: 0.5861\n",
      "Epoch [3788], train_loss: 0.0239, val_loss: 5.8445, val_acc: 0.5763\n",
      "Epoch [3789], train_loss: 0.0623, val_loss: 3.5085, val_acc: 0.6238\n",
      "Epoch [3790], train_loss: 0.0390, val_loss: 4.2164, val_acc: 0.6313\n",
      "Epoch [3791], train_loss: 0.0246, val_loss: 4.3276, val_acc: 0.6179\n",
      "Epoch [3792], train_loss: 0.0166, val_loss: 3.7682, val_acc: 0.6124\n",
      "Epoch [3793], train_loss: 0.0016, val_loss: 4.5234, val_acc: 0.6235\n",
      "Epoch [3794], train_loss: 0.0006, val_loss: 4.6461, val_acc: 0.6101\n",
      "Epoch [3795], train_loss: 0.0002, val_loss: 5.0519, val_acc: 0.6209\n",
      "Epoch [3796], train_loss: 0.0001, val_loss: 4.8930, val_acc: 0.6127\n",
      "Epoch [3797], train_loss: 0.0001, val_loss: 4.8110, val_acc: 0.6075\n",
      "Epoch [3798], train_loss: 0.0001, val_loss: 5.2084, val_acc: 0.6183\n",
      "Epoch [3799], train_loss: 0.0000, val_loss: 5.1372, val_acc: 0.6075\n",
      "Epoch [3800], train_loss: 0.0000, val_loss: 4.9643, val_acc: 0.6101\n",
      "Epoch [3801], train_loss: 0.0000, val_loss: 4.9666, val_acc: 0.6209\n",
      "Epoch [3802], train_loss: 0.0000, val_loss: 5.3238, val_acc: 0.6183\n",
      "Epoch [3803], train_loss: 0.0071, val_loss: 4.9270, val_acc: 0.6287\n",
      "Epoch [3804], train_loss: 0.0748, val_loss: 2.7549, val_acc: 0.6147\n",
      "Epoch [3805], train_loss: 0.0074, val_loss: 3.9162, val_acc: 0.6254\n",
      "Epoch [3806], train_loss: 0.0702, val_loss: 1.3236, val_acc: 0.6020\n",
      "Epoch [3807], train_loss: 0.0152, val_loss: 3.0250, val_acc: 0.6127\n",
      "Epoch [3808], train_loss: 0.0005, val_loss: 3.1538, val_acc: 0.6368\n",
      "Epoch [3809], train_loss: 0.0002, val_loss: 3.1351, val_acc: 0.6261\n",
      "Epoch [3810], train_loss: 0.0001, val_loss: 3.4473, val_acc: 0.6287\n",
      "Epoch [3811], train_loss: 0.0001, val_loss: 3.6341, val_acc: 0.6179\n",
      "Epoch [3812], train_loss: 0.0006, val_loss: 3.5146, val_acc: 0.6235\n",
      "Epoch [3813], train_loss: 0.0002, val_loss: 3.8613, val_acc: 0.6101\n",
      "Epoch [3814], train_loss: 0.0001, val_loss: 3.8065, val_acc: 0.6049\n",
      "Epoch [3815], train_loss: 0.0001, val_loss: 3.8915, val_acc: 0.6264\n",
      "Epoch [3816], train_loss: 0.0001, val_loss: 4.1594, val_acc: 0.6290\n",
      "Epoch [3817], train_loss: 0.0000, val_loss: 4.0435, val_acc: 0.6394\n",
      "Epoch [3818], train_loss: 0.0001, val_loss: 4.0751, val_acc: 0.6316\n",
      "Epoch [3819], train_loss: 0.0000, val_loss: 4.0882, val_acc: 0.6290\n",
      "Epoch [3820], train_loss: 0.0000, val_loss: 4.2721, val_acc: 0.6316\n",
      "Epoch [3821], train_loss: 0.0000, val_loss: 3.9775, val_acc: 0.6264\n",
      "Epoch [3822], train_loss: 0.0000, val_loss: 4.2616, val_acc: 0.6235\n",
      "Epoch [3823], train_loss: 0.0000, val_loss: 4.2855, val_acc: 0.6316\n",
      "Epoch [3824], train_loss: 0.0000, val_loss: 4.2568, val_acc: 0.6290\n",
      "Epoch [3825], train_loss: 0.0000, val_loss: 4.3351, val_acc: 0.6316\n",
      "Epoch [3826], train_loss: 0.0000, val_loss: 4.3053, val_acc: 0.6290\n",
      "Epoch [3827], train_loss: 0.0000, val_loss: 4.4576, val_acc: 0.6342\n",
      "Epoch [3828], train_loss: 0.0000, val_loss: 4.5034, val_acc: 0.6209\n",
      "Epoch [3829], train_loss: 0.0000, val_loss: 4.4277, val_acc: 0.6316\n",
      "Epoch [3830], train_loss: 0.0000, val_loss: 4.6039, val_acc: 0.6368\n",
      "Epoch [3831], train_loss: 0.0000, val_loss: 4.3374, val_acc: 0.6342\n",
      "Epoch [3832], train_loss: 0.0000, val_loss: 4.5430, val_acc: 0.6316\n",
      "Epoch [3833], train_loss: 0.0001, val_loss: 4.4730, val_acc: 0.6316\n",
      "Epoch [3834], train_loss: 0.0000, val_loss: 4.5632, val_acc: 0.6313\n",
      "Epoch [3835], train_loss: 0.0000, val_loss: 4.3660, val_acc: 0.6287\n",
      "Epoch [3836], train_loss: 0.0000, val_loss: 4.5803, val_acc: 0.6261\n",
      "Epoch [3837], train_loss: 0.0000, val_loss: 4.6015, val_acc: 0.6261\n",
      "Epoch [3838], train_loss: 0.0000, val_loss: 4.8208, val_acc: 0.6261\n",
      "Epoch [3839], train_loss: 0.0000, val_loss: 4.6481, val_acc: 0.6261\n",
      "Epoch [3840], train_loss: 0.0000, val_loss: 4.5494, val_acc: 0.6261\n",
      "Epoch [3841], train_loss: 0.0000, val_loss: 4.9899, val_acc: 0.6313\n",
      "Epoch [3842], train_loss: 0.0000, val_loss: 4.8074, val_acc: 0.6235\n",
      "Epoch [3843], train_loss: 0.0000, val_loss: 4.7171, val_acc: 0.6287\n",
      "Epoch [3844], train_loss: 0.0000, val_loss: 4.9207, val_acc: 0.6287\n",
      "Epoch [3845], train_loss: 0.0000, val_loss: 4.6446, val_acc: 0.6394\n",
      "Epoch [3846], train_loss: 0.0000, val_loss: 4.8506, val_acc: 0.6261\n",
      "Epoch [3847], train_loss: 0.0000, val_loss: 4.9351, val_acc: 0.6261\n",
      "Epoch [3848], train_loss: 0.0000, val_loss: 4.8208, val_acc: 0.6313\n",
      "Epoch [3849], train_loss: 0.0000, val_loss: 4.9544, val_acc: 0.6261\n",
      "Epoch [3850], train_loss: 0.0000, val_loss: 4.8868, val_acc: 0.6179\n",
      "Epoch [3851], train_loss: 0.0000, val_loss: 4.8446, val_acc: 0.6261\n",
      "Epoch [3852], train_loss: 0.0000, val_loss: 5.0439, val_acc: 0.6179\n",
      "Epoch [3853], train_loss: 0.0000, val_loss: 4.9222, val_acc: 0.6206\n",
      "Epoch [3854], train_loss: 0.0000, val_loss: 5.0275, val_acc: 0.6179\n",
      "Epoch [3855], train_loss: 0.0000, val_loss: 5.0757, val_acc: 0.6394\n",
      "Epoch [3856], train_loss: 0.0000, val_loss: 4.9417, val_acc: 0.6206\n",
      "Epoch [3857], train_loss: 0.0000, val_loss: 5.0009, val_acc: 0.6258\n",
      "Epoch [3858], train_loss: 0.0000, val_loss: 5.1014, val_acc: 0.6313\n",
      "Epoch [3859], train_loss: 0.0000, val_loss: 5.0869, val_acc: 0.6287\n",
      "Epoch [3860], train_loss: 0.0000, val_loss: 4.8809, val_acc: 0.6261\n",
      "Epoch [3861], train_loss: 0.0000, val_loss: 5.0766, val_acc: 0.6342\n",
      "Epoch [3862], train_loss: 0.0000, val_loss: 4.8748, val_acc: 0.6287\n",
      "Epoch [3863], train_loss: 0.0000, val_loss: 5.0174, val_acc: 0.6287\n",
      "Epoch [3864], train_loss: 0.0000, val_loss: 5.1754, val_acc: 0.6261\n",
      "Epoch [3865], train_loss: 0.0000, val_loss: 5.1354, val_acc: 0.6313\n",
      "Epoch [3866], train_loss: 0.0000, val_loss: 5.2230, val_acc: 0.6287\n",
      "Epoch [3867], train_loss: 0.0000, val_loss: 5.1780, val_acc: 0.6261\n",
      "Epoch [3868], train_loss: 0.0000, val_loss: 4.9827, val_acc: 0.6313\n",
      "Epoch [3869], train_loss: 0.0000, val_loss: 5.1140, val_acc: 0.6313\n",
      "Epoch [3870], train_loss: 0.0000, val_loss: 5.3994, val_acc: 0.6261\n",
      "Epoch [3871], train_loss: 0.0000, val_loss: 5.2309, val_acc: 0.6261\n",
      "Epoch [3872], train_loss: 0.0000, val_loss: 5.2920, val_acc: 0.6258\n",
      "Epoch [3873], train_loss: 0.0000, val_loss: 5.2310, val_acc: 0.6232\n",
      "Epoch [3874], train_loss: 0.0000, val_loss: 5.3613, val_acc: 0.6258\n",
      "Epoch [3875], train_loss: 0.0000, val_loss: 5.3383, val_acc: 0.6261\n",
      "Epoch [3876], train_loss: 0.0000, val_loss: 5.2651, val_acc: 0.6179\n",
      "Epoch [3877], train_loss: 0.0000, val_loss: 5.4359, val_acc: 0.6339\n",
      "Epoch [3878], train_loss: 0.0000, val_loss: 5.4695, val_acc: 0.6339\n",
      "Epoch [3879], train_loss: 0.0000, val_loss: 5.5251, val_acc: 0.6394\n",
      "Epoch [3880], train_loss: 0.0000, val_loss: 5.6309, val_acc: 0.6368\n",
      "Epoch [3881], train_loss: 0.0000, val_loss: 5.2395, val_acc: 0.6342\n",
      "Epoch [3882], train_loss: 0.0004, val_loss: 5.2322, val_acc: 0.6206\n",
      "Epoch [3883], train_loss: 0.0339, val_loss: 4.1215, val_acc: 0.5646\n",
      "Epoch [3884], train_loss: 0.0319, val_loss: 3.8579, val_acc: 0.6176\n",
      "Epoch [3885], train_loss: 0.0192, val_loss: 3.5421, val_acc: 0.5809\n",
      "Epoch [3886], train_loss: 0.0064, val_loss: 3.6520, val_acc: 0.6179\n",
      "Epoch [3887], train_loss: 0.0014, val_loss: 4.1797, val_acc: 0.6339\n",
      "Epoch [3888], train_loss: 0.0006, val_loss: 4.0918, val_acc: 0.5831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3889], train_loss: 0.0002, val_loss: 4.0621, val_acc: 0.5857\n",
      "Epoch [3890], train_loss: 0.0001, val_loss: 4.3881, val_acc: 0.5750\n",
      "Epoch [3891], train_loss: 0.0001, val_loss: 4.4707, val_acc: 0.5802\n",
      "Epoch [3892], train_loss: 0.0003, val_loss: 4.4482, val_acc: 0.5776\n",
      "Epoch [3893], train_loss: 0.0003, val_loss: 5.0539, val_acc: 0.6046\n",
      "Epoch [3894], train_loss: 0.0001, val_loss: 4.6315, val_acc: 0.5965\n",
      "Epoch [3895], train_loss: 0.0001, val_loss: 4.9865, val_acc: 0.6075\n",
      "Epoch [3896], train_loss: 0.0000, val_loss: 4.9561, val_acc: 0.5994\n",
      "Epoch [3897], train_loss: 0.0000, val_loss: 4.9513, val_acc: 0.5994\n",
      "Epoch [3898], train_loss: 0.0000, val_loss: 4.9339, val_acc: 0.6075\n",
      "Epoch [3899], train_loss: 0.0000, val_loss: 4.9551, val_acc: 0.6075\n",
      "Epoch [3900], train_loss: 0.0000, val_loss: 4.8046, val_acc: 0.6101\n",
      "Epoch [3901], train_loss: 0.0000, val_loss: 5.1206, val_acc: 0.6020\n",
      "Epoch [3902], train_loss: 0.0000, val_loss: 5.2401, val_acc: 0.5965\n",
      "Epoch [3903], train_loss: 0.0000, val_loss: 5.0538, val_acc: 0.6127\n",
      "Epoch [3904], train_loss: 0.0000, val_loss: 4.9486, val_acc: 0.6153\n",
      "Epoch [3905], train_loss: 0.0000, val_loss: 5.1306, val_acc: 0.6235\n",
      "Epoch [3906], train_loss: 0.0058, val_loss: 5.0048, val_acc: 0.6069\n",
      "Epoch [3907], train_loss: 0.0597, val_loss: 3.5846, val_acc: 0.6082\n",
      "Epoch [3908], train_loss: 0.0110, val_loss: 3.7515, val_acc: 0.6420\n",
      "Epoch [3909], train_loss: 0.0008, val_loss: 4.3066, val_acc: 0.5942\n",
      "Epoch [3910], train_loss: 0.0003, val_loss: 4.5961, val_acc: 0.6134\n",
      "Epoch [3911], train_loss: 0.0003, val_loss: 4.6747, val_acc: 0.6105\n",
      "Epoch [3912], train_loss: 0.0001, val_loss: 4.6035, val_acc: 0.6105\n",
      "Epoch [3913], train_loss: 0.0001, val_loss: 4.7050, val_acc: 0.6160\n",
      "Epoch [3914], train_loss: 0.0001, val_loss: 4.6712, val_acc: 0.6160\n",
      "Epoch [3915], train_loss: 0.0000, val_loss: 4.7249, val_acc: 0.6105\n",
      "Epoch [3916], train_loss: 0.0000, val_loss: 4.6272, val_acc: 0.6105\n",
      "Epoch [3917], train_loss: 0.0000, val_loss: 4.6664, val_acc: 0.6160\n",
      "Epoch [3918], train_loss: 0.0000, val_loss: 4.7217, val_acc: 0.6131\n",
      "Epoch [3919], train_loss: 0.0000, val_loss: 4.6747, val_acc: 0.6105\n",
      "Epoch [3920], train_loss: 0.0000, val_loss: 4.7568, val_acc: 0.6160\n",
      "Epoch [3921], train_loss: 0.0000, val_loss: 4.8243, val_acc: 0.6131\n",
      "Epoch [3922], train_loss: 0.0000, val_loss: 4.8364, val_acc: 0.6131\n",
      "Epoch [3923], train_loss: 0.0000, val_loss: 4.7514, val_acc: 0.6131\n",
      "Epoch [3924], train_loss: 0.0006, val_loss: 4.9597, val_acc: 0.6264\n",
      "Epoch [3925], train_loss: 0.0096, val_loss: 3.9850, val_acc: 0.6212\n",
      "Epoch [3926], train_loss: 0.0236, val_loss: 4.3659, val_acc: 0.6183\n",
      "Epoch [3927], train_loss: 0.0284, val_loss: 4.0084, val_acc: 0.6209\n",
      "Epoch [3928], train_loss: 0.0065, val_loss: 3.6580, val_acc: 0.5997\n",
      "Epoch [3929], train_loss: 0.0005, val_loss: 4.1481, val_acc: 0.6127\n",
      "Epoch [3930], train_loss: 0.0015, val_loss: 4.6718, val_acc: 0.6157\n",
      "Epoch [3931], train_loss: 0.0210, val_loss: 3.1919, val_acc: 0.6179\n",
      "Epoch [3932], train_loss: 0.0032, val_loss: 3.9314, val_acc: 0.6371\n",
      "Epoch [3933], train_loss: 0.0008, val_loss: 4.1282, val_acc: 0.6322\n",
      "Epoch [3934], train_loss: 0.0001, val_loss: 4.1939, val_acc: 0.6296\n",
      "Epoch [3935], train_loss: 0.0000, val_loss: 4.2557, val_acc: 0.6270\n",
      "Epoch [3936], train_loss: 0.0001, val_loss: 4.4646, val_acc: 0.6374\n",
      "Epoch [3937], train_loss: 0.0001, val_loss: 4.3930, val_acc: 0.6134\n",
      "Epoch [3938], train_loss: 0.0001, val_loss: 4.4891, val_acc: 0.6215\n",
      "Epoch [3939], train_loss: 0.0000, val_loss: 4.5835, val_acc: 0.6241\n",
      "Epoch [3940], train_loss: 0.0000, val_loss: 4.4871, val_acc: 0.6241\n",
      "Epoch [3941], train_loss: 0.0000, val_loss: 4.4297, val_acc: 0.6160\n",
      "Epoch [3942], train_loss: 0.0000, val_loss: 4.5499, val_acc: 0.6241\n",
      "Epoch [3943], train_loss: 0.0000, val_loss: 4.5766, val_acc: 0.6241\n",
      "Epoch [3944], train_loss: 0.0005, val_loss: 4.6144, val_acc: 0.6079\n",
      "Epoch [3945], train_loss: 0.0000, val_loss: 4.5229, val_acc: 0.6105\n",
      "Epoch [3946], train_loss: 0.0000, val_loss: 4.5934, val_acc: 0.6186\n",
      "Epoch [3947], train_loss: 0.0000, val_loss: 4.6165, val_acc: 0.6131\n",
      "Epoch [3948], train_loss: 0.0000, val_loss: 4.6695, val_acc: 0.6160\n",
      "Epoch [3949], train_loss: 0.0000, val_loss: 4.6491, val_acc: 0.6186\n",
      "Epoch [3950], train_loss: 0.0000, val_loss: 4.6635, val_acc: 0.6160\n",
      "Epoch [3951], train_loss: 0.0000, val_loss: 4.7811, val_acc: 0.6052\n",
      "Epoch [3952], train_loss: 0.0000, val_loss: 4.7635, val_acc: 0.6186\n",
      "Epoch [3953], train_loss: 0.0000, val_loss: 4.7544, val_acc: 0.6079\n",
      "Epoch [3954], train_loss: 0.0000, val_loss: 4.7353, val_acc: 0.6079\n",
      "Epoch [3955], train_loss: 0.0000, val_loss: 4.7651, val_acc: 0.6052\n",
      "Epoch [3956], train_loss: 0.0000, val_loss: 4.7891, val_acc: 0.6131\n",
      "Epoch [3957], train_loss: 0.0000, val_loss: 4.8886, val_acc: 0.6105\n",
      "Epoch [3958], train_loss: 0.0000, val_loss: 4.7136, val_acc: 0.6026\n",
      "Epoch [3959], train_loss: 0.0000, val_loss: 5.0149, val_acc: 0.6131\n",
      "Epoch [3960], train_loss: 0.0000, val_loss: 4.9237, val_acc: 0.6052\n",
      "Epoch [3961], train_loss: 0.0000, val_loss: 4.8433, val_acc: 0.6052\n",
      "Epoch [3962], train_loss: 0.0000, val_loss: 4.7869, val_acc: 0.6160\n",
      "Epoch [3963], train_loss: 0.0000, val_loss: 4.9058, val_acc: 0.6052\n",
      "Epoch [3964], train_loss: 0.0000, val_loss: 4.8799, val_acc: 0.6079\n",
      "Epoch [3965], train_loss: 0.0000, val_loss: 5.0333, val_acc: 0.6105\n",
      "Epoch [3966], train_loss: 0.0000, val_loss: 4.9853, val_acc: 0.6079\n",
      "Epoch [3967], train_loss: 0.0000, val_loss: 4.9360, val_acc: 0.6105\n",
      "Epoch [3968], train_loss: 0.0000, val_loss: 4.9283, val_acc: 0.6186\n",
      "Epoch [3969], train_loss: 0.0000, val_loss: 4.8334, val_acc: 0.6241\n",
      "Epoch [3970], train_loss: 0.0000, val_loss: 5.0683, val_acc: 0.6160\n",
      "Epoch [3971], train_loss: 0.0000, val_loss: 4.8771, val_acc: 0.6079\n",
      "Epoch [3972], train_loss: 0.0000, val_loss: 5.0403, val_acc: 0.6160\n",
      "Epoch [3973], train_loss: 0.0000, val_loss: 4.9914, val_acc: 0.6241\n",
      "Epoch [3974], train_loss: 0.0000, val_loss: 4.9343, val_acc: 0.6163\n",
      "Epoch [3975], train_loss: 0.0000, val_loss: 4.9814, val_acc: 0.6160\n",
      "Epoch [3976], train_loss: 0.0000, val_loss: 4.9104, val_acc: 0.6134\n",
      "Epoch [3977], train_loss: 0.0000, val_loss: 5.0707, val_acc: 0.6186\n",
      "Epoch [3978], train_loss: 0.0000, val_loss: 5.1001, val_acc: 0.6079\n",
      "Epoch [3979], train_loss: 0.0000, val_loss: 5.1325, val_acc: 0.6079\n",
      "Epoch [3980], train_loss: 0.0000, val_loss: 5.0882, val_acc: 0.6052\n",
      "Epoch [3981], train_loss: 0.0000, val_loss: 5.1717, val_acc: 0.6157\n",
      "Epoch [3982], train_loss: 0.0000, val_loss: 5.1519, val_acc: 0.6186\n",
      "Epoch [3983], train_loss: 0.0000, val_loss: 5.2306, val_acc: 0.6105\n",
      "Epoch [3984], train_loss: 0.0000, val_loss: 5.1981, val_acc: 0.6105\n",
      "Epoch [3985], train_loss: 0.0000, val_loss: 5.1846, val_acc: 0.6105\n",
      "Epoch [3986], train_loss: 0.0000, val_loss: 5.1969, val_acc: 0.6160\n",
      "Epoch [3987], train_loss: 0.0000, val_loss: 5.1874, val_acc: 0.6108\n",
      "Epoch [3988], train_loss: 0.0000, val_loss: 5.2283, val_acc: 0.6215\n",
      "Epoch [3989], train_loss: 0.0000, val_loss: 5.1260, val_acc: 0.6134\n",
      "Epoch [3990], train_loss: 0.0000, val_loss: 5.3352, val_acc: 0.6296\n",
      "Epoch [3991], train_loss: 0.0000, val_loss: 5.2728, val_acc: 0.6348\n",
      "Epoch [3992], train_loss: 0.0000, val_loss: 5.3269, val_acc: 0.6134\n",
      "Epoch [3993], train_loss: 0.0000, val_loss: 5.2143, val_acc: 0.6160\n",
      "Epoch [3994], train_loss: 0.0000, val_loss: 5.3033, val_acc: 0.6241\n",
      "Epoch [3995], train_loss: 0.0000, val_loss: 5.2795, val_acc: 0.6241\n",
      "Epoch [3996], train_loss: 0.0000, val_loss: 5.3713, val_acc: 0.6160\n",
      "Epoch [3997], train_loss: 0.0000, val_loss: 5.3115, val_acc: 0.6267\n",
      "Epoch [3998], train_loss: 0.0000, val_loss: 5.3097, val_acc: 0.6160\n",
      "Epoch [3999], train_loss: 0.0000, val_loss: 5.2235, val_acc: 0.6186\n",
      "Epoch [4000], train_loss: 0.0000, val_loss: 5.3362, val_acc: 0.6238\n",
      "Epoch [4001], train_loss: 0.0000, val_loss: 5.4047, val_acc: 0.6105\n",
      "Epoch [4002], train_loss: 0.0000, val_loss: 5.3231, val_acc: 0.6079\n",
      "Epoch [4003], train_loss: 0.0000, val_loss: 5.4275, val_acc: 0.6105\n",
      "Epoch [4004], train_loss: 0.0000, val_loss: 5.3648, val_acc: 0.6134\n",
      "Epoch [4005], train_loss: 0.0000, val_loss: 5.4270, val_acc: 0.6105\n",
      "Epoch [4006], train_loss: 0.0000, val_loss: 5.4690, val_acc: 0.6079\n",
      "Epoch [4007], train_loss: 0.0000, val_loss: 5.5101, val_acc: 0.6026\n",
      "Epoch [4008], train_loss: 0.0000, val_loss: 5.5146, val_acc: 0.6105\n",
      "Epoch [4009], train_loss: 0.0000, val_loss: 5.4494, val_acc: 0.6160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4010], train_loss: 0.0000, val_loss: 5.5213, val_acc: 0.6160\n",
      "Epoch [4011], train_loss: 0.0000, val_loss: 5.5036, val_acc: 0.6079\n",
      "Epoch [4012], train_loss: 0.0000, val_loss: 5.3658, val_acc: 0.6348\n",
      "Epoch [4013], train_loss: 0.0000, val_loss: 5.4590, val_acc: 0.6000\n",
      "Epoch [4014], train_loss: 0.0000, val_loss: 5.5594, val_acc: 0.6186\n",
      "Epoch [4015], train_loss: 0.0000, val_loss: 5.4481, val_acc: 0.6241\n",
      "Epoch [4016], train_loss: 0.0000, val_loss: 5.4946, val_acc: 0.6079\n",
      "Epoch [4017], train_loss: 0.0000, val_loss: 5.4013, val_acc: 0.6134\n",
      "Epoch [4018], train_loss: 0.0000, val_loss: 5.3888, val_acc: 0.6241\n",
      "Epoch [4019], train_loss: 0.0000, val_loss: 5.6016, val_acc: 0.6134\n",
      "Epoch [4020], train_loss: 0.0000, val_loss: 5.4668, val_acc: 0.6134\n",
      "Epoch [4021], train_loss: 0.0000, val_loss: 5.5717, val_acc: 0.6186\n",
      "Epoch [4022], train_loss: 0.0000, val_loss: 5.6102, val_acc: 0.6160\n",
      "Epoch [4023], train_loss: 0.0000, val_loss: 5.4257, val_acc: 0.6215\n",
      "Epoch [4024], train_loss: 0.0000, val_loss: 5.2606, val_acc: 0.6160\n",
      "Epoch [4025], train_loss: 0.0000, val_loss: 5.6598, val_acc: 0.6160\n",
      "Epoch [4026], train_loss: 0.0000, val_loss: 5.6395, val_acc: 0.6160\n",
      "Epoch [4027], train_loss: 0.0000, val_loss: 5.5922, val_acc: 0.6215\n",
      "Epoch [4028], train_loss: 0.0000, val_loss: 5.6784, val_acc: 0.6160\n",
      "Epoch [4029], train_loss: 0.0000, val_loss: 5.5304, val_acc: 0.6160\n",
      "Epoch [4030], train_loss: 0.0000, val_loss: 5.3455, val_acc: 0.6296\n",
      "Epoch [4031], train_loss: 0.0000, val_loss: 5.4868, val_acc: 0.6267\n",
      "Epoch [4032], train_loss: 0.0000, val_loss: 5.6626, val_acc: 0.6186\n",
      "Epoch [4033], train_loss: 0.0000, val_loss: 5.5337, val_acc: 0.6134\n",
      "Epoch [4034], train_loss: 0.0000, val_loss: 5.6045, val_acc: 0.6160\n",
      "Epoch [4035], train_loss: 0.0000, val_loss: 5.7561, val_acc: 0.6160\n",
      "Epoch [4036], train_loss: 0.0000, val_loss: 5.7162, val_acc: 0.6079\n",
      "Epoch [4037], train_loss: 0.0000, val_loss: 5.5931, val_acc: 0.6105\n",
      "Epoch [4038], train_loss: 0.0000, val_loss: 5.5865, val_acc: 0.6134\n",
      "Epoch [4039], train_loss: 0.0000, val_loss: 5.6151, val_acc: 0.6160\n",
      "Epoch [4040], train_loss: 0.0000, val_loss: 5.4557, val_acc: 0.6241\n",
      "Epoch [4041], train_loss: 0.0000, val_loss: 5.6680, val_acc: 0.6160\n",
      "Epoch [4042], train_loss: 0.0000, val_loss: 5.6865, val_acc: 0.6052\n",
      "Epoch [4043], train_loss: 0.0000, val_loss: 5.5178, val_acc: 0.6241\n",
      "Epoch [4044], train_loss: 0.0000, val_loss: 5.8255, val_acc: 0.6296\n",
      "Epoch [4045], train_loss: 0.0000, val_loss: 5.6076, val_acc: 0.6189\n",
      "Epoch [4046], train_loss: 0.0000, val_loss: 5.6812, val_acc: 0.6241\n",
      "Epoch [4047], train_loss: 0.0000, val_loss: 5.6548, val_acc: 0.6215\n",
      "Epoch [4048], train_loss: 0.0000, val_loss: 5.6697, val_acc: 0.6296\n",
      "Epoch [4049], train_loss: 0.0000, val_loss: 5.8281, val_acc: 0.6215\n",
      "Epoch [4050], train_loss: 0.0000, val_loss: 5.6291, val_acc: 0.6215\n",
      "Epoch [4051], train_loss: 0.0000, val_loss: 5.6902, val_acc: 0.6267\n",
      "Epoch [4052], train_loss: 0.0000, val_loss: 5.7213, val_acc: 0.6134\n",
      "Epoch [4053], train_loss: 0.0000, val_loss: 5.8284, val_acc: 0.6026\n",
      "Epoch [4054], train_loss: 0.0000, val_loss: 5.6979, val_acc: 0.6267\n",
      "Epoch [4055], train_loss: 0.0000, val_loss: 5.6713, val_acc: 0.6134\n",
      "Epoch [4056], train_loss: 0.0000, val_loss: 5.8280, val_acc: 0.6215\n",
      "Epoch [4057], train_loss: 0.0000, val_loss: 5.8673, val_acc: 0.6215\n",
      "Epoch [4058], train_loss: 0.0000, val_loss: 5.8457, val_acc: 0.6052\n",
      "Epoch [4059], train_loss: 0.0000, val_loss: 5.8424, val_acc: 0.6079\n",
      "Epoch [4060], train_loss: 0.0000, val_loss: 5.9099, val_acc: 0.6026\n",
      "Epoch [4061], train_loss: 0.0000, val_loss: 5.7081, val_acc: 0.6348\n",
      "Epoch [4062], train_loss: 0.0000, val_loss: 6.0268, val_acc: 0.6026\n",
      "Epoch [4063], train_loss: 0.0000, val_loss: 5.8679, val_acc: 0.6160\n",
      "Epoch [4064], train_loss: 0.0000, val_loss: 5.7512, val_acc: 0.6404\n",
      "Epoch [4065], train_loss: 0.0000, val_loss: 5.6756, val_acc: 0.6296\n",
      "Epoch [4066], train_loss: 0.0000, val_loss: 5.8326, val_acc: 0.6348\n",
      "Epoch [4067], train_loss: 0.0000, val_loss: 5.8087, val_acc: 0.6108\n",
      "Epoch [4068], train_loss: 0.0000, val_loss: 5.7632, val_acc: 0.6215\n",
      "Epoch [4069], train_loss: 0.0000, val_loss: 5.6563, val_acc: 0.6270\n",
      "Epoch [4070], train_loss: 0.0000, val_loss: 6.0310, val_acc: 0.6267\n",
      "Epoch [4071], train_loss: 0.0000, val_loss: 5.8376, val_acc: 0.6322\n",
      "Epoch [4072], train_loss: 0.0000, val_loss: 5.9023, val_acc: 0.6215\n",
      "Epoch [4073], train_loss: 0.0000, val_loss: 5.8843, val_acc: 0.6267\n",
      "Epoch [4074], train_loss: 0.0000, val_loss: 5.8648, val_acc: 0.6189\n",
      "Epoch [4075], train_loss: 0.0000, val_loss: 5.8941, val_acc: 0.6052\n",
      "Epoch [4076], train_loss: 0.0000, val_loss: 5.9030, val_acc: 0.6241\n",
      "Epoch [4077], train_loss: 0.0000, val_loss: 5.9993, val_acc: 0.6134\n",
      "Epoch [4078], train_loss: 0.0000, val_loss: 5.8860, val_acc: 0.6322\n",
      "Epoch [4079], train_loss: 0.0000, val_loss: 6.1106, val_acc: 0.6267\n",
      "Epoch [4080], train_loss: 0.0000, val_loss: 5.9261, val_acc: 0.6241\n",
      "Epoch [4081], train_loss: 0.0000, val_loss: 6.0808, val_acc: 0.6052\n",
      "Epoch [4082], train_loss: 0.0000, val_loss: 6.0178, val_acc: 0.6105\n",
      "Epoch [4083], train_loss: 0.0000, val_loss: 6.0783, val_acc: 0.6186\n",
      "Epoch [4084], train_loss: 0.0000, val_loss: 5.9464, val_acc: 0.6267\n",
      "Epoch [4085], train_loss: 0.0000, val_loss: 5.9204, val_acc: 0.6215\n",
      "Epoch [4086], train_loss: 0.0000, val_loss: 6.0709, val_acc: 0.6267\n",
      "Epoch [4087], train_loss: 0.0000, val_loss: 6.0417, val_acc: 0.6186\n",
      "Epoch [4088], train_loss: 0.0000, val_loss: 6.0197, val_acc: 0.6186\n",
      "Epoch [4089], train_loss: 0.0000, val_loss: 6.0991, val_acc: 0.6212\n",
      "Epoch [4090], train_loss: 0.0000, val_loss: 5.8093, val_acc: 0.6270\n",
      "Epoch [4091], train_loss: 0.0000, val_loss: 6.0648, val_acc: 0.6186\n",
      "Epoch [4092], train_loss: 0.0000, val_loss: 6.2573, val_acc: 0.6160\n",
      "Epoch [4093], train_loss: 0.0000, val_loss: 6.0417, val_acc: 0.6241\n",
      "Epoch [4094], train_loss: 0.0000, val_loss: 5.9906, val_acc: 0.6186\n",
      "Epoch [4095], train_loss: 0.0000, val_loss: 6.0297, val_acc: 0.6322\n",
      "Epoch [4096], train_loss: 0.0000, val_loss: 6.2813, val_acc: 0.6134\n",
      "Epoch [4097], train_loss: 0.0000, val_loss: 6.0764, val_acc: 0.6134\n",
      "Epoch [4098], train_loss: 0.0000, val_loss: 5.9358, val_acc: 0.6189\n",
      "Epoch [4099], train_loss: 0.0000, val_loss: 6.2324, val_acc: 0.6052\n",
      "Epoch [4100], train_loss: 0.0000, val_loss: 6.1014, val_acc: 0.6189\n",
      "Epoch [4101], train_loss: 0.0000, val_loss: 6.2567, val_acc: 0.6215\n",
      "Epoch [4102], train_loss: 0.0000, val_loss: 6.1096, val_acc: 0.6241\n",
      "Epoch [4103], train_loss: 0.0000, val_loss: 6.1078, val_acc: 0.6160\n",
      "Epoch [4104], train_loss: 0.0000, val_loss: 6.1251, val_acc: 0.6241\n",
      "Epoch [4105], train_loss: 0.0000, val_loss: 6.2234, val_acc: 0.6160\n",
      "Epoch [4106], train_loss: 0.0000, val_loss: 6.2260, val_acc: 0.6267\n",
      "Epoch [4107], train_loss: 0.0000, val_loss: 6.1255, val_acc: 0.6215\n",
      "Epoch [4108], train_loss: 0.0000, val_loss: 6.0766, val_acc: 0.6267\n",
      "Epoch [4109], train_loss: 0.0000, val_loss: 5.9784, val_acc: 0.6348\n",
      "Epoch [4110], train_loss: 0.0000, val_loss: 6.0542, val_acc: 0.6215\n",
      "Epoch [4111], train_loss: 0.0000, val_loss: 6.2117, val_acc: 0.6241\n",
      "Epoch [4112], train_loss: 0.0000, val_loss: 6.1704, val_acc: 0.6215\n",
      "Epoch [4113], train_loss: 0.0000, val_loss: 6.2499, val_acc: 0.6215\n",
      "Epoch [4114], train_loss: 0.0000, val_loss: 6.0979, val_acc: 0.6079\n",
      "Epoch [4115], train_loss: 0.0000, val_loss: 6.3168, val_acc: 0.6160\n",
      "Epoch [4116], train_loss: 0.0000, val_loss: 6.2284, val_acc: 0.6348\n",
      "Epoch [4117], train_loss: 0.0000, val_loss: 6.3362, val_acc: 0.6215\n",
      "Epoch [4118], train_loss: 0.0000, val_loss: 6.3257, val_acc: 0.6160\n",
      "Epoch [4119], train_loss: 0.0000, val_loss: 6.3881, val_acc: 0.6241\n",
      "Epoch [4120], train_loss: 0.0000, val_loss: 6.3141, val_acc: 0.6267\n",
      "Epoch [4121], train_loss: 0.0000, val_loss: 6.3080, val_acc: 0.6160\n",
      "Epoch [4122], train_loss: 0.0000, val_loss: 6.0569, val_acc: 0.6296\n",
      "Epoch [4123], train_loss: 0.0000, val_loss: 6.1698, val_acc: 0.6215\n",
      "Epoch [4124], train_loss: 0.0000, val_loss: 6.1998, val_acc: 0.6241\n",
      "Epoch [4125], train_loss: 0.0000, val_loss: 6.3843, val_acc: 0.6322\n",
      "Epoch [4126], train_loss: 0.0000, val_loss: 6.3829, val_acc: 0.6238\n",
      "Epoch [4127], train_loss: 0.0000, val_loss: 6.3133, val_acc: 0.6322\n",
      "Epoch [4128], train_loss: 0.0000, val_loss: 6.3313, val_acc: 0.6241\n",
      "Epoch [4129], train_loss: 0.0000, val_loss: 6.2599, val_acc: 0.6293\n",
      "Epoch [4130], train_loss: 0.0000, val_loss: 6.4869, val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4131], train_loss: 0.0000, val_loss: 6.5842, val_acc: 0.6293\n",
      "Epoch [4132], train_loss: 0.0000, val_loss: 6.3787, val_acc: 0.6267\n",
      "Epoch [4133], train_loss: 0.0000, val_loss: 6.5160, val_acc: 0.6267\n",
      "Epoch [4134], train_loss: 0.0000, val_loss: 6.5992, val_acc: 0.6267\n",
      "Epoch [4135], train_loss: 0.0000, val_loss: 6.4059, val_acc: 0.6241\n",
      "Epoch [4136], train_loss: 0.0000, val_loss: 6.4234, val_acc: 0.6241\n",
      "Epoch [4137], train_loss: 0.0000, val_loss: 6.4870, val_acc: 0.6241\n",
      "Epoch [4138], train_loss: 0.0000, val_loss: 6.6226, val_acc: 0.6267\n",
      "Epoch [4139], train_loss: 0.0000, val_loss: 6.4969, val_acc: 0.6241\n",
      "Epoch [4140], train_loss: 0.0000, val_loss: 6.4577, val_acc: 0.6241\n",
      "Epoch [4141], train_loss: 0.0000, val_loss: 6.4646, val_acc: 0.6296\n",
      "Epoch [4142], train_loss: 0.0000, val_loss: 6.5785, val_acc: 0.6404\n",
      "Epoch [4143], train_loss: 0.0000, val_loss: 6.6480, val_acc: 0.6348\n",
      "Epoch [4144], train_loss: 0.0000, val_loss: 6.4141, val_acc: 0.6404\n",
      "Epoch [4145], train_loss: 0.0000, val_loss: 6.5541, val_acc: 0.6430\n",
      "Epoch [4146], train_loss: 0.0000, val_loss: 6.3504, val_acc: 0.6378\n",
      "Epoch [4147], train_loss: 0.0000, val_loss: 6.5574, val_acc: 0.6378\n",
      "Epoch [4148], train_loss: 0.0000, val_loss: 6.8180, val_acc: 0.6296\n",
      "Epoch [4149], train_loss: 0.0000, val_loss: 6.5019, val_acc: 0.6430\n",
      "Epoch [4150], train_loss: 0.0000, val_loss: 6.5319, val_acc: 0.6322\n",
      "Epoch [4151], train_loss: 0.0000, val_loss: 6.3435, val_acc: 0.6430\n",
      "Epoch [4152], train_loss: 0.0000, val_loss: 6.3297, val_acc: 0.6404\n",
      "Epoch [4153], train_loss: 0.0000, val_loss: 6.3630, val_acc: 0.6378\n",
      "Epoch [4154], train_loss: 0.0000, val_loss: 6.5420, val_acc: 0.6267\n",
      "Epoch [4155], train_loss: 0.0000, val_loss: 6.7168, val_acc: 0.6267\n",
      "Epoch [4156], train_loss: 0.0000, val_loss: 6.6437, val_acc: 0.6378\n",
      "Epoch [4157], train_loss: 0.0000, val_loss: 6.6246, val_acc: 0.6378\n",
      "Epoch [4158], train_loss: 0.0000, val_loss: 6.6290, val_acc: 0.6430\n",
      "Epoch [4159], train_loss: 0.0000, val_loss: 6.5117, val_acc: 0.6378\n",
      "Epoch [4160], train_loss: 0.0000, val_loss: 6.7300, val_acc: 0.6348\n",
      "Epoch [4161], train_loss: 0.0000, val_loss: 6.6541, val_acc: 0.6348\n",
      "Epoch [4162], train_loss: 0.0000, val_loss: 6.6753, val_acc: 0.6374\n",
      "Epoch [4163], train_loss: 0.0000, val_loss: 6.6806, val_acc: 0.6322\n",
      "Epoch [4164], train_loss: 0.0000, val_loss: 6.9302, val_acc: 0.6322\n",
      "Epoch [4165], train_loss: 0.0000, val_loss: 6.6882, val_acc: 0.6374\n",
      "Epoch [4166], train_loss: 0.0000, val_loss: 6.8113, val_acc: 0.6430\n",
      "Epoch [4167], train_loss: 0.0000, val_loss: 6.6752, val_acc: 0.6456\n",
      "Epoch [4168], train_loss: 0.0000, val_loss: 6.5739, val_acc: 0.6404\n",
      "Epoch [4169], train_loss: 0.0000, val_loss: 6.7023, val_acc: 0.6374\n",
      "Epoch [4170], train_loss: 0.0000, val_loss: 6.8711, val_acc: 0.6456\n",
      "Epoch [4171], train_loss: 0.0000, val_loss: 6.6263, val_acc: 0.6401\n",
      "Epoch [4172], train_loss: 0.0000, val_loss: 6.6857, val_acc: 0.6322\n",
      "Epoch [4173], train_loss: 0.0000, val_loss: 6.7681, val_acc: 0.6348\n",
      "Epoch [4174], train_loss: 0.0000, val_loss: 6.5588, val_acc: 0.6296\n",
      "Epoch [4175], train_loss: 0.0000, val_loss: 6.8080, val_acc: 0.6348\n",
      "Epoch [4176], train_loss: 0.0000, val_loss: 6.7402, val_acc: 0.6348\n",
      "Epoch [4177], train_loss: 0.0000, val_loss: 6.7194, val_acc: 0.6322\n",
      "Epoch [4178], train_loss: 0.0000, val_loss: 6.6345, val_acc: 0.6456\n",
      "Epoch [4179], train_loss: 0.0000, val_loss: 6.7345, val_acc: 0.6322\n",
      "Epoch [4180], train_loss: 0.0000, val_loss: 6.8306, val_acc: 0.6348\n",
      "Epoch [4181], train_loss: 0.0000, val_loss: 6.8575, val_acc: 0.6374\n",
      "Epoch [4182], train_loss: 0.0000, val_loss: 6.3791, val_acc: 0.6241\n",
      "Epoch [4183], train_loss: 0.0000, val_loss: 6.3230, val_acc: 0.6131\n",
      "Epoch [4184], train_loss: 0.0000, val_loss: 6.4789, val_acc: 0.6264\n",
      "Epoch [4185], train_loss: 0.0000, val_loss: 7.0427, val_acc: 0.6345\n",
      "Epoch [4186], train_loss: 0.0000, val_loss: 6.8001, val_acc: 0.6264\n",
      "Epoch [4187], train_loss: 0.0000, val_loss: 6.8575, val_acc: 0.6290\n",
      "Epoch [4188], train_loss: 0.0000, val_loss: 6.9408, val_acc: 0.6290\n",
      "Epoch [4189], train_loss: 0.0001, val_loss: 6.1887, val_acc: 0.6049\n",
      "Epoch [4190], train_loss: 0.1902, val_loss: 1.4244, val_acc: 0.5698\n",
      "Epoch [4191], train_loss: 0.0985, val_loss: 1.8563, val_acc: 0.5646\n",
      "Epoch [4192], train_loss: 0.0483, val_loss: 5.0336, val_acc: 0.6101\n",
      "Epoch [4193], train_loss: 0.0149, val_loss: 4.2003, val_acc: 0.5854\n",
      "Epoch [4194], train_loss: 0.0021, val_loss: 4.0443, val_acc: 0.5857\n",
      "Epoch [4195], train_loss: 0.0007, val_loss: 4.6900, val_acc: 0.5884\n",
      "Epoch [4196], train_loss: 0.0003, val_loss: 4.8768, val_acc: 0.5695\n",
      "Epoch [4197], train_loss: 0.0002, val_loss: 5.1992, val_acc: 0.5695\n",
      "Epoch [4198], train_loss: 0.0001, val_loss: 4.9220, val_acc: 0.5857\n",
      "Epoch [4199], train_loss: 0.0001, val_loss: 5.2358, val_acc: 0.5884\n",
      "Epoch [4200], train_loss: 0.0001, val_loss: 5.3962, val_acc: 0.5695\n",
      "Epoch [4201], train_loss: 0.0240, val_loss: 5.7221, val_acc: 0.6020\n",
      "Epoch [4202], train_loss: 0.0152, val_loss: 4.1050, val_acc: 0.5825\n",
      "Epoch [4203], train_loss: 0.0043, val_loss: 4.6125, val_acc: 0.5698\n",
      "Epoch [4204], train_loss: 0.0083, val_loss: 4.6818, val_acc: 0.5669\n",
      "Epoch [4205], train_loss: 0.0014, val_loss: 4.5182, val_acc: 0.5962\n",
      "Epoch [4206], train_loss: 0.0003, val_loss: 4.8567, val_acc: 0.5831\n",
      "Epoch [4207], train_loss: 0.0002, val_loss: 4.9502, val_acc: 0.5802\n",
      "Epoch [4208], train_loss: 0.0001, val_loss: 5.0865, val_acc: 0.5857\n",
      "Epoch [4209], train_loss: 0.0001, val_loss: 5.1768, val_acc: 0.5857\n",
      "Epoch [4210], train_loss: 0.0001, val_loss: 5.2009, val_acc: 0.5962\n",
      "Epoch [4211], train_loss: 0.0001, val_loss: 5.2056, val_acc: 0.5828\n",
      "Epoch [4212], train_loss: 0.0001, val_loss: 5.2897, val_acc: 0.5802\n",
      "Epoch [4213], train_loss: 0.0000, val_loss: 5.4351, val_acc: 0.5776\n",
      "Epoch [4214], train_loss: 0.0001, val_loss: 5.5236, val_acc: 0.5884\n",
      "Epoch [4215], train_loss: 0.0000, val_loss: 5.2652, val_acc: 0.5831\n",
      "Epoch [4216], train_loss: 0.0000, val_loss: 5.4394, val_acc: 0.5910\n",
      "Epoch [4217], train_loss: 0.0000, val_loss: 5.4790, val_acc: 0.5910\n",
      "Epoch [4218], train_loss: 0.0000, val_loss: 5.6202, val_acc: 0.5910\n",
      "Epoch [4219], train_loss: 0.0000, val_loss: 5.4960, val_acc: 0.5936\n",
      "Epoch [4220], train_loss: 0.0000, val_loss: 5.4732, val_acc: 0.5936\n",
      "Epoch [4221], train_loss: 0.0000, val_loss: 5.6717, val_acc: 0.5910\n",
      "Epoch [4222], train_loss: 0.0000, val_loss: 5.6295, val_acc: 0.5936\n",
      "Epoch [4223], train_loss: 0.0000, val_loss: 5.3670, val_acc: 0.5936\n",
      "Epoch [4224], train_loss: 0.0000, val_loss: 5.6260, val_acc: 0.5910\n",
      "Epoch [4225], train_loss: 0.0000, val_loss: 5.5324, val_acc: 0.5910\n",
      "Epoch [4226], train_loss: 0.0000, val_loss: 5.5932, val_acc: 0.5936\n",
      "Epoch [4227], train_loss: 0.0000, val_loss: 5.9087, val_acc: 0.5884\n",
      "Epoch [4228], train_loss: 0.0000, val_loss: 5.9343, val_acc: 0.5962\n",
      "Epoch [4229], train_loss: 0.0000, val_loss: 5.6684, val_acc: 0.5880\n",
      "Epoch [4230], train_loss: 0.0000, val_loss: 5.7022, val_acc: 0.5854\n",
      "Epoch [4231], train_loss: 0.0000, val_loss: 5.8761, val_acc: 0.5910\n",
      "Epoch [4232], train_loss: 0.0000, val_loss: 5.8757, val_acc: 0.5936\n",
      "Epoch [4233], train_loss: 0.0000, val_loss: 5.7758, val_acc: 0.5880\n",
      "Epoch [4234], train_loss: 0.0000, val_loss: 5.8580, val_acc: 0.5854\n",
      "Epoch [4235], train_loss: 0.0000, val_loss: 5.7507, val_acc: 0.5854\n",
      "Epoch [4236], train_loss: 0.0000, val_loss: 6.0845, val_acc: 0.5936\n",
      "Epoch [4237], train_loss: 0.0000, val_loss: 6.1087, val_acc: 0.5880\n",
      "Epoch [4238], train_loss: 0.0000, val_loss: 5.7782, val_acc: 0.5854\n",
      "Epoch [4239], train_loss: 0.0000, val_loss: 5.8691, val_acc: 0.5854\n",
      "Epoch [4240], train_loss: 0.0000, val_loss: 6.0935, val_acc: 0.5906\n",
      "Epoch [4241], train_loss: 0.0000, val_loss: 5.8869, val_acc: 0.5773\n",
      "Epoch [4242], train_loss: 0.0000, val_loss: 6.0003, val_acc: 0.5906\n",
      "Epoch [4243], train_loss: 0.0000, val_loss: 6.0311, val_acc: 0.5880\n",
      "Epoch [4244], train_loss: 0.0000, val_loss: 6.1278, val_acc: 0.5962\n",
      "Epoch [4245], train_loss: 0.0000, val_loss: 6.0218, val_acc: 0.5854\n",
      "Epoch [4246], train_loss: 0.0000, val_loss: 6.0245, val_acc: 0.5880\n",
      "Epoch [4247], train_loss: 0.0000, val_loss: 5.9574, val_acc: 0.5932\n",
      "Epoch [4248], train_loss: 0.0000, val_loss: 6.3732, val_acc: 0.5906\n",
      "Epoch [4249], train_loss: 0.0000, val_loss: 6.0938, val_acc: 0.5880\n",
      "Epoch [4250], train_loss: 0.0000, val_loss: 5.6892, val_acc: 0.5906\n",
      "Epoch [4251], train_loss: 0.0000, val_loss: 6.0209, val_acc: 0.5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4252], train_loss: 0.0000, val_loss: 6.1686, val_acc: 0.5880\n",
      "Epoch [4253], train_loss: 0.0000, val_loss: 6.2254, val_acc: 0.5880\n",
      "Epoch [4254], train_loss: 0.0000, val_loss: 6.2255, val_acc: 0.5906\n",
      "Epoch [4255], train_loss: 0.0000, val_loss: 6.0706, val_acc: 0.5906\n",
      "Epoch [4256], train_loss: 0.0000, val_loss: 6.1127, val_acc: 0.5932\n",
      "Epoch [4257], train_loss: 0.0000, val_loss: 6.0833, val_acc: 0.5962\n",
      "Epoch [4258], train_loss: 0.0000, val_loss: 6.1807, val_acc: 0.5854\n",
      "Epoch [4259], train_loss: 0.0000, val_loss: 6.0376, val_acc: 0.5906\n",
      "Epoch [4260], train_loss: 0.0000, val_loss: 6.0175, val_acc: 0.5988\n",
      "Epoch [4261], train_loss: 0.0000, val_loss: 6.0783, val_acc: 0.5880\n",
      "Epoch [4262], train_loss: 0.0000, val_loss: 6.2813, val_acc: 0.5936\n",
      "Epoch [4263], train_loss: 0.0000, val_loss: 6.2367, val_acc: 0.5880\n",
      "Epoch [4264], train_loss: 0.0000, val_loss: 6.1570, val_acc: 0.5880\n",
      "Epoch [4265], train_loss: 0.0000, val_loss: 6.1416, val_acc: 0.5854\n",
      "Epoch [4266], train_loss: 0.0000, val_loss: 6.0485, val_acc: 0.5854\n",
      "Epoch [4267], train_loss: 0.0000, val_loss: 6.3648, val_acc: 0.5936\n",
      "Epoch [4268], train_loss: 0.0000, val_loss: 6.5314, val_acc: 0.5936\n",
      "Epoch [4269], train_loss: 0.0000, val_loss: 6.0765, val_acc: 0.5962\n",
      "Epoch [4270], train_loss: 0.0000, val_loss: 6.1785, val_acc: 0.5854\n",
      "Epoch [4271], train_loss: 0.0000, val_loss: 6.3230, val_acc: 0.5962\n",
      "Epoch [4272], train_loss: 0.0000, val_loss: 6.2967, val_acc: 0.5906\n",
      "Epoch [4273], train_loss: 0.0000, val_loss: 6.2458, val_acc: 0.5962\n",
      "Epoch [4274], train_loss: 0.0000, val_loss: 6.3606, val_acc: 0.5962\n",
      "Epoch [4275], train_loss: 0.0000, val_loss: 6.4564, val_acc: 0.5962\n",
      "Epoch [4276], train_loss: 0.0000, val_loss: 6.3806, val_acc: 0.5880\n",
      "Epoch [4277], train_loss: 0.0000, val_loss: 6.3397, val_acc: 0.5906\n",
      "Epoch [4278], train_loss: 0.0000, val_loss: 6.2032, val_acc: 0.5880\n",
      "Epoch [4279], train_loss: 0.0000, val_loss: 6.1819, val_acc: 0.5854\n",
      "Epoch [4280], train_loss: 0.0000, val_loss: 6.5100, val_acc: 0.5936\n",
      "Epoch [4281], train_loss: 0.0000, val_loss: 6.4258, val_acc: 0.5828\n",
      "Epoch [4282], train_loss: 0.0001, val_loss: 6.4257, val_acc: 0.5906\n",
      "Epoch [4283], train_loss: 0.0459, val_loss: 2.2543, val_acc: 0.5916\n",
      "Epoch [4284], train_loss: 0.1057, val_loss: 2.9036, val_acc: 0.6127\n",
      "Epoch [4285], train_loss: 0.0118, val_loss: 4.9331, val_acc: 0.6423\n",
      "Epoch [4286], train_loss: 0.0055, val_loss: 4.7301, val_acc: 0.6423\n",
      "Epoch [4287], train_loss: 0.0123, val_loss: 3.6854, val_acc: 0.5704\n",
      "Epoch [4288], train_loss: 0.0353, val_loss: 2.4844, val_acc: 0.6079\n",
      "Epoch [4289], train_loss: 0.0360, val_loss: 2.9434, val_acc: 0.6153\n",
      "Epoch [4290], train_loss: 0.0055, val_loss: 2.6906, val_acc: 0.6157\n",
      "Epoch [4291], train_loss: 0.0009, val_loss: 3.3728, val_acc: 0.6261\n",
      "Epoch [4292], train_loss: 0.0003, val_loss: 3.5444, val_acc: 0.6209\n",
      "Epoch [4293], train_loss: 0.0001, val_loss: 3.6457, val_acc: 0.6235\n",
      "Epoch [4294], train_loss: 0.0001, val_loss: 3.7536, val_acc: 0.6209\n",
      "Epoch [4295], train_loss: 0.0001, val_loss: 3.7278, val_acc: 0.6261\n",
      "Epoch [4296], train_loss: 0.0001, val_loss: 3.6884, val_acc: 0.6179\n",
      "Epoch [4297], train_loss: 0.0001, val_loss: 3.9881, val_acc: 0.6153\n",
      "Epoch [4298], train_loss: 0.0001, val_loss: 4.1100, val_acc: 0.6287\n",
      "Epoch [4299], train_loss: 0.0001, val_loss: 4.0640, val_acc: 0.6179\n",
      "Epoch [4300], train_loss: 0.0000, val_loss: 4.1635, val_acc: 0.6287\n",
      "Epoch [4301], train_loss: 0.0000, val_loss: 4.0484, val_acc: 0.6235\n",
      "Epoch [4302], train_loss: 0.0000, val_loss: 3.9511, val_acc: 0.6261\n",
      "Epoch [4303], train_loss: 0.0000, val_loss: 4.0591, val_acc: 0.6287\n",
      "Epoch [4304], train_loss: 0.0000, val_loss: 4.2741, val_acc: 0.6261\n",
      "Epoch [4305], train_loss: 0.0000, val_loss: 4.2790, val_acc: 0.6235\n",
      "Epoch [4306], train_loss: 0.0000, val_loss: 4.2777, val_acc: 0.6261\n",
      "Epoch [4307], train_loss: 0.0001, val_loss: 4.1306, val_acc: 0.6313\n",
      "Epoch [4308], train_loss: 0.0000, val_loss: 4.3657, val_acc: 0.6287\n",
      "Epoch [4309], train_loss: 0.0000, val_loss: 4.5043, val_acc: 0.6261\n",
      "Epoch [4310], train_loss: 0.0003, val_loss: 4.4002, val_acc: 0.6287\n",
      "Epoch [4311], train_loss: 0.0002, val_loss: 4.7316, val_acc: 0.6046\n",
      "Epoch [4312], train_loss: 0.0000, val_loss: 4.8236, val_acc: 0.6179\n",
      "Epoch [4313], train_loss: 0.0000, val_loss: 4.5379, val_acc: 0.6150\n",
      "Epoch [4314], train_loss: 0.0000, val_loss: 4.5425, val_acc: 0.6179\n",
      "Epoch [4315], train_loss: 0.0002, val_loss: 4.9151, val_acc: 0.6179\n",
      "Epoch [4316], train_loss: 0.0000, val_loss: 4.8948, val_acc: 0.6287\n",
      "Epoch [4317], train_loss: 0.0000, val_loss: 5.0323, val_acc: 0.6313\n",
      "Epoch [4318], train_loss: 0.0000, val_loss: 5.0380, val_acc: 0.6339\n",
      "Epoch [4319], train_loss: 0.0000, val_loss: 4.9268, val_acc: 0.6313\n",
      "Epoch [4320], train_loss: 0.0000, val_loss: 4.9527, val_acc: 0.6339\n",
      "Epoch [4321], train_loss: 0.0000, val_loss: 4.9420, val_acc: 0.6339\n",
      "Epoch [4322], train_loss: 0.0000, val_loss: 4.9196, val_acc: 0.6206\n",
      "Epoch [4323], train_loss: 0.0000, val_loss: 4.9493, val_acc: 0.6261\n",
      "Epoch [4324], train_loss: 0.0000, val_loss: 4.8193, val_acc: 0.6258\n",
      "Epoch [4325], train_loss: 0.0000, val_loss: 5.1173, val_acc: 0.6313\n",
      "Epoch [4326], train_loss: 0.0000, val_loss: 5.0733, val_acc: 0.6235\n",
      "Epoch [4327], train_loss: 0.0000, val_loss: 4.8470, val_acc: 0.6339\n",
      "Epoch [4328], train_loss: 0.0000, val_loss: 4.9367, val_acc: 0.6339\n",
      "Epoch [4329], train_loss: 0.0000, val_loss: 5.1700, val_acc: 0.6287\n",
      "Epoch [4330], train_loss: 0.0000, val_loss: 5.1496, val_acc: 0.6313\n",
      "Epoch [4331], train_loss: 0.0000, val_loss: 5.1446, val_acc: 0.6313\n",
      "Epoch [4332], train_loss: 0.0000, val_loss: 5.0590, val_acc: 0.6287\n",
      "Epoch [4333], train_loss: 0.0000, val_loss: 5.2176, val_acc: 0.6313\n",
      "Epoch [4334], train_loss: 0.0000, val_loss: 5.0493, val_acc: 0.6313\n",
      "Epoch [4335], train_loss: 0.0000, val_loss: 5.1072, val_acc: 0.6261\n",
      "Epoch [4336], train_loss: 0.0000, val_loss: 5.0669, val_acc: 0.6313\n",
      "Epoch [4337], train_loss: 0.0000, val_loss: 5.2714, val_acc: 0.6209\n",
      "Epoch [4338], train_loss: 0.0000, val_loss: 5.0267, val_acc: 0.6313\n",
      "Epoch [4339], train_loss: 0.0000, val_loss: 5.2422, val_acc: 0.6313\n",
      "Epoch [4340], train_loss: 0.0000, val_loss: 5.1447, val_acc: 0.6261\n",
      "Epoch [4341], train_loss: 0.0000, val_loss: 5.2021, val_acc: 0.6313\n",
      "Epoch [4342], train_loss: 0.0000, val_loss: 5.1923, val_acc: 0.6339\n",
      "Epoch [4343], train_loss: 0.0000, val_loss: 5.2712, val_acc: 0.6206\n",
      "Epoch [4344], train_loss: 0.0000, val_loss: 5.2582, val_acc: 0.6235\n",
      "Epoch [4345], train_loss: 0.0000, val_loss: 5.3632, val_acc: 0.6179\n",
      "Epoch [4346], train_loss: 0.0000, val_loss: 5.2084, val_acc: 0.6232\n",
      "Epoch [4347], train_loss: 0.0000, val_loss: 5.0139, val_acc: 0.6235\n",
      "Epoch [4348], train_loss: 0.0000, val_loss: 5.3824, val_acc: 0.6287\n",
      "Epoch [4349], train_loss: 0.0000, val_loss: 5.2548, val_acc: 0.6287\n",
      "Epoch [4350], train_loss: 0.0000, val_loss: 5.3244, val_acc: 0.6206\n",
      "Epoch [4351], train_loss: 0.0000, val_loss: 5.1309, val_acc: 0.6287\n",
      "Epoch [4352], train_loss: 0.0000, val_loss: 5.3495, val_acc: 0.6206\n",
      "Epoch [4353], train_loss: 0.0000, val_loss: 5.3716, val_acc: 0.6153\n",
      "Epoch [4354], train_loss: 0.0000, val_loss: 5.1922, val_acc: 0.6179\n",
      "Epoch [4355], train_loss: 0.0000, val_loss: 5.4501, val_acc: 0.6287\n",
      "Epoch [4356], train_loss: 0.0000, val_loss: 5.5147, val_acc: 0.6287\n",
      "Epoch [4357], train_loss: 0.0000, val_loss: 5.2250, val_acc: 0.6339\n",
      "Epoch [4358], train_loss: 0.0000, val_loss: 5.2623, val_acc: 0.6339\n",
      "Epoch [4359], train_loss: 0.0000, val_loss: 5.4330, val_acc: 0.6206\n",
      "Epoch [4360], train_loss: 0.0000, val_loss: 5.2143, val_acc: 0.6339\n",
      "Epoch [4361], train_loss: 0.0000, val_loss: 5.3519, val_acc: 0.6206\n",
      "Epoch [4362], train_loss: 0.0000, val_loss: 5.1869, val_acc: 0.6365\n",
      "Epoch [4363], train_loss: 0.0000, val_loss: 5.4842, val_acc: 0.6287\n",
      "Epoch [4364], train_loss: 0.0000, val_loss: 5.6247, val_acc: 0.6206\n",
      "Epoch [4365], train_loss: 0.0000, val_loss: 5.4866, val_acc: 0.6287\n",
      "Epoch [4366], train_loss: 0.0000, val_loss: 5.6059, val_acc: 0.6232\n",
      "Epoch [4367], train_loss: 0.0000, val_loss: 5.3143, val_acc: 0.6339\n",
      "Epoch [4368], train_loss: 0.0000, val_loss: 5.2345, val_acc: 0.6261\n",
      "Epoch [4369], train_loss: 0.0000, val_loss: 5.3997, val_acc: 0.6313\n",
      "Epoch [4370], train_loss: 0.0000, val_loss: 5.5259, val_acc: 0.6313\n",
      "Epoch [4371], train_loss: 0.0000, val_loss: 5.5857, val_acc: 0.6287\n",
      "Epoch [4372], train_loss: 0.0000, val_loss: 5.5083, val_acc: 0.6339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4373], train_loss: 0.0000, val_loss: 5.4428, val_acc: 0.6339\n",
      "Epoch [4374], train_loss: 0.0000, val_loss: 5.4757, val_acc: 0.6313\n",
      "Epoch [4375], train_loss: 0.0000, val_loss: 5.2860, val_acc: 0.6339\n",
      "Epoch [4376], train_loss: 0.0000, val_loss: 5.5896, val_acc: 0.6339\n",
      "Epoch [4377], train_loss: 0.0000, val_loss: 5.5485, val_acc: 0.6339\n",
      "Epoch [4378], train_loss: 0.0000, val_loss: 5.6916, val_acc: 0.6313\n",
      "Epoch [4379], train_loss: 0.0000, val_loss: 5.5984, val_acc: 0.6313\n",
      "Epoch [4380], train_loss: 0.0000, val_loss: 5.5924, val_acc: 0.6313\n",
      "Epoch [4381], train_loss: 0.0000, val_loss: 5.5084, val_acc: 0.6339\n",
      "Epoch [4382], train_loss: 0.0000, val_loss: 5.5533, val_acc: 0.6313\n",
      "Epoch [4383], train_loss: 0.0000, val_loss: 5.7475, val_acc: 0.6339\n",
      "Epoch [4384], train_loss: 0.0000, val_loss: 5.8267, val_acc: 0.6339\n",
      "Epoch [4385], train_loss: 0.0000, val_loss: 5.5248, val_acc: 0.6313\n",
      "Epoch [4386], train_loss: 0.0000, val_loss: 5.7806, val_acc: 0.6179\n",
      "Epoch [4387], train_loss: 0.0000, val_loss: 5.7389, val_acc: 0.6313\n",
      "Epoch [4388], train_loss: 0.0000, val_loss: 5.7662, val_acc: 0.6287\n",
      "Epoch [4389], train_loss: 0.0000, val_loss: 5.6680, val_acc: 0.6313\n",
      "Epoch [4390], train_loss: 0.0000, val_loss: 5.5204, val_acc: 0.6313\n",
      "Epoch [4391], train_loss: 0.0000, val_loss: 5.6984, val_acc: 0.6313\n",
      "Epoch [4392], train_loss: 0.0000, val_loss: 5.6747, val_acc: 0.6287\n",
      "Epoch [4393], train_loss: 0.0000, val_loss: 5.7260, val_acc: 0.6287\n",
      "Epoch [4394], train_loss: 0.0000, val_loss: 5.4393, val_acc: 0.6313\n",
      "Epoch [4395], train_loss: 0.0000, val_loss: 5.8159, val_acc: 0.6261\n",
      "Epoch [4396], train_loss: 0.0000, val_loss: 5.9106, val_acc: 0.6287\n",
      "Epoch [4397], train_loss: 0.0000, val_loss: 5.7332, val_acc: 0.6313\n",
      "Epoch [4398], train_loss: 0.0000, val_loss: 5.6021, val_acc: 0.6313\n",
      "Epoch [4399], train_loss: 0.0000, val_loss: 5.6070, val_acc: 0.6339\n",
      "Epoch [4400], train_loss: 0.0000, val_loss: 5.6156, val_acc: 0.6339\n",
      "Epoch [4401], train_loss: 0.0000, val_loss: 5.8057, val_acc: 0.6313\n",
      "Epoch [4402], train_loss: 0.0000, val_loss: 6.0133, val_acc: 0.6287\n",
      "Epoch [4403], train_loss: 0.0000, val_loss: 5.8484, val_acc: 0.6232\n",
      "Epoch [4404], train_loss: 0.0000, val_loss: 5.8541, val_acc: 0.6287\n",
      "Epoch [4405], train_loss: 0.0000, val_loss: 5.8398, val_acc: 0.6287\n",
      "Epoch [4406], train_loss: 0.0000, val_loss: 5.8310, val_acc: 0.6232\n",
      "Epoch [4407], train_loss: 0.0000, val_loss: 5.7421, val_acc: 0.6313\n",
      "Epoch [4408], train_loss: 0.0000, val_loss: 5.9029, val_acc: 0.6313\n",
      "Epoch [4409], train_loss: 0.0000, val_loss: 5.8195, val_acc: 0.6258\n",
      "Epoch [4410], train_loss: 0.0000, val_loss: 5.6751, val_acc: 0.6313\n",
      "Epoch [4411], train_loss: 0.0000, val_loss: 5.9890, val_acc: 0.6339\n",
      "Epoch [4412], train_loss: 0.0000, val_loss: 5.8219, val_acc: 0.6339\n",
      "Epoch [4413], train_loss: 0.0000, val_loss: 5.8855, val_acc: 0.6287\n",
      "Epoch [4414], train_loss: 0.0000, val_loss: 5.8525, val_acc: 0.6313\n",
      "Epoch [4415], train_loss: 0.0000, val_loss: 6.0937, val_acc: 0.6179\n",
      "Epoch [4416], train_loss: 0.0000, val_loss: 5.8394, val_acc: 0.6339\n",
      "Epoch [4417], train_loss: 0.0002, val_loss: 5.9896, val_acc: 0.6258\n",
      "Epoch [4418], train_loss: 0.0896, val_loss: 2.5268, val_acc: 0.6072\n",
      "Epoch [4419], train_loss: 0.1489, val_loss: 3.3291, val_acc: 0.5623\n",
      "Epoch [4420], train_loss: 0.0495, val_loss: 3.7814, val_acc: 0.6046\n",
      "Epoch [4421], train_loss: 0.0167, val_loss: 3.7337, val_acc: 0.6017\n",
      "Epoch [4422], train_loss: 0.0017, val_loss: 4.0119, val_acc: 0.6153\n",
      "Epoch [4423], train_loss: 0.0003, val_loss: 4.1585, val_acc: 0.5991\n",
      "Epoch [4424], train_loss: 0.0001, val_loss: 4.2850, val_acc: 0.6098\n",
      "Epoch [4425], train_loss: 0.0001, val_loss: 4.2676, val_acc: 0.6069\n",
      "Epoch [4426], train_loss: 0.0001, val_loss: 4.4199, val_acc: 0.6150\n",
      "Epoch [4427], train_loss: 0.0001, val_loss: 4.3484, val_acc: 0.6072\n",
      "Epoch [4428], train_loss: 0.0001, val_loss: 4.3355, val_acc: 0.5965\n",
      "Epoch [4429], train_loss: 0.0027, val_loss: 3.9903, val_acc: 0.6023\n",
      "Epoch [4430], train_loss: 0.0084, val_loss: 4.4101, val_acc: 0.5825\n",
      "Epoch [4431], train_loss: 0.0002, val_loss: 3.8789, val_acc: 0.6284\n",
      "Epoch [4432], train_loss: 0.0002, val_loss: 4.2054, val_acc: 0.6069\n",
      "Epoch [4433], train_loss: 0.0001, val_loss: 4.0282, val_acc: 0.6043\n",
      "Epoch [4434], train_loss: 0.0001, val_loss: 4.2230, val_acc: 0.6124\n",
      "Epoch [4435], train_loss: 0.0001, val_loss: 4.4968, val_acc: 0.6043\n",
      "Epoch [4436], train_loss: 0.0001, val_loss: 4.3477, val_acc: 0.6202\n",
      "Epoch [4437], train_loss: 0.0000, val_loss: 4.3405, val_acc: 0.6176\n",
      "Epoch [4438], train_loss: 0.0001, val_loss: 4.3309, val_acc: 0.6258\n",
      "Epoch [4439], train_loss: 0.0001, val_loss: 4.3897, val_acc: 0.6313\n",
      "Epoch [4440], train_loss: 0.0000, val_loss: 4.5265, val_acc: 0.6124\n",
      "Epoch [4441], train_loss: 0.0000, val_loss: 4.3708, val_acc: 0.6206\n",
      "Epoch [4442], train_loss: 0.0000, val_loss: 4.4641, val_acc: 0.6206\n",
      "Epoch [4443], train_loss: 0.0000, val_loss: 4.6423, val_acc: 0.6206\n",
      "Epoch [4444], train_loss: 0.0000, val_loss: 4.5543, val_acc: 0.6232\n",
      "Epoch [4445], train_loss: 0.0000, val_loss: 4.6855, val_acc: 0.6258\n",
      "Epoch [4446], train_loss: 0.0000, val_loss: 4.6133, val_acc: 0.6098\n",
      "Epoch [4447], train_loss: 0.0000, val_loss: 4.4617, val_acc: 0.6206\n",
      "Epoch [4448], train_loss: 0.0000, val_loss: 4.7352, val_acc: 0.6176\n",
      "Epoch [4449], train_loss: 0.0000, val_loss: 4.5772, val_acc: 0.6150\n",
      "Epoch [4450], train_loss: 0.0000, val_loss: 4.5407, val_acc: 0.6124\n",
      "Epoch [4451], train_loss: 0.0000, val_loss: 4.7696, val_acc: 0.6313\n",
      "Epoch [4452], train_loss: 0.0000, val_loss: 4.5341, val_acc: 0.6043\n",
      "Epoch [4453], train_loss: 0.0000, val_loss: 4.8050, val_acc: 0.6124\n",
      "Epoch [4454], train_loss: 0.0000, val_loss: 4.7750, val_acc: 0.6098\n",
      "Epoch [4455], train_loss: 0.0000, val_loss: 4.7236, val_acc: 0.6124\n",
      "Epoch [4456], train_loss: 0.0000, val_loss: 4.7471, val_acc: 0.6176\n",
      "Epoch [4457], train_loss: 0.0000, val_loss: 4.7759, val_acc: 0.6069\n",
      "Epoch [4458], train_loss: 0.0000, val_loss: 4.7088, val_acc: 0.6150\n",
      "Epoch [4459], train_loss: 0.0000, val_loss: 4.7115, val_acc: 0.6124\n",
      "Epoch [4460], train_loss: 0.0000, val_loss: 4.8899, val_acc: 0.6095\n",
      "Epoch [4461], train_loss: 0.0000, val_loss: 4.8206, val_acc: 0.6124\n",
      "Epoch [4462], train_loss: 0.0000, val_loss: 4.7624, val_acc: 0.6124\n",
      "Epoch [4463], train_loss: 0.0000, val_loss: 4.8401, val_acc: 0.6043\n",
      "Epoch [4464], train_loss: 0.0000, val_loss: 5.0818, val_acc: 0.6179\n",
      "Epoch [4465], train_loss: 0.0001, val_loss: 4.9989, val_acc: 0.6069\n",
      "Epoch [4466], train_loss: 0.0000, val_loss: 5.1729, val_acc: 0.6098\n",
      "Epoch [4467], train_loss: 0.0000, val_loss: 4.9577, val_acc: 0.6017\n",
      "Epoch [4468], train_loss: 0.0000, val_loss: 4.9598, val_acc: 0.6098\n",
      "Epoch [4469], train_loss: 0.0000, val_loss: 4.9020, val_acc: 0.6258\n",
      "Epoch [4470], train_loss: 0.0000, val_loss: 4.9966, val_acc: 0.6017\n",
      "Epoch [4471], train_loss: 0.0000, val_loss: 4.9538, val_acc: 0.6176\n",
      "Epoch [4472], train_loss: 0.0000, val_loss: 5.0092, val_acc: 0.6098\n",
      "Epoch [4473], train_loss: 0.0000, val_loss: 5.0486, val_acc: 0.6124\n",
      "Epoch [4474], train_loss: 0.0000, val_loss: 4.9593, val_acc: 0.6098\n",
      "Epoch [4475], train_loss: 0.0000, val_loss: 5.1163, val_acc: 0.6098\n",
      "Epoch [4476], train_loss: 0.0000, val_loss: 4.9263, val_acc: 0.6069\n",
      "Epoch [4477], train_loss: 0.0000, val_loss: 5.0256, val_acc: 0.6014\n",
      "Epoch [4478], train_loss: 0.0000, val_loss: 4.9976, val_acc: 0.6095\n",
      "Epoch [4479], train_loss: 0.0000, val_loss: 4.9957, val_acc: 0.6150\n",
      "Epoch [4480], train_loss: 0.0000, val_loss: 4.9724, val_acc: 0.6258\n",
      "Epoch [4481], train_loss: 0.0000, val_loss: 5.1016, val_acc: 0.6069\n",
      "Epoch [4482], train_loss: 0.0000, val_loss: 5.1487, val_acc: 0.6069\n",
      "Epoch [4483], train_loss: 0.0000, val_loss: 5.1343, val_acc: 0.6043\n",
      "Epoch [4484], train_loss: 0.0000, val_loss: 5.0229, val_acc: 0.5965\n",
      "Epoch [4485], train_loss: 0.0000, val_loss: 5.1002, val_acc: 0.6043\n",
      "Epoch [4486], train_loss: 0.0000, val_loss: 5.2608, val_acc: 0.6095\n",
      "Epoch [4487], train_loss: 0.0000, val_loss: 5.2636, val_acc: 0.6069\n",
      "Epoch [4488], train_loss: 0.0000, val_loss: 5.2548, val_acc: 0.5988\n",
      "Epoch [4489], train_loss: 0.0000, val_loss: 5.2243, val_acc: 0.6066\n",
      "Epoch [4490], train_loss: 0.0000, val_loss: 5.1849, val_acc: 0.5962\n",
      "Epoch [4491], train_loss: 0.0000, val_loss: 5.2175, val_acc: 0.5965\n",
      "Epoch [4492], train_loss: 0.0000, val_loss: 5.1709, val_acc: 0.6017\n",
      "Epoch [4493], train_loss: 0.0011, val_loss: 5.2443, val_acc: 0.5753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4494], train_loss: 0.0399, val_loss: 3.8696, val_acc: 0.5678\n",
      "Epoch [4495], train_loss: 0.0376, val_loss: 3.4108, val_acc: 0.5747\n",
      "Epoch [4496], train_loss: 0.0292, val_loss: 3.0887, val_acc: 0.6105\n",
      "Epoch [4497], train_loss: 0.0739, val_loss: 4.2349, val_acc: 0.6023\n",
      "Epoch [4498], train_loss: 0.0046, val_loss: 4.0920, val_acc: 0.6264\n",
      "Epoch [4499], train_loss: 0.0008, val_loss: 4.6922, val_acc: 0.6261\n",
      "Epoch [4500], train_loss: 0.0011, val_loss: 4.5589, val_acc: 0.6212\n",
      "Epoch [4501], train_loss: 0.0002, val_loss: 4.8108, val_acc: 0.6238\n",
      "Epoch [4502], train_loss: 0.0001, val_loss: 5.0868, val_acc: 0.6264\n",
      "Epoch [4503], train_loss: 0.0000, val_loss: 4.9241, val_acc: 0.6316\n",
      "Epoch [4504], train_loss: 0.0000, val_loss: 5.0733, val_acc: 0.6316\n",
      "Epoch [4505], train_loss: 0.0000, val_loss: 5.0705, val_acc: 0.6290\n",
      "Epoch [4506], train_loss: 0.0000, val_loss: 4.9482, val_acc: 0.6316\n",
      "Epoch [4507], train_loss: 0.0000, val_loss: 5.1793, val_acc: 0.6316\n",
      "Epoch [4508], train_loss: 0.0000, val_loss: 5.1389, val_acc: 0.6316\n",
      "Epoch [4509], train_loss: 0.0000, val_loss: 5.2730, val_acc: 0.6342\n",
      "Epoch [4510], train_loss: 0.0000, val_loss: 5.2416, val_acc: 0.6290\n",
      "Epoch [4511], train_loss: 0.0000, val_loss: 5.0471, val_acc: 0.6368\n",
      "Epoch [4512], train_loss: 0.0000, val_loss: 5.3085, val_acc: 0.6238\n",
      "Epoch [4513], train_loss: 0.0000, val_loss: 5.2163, val_acc: 0.6342\n",
      "Epoch [4514], train_loss: 0.0000, val_loss: 5.3863, val_acc: 0.6342\n",
      "Epoch [4515], train_loss: 0.0000, val_loss: 5.3010, val_acc: 0.6342\n",
      "Epoch [4516], train_loss: 0.0000, val_loss: 5.5295, val_acc: 0.6316\n",
      "Epoch [4517], train_loss: 0.0000, val_loss: 5.5226, val_acc: 0.6316\n",
      "Epoch [4518], train_loss: 0.0000, val_loss: 5.3392, val_acc: 0.6342\n",
      "Epoch [4519], train_loss: 0.0000, val_loss: 5.4176, val_acc: 0.6316\n",
      "Epoch [4520], train_loss: 0.0000, val_loss: 5.4994, val_acc: 0.6342\n",
      "Epoch [4521], train_loss: 0.0000, val_loss: 5.4718, val_acc: 0.6316\n",
      "Epoch [4522], train_loss: 0.0000, val_loss: 5.4936, val_acc: 0.6316\n",
      "Epoch [4523], train_loss: 0.0000, val_loss: 5.4196, val_acc: 0.6342\n",
      "Epoch [4524], train_loss: 0.0000, val_loss: 5.5256, val_acc: 0.6290\n",
      "Epoch [4525], train_loss: 0.0000, val_loss: 5.6247, val_acc: 0.6290\n",
      "Epoch [4526], train_loss: 0.0000, val_loss: 5.5097, val_acc: 0.6316\n",
      "Epoch [4527], train_loss: 0.0000, val_loss: 5.5026, val_acc: 0.6316\n",
      "Epoch [4528], train_loss: 0.0000, val_loss: 5.6650, val_acc: 0.6316\n",
      "Epoch [4529], train_loss: 0.0000, val_loss: 5.7328, val_acc: 0.6316\n",
      "Epoch [4530], train_loss: 0.0000, val_loss: 5.5888, val_acc: 0.6342\n",
      "Epoch [4531], train_loss: 0.0000, val_loss: 5.5709, val_acc: 0.6290\n",
      "Epoch [4532], train_loss: 0.0000, val_loss: 5.5891, val_acc: 0.6316\n",
      "Epoch [4533], train_loss: 0.0000, val_loss: 5.7351, val_acc: 0.6316\n",
      "Epoch [4534], train_loss: 0.0000, val_loss: 5.6587, val_acc: 0.6316\n",
      "Epoch [4535], train_loss: 0.0000, val_loss: 5.7836, val_acc: 0.6316\n",
      "Epoch [4536], train_loss: 0.0000, val_loss: 5.5932, val_acc: 0.6316\n",
      "Epoch [4537], train_loss: 0.0000, val_loss: 5.8169, val_acc: 0.6316\n",
      "Epoch [4538], train_loss: 0.0000, val_loss: 5.7198, val_acc: 0.6264\n",
      "Epoch [4539], train_loss: 0.0000, val_loss: 5.7833, val_acc: 0.6290\n",
      "Epoch [4540], train_loss: 0.0000, val_loss: 5.6860, val_acc: 0.6290\n",
      "Epoch [4541], train_loss: 0.0000, val_loss: 5.8619, val_acc: 0.6290\n",
      "Epoch [4542], train_loss: 0.0000, val_loss: 5.8561, val_acc: 0.6316\n",
      "Epoch [4543], train_loss: 0.0000, val_loss: 5.8074, val_acc: 0.6290\n",
      "Epoch [4544], train_loss: 0.0000, val_loss: 6.0009, val_acc: 0.6290\n",
      "Epoch [4545], train_loss: 0.0000, val_loss: 5.7247, val_acc: 0.6290\n",
      "Epoch [4546], train_loss: 0.0000, val_loss: 5.8193, val_acc: 0.6342\n",
      "Epoch [4547], train_loss: 0.0000, val_loss: 5.8880, val_acc: 0.6316\n",
      "Epoch [4548], train_loss: 0.0000, val_loss: 5.7960, val_acc: 0.6316\n",
      "Epoch [4549], train_loss: 0.0000, val_loss: 5.9349, val_acc: 0.6290\n",
      "Epoch [4550], train_loss: 0.0000, val_loss: 6.0072, val_acc: 0.6316\n",
      "Epoch [4551], train_loss: 0.0000, val_loss: 5.8823, val_acc: 0.6316\n",
      "Epoch [4552], train_loss: 0.0000, val_loss: 5.9806, val_acc: 0.6316\n",
      "Epoch [4553], train_loss: 0.0000, val_loss: 5.7752, val_acc: 0.6342\n",
      "Epoch [4554], train_loss: 0.0000, val_loss: 5.9877, val_acc: 0.6290\n",
      "Epoch [4555], train_loss: 0.0000, val_loss: 5.9216, val_acc: 0.6342\n",
      "Epoch [4556], train_loss: 0.0000, val_loss: 5.9162, val_acc: 0.6157\n",
      "Epoch [4557], train_loss: 0.0000, val_loss: 5.9851, val_acc: 0.6290\n",
      "Epoch [4558], train_loss: 0.0000, val_loss: 5.8031, val_acc: 0.6342\n",
      "Epoch [4559], train_loss: 0.0000, val_loss: 6.0346, val_acc: 0.6290\n",
      "Epoch [4560], train_loss: 0.0000, val_loss: 6.0179, val_acc: 0.6342\n",
      "Epoch [4561], train_loss: 0.0000, val_loss: 6.0456, val_acc: 0.6316\n",
      "Epoch [4562], train_loss: 0.0000, val_loss: 6.1150, val_acc: 0.6342\n",
      "Epoch [4563], train_loss: 0.0000, val_loss: 6.1492, val_acc: 0.6290\n",
      "Epoch [4564], train_loss: 0.0000, val_loss: 6.1361, val_acc: 0.6290\n",
      "Epoch [4565], train_loss: 0.0000, val_loss: 6.1112, val_acc: 0.6264\n",
      "Epoch [4566], train_loss: 0.0000, val_loss: 6.1366, val_acc: 0.6342\n",
      "Epoch [4567], train_loss: 0.0000, val_loss: 6.0870, val_acc: 0.6316\n",
      "Epoch [4568], train_loss: 0.0256, val_loss: 3.8363, val_acc: 0.5890\n",
      "Epoch [4569], train_loss: 0.0993, val_loss: 3.3772, val_acc: 0.6232\n",
      "Epoch [4570], train_loss: 0.0130, val_loss: 4.2949, val_acc: 0.6261\n",
      "Epoch [4571], train_loss: 0.0209, val_loss: 6.0876, val_acc: 0.6000\n",
      "Epoch [4572], train_loss: 0.1099, val_loss: 2.9001, val_acc: 0.6157\n",
      "Epoch [4573], train_loss: 0.0498, val_loss: 3.1408, val_acc: 0.5884\n",
      "Epoch [4574], train_loss: 0.0104, val_loss: 3.1537, val_acc: 0.6183\n",
      "Epoch [4575], train_loss: 0.0010, val_loss: 3.8577, val_acc: 0.6316\n",
      "Epoch [4576], train_loss: 0.0006, val_loss: 3.8959, val_acc: 0.6261\n",
      "Epoch [4577], train_loss: 0.0008, val_loss: 3.9531, val_acc: 0.6313\n",
      "Epoch [4578], train_loss: 0.0004, val_loss: 4.2854, val_acc: 0.6127\n",
      "Epoch [4579], train_loss: 0.0002, val_loss: 4.3703, val_acc: 0.6127\n",
      "Epoch [4580], train_loss: 0.0001, val_loss: 4.3381, val_acc: 0.6153\n",
      "Epoch [4581], train_loss: 0.0001, val_loss: 4.4466, val_acc: 0.6206\n",
      "Epoch [4582], train_loss: 0.0001, val_loss: 4.4888, val_acc: 0.6261\n",
      "Epoch [4583], train_loss: 0.0001, val_loss: 4.4665, val_acc: 0.6153\n",
      "Epoch [4584], train_loss: 0.0001, val_loss: 4.7059, val_acc: 0.6179\n",
      "Epoch [4585], train_loss: 0.0001, val_loss: 4.6746, val_acc: 0.6153\n",
      "Epoch [4586], train_loss: 0.0000, val_loss: 4.5255, val_acc: 0.6179\n",
      "Epoch [4587], train_loss: 0.0001, val_loss: 4.7375, val_acc: 0.6206\n",
      "Epoch [4588], train_loss: 0.0000, val_loss: 4.7686, val_acc: 0.6235\n",
      "Epoch [4589], train_loss: 0.0000, val_loss: 4.6194, val_acc: 0.6179\n",
      "Epoch [4590], train_loss: 0.0000, val_loss: 4.8137, val_acc: 0.6368\n",
      "Epoch [4591], train_loss: 0.0000, val_loss: 4.6934, val_acc: 0.6394\n",
      "Epoch [4592], train_loss: 0.0000, val_loss: 4.9289, val_acc: 0.6342\n",
      "Epoch [4593], train_loss: 0.0000, val_loss: 4.8358, val_acc: 0.6235\n",
      "Epoch [4594], train_loss: 0.0000, val_loss: 4.9434, val_acc: 0.6368\n",
      "Epoch [4595], train_loss: 0.0000, val_loss: 4.8816, val_acc: 0.6183\n",
      "Epoch [4596], train_loss: 0.0000, val_loss: 5.1538, val_acc: 0.6368\n",
      "Epoch [4597], train_loss: 0.0000, val_loss: 4.6828, val_acc: 0.6290\n",
      "Epoch [4598], train_loss: 0.0000, val_loss: 4.9921, val_acc: 0.6368\n",
      "Epoch [4599], train_loss: 0.0000, val_loss: 5.1397, val_acc: 0.6342\n",
      "Epoch [4600], train_loss: 0.0000, val_loss: 4.8763, val_acc: 0.6287\n",
      "Epoch [4601], train_loss: 0.0001, val_loss: 4.6270, val_acc: 0.6342\n",
      "Epoch [4602], train_loss: 0.0000, val_loss: 4.8210, val_acc: 0.6342\n",
      "Epoch [4603], train_loss: 0.0000, val_loss: 5.3006, val_acc: 0.6316\n",
      "Epoch [4604], train_loss: 0.0000, val_loss: 5.2631, val_acc: 0.6394\n",
      "Epoch [4605], train_loss: 0.0000, val_loss: 4.8233, val_acc: 0.6368\n",
      "Epoch [4606], train_loss: 0.0000, val_loss: 5.0071, val_acc: 0.6368\n",
      "Epoch [4607], train_loss: 0.0000, val_loss: 5.2417, val_acc: 0.6368\n",
      "Epoch [4608], train_loss: 0.0000, val_loss: 5.0854, val_acc: 0.6368\n",
      "Epoch [4609], train_loss: 0.0000, val_loss: 5.1718, val_acc: 0.6368\n",
      "Epoch [4610], train_loss: 0.0000, val_loss: 5.2272, val_acc: 0.6342\n",
      "Epoch [4611], train_loss: 0.0000, val_loss: 5.1083, val_acc: 0.6261\n",
      "Epoch [4612], train_loss: 0.0000, val_loss: 5.1152, val_acc: 0.6313\n",
      "Epoch [4613], train_loss: 0.0000, val_loss: 5.2638, val_acc: 0.6449\n",
      "Epoch [4614], train_loss: 0.0000, val_loss: 5.2323, val_acc: 0.6313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4615], train_loss: 0.0000, val_loss: 5.0927, val_acc: 0.6368\n",
      "Epoch [4616], train_loss: 0.0000, val_loss: 5.2344, val_acc: 0.6368\n",
      "Epoch [4617], train_loss: 0.0001, val_loss: 4.9504, val_acc: 0.6475\n",
      "Epoch [4618], train_loss: 0.0001, val_loss: 5.3877, val_acc: 0.6423\n",
      "Epoch [4619], train_loss: 0.0000, val_loss: 5.5465, val_acc: 0.6371\n",
      "Epoch [4620], train_loss: 0.0000, val_loss: 5.5386, val_acc: 0.6345\n",
      "Epoch [4621], train_loss: 0.0000, val_loss: 5.4090, val_acc: 0.6371\n",
      "Epoch [4622], train_loss: 0.0000, val_loss: 5.5588, val_acc: 0.6345\n",
      "Epoch [4623], train_loss: 0.0000, val_loss: 5.6040, val_acc: 0.6371\n",
      "Epoch [4624], train_loss: 0.0000, val_loss: 5.7219, val_acc: 0.6397\n",
      "Epoch [4625], train_loss: 0.0000, val_loss: 5.8222, val_acc: 0.6397\n",
      "Epoch [4626], train_loss: 0.0000, val_loss: 5.6838, val_acc: 0.6397\n",
      "Epoch [4627], train_loss: 0.0000, val_loss: 5.7815, val_acc: 0.6449\n",
      "Epoch [4628], train_loss: 0.0000, val_loss: 5.6603, val_acc: 0.6557\n",
      "Epoch [4629], train_loss: 0.0000, val_loss: 6.0902, val_acc: 0.6479\n",
      "Epoch [4630], train_loss: 0.0000, val_loss: 5.7784, val_acc: 0.6423\n",
      "Epoch [4631], train_loss: 0.0000, val_loss: 6.0528, val_acc: 0.6397\n",
      "Epoch [4632], train_loss: 0.0000, val_loss: 6.0257, val_acc: 0.6397\n",
      "Epoch [4633], train_loss: 0.0000, val_loss: 5.8400, val_acc: 0.6423\n",
      "Epoch [4634], train_loss: 0.0000, val_loss: 5.7639, val_acc: 0.6453\n",
      "Epoch [4635], train_loss: 0.0000, val_loss: 6.2070, val_acc: 0.6397\n",
      "Epoch [4636], train_loss: 0.0000, val_loss: 5.8637, val_acc: 0.6449\n",
      "Epoch [4637], train_loss: 0.0000, val_loss: 6.1957, val_acc: 0.6397\n",
      "Epoch [4638], train_loss: 0.0000, val_loss: 5.9629, val_acc: 0.6368\n",
      "Epoch [4639], train_loss: 0.0000, val_loss: 5.8805, val_acc: 0.6368\n",
      "Epoch [4640], train_loss: 0.0000, val_loss: 5.9551, val_acc: 0.6342\n",
      "Epoch [4641], train_loss: 0.0000, val_loss: 6.0345, val_acc: 0.6316\n",
      "Epoch [4642], train_loss: 0.0000, val_loss: 5.9174, val_acc: 0.6423\n",
      "Epoch [4643], train_loss: 0.0000, val_loss: 6.0553, val_acc: 0.6368\n",
      "Epoch [4644], train_loss: 0.0000, val_loss: 6.2138, val_acc: 0.6316\n",
      "Epoch [4645], train_loss: 0.0000, val_loss: 6.1766, val_acc: 0.6397\n",
      "Epoch [4646], train_loss: 0.0000, val_loss: 5.8897, val_acc: 0.6423\n",
      "Epoch [4647], train_loss: 0.0000, val_loss: 6.0120, val_acc: 0.6342\n",
      "Epoch [4648], train_loss: 0.0000, val_loss: 6.0658, val_acc: 0.6449\n",
      "Epoch [4649], train_loss: 0.0000, val_loss: 6.0885, val_acc: 0.6368\n",
      "Epoch [4650], train_loss: 0.0000, val_loss: 6.0785, val_acc: 0.6342\n",
      "Epoch [4651], train_loss: 0.0000, val_loss: 6.0560, val_acc: 0.6342\n",
      "Epoch [4652], train_loss: 0.0000, val_loss: 6.2698, val_acc: 0.6371\n",
      "Epoch [4653], train_loss: 0.0000, val_loss: 6.1220, val_acc: 0.6423\n",
      "Epoch [4654], train_loss: 0.0000, val_loss: 6.0269, val_acc: 0.6423\n",
      "Epoch [4655], train_loss: 0.0000, val_loss: 6.1332, val_acc: 0.6397\n",
      "Epoch [4656], train_loss: 0.0000, val_loss: 6.0038, val_acc: 0.6342\n",
      "Epoch [4657], train_loss: 0.0000, val_loss: 6.1837, val_acc: 0.6368\n",
      "Epoch [4658], train_loss: 0.0000, val_loss: 6.0543, val_acc: 0.6290\n",
      "Epoch [4659], train_loss: 0.0001, val_loss: 6.2590, val_acc: 0.6342\n",
      "Epoch [4660], train_loss: 0.0010, val_loss: 9.1665, val_acc: 0.6209\n",
      "Epoch [4661], train_loss: 0.0463, val_loss: 4.5969, val_acc: 0.6186\n",
      "Epoch [4662], train_loss: 0.0323, val_loss: 3.0990, val_acc: 0.5968\n",
      "Epoch [4663], train_loss: 0.0917, val_loss: 3.8542, val_acc: 0.6020\n",
      "Epoch [4664], train_loss: 0.0281, val_loss: 3.5882, val_acc: 0.6280\n",
      "Epoch [4665], train_loss: 0.0032, val_loss: 3.3997, val_acc: 0.6098\n",
      "Epoch [4666], train_loss: 0.0008, val_loss: 3.7412, val_acc: 0.6258\n",
      "Epoch [4667], train_loss: 0.0006, val_loss: 3.7887, val_acc: 0.6095\n",
      "Epoch [4668], train_loss: 0.0003, val_loss: 3.9463, val_acc: 0.6124\n",
      "Epoch [4669], train_loss: 0.0001, val_loss: 4.2055, val_acc: 0.6176\n",
      "Epoch [4670], train_loss: 0.0000, val_loss: 4.2577, val_acc: 0.6206\n",
      "Epoch [4671], train_loss: 0.0002, val_loss: 4.4493, val_acc: 0.6232\n",
      "Epoch [4672], train_loss: 0.0001, val_loss: 4.4680, val_acc: 0.6206\n",
      "Epoch [4673], train_loss: 0.0000, val_loss: 4.4958, val_acc: 0.6287\n",
      "Epoch [4674], train_loss: 0.0000, val_loss: 4.7137, val_acc: 0.6232\n",
      "Epoch [4675], train_loss: 0.0000, val_loss: 4.5140, val_acc: 0.6232\n",
      "Epoch [4676], train_loss: 0.0000, val_loss: 4.6533, val_acc: 0.6261\n",
      "Epoch [4677], train_loss: 0.0000, val_loss: 4.6005, val_acc: 0.6232\n",
      "Epoch [4678], train_loss: 0.0000, val_loss: 4.6305, val_acc: 0.6206\n",
      "Epoch [4679], train_loss: 0.0000, val_loss: 4.5706, val_acc: 0.6287\n",
      "Epoch [4680], train_loss: 0.0000, val_loss: 4.7886, val_acc: 0.6232\n",
      "Epoch [4681], train_loss: 0.0000, val_loss: 4.7289, val_acc: 0.6258\n",
      "Epoch [4682], train_loss: 0.0000, val_loss: 4.7024, val_acc: 0.6232\n",
      "Epoch [4683], train_loss: 0.0000, val_loss: 4.7778, val_acc: 0.6261\n",
      "Epoch [4684], train_loss: 0.0000, val_loss: 4.6803, val_acc: 0.6261\n",
      "Epoch [4685], train_loss: 0.0000, val_loss: 4.7374, val_acc: 0.6287\n",
      "Epoch [4686], train_loss: 0.0000, val_loss: 4.8257, val_acc: 0.6258\n",
      "Epoch [4687], train_loss: 0.0000, val_loss: 4.8206, val_acc: 0.6235\n",
      "Epoch [4688], train_loss: 0.0000, val_loss: 4.9858, val_acc: 0.6313\n",
      "Epoch [4689], train_loss: 0.0000, val_loss: 4.9614, val_acc: 0.6261\n",
      "Epoch [4690], train_loss: 0.0000, val_loss: 4.9670, val_acc: 0.6235\n",
      "Epoch [4691], train_loss: 0.0000, val_loss: 4.8722, val_acc: 0.6287\n",
      "Epoch [4692], train_loss: 0.0000, val_loss: 5.1045, val_acc: 0.6261\n",
      "Epoch [4693], train_loss: 0.0000, val_loss: 4.8863, val_acc: 0.6124\n",
      "Epoch [4694], train_loss: 0.0000, val_loss: 5.1636, val_acc: 0.6258\n",
      "Epoch [4695], train_loss: 0.0000, val_loss: 5.0153, val_acc: 0.6235\n",
      "Epoch [4696], train_loss: 0.0000, val_loss: 4.9018, val_acc: 0.6287\n",
      "Epoch [4697], train_loss: 0.0000, val_loss: 4.8977, val_acc: 0.6235\n",
      "Epoch [4698], train_loss: 0.0000, val_loss: 5.0715, val_acc: 0.6235\n",
      "Epoch [4699], train_loss: 0.0000, val_loss: 5.0674, val_acc: 0.6287\n",
      "Epoch [4700], train_loss: 0.0000, val_loss: 5.0540, val_acc: 0.6287\n",
      "Epoch [4701], train_loss: 0.0000, val_loss: 5.1152, val_acc: 0.6261\n",
      "Epoch [4702], train_loss: 0.0000, val_loss: 5.2071, val_acc: 0.6261\n",
      "Epoch [4703], train_loss: 0.0000, val_loss: 5.1303, val_acc: 0.6209\n",
      "Epoch [4704], train_loss: 0.0000, val_loss: 5.0620, val_acc: 0.6261\n",
      "Epoch [4705], train_loss: 0.0000, val_loss: 4.9953, val_acc: 0.6235\n",
      "Epoch [4706], train_loss: 0.0000, val_loss: 5.1827, val_acc: 0.6287\n",
      "Epoch [4707], train_loss: 0.0000, val_loss: 5.2857, val_acc: 0.6287\n",
      "Epoch [4708], train_loss: 0.0000, val_loss: 5.1931, val_acc: 0.6235\n",
      "Epoch [4709], train_loss: 0.0000, val_loss: 5.2254, val_acc: 0.6206\n",
      "Epoch [4710], train_loss: 0.0000, val_loss: 5.4540, val_acc: 0.6179\n",
      "Epoch [4711], train_loss: 0.0000, val_loss: 5.3463, val_acc: 0.6232\n",
      "Epoch [4712], train_loss: 0.0000, val_loss: 5.2160, val_acc: 0.6232\n",
      "Epoch [4713], train_loss: 0.0000, val_loss: 5.1981, val_acc: 0.6153\n",
      "Epoch [4714], train_loss: 0.0000, val_loss: 5.3646, val_acc: 0.6206\n",
      "Epoch [4715], train_loss: 0.0000, val_loss: 5.3301, val_acc: 0.6206\n",
      "Epoch [4716], train_loss: 0.0000, val_loss: 5.2031, val_acc: 0.6339\n",
      "Epoch [4717], train_loss: 0.0000, val_loss: 5.3001, val_acc: 0.6287\n",
      "Epoch [4718], train_loss: 0.0000, val_loss: 5.3066, val_acc: 0.6206\n",
      "Epoch [4719], train_loss: 0.0000, val_loss: 5.4243, val_acc: 0.6287\n",
      "Epoch [4720], train_loss: 0.0000, val_loss: 5.3073, val_acc: 0.6206\n",
      "Epoch [4721], train_loss: 0.0000, val_loss: 5.4026, val_acc: 0.6235\n",
      "Epoch [4722], train_loss: 0.0000, val_loss: 5.3069, val_acc: 0.6287\n",
      "Epoch [4723], train_loss: 0.0000, val_loss: 5.2959, val_acc: 0.6098\n",
      "Epoch [4724], train_loss: 0.0000, val_loss: 5.4688, val_acc: 0.6206\n",
      "Epoch [4725], train_loss: 0.0000, val_loss: 5.4102, val_acc: 0.6206\n",
      "Epoch [4726], train_loss: 0.0000, val_loss: 5.4203, val_acc: 0.6179\n",
      "Epoch [4727], train_loss: 0.0000, val_loss: 5.5266, val_acc: 0.6179\n",
      "Epoch [4728], train_loss: 0.0000, val_loss: 5.3682, val_acc: 0.6124\n",
      "Epoch [4729], train_loss: 0.0000, val_loss: 5.5127, val_acc: 0.6261\n",
      "Epoch [4730], train_loss: 0.0000, val_loss: 5.4703, val_acc: 0.6261\n",
      "Epoch [4731], train_loss: 0.0001, val_loss: 5.4737, val_acc: 0.6098\n",
      "Epoch [4732], train_loss: 0.0000, val_loss: 5.6517, val_acc: 0.6206\n",
      "Epoch [4733], train_loss: 0.0000, val_loss: 5.6752, val_acc: 0.6124\n",
      "Epoch [4734], train_loss: 0.0000, val_loss: 5.6763, val_acc: 0.6098\n",
      "Epoch [4735], train_loss: 0.0000, val_loss: 5.5441, val_acc: 0.6072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4736], train_loss: 0.0000, val_loss: 5.6895, val_acc: 0.6206\n",
      "Epoch [4737], train_loss: 0.0000, val_loss: 5.6445, val_acc: 0.6150\n",
      "Epoch [4738], train_loss: 0.0000, val_loss: 5.6889, val_acc: 0.6098\n",
      "Epoch [4739], train_loss: 0.0000, val_loss: 5.7479, val_acc: 0.6153\n",
      "Epoch [4740], train_loss: 0.0000, val_loss: 5.6713, val_acc: 0.6072\n",
      "Epoch [4741], train_loss: 0.0000, val_loss: 5.6745, val_acc: 0.6124\n",
      "Epoch [4742], train_loss: 0.0000, val_loss: 5.8499, val_acc: 0.6072\n",
      "Epoch [4743], train_loss: 0.0130, val_loss: 6.1627, val_acc: 0.6388\n",
      "Epoch [4744], train_loss: 0.0493, val_loss: 3.2858, val_acc: 0.6456\n",
      "Epoch [4745], train_loss: 0.0489, val_loss: 3.1625, val_acc: 0.5890\n",
      "Epoch [4746], train_loss: 0.0372, val_loss: 2.6716, val_acc: 0.6069\n",
      "Epoch [4747], train_loss: 0.0067, val_loss: 4.0602, val_acc: 0.5779\n",
      "Epoch [4748], train_loss: 0.0025, val_loss: 3.8785, val_acc: 0.5936\n",
      "Epoch [4749], train_loss: 0.0006, val_loss: 4.4118, val_acc: 0.5854\n",
      "Epoch [4750], train_loss: 0.0004, val_loss: 4.7433, val_acc: 0.5776\n",
      "Epoch [4751], train_loss: 0.0005, val_loss: 5.3243, val_acc: 0.5591\n",
      "Epoch [4752], train_loss: 0.0002, val_loss: 5.3698, val_acc: 0.5695\n",
      "Epoch [4753], train_loss: 0.0000, val_loss: 5.4567, val_acc: 0.5617\n",
      "Epoch [4754], train_loss: 0.0000, val_loss: 5.2517, val_acc: 0.5669\n",
      "Epoch [4755], train_loss: 0.0000, val_loss: 5.6489, val_acc: 0.5669\n",
      "Epoch [4756], train_loss: 0.0000, val_loss: 5.5822, val_acc: 0.5669\n",
      "Epoch [4757], train_loss: 0.0000, val_loss: 5.6586, val_acc: 0.5669\n",
      "Epoch [4758], train_loss: 0.0000, val_loss: 5.7757, val_acc: 0.5695\n",
      "Epoch [4759], train_loss: 0.0000, val_loss: 5.7522, val_acc: 0.5643\n",
      "Epoch [4760], train_loss: 0.0000, val_loss: 6.0186, val_acc: 0.5643\n",
      "Epoch [4761], train_loss: 0.0000, val_loss: 5.8653, val_acc: 0.5721\n",
      "Epoch [4762], train_loss: 0.0000, val_loss: 5.7642, val_acc: 0.5669\n",
      "Epoch [4763], train_loss: 0.0000, val_loss: 5.8053, val_acc: 0.5721\n",
      "Epoch [4764], train_loss: 0.0000, val_loss: 5.7176, val_acc: 0.5695\n",
      "Epoch [4765], train_loss: 0.0000, val_loss: 5.8863, val_acc: 0.5695\n",
      "Epoch [4766], train_loss: 0.0000, val_loss: 5.8147, val_acc: 0.5669\n",
      "Epoch [4767], train_loss: 0.0000, val_loss: 5.7474, val_acc: 0.5747\n",
      "Epoch [4768], train_loss: 0.0000, val_loss: 5.7298, val_acc: 0.5880\n",
      "Epoch [4769], train_loss: 0.0000, val_loss: 5.7869, val_acc: 0.5773\n",
      "Epoch [4770], train_loss: 0.0000, val_loss: 5.7835, val_acc: 0.5828\n",
      "Epoch [4771], train_loss: 0.0000, val_loss: 5.9403, val_acc: 0.5802\n",
      "Epoch [4772], train_loss: 0.0000, val_loss: 6.0945, val_acc: 0.5747\n",
      "Epoch [4773], train_loss: 0.0000, val_loss: 5.6776, val_acc: 0.5802\n",
      "Epoch [4774], train_loss: 0.0000, val_loss: 6.0485, val_acc: 0.5721\n",
      "Epoch [4775], train_loss: 0.0000, val_loss: 5.9625, val_acc: 0.5854\n",
      "Epoch [4776], train_loss: 0.0000, val_loss: 5.9393, val_acc: 0.5828\n",
      "Epoch [4777], train_loss: 0.0000, val_loss: 5.9402, val_acc: 0.5773\n",
      "Epoch [4778], train_loss: 0.0000, val_loss: 5.8953, val_acc: 0.5721\n",
      "Epoch [4779], train_loss: 0.0000, val_loss: 6.0528, val_acc: 0.5773\n",
      "Epoch [4780], train_loss: 0.0001, val_loss: 6.2772, val_acc: 0.5695\n",
      "Epoch [4781], train_loss: 0.0001, val_loss: 6.4421, val_acc: 0.5802\n",
      "Epoch [4782], train_loss: 0.0000, val_loss: 6.2743, val_acc: 0.5802\n",
      "Epoch [4783], train_loss: 0.0001, val_loss: 6.6060, val_acc: 0.5880\n",
      "Epoch [4784], train_loss: 0.0000, val_loss: 6.5565, val_acc: 0.5880\n",
      "Epoch [4785], train_loss: 0.0000, val_loss: 6.6153, val_acc: 0.5802\n",
      "Epoch [4786], train_loss: 0.0000, val_loss: 6.8433, val_acc: 0.5802\n",
      "Epoch [4787], train_loss: 0.0000, val_loss: 6.7481, val_acc: 0.5906\n",
      "Epoch [4788], train_loss: 0.0000, val_loss: 6.9580, val_acc: 0.5802\n",
      "Epoch [4789], train_loss: 0.0000, val_loss: 6.6543, val_acc: 0.5802\n",
      "Epoch [4790], train_loss: 0.0000, val_loss: 6.7627, val_acc: 0.5828\n",
      "Epoch [4791], train_loss: 0.0000, val_loss: 6.7661, val_acc: 0.5802\n",
      "Epoch [4792], train_loss: 0.0000, val_loss: 6.7250, val_acc: 0.5828\n",
      "Epoch [4793], train_loss: 0.0000, val_loss: 6.4457, val_acc: 0.5854\n",
      "Epoch [4794], train_loss: 0.0000, val_loss: 6.7597, val_acc: 0.5854\n",
      "Epoch [4795], train_loss: 0.0000, val_loss: 6.7210, val_acc: 0.5828\n",
      "Epoch [4796], train_loss: 0.0000, val_loss: 6.6449, val_acc: 0.5802\n",
      "Epoch [4797], train_loss: 0.0000, val_loss: 6.7936, val_acc: 0.5799\n",
      "Epoch [4798], train_loss: 0.0000, val_loss: 6.7979, val_acc: 0.5828\n",
      "Epoch [4799], train_loss: 0.0000, val_loss: 6.6287, val_acc: 0.5828\n",
      "Epoch [4800], train_loss: 0.0000, val_loss: 6.7841, val_acc: 0.5828\n",
      "Epoch [4801], train_loss: 0.0000, val_loss: 6.8819, val_acc: 0.5880\n",
      "Epoch [4802], train_loss: 0.0000, val_loss: 6.7130, val_acc: 0.5828\n",
      "Epoch [4803], train_loss: 0.0000, val_loss: 6.8402, val_acc: 0.5802\n",
      "Epoch [4804], train_loss: 0.0000, val_loss: 7.0755, val_acc: 0.5776\n",
      "Epoch [4805], train_loss: 0.0000, val_loss: 7.0407, val_acc: 0.5776\n",
      "Epoch [4806], train_loss: 0.0000, val_loss: 6.9742, val_acc: 0.5802\n",
      "Epoch [4807], train_loss: 0.0000, val_loss: 6.6874, val_acc: 0.5880\n",
      "Epoch [4808], train_loss: 0.0000, val_loss: 7.0407, val_acc: 0.5776\n",
      "Epoch [4809], train_loss: 0.0000, val_loss: 6.8255, val_acc: 0.5802\n",
      "Epoch [4810], train_loss: 0.0000, val_loss: 7.1299, val_acc: 0.5750\n",
      "Epoch [4811], train_loss: 0.0000, val_loss: 6.8792, val_acc: 0.5880\n",
      "Epoch [4812], train_loss: 0.0000, val_loss: 7.0100, val_acc: 0.5802\n",
      "Epoch [4813], train_loss: 0.0000, val_loss: 6.8057, val_acc: 0.5854\n",
      "Epoch [4814], train_loss: 0.0000, val_loss: 6.7632, val_acc: 0.5854\n",
      "Epoch [4815], train_loss: 0.0000, val_loss: 7.2172, val_acc: 0.5724\n",
      "Epoch [4816], train_loss: 0.0000, val_loss: 7.1638, val_acc: 0.5776\n",
      "Epoch [4817], train_loss: 0.0000, val_loss: 6.9204, val_acc: 0.5828\n",
      "Epoch [4818], train_loss: 0.0000, val_loss: 6.8525, val_acc: 0.5854\n",
      "Epoch [4819], train_loss: 0.0000, val_loss: 7.0389, val_acc: 0.5854\n",
      "Epoch [4820], train_loss: 0.0000, val_loss: 6.9983, val_acc: 0.5828\n",
      "Epoch [4821], train_loss: 0.0000, val_loss: 7.1476, val_acc: 0.5776\n",
      "Epoch [4822], train_loss: 0.0000, val_loss: 6.8156, val_acc: 0.5695\n",
      "Epoch [4823], train_loss: 0.0000, val_loss: 7.1388, val_acc: 0.5802\n",
      "Epoch [4824], train_loss: 0.0000, val_loss: 6.9011, val_acc: 0.5802\n",
      "Epoch [4825], train_loss: 0.0000, val_loss: 7.1234, val_acc: 0.5802\n",
      "Epoch [4826], train_loss: 0.0000, val_loss: 6.9206, val_acc: 0.5828\n",
      "Epoch [4827], train_loss: 0.0000, val_loss: 6.8329, val_acc: 0.5802\n",
      "Epoch [4828], train_loss: 0.0000, val_loss: 7.2214, val_acc: 0.5776\n",
      "Epoch [4829], train_loss: 0.0000, val_loss: 7.0896, val_acc: 0.5854\n",
      "Epoch [4830], train_loss: 0.0000, val_loss: 7.1453, val_acc: 0.5828\n",
      "Epoch [4831], train_loss: 0.0000, val_loss: 7.0074, val_acc: 0.5828\n",
      "Epoch [4832], train_loss: 0.0000, val_loss: 6.9796, val_acc: 0.5802\n",
      "Epoch [4833], train_loss: 0.0000, val_loss: 7.0811, val_acc: 0.5776\n",
      "Epoch [4834], train_loss: 0.0000, val_loss: 7.0184, val_acc: 0.5828\n",
      "Epoch [4835], train_loss: 0.0000, val_loss: 7.1949, val_acc: 0.5802\n",
      "Epoch [4836], train_loss: 0.0000, val_loss: 7.1090, val_acc: 0.5828\n",
      "Epoch [4837], train_loss: 0.0000, val_loss: 7.2320, val_acc: 0.5776\n",
      "Epoch [4838], train_loss: 0.0000, val_loss: 7.3088, val_acc: 0.5802\n",
      "Epoch [4839], train_loss: 0.0000, val_loss: 6.9964, val_acc: 0.5776\n",
      "Epoch [4840], train_loss: 0.0000, val_loss: 6.7787, val_acc: 0.5776\n",
      "Epoch [4841], train_loss: 0.0001, val_loss: 6.3852, val_acc: 0.5857\n",
      "Epoch [4842], train_loss: 0.0386, val_loss: 3.6535, val_acc: 0.6609\n",
      "Epoch [4843], train_loss: 0.0486, val_loss: 6.5589, val_acc: 0.6023\n",
      "Epoch [4844], train_loss: 0.0604, val_loss: 3.2686, val_acc: 0.5623\n",
      "Epoch [4845], train_loss: 0.0260, val_loss: 3.6796, val_acc: 0.5857\n",
      "Epoch [4846], train_loss: 0.0506, val_loss: 5.4283, val_acc: 0.5919\n",
      "Epoch [4847], train_loss: 0.0620, val_loss: 4.2872, val_acc: 0.5701\n",
      "Epoch [4848], train_loss: 0.0114, val_loss: 3.3560, val_acc: 0.5786\n",
      "Epoch [4849], train_loss: 0.0021, val_loss: 4.5202, val_acc: 0.6124\n",
      "Epoch [4850], train_loss: 0.0005, val_loss: 4.5110, val_acc: 0.6072\n",
      "Epoch [4851], train_loss: 0.0003, val_loss: 4.8713, val_acc: 0.6072\n",
      "Epoch [4852], train_loss: 0.0002, val_loss: 4.6861, val_acc: 0.6098\n",
      "Epoch [4853], train_loss: 0.0002, val_loss: 4.9108, val_acc: 0.6127\n",
      "Epoch [4854], train_loss: 0.0001, val_loss: 4.8824, val_acc: 0.6179\n",
      "Epoch [4855], train_loss: 0.0001, val_loss: 5.2123, val_acc: 0.6072\n",
      "Epoch [4856], train_loss: 0.0001, val_loss: 5.3232, val_acc: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4857], train_loss: 0.0001, val_loss: 5.2171, val_acc: 0.6046\n",
      "Epoch [4858], train_loss: 0.0001, val_loss: 5.4111, val_acc: 0.6072\n",
      "Epoch [4859], train_loss: 0.0001, val_loss: 5.3453, val_acc: 0.5991\n",
      "Epoch [4860], train_loss: 0.0000, val_loss: 5.2105, val_acc: 0.6153\n",
      "Epoch [4861], train_loss: 0.0000, val_loss: 5.4683, val_acc: 0.6046\n",
      "Epoch [4862], train_loss: 0.0000, val_loss: 5.4059, val_acc: 0.6101\n",
      "Epoch [4863], train_loss: 0.0000, val_loss: 5.5240, val_acc: 0.5965\n",
      "Epoch [4864], train_loss: 0.0000, val_loss: 5.6877, val_acc: 0.5965\n",
      "Epoch [4865], train_loss: 0.0001, val_loss: 5.6192, val_acc: 0.5965\n",
      "Epoch [4866], train_loss: 0.0000, val_loss: 5.7524, val_acc: 0.6072\n",
      "Epoch [4867], train_loss: 0.0000, val_loss: 5.7609, val_acc: 0.6046\n",
      "Epoch [4868], train_loss: 0.0000, val_loss: 5.6743, val_acc: 0.6153\n",
      "Epoch [4869], train_loss: 0.0001, val_loss: 5.8573, val_acc: 0.6075\n",
      "Epoch [4870], train_loss: 0.0000, val_loss: 5.9031, val_acc: 0.6101\n",
      "Epoch [4871], train_loss: 0.0000, val_loss: 5.8536, val_acc: 0.6046\n",
      "Epoch [4872], train_loss: 0.0000, val_loss: 5.7501, val_acc: 0.6127\n",
      "Epoch [4873], train_loss: 0.0000, val_loss: 5.9660, val_acc: 0.6075\n",
      "Epoch [4874], train_loss: 0.0000, val_loss: 5.7855, val_acc: 0.6098\n",
      "Epoch [4875], train_loss: 0.0000, val_loss: 5.8290, val_acc: 0.6020\n",
      "Epoch [4876], train_loss: 0.0000, val_loss: 6.0710, val_acc: 0.6072\n",
      "Epoch [4877], train_loss: 0.0000, val_loss: 6.0241, val_acc: 0.6020\n",
      "Epoch [4878], train_loss: 0.0000, val_loss: 6.0163, val_acc: 0.6101\n",
      "Epoch [4879], train_loss: 0.0000, val_loss: 6.3203, val_acc: 0.6287\n",
      "Epoch [4880], train_loss: 0.0000, val_loss: 5.9594, val_acc: 0.6153\n",
      "Epoch [4881], train_loss: 0.0000, val_loss: 5.9141, val_acc: 0.6020\n",
      "Epoch [4882], train_loss: 0.0000, val_loss: 6.1868, val_acc: 0.6072\n",
      "Epoch [4883], train_loss: 0.0000, val_loss: 6.1487, val_acc: 0.6098\n",
      "Epoch [4884], train_loss: 0.0000, val_loss: 6.1519, val_acc: 0.6098\n",
      "Epoch [4885], train_loss: 0.0000, val_loss: 6.2540, val_acc: 0.6206\n",
      "Epoch [4886], train_loss: 0.0000, val_loss: 6.1801, val_acc: 0.6153\n",
      "Epoch [4887], train_loss: 0.0000, val_loss: 6.2220, val_acc: 0.6127\n",
      "Epoch [4888], train_loss: 0.0000, val_loss: 6.2682, val_acc: 0.6179\n",
      "Epoch [4889], train_loss: 0.0000, val_loss: 6.2317, val_acc: 0.6179\n",
      "Epoch [4890], train_loss: 0.0000, val_loss: 6.3595, val_acc: 0.6072\n",
      "Epoch [4891], train_loss: 0.0000, val_loss: 6.1822, val_acc: 0.6153\n",
      "Epoch [4892], train_loss: 0.0000, val_loss: 6.1581, val_acc: 0.6206\n",
      "Epoch [4893], train_loss: 0.0000, val_loss: 6.2258, val_acc: 0.6098\n",
      "Epoch [4894], train_loss: 0.0000, val_loss: 6.2144, val_acc: 0.6072\n",
      "Epoch [4895], train_loss: 0.0000, val_loss: 6.3429, val_acc: 0.6179\n",
      "Epoch [4896], train_loss: 0.0000, val_loss: 6.3113, val_acc: 0.6098\n",
      "Epoch [4897], train_loss: 0.0000, val_loss: 6.4630, val_acc: 0.6098\n",
      "Epoch [4898], train_loss: 0.0000, val_loss: 6.4649, val_acc: 0.6179\n",
      "Epoch [4899], train_loss: 0.0000, val_loss: 6.6139, val_acc: 0.6209\n",
      "Epoch [4900], train_loss: 0.0000, val_loss: 6.4272, val_acc: 0.6179\n",
      "Epoch [4901], train_loss: 0.0000, val_loss: 6.3254, val_acc: 0.6153\n",
      "Epoch [4902], train_loss: 0.0000, val_loss: 6.5215, val_acc: 0.6179\n",
      "Epoch [4903], train_loss: 0.0000, val_loss: 6.2570, val_acc: 0.6127\n",
      "Epoch [4904], train_loss: 0.0000, val_loss: 6.3956, val_acc: 0.6072\n",
      "Epoch [4905], train_loss: 0.0000, val_loss: 6.4848, val_acc: 0.5991\n",
      "Epoch [4906], train_loss: 0.0000, val_loss: 6.5159, val_acc: 0.6127\n",
      "Epoch [4907], train_loss: 0.0000, val_loss: 6.5894, val_acc: 0.6072\n",
      "Epoch [4908], train_loss: 0.0000, val_loss: 6.9469, val_acc: 0.6014\n",
      "Epoch [4909], train_loss: 0.0223, val_loss: 4.1025, val_acc: 0.6150\n",
      "Epoch [4910], train_loss: 0.0381, val_loss: 4.5334, val_acc: 0.6124\n",
      "Epoch [4911], train_loss: 0.0429, val_loss: 2.8995, val_acc: 0.5480\n",
      "Epoch [4912], train_loss: 0.0458, val_loss: 5.2565, val_acc: 0.5597\n",
      "Epoch [4913], train_loss: 0.0093, val_loss: 4.2914, val_acc: 0.5835\n",
      "Epoch [4914], train_loss: 0.0039, val_loss: 4.7834, val_acc: 0.5994\n",
      "Epoch [4915], train_loss: 0.0220, val_loss: 3.7475, val_acc: 0.5887\n",
      "Epoch [4916], train_loss: 0.0014, val_loss: 5.6968, val_acc: 0.6046\n",
      "Epoch [4917], train_loss: 0.0002, val_loss: 5.6307, val_acc: 0.5965\n",
      "Epoch [4918], train_loss: 0.0003, val_loss: 5.8710, val_acc: 0.5991\n",
      "Epoch [4919], train_loss: 0.0001, val_loss: 6.0902, val_acc: 0.5991\n",
      "Epoch [4920], train_loss: 0.0000, val_loss: 5.8413, val_acc: 0.5910\n",
      "Epoch [4921], train_loss: 0.0000, val_loss: 5.7533, val_acc: 0.5962\n",
      "Epoch [4922], train_loss: 0.0000, val_loss: 6.1079, val_acc: 0.5936\n",
      "Epoch [4923], train_loss: 0.0314, val_loss: 3.1888, val_acc: 0.5864\n",
      "Epoch [4924], train_loss: 0.0067, val_loss: 6.1817, val_acc: 0.5809\n",
      "Epoch [4925], train_loss: 0.0040, val_loss: 4.2032, val_acc: 0.5730\n",
      "Epoch [4926], train_loss: 0.0023, val_loss: 4.5695, val_acc: 0.5831\n",
      "Epoch [4927], train_loss: 0.0004, val_loss: 4.8337, val_acc: 0.5857\n",
      "Epoch [4928], train_loss: 0.0001, val_loss: 4.9830, val_acc: 0.5965\n",
      "Epoch [4929], train_loss: 0.0001, val_loss: 5.1727, val_acc: 0.5854\n",
      "Epoch [4930], train_loss: 0.0001, val_loss: 5.1819, val_acc: 0.5776\n",
      "Epoch [4931], train_loss: 0.0000, val_loss: 5.1429, val_acc: 0.5965\n",
      "Epoch [4932], train_loss: 0.0003, val_loss: 5.3673, val_acc: 0.5857\n",
      "Epoch [4933], train_loss: 0.0002, val_loss: 5.3397, val_acc: 0.5939\n",
      "Epoch [4934], train_loss: 0.0000, val_loss: 5.3346, val_acc: 0.5965\n",
      "Epoch [4935], train_loss: 0.0001, val_loss: 5.5922, val_acc: 0.5991\n",
      "Epoch [4936], train_loss: 0.0000, val_loss: 5.5157, val_acc: 0.5910\n",
      "Epoch [4937], train_loss: 0.0000, val_loss: 5.7076, val_acc: 0.5910\n",
      "Epoch [4938], train_loss: 0.0000, val_loss: 5.6144, val_acc: 0.5991\n",
      "Epoch [4939], train_loss: 0.0000, val_loss: 5.7556, val_acc: 0.5884\n",
      "Epoch [4940], train_loss: 0.0000, val_loss: 5.6606, val_acc: 0.5991\n",
      "Epoch [4941], train_loss: 0.0000, val_loss: 6.0125, val_acc: 0.5965\n",
      "Epoch [4942], train_loss: 0.0000, val_loss: 5.7664, val_acc: 0.6017\n",
      "Epoch [4943], train_loss: 0.0000, val_loss: 5.9001, val_acc: 0.5854\n",
      "Epoch [4944], train_loss: 0.0000, val_loss: 5.5375, val_acc: 0.5991\n",
      "Epoch [4945], train_loss: 0.0000, val_loss: 5.7679, val_acc: 0.5936\n",
      "Epoch [4946], train_loss: 0.0000, val_loss: 5.5691, val_acc: 0.5857\n",
      "Epoch [4947], train_loss: 0.0000, val_loss: 5.8831, val_acc: 0.5854\n",
      "Epoch [4948], train_loss: 0.0000, val_loss: 5.7921, val_acc: 0.5936\n",
      "Epoch [4949], train_loss: 0.0000, val_loss: 5.9104, val_acc: 0.5910\n",
      "Epoch [4950], train_loss: 0.0000, val_loss: 5.9924, val_acc: 0.5854\n",
      "Epoch [4951], train_loss: 0.0000, val_loss: 5.9447, val_acc: 0.5936\n",
      "Epoch [4952], train_loss: 0.0000, val_loss: 5.9198, val_acc: 0.5991\n",
      "Epoch [4953], train_loss: 0.0000, val_loss: 5.9994, val_acc: 0.5857\n",
      "Epoch [4954], train_loss: 0.0000, val_loss: 6.0931, val_acc: 0.5936\n",
      "Epoch [4955], train_loss: 0.0000, val_loss: 6.1230, val_acc: 0.5857\n",
      "Epoch [4956], train_loss: 0.0000, val_loss: 5.9341, val_acc: 0.5910\n",
      "Epoch [4957], train_loss: 0.0000, val_loss: 6.2593, val_acc: 0.5854\n",
      "Epoch [4958], train_loss: 0.0000, val_loss: 6.1624, val_acc: 0.5831\n",
      "Epoch [4959], train_loss: 0.0000, val_loss: 6.0864, val_acc: 0.5936\n",
      "Epoch [4960], train_loss: 0.0000, val_loss: 6.2479, val_acc: 0.5854\n",
      "Epoch [4961], train_loss: 0.0000, val_loss: 6.0774, val_acc: 0.5991\n",
      "Epoch [4962], train_loss: 0.0000, val_loss: 6.0603, val_acc: 0.5991\n",
      "Epoch [4963], train_loss: 0.0000, val_loss: 6.0477, val_acc: 0.5910\n",
      "Epoch [4964], train_loss: 0.0000, val_loss: 6.1871, val_acc: 0.5939\n",
      "Epoch [4965], train_loss: 0.0000, val_loss: 6.3254, val_acc: 0.5857\n",
      "Epoch [4966], train_loss: 0.0000, val_loss: 5.8965, val_acc: 0.6072\n",
      "Epoch [4967], train_loss: 0.0000, val_loss: 6.1465, val_acc: 0.5828\n",
      "Epoch [4968], train_loss: 0.0000, val_loss: 6.3846, val_acc: 0.5854\n",
      "Epoch [4969], train_loss: 0.0000, val_loss: 6.5775, val_acc: 0.5857\n",
      "Epoch [4970], train_loss: 0.0000, val_loss: 6.1070, val_acc: 0.6072\n",
      "Epoch [4971], train_loss: 0.0000, val_loss: 6.0890, val_acc: 0.5857\n",
      "Epoch [4972], train_loss: 0.0000, val_loss: 6.2140, val_acc: 0.5857\n",
      "Epoch [4973], train_loss: 0.0000, val_loss: 5.9897, val_acc: 0.6072\n",
      "Epoch [4974], train_loss: 0.0000, val_loss: 6.4473, val_acc: 0.5802\n",
      "Epoch [4975], train_loss: 0.0000, val_loss: 6.3550, val_acc: 0.5913\n",
      "Epoch [4976], train_loss: 0.0000, val_loss: 6.5270, val_acc: 0.5776\n",
      "Epoch [4977], train_loss: 0.0000, val_loss: 6.4835, val_acc: 0.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4978], train_loss: 0.0000, val_loss: 6.6661, val_acc: 0.5991\n",
      "Epoch [4979], train_loss: 0.0000, val_loss: 6.2180, val_acc: 0.5854\n",
      "Epoch [4980], train_loss: 0.0000, val_loss: 6.4420, val_acc: 0.6017\n",
      "Epoch [4981], train_loss: 0.0000, val_loss: 6.3413, val_acc: 0.5913\n",
      "Epoch [4982], train_loss: 0.0000, val_loss: 6.5394, val_acc: 0.5910\n",
      "Epoch [4983], train_loss: 0.0000, val_loss: 6.6826, val_acc: 0.5828\n",
      "Epoch [4984], train_loss: 0.0000, val_loss: 6.3785, val_acc: 0.5965\n",
      "Epoch [4985], train_loss: 0.0000, val_loss: 6.5820, val_acc: 0.5828\n",
      "Epoch [4986], train_loss: 0.0000, val_loss: 6.4393, val_acc: 0.5910\n",
      "Epoch [4987], train_loss: 0.0000, val_loss: 6.4718, val_acc: 0.5910\n",
      "Epoch [4988], train_loss: 0.0000, val_loss: 6.7293, val_acc: 0.5828\n",
      "Epoch [4989], train_loss: 0.0000, val_loss: 6.7428, val_acc: 0.5776\n",
      "Epoch [4990], train_loss: 0.0000, val_loss: 6.1167, val_acc: 0.6046\n",
      "Epoch [4991], train_loss: 0.0000, val_loss: 6.4929, val_acc: 0.5828\n",
      "Epoch [4992], train_loss: 0.0000, val_loss: 6.4093, val_acc: 0.5939\n",
      "Epoch [4993], train_loss: 0.0000, val_loss: 6.5606, val_acc: 0.5857\n",
      "Epoch [4994], train_loss: 0.0000, val_loss: 6.5655, val_acc: 0.5910\n",
      "Epoch [4995], train_loss: 0.0000, val_loss: 6.7998, val_acc: 0.5857\n",
      "Epoch [4996], train_loss: 0.0000, val_loss: 6.6761, val_acc: 0.5776\n",
      "Epoch [4997], train_loss: 0.0000, val_loss: 6.7640, val_acc: 0.5857\n",
      "Epoch [4998], train_loss: 0.0000, val_loss: 6.8978, val_acc: 0.5828\n",
      "Epoch [4999], train_loss: 0.0000, val_loss: 6.6884, val_acc: 0.5828\n"
     ]
    }
   ],
   "source": [
    "# CTX = torch.device('cuda')\n",
    "# train_dl.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # train_dl.train_labels.to(CTX)\n",
    "# # val_dl.train_data.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # val_dl.train_labels.to(CTX)\n",
    "num_epochs = 5000\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26874318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "\n",
    "plot_accuracies(history)\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60afc6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6898500919342041"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x['val_acc'] for x in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3164b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
