{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33392872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import pickle\n",
    "def load_data(in_dir):\n",
    "    f = open(in_dir,'rb')\n",
    "    train_data,train_label,valid_data,valid_label = pickle.load(f)\n",
    "    return train_data,train_label,valid_data,valid_label\n",
    "\n",
    "# data_path = 'adress_512.pkl'\n",
    "data_path = 'adress_Att_Net.pkl'\n",
    "checkpoint = 'checkpoint/'\n",
    "\n",
    "train_data,train_label,valid_data,valid_label = load_data(data_path)\n",
    "\n",
    "# converting training images into torch format\n",
    "train_x = train_data\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_label\n",
    "train_y = train_y.reshape(1392).astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "# train_x.shape, train_y.shape\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "# my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "# tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "# tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "CTX = torch.device('cuda')\n",
    "\n",
    "train_dataset = TensorDataset(train_x.to(CTX),train_y.to(CTX)) # create your datset\n",
    "\n",
    " # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09537d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "val_x = valid_data\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = valid_label\n",
    "val_y = val_y.reshape(74).astype(float);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "# shape of training data\n",
    "\n",
    "val_dataset = TensorDataset(val_x,val_y) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4701d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 64\n",
    "val_size = 297\n",
    "# train_size = train_x.size(0) - val_size \n",
    "\n",
    "# train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "# print(f\"Length of Train Data : {len(train_data)}\")\n",
    "# print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 2379\n",
    "#Length of Validation Data : 297\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_dataset,batch_size, shuffle = True, num_workers = 0)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d492176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda())   # Calculate loss\n",
    "        acc = accuracy(out, labels.to(torch.int64).cuda())           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e9be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "\n",
    "class ParallelPolarizedSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, channel=512):\n",
    "        super().__init__()\n",
    "        self.ch_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.ch_wq=nn.Conv2d(channel,1,kernel_size=(1,1))\n",
    "        self.softmax_channel=nn.Softmax(1)\n",
    "        self.softmax_spatial=nn.Softmax(-1)\n",
    "        self.ch_wz=nn.Conv2d(channel//2,channel,kernel_size=(1,1))\n",
    "        self.ln=nn.LayerNorm(channel)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.sp_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.sp_wq=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.agp=nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        #Channel-only Self-Attention\n",
    "        channel_wv=self.ch_wv(x) #bs,c//2,h,w\n",
    "        channel_wq=self.ch_wq(x) #bs,1,h,w\n",
    "        channel_wv=channel_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n",
    "        channel_wq=channel_wq.reshape(b,-1,1) #bs,h*w,1\n",
    "        channel_wq=self.softmax_channel(channel_wq)\n",
    "        channel_wz=torch.matmul(channel_wv,channel_wq).unsqueeze(-1) #bs,c//2,1,1\n",
    "        channel_weight=self.sigmoid(self.ln(self.ch_wz(channel_wz).reshape(b,c,1).permute(0,2,1))).permute(0,2,1).reshape(b,c,1,1) #bs,c,1,1\n",
    "        channel_out=channel_weight*x\n",
    "\n",
    "        #Spatial-only Self-Attention\n",
    "        spatial_wv=self.sp_wv(x) #bs,c//2,h,w\n",
    "        spatial_wq=self.sp_wq(x) #bs,c//2,h,w\n",
    "        spatial_wq=self.agp(spatial_wq) #bs,c//2,1,1\n",
    "        spatial_wv=spatial_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n",
    "        spatial_wq=spatial_wq.permute(0,2,3,1).reshape(b,1,c//2) #bs,1,c//2\n",
    "        spatial_wq=self.softmax_spatial(spatial_wq)\n",
    "        spatial_wz=torch.matmul(spatial_wq,spatial_wv) #bs,1,h*w\n",
    "        spatial_weight=self.sigmoid(spatial_wz.reshape(b,1,h,w)) #bs,1,h,w\n",
    "        spatial_out=spatial_weight*x\n",
    "        out=spatial_out+channel_out\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SequentialPolarizedSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, channel=512):\n",
    "        super().__init__()\n",
    "        self.ch_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.ch_wq=nn.Conv2d(channel,1,kernel_size=(1,1))\n",
    "        self.softmax_channel=nn.Softmax(1)\n",
    "        self.softmax_spatial=nn.Softmax(-1)\n",
    "        self.ch_wz=nn.Conv2d(channel//2,channel,kernel_size=(1,1))\n",
    "        self.ln=nn.LayerNorm(channel)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.sp_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.sp_wq=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.agp=nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        #Channel-only Self-Attention\n",
    "        channel_wv=self.ch_wv(x) #bs,c//2,h,w\n",
    "        channel_wq=self.ch_wq(x) #bs,1,h,w\n",
    "        channel_wv=channel_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n",
    "        channel_wq=channel_wq.reshape(b,-1,1) #bs,h*w,1\n",
    "        channel_wq=self.softmax_channel(channel_wq)\n",
    "        channel_wz=torch.matmul(channel_wv,channel_wq).unsqueeze(-1) #bs,c//2,1,1\n",
    "        channel_weight=self.sigmoid(self.ln(self.ch_wz(channel_wz).reshape(b,c,1).permute(0,2,1))).permute(0,2,1).reshape(b,c,1,1) #bs,c,1,1\n",
    "        channel_out=channel_weight*x\n",
    "\n",
    "        #Spatial-only Self-Attention\n",
    "        spatial_wv=self.sp_wv(channel_out) #bs,c//2,h,w\n",
    "        spatial_wq=self.sp_wq(channel_out) #bs,c//2,h,w\n",
    "        spatial_wq=self.agp(spatial_wq) #bs,c//2,1,1\n",
    "        spatial_wv=spatial_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n",
    "        spatial_wq=spatial_wq.permute(0,2,3,1).reshape(b,1,c//2) #bs,1,c//2\n",
    "        spatial_wq=self.softmax_spatial(spatial_wq)\n",
    "        spatial_wz=torch.matmul(spatial_wq,spatial_wv) #bs,1,h*w\n",
    "        spatial_weight=self.sigmoid(spatial_wz.reshape(b,1,h,w)) #bs,1,h,w\n",
    "        spatial_out=spatial_weight*channel_out\n",
    "        return spatial_out\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     input=torch.randn(50,512,7,7)\n",
    "#     bam = BAMBlock(channel=512,reduction=16,dia_val=2)\n",
    "#     output=bam(input)\n",
    "#     print(output.shape)\n",
    "    \n",
    "    \n",
    "class Att_Net(ImageClassificationBase):   \n",
    "    def __init__(self):\n",
    "        super(Att_Net, self).__init__()\n",
    "        #The LW_CNN module utilizes three convolutions (C), two max-pooling\n",
    "        # (MP), one average-pooling (AP), and one batch normalization\n",
    "        # (BN) layer.\n",
    "        self.LW_CNN = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "#             Conv2d(300, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(256),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Defining another 2D convolution layer\n",
    "#             Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(128),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=1, stride=1),\n",
    "            \n",
    "              #C1, we used 120 number of kernels with size (11\n",
    "              # × 11) using (4 × 4) stride setting without padding to extract\n",
    "              # initially hidden patterns from input data. \n",
    "              Conv2d(3, 120, kernel_size=(5,5), stride=(3,3), padding=0),\n",
    "              MaxPool2d(kernel_size=(2,2), stride=None),\n",
    "              Conv2d(120, 256, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "#               MaxPool2d(kernel_size=(2,2)),\n",
    "#               Conv2d(256, 384, kernel_size=(2,2), padding='same'),\n",
    "#               MaxPool2d(kernel_size=1, stride=0),\n",
    "#               Conv2d(128, 1, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "              torch.nn.AvgPool2d(kernel_size=(2,2), stride=1),\n",
    "              BatchNorm2d(256),\n",
    "              ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(256 * 84 * 20, 128),\n",
    "#             Linear(256, 64),\n",
    "            Linear(128, 2),\n",
    "        )\n",
    "\n",
    "        self.attention = SequentialPolarizedSelfAttention(channel = 256)\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "#         x = x.view(-1, x.size(3),x.size(2),x.size(1))\n",
    "#         print(x.size)\n",
    "        x = self.LW_CNN(x)\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f81fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Att_Net(\n",
      "  (LW_CNN): Sequential(\n",
      "    (0): Conv2d(3, 120, kernel_size=(5, 5), stride=(3, 3))\n",
      "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(120, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=430080, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      "  (attention): SequentialPolarizedSelfAttention(\n",
      "    (ch_wv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (ch_wq): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax_channel): Softmax(dim=1)\n",
      "    (softmax_spatial): Softmax(dim=-1)\n",
      "    (ch_wz): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (sp_wv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (sp_wq): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (agp): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Att_Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477fd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 120, 170, 42]           9,120\n",
      "         MaxPool2d-2          [-1, 120, 85, 21]               0\n",
      "            Conv2d-3          [-1, 256, 85, 21]         276,736\n",
      "         AvgPool2d-4          [-1, 256, 84, 20]               0\n",
      "       BatchNorm2d-5          [-1, 256, 84, 20]             512\n",
      "              ReLU-6          [-1, 256, 84, 20]               0\n",
      "            Conv2d-7          [-1, 128, 84, 20]          32,896\n",
      "            Conv2d-8            [-1, 1, 84, 20]             257\n",
      "           Softmax-9              [-1, 1680, 1]               0\n",
      "           Conv2d-10            [-1, 256, 1, 1]          33,024\n",
      "        LayerNorm-11               [-1, 1, 256]             512\n",
      "          Sigmoid-12               [-1, 1, 256]               0\n",
      "           Conv2d-13          [-1, 128, 84, 20]          32,896\n",
      "           Conv2d-14          [-1, 128, 84, 20]          32,896\n",
      "AdaptiveAvgPool2d-15            [-1, 128, 1, 1]               0\n",
      "          Softmax-16               [-1, 1, 128]               0\n",
      "          Sigmoid-17            [-1, 1, 84, 20]               0\n",
      "SequentialPolarizedSelfAttention-18          [-1, 256, 84, 20]               0\n",
      "           Linear-19                  [-1, 128]      55,050,368\n",
      "           Linear-20                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 55,469,475\n",
      "Trainable params: 55,469,475\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 29.75\n",
      "Params size (MB): 211.60\n",
      "Estimated Total Size (MB): 242.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 512, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932937ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input=torch.randn(50,256,7,7)\n",
    "# bam = BAMBlock(channel=256,reduction=16,dia_val=2)\n",
    "# output=bam(input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a72cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 17.4550, val_loss: 4.8917, val_acc: 0.5676\n",
      "Epoch [1], train_loss: 3.0657, val_loss: 1.0265, val_acc: 0.5811\n",
      "Epoch [2], train_loss: 0.8071, val_loss: 0.8435, val_acc: 0.4459\n",
      "Epoch [3], train_loss: 0.6944, val_loss: 0.7216, val_acc: 0.6892\n",
      "Epoch [4], train_loss: 0.6394, val_loss: 0.7804, val_acc: 0.4730\n",
      "Epoch [5], train_loss: 0.6519, val_loss: 0.7925, val_acc: 0.6486\n",
      "Epoch [6], train_loss: 0.7854, val_loss: 1.1324, val_acc: 0.4324\n",
      "Epoch [7], train_loss: 0.9419, val_loss: 1.3786, val_acc: 0.3784\n",
      "Epoch [8], train_loss: 0.6622, val_loss: 0.7435, val_acc: 0.6486\n",
      "Epoch [9], train_loss: 0.6241, val_loss: 0.7221, val_acc: 0.5811\n",
      "Epoch [10], train_loss: 0.5847, val_loss: 0.7103, val_acc: 0.5811\n",
      "Epoch [11], train_loss: 0.5997, val_loss: 0.7760, val_acc: 0.5000\n",
      "Epoch [12], train_loss: 0.5843, val_loss: 0.6989, val_acc: 0.6081\n",
      "Epoch [13], train_loss: 0.5931, val_loss: 0.7098, val_acc: 0.6216\n",
      "Epoch [14], train_loss: 0.5748, val_loss: 0.6917, val_acc: 0.5946\n",
      "Epoch [15], train_loss: 0.5679, val_loss: 0.7189, val_acc: 0.5405\n",
      "Epoch [16], train_loss: 0.5877, val_loss: 0.7020, val_acc: 0.6486\n",
      "Epoch [17], train_loss: 0.6536, val_loss: 0.6892, val_acc: 0.5946\n",
      "Epoch [18], train_loss: 0.5827, val_loss: 0.8071, val_acc: 0.4865\n",
      "Epoch [19], train_loss: 0.5549, val_loss: 0.6924, val_acc: 0.5946\n",
      "Epoch [20], train_loss: 0.5521, val_loss: 0.6914, val_acc: 0.7027\n",
      "Epoch [21], train_loss: 0.5609, val_loss: 0.6728, val_acc: 0.6081\n",
      "Epoch [22], train_loss: 0.5302, val_loss: 0.7099, val_acc: 0.7027\n",
      "Epoch [23], train_loss: 0.5650, val_loss: 1.1124, val_acc: 0.4054\n",
      "Epoch [24], train_loss: 0.6443, val_loss: 0.7633, val_acc: 0.6351\n",
      "Epoch [25], train_loss: 0.5945, val_loss: 0.7169, val_acc: 0.5135\n",
      "Epoch [26], train_loss: 0.5255, val_loss: 0.7187, val_acc: 0.5676\n",
      "Epoch [27], train_loss: 0.5101, val_loss: 0.7040, val_acc: 0.5811\n",
      "Epoch [28], train_loss: 0.4829, val_loss: 0.8668, val_acc: 0.4865\n",
      "Epoch [29], train_loss: 0.4955, val_loss: 0.9798, val_acc: 0.4730\n",
      "Epoch [30], train_loss: 0.4989, val_loss: 0.7375, val_acc: 0.5405\n",
      "Epoch [31], train_loss: 0.4788, val_loss: 0.7431, val_acc: 0.5541\n",
      "Epoch [32], train_loss: 0.4347, val_loss: 0.7977, val_acc: 0.5541\n",
      "Epoch [33], train_loss: 0.4194, val_loss: 0.8233, val_acc: 0.5676\n",
      "Epoch [34], train_loss: 0.4728, val_loss: 0.8056, val_acc: 0.5811\n",
      "Epoch [35], train_loss: 0.4135, val_loss: 0.8161, val_acc: 0.5270\n",
      "Epoch [36], train_loss: 0.3844, val_loss: 1.1367, val_acc: 0.4730\n",
      "Epoch [37], train_loss: 0.4097, val_loss: 0.9327, val_acc: 0.7162\n",
      "Epoch [38], train_loss: 0.3626, val_loss: 1.0873, val_acc: 0.5811\n",
      "Epoch [39], train_loss: 0.3155, val_loss: 0.9427, val_acc: 0.5405\n",
      "Epoch [40], train_loss: 0.2877, val_loss: 1.1153, val_acc: 0.5000\n",
      "Epoch [41], train_loss: 0.2732, val_loss: 1.0602, val_acc: 0.6216\n",
      "Epoch [42], train_loss: 0.2168, val_loss: 1.1833, val_acc: 0.5405\n",
      "Epoch [43], train_loss: 0.1935, val_loss: 1.6645, val_acc: 0.5405\n",
      "Epoch [44], train_loss: 0.1905, val_loss: 1.6520, val_acc: 0.5541\n",
      "Epoch [45], train_loss: 0.1660, val_loss: 1.6028, val_acc: 0.5000\n",
      "Epoch [46], train_loss: 0.0926, val_loss: 1.8575, val_acc: 0.5270\n",
      "Epoch [47], train_loss: 0.1324, val_loss: 1.8660, val_acc: 0.6081\n",
      "Epoch [48], train_loss: 0.1469, val_loss: 2.0402, val_acc: 0.5135\n",
      "Epoch [49], train_loss: 0.1187, val_loss: 1.7836, val_acc: 0.6081\n",
      "Epoch [50], train_loss: 0.0779, val_loss: 2.2446, val_acc: 0.6622\n",
      "Epoch [51], train_loss: 0.0900, val_loss: 2.3364, val_acc: 0.5541\n",
      "Epoch [52], train_loss: 0.0623, val_loss: 2.5113, val_acc: 0.5811\n",
      "Epoch [53], train_loss: 0.0948, val_loss: 2.1830, val_acc: 0.6216\n",
      "Epoch [54], train_loss: 0.1574, val_loss: 2.1443, val_acc: 0.5541\n",
      "Epoch [55], train_loss: 0.0640, val_loss: 2.4125, val_acc: 0.5811\n",
      "Epoch [56], train_loss: 0.0272, val_loss: 2.2697, val_acc: 0.5946\n",
      "Epoch [57], train_loss: 0.0149, val_loss: 2.4545, val_acc: 0.6216\n",
      "Epoch [58], train_loss: 0.0103, val_loss: 2.7493, val_acc: 0.5676\n",
      "Epoch [59], train_loss: 0.0080, val_loss: 2.7926, val_acc: 0.6216\n",
      "Epoch [60], train_loss: 0.0086, val_loss: 3.4084, val_acc: 0.5676\n",
      "Epoch [61], train_loss: 0.0063, val_loss: 3.1606, val_acc: 0.6081\n",
      "Epoch [62], train_loss: 0.0049, val_loss: 3.5057, val_acc: 0.5811\n",
      "Epoch [63], train_loss: 0.0040, val_loss: 3.6396, val_acc: 0.5811\n",
      "Epoch [64], train_loss: 0.0025, val_loss: 3.4316, val_acc: 0.6081\n",
      "Epoch [65], train_loss: 0.0026, val_loss: 3.7927, val_acc: 0.5811\n",
      "Epoch [66], train_loss: 0.0016, val_loss: 3.6768, val_acc: 0.5811\n",
      "Epoch [67], train_loss: 0.0012, val_loss: 3.8780, val_acc: 0.5676\n",
      "Epoch [68], train_loss: 0.0012, val_loss: 3.8321, val_acc: 0.5811\n",
      "Epoch [69], train_loss: 0.0015, val_loss: 3.9393, val_acc: 0.5946\n",
      "Epoch [70], train_loss: 0.0034, val_loss: 4.2031, val_acc: 0.5270\n",
      "Epoch [71], train_loss: 0.0058, val_loss: 4.0678, val_acc: 0.5676\n",
      "Epoch [72], train_loss: 0.0060, val_loss: 3.5129, val_acc: 0.6081\n",
      "Epoch [73], train_loss: 0.0251, val_loss: 5.6851, val_acc: 0.4324\n",
      "Epoch [74], train_loss: 0.1233, val_loss: 2.9786, val_acc: 0.5270\n",
      "Epoch [75], train_loss: 0.1026, val_loss: 2.5206, val_acc: 0.5946\n",
      "Epoch [76], train_loss: 0.1062, val_loss: 2.6690, val_acc: 0.5676\n",
      "Epoch [77], train_loss: 0.0330, val_loss: 2.7217, val_acc: 0.5676\n",
      "Epoch [78], train_loss: 0.0327, val_loss: 3.7601, val_acc: 0.5811\n",
      "Epoch [79], train_loss: 0.0281, val_loss: 3.7557, val_acc: 0.5811\n",
      "Epoch [80], train_loss: 0.0349, val_loss: 3.4012, val_acc: 0.5676\n",
      "Epoch [81], train_loss: 0.0149, val_loss: 3.3173, val_acc: 0.6081\n",
      "Epoch [82], train_loss: 0.0094, val_loss: 3.6280, val_acc: 0.6081\n",
      "Epoch [83], train_loss: 0.0127, val_loss: 4.2088, val_acc: 0.5676\n",
      "Epoch [84], train_loss: 0.0059, val_loss: 3.9357, val_acc: 0.6216\n",
      "Epoch [85], train_loss: 0.0018, val_loss: 4.2606, val_acc: 0.6081\n",
      "Epoch [86], train_loss: 0.0011, val_loss: 4.3328, val_acc: 0.5946\n",
      "Epoch [87], train_loss: 0.0006, val_loss: 4.4255, val_acc: 0.5811\n",
      "Epoch [88], train_loss: 0.0005, val_loss: 4.5007, val_acc: 0.5811\n",
      "Epoch [89], train_loss: 0.0005, val_loss: 4.4960, val_acc: 0.5811\n",
      "Epoch [90], train_loss: 0.0006, val_loss: 4.5418, val_acc: 0.5811\n",
      "Epoch [91], train_loss: 0.0005, val_loss: 4.5840, val_acc: 0.5946\n",
      "Epoch [92], train_loss: 0.0005, val_loss: 4.6456, val_acc: 0.5946\n",
      "Epoch [93], train_loss: 0.0003, val_loss: 4.6416, val_acc: 0.5811\n",
      "Epoch [94], train_loss: 0.0003, val_loss: 4.6510, val_acc: 0.5811\n",
      "Epoch [95], train_loss: 0.0003, val_loss: 4.7066, val_acc: 0.5676\n",
      "Epoch [96], train_loss: 0.0002, val_loss: 4.7305, val_acc: 0.5676\n",
      "Epoch [97], train_loss: 0.0003, val_loss: 4.7435, val_acc: 0.5676\n",
      "Epoch [98], train_loss: 0.0003, val_loss: 4.7751, val_acc: 0.5676\n",
      "Epoch [99], train_loss: 0.0002, val_loss: 4.8032, val_acc: 0.5676\n"
     ]
    }
   ],
   "source": [
    "# CTX = torch.device('cuda')\n",
    "# train_dl.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # train_dl.train_labels.to(CTX)\n",
    "# # val_dl.train_data.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # val_dl.train_labels.to(CTX)\n",
    "num_epochs = 100\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26874318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "\n",
    "plot_accuracies(history)\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60afc6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7162162065505981"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x['val_acc'] for x in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3164b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
