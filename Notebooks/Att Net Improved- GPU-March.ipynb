{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33392872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import pickle\n",
    "def load_data(in_dir):\n",
    "    f = open(in_dir,'rb')\n",
    "    train_data,train_label,valid_data,valid_label = pickle.load(f)\n",
    "    return train_data,train_label,valid_data,valid_label\n",
    "\n",
    "# data_path = 'adress_512.pkl'\n",
    "data_path = 'adress_Att_Net.pkl'\n",
    "checkpoint = 'checkpoint/'\n",
    "\n",
    "train_data,train_label,valid_data,valid_label = load_data(data_path)\n",
    "\n",
    "# converting training images into torch format\n",
    "train_x = train_data\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_label\n",
    "train_y = train_y.reshape(1392).astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "# train_x.shape, train_y.shape\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "# my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "# tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "# tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "CTX = torch.device('cuda')\n",
    "\n",
    "train_dataset = TensorDataset(train_x.to(CTX),train_y.to(CTX)) # create your datset\n",
    "\n",
    " # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09537d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "val_x = valid_data\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = valid_label\n",
    "val_y = val_y.reshape(74).astype(float);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "# shape of training data\n",
    "\n",
    "val_dataset = TensorDataset(val_x,val_y) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4701d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 64\n",
    "val_size = 297\n",
    "# train_size = train_x.size(0) - val_size \n",
    "\n",
    "# train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "# print(f\"Length of Train Data : {len(train_data)}\")\n",
    "# print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 2379\n",
    "#Length of Validation Data : 297\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_dataset,batch_size, shuffle = True, num_workers = 0)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d492176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda())   # Calculate loss\n",
    "        acc = accuracy(out, labels.to(torch.int64).cuda())           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "#         print(x.shape())\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n",
    "    \n",
    "    \n",
    "class Att_Net(ImageClassificationBase):   \n",
    "    def __init__(self):\n",
    "        super(Att_Net, self).__init__()\n",
    "        #The LW_CNN module utilizes three convolutions (C), two max-pooling\n",
    "        # (MP), one average-pooling (AP), and one batch normalization\n",
    "        # (BN) layer.\n",
    "        self.LW_CNN = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "#             Conv2d(300, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(256),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Defining another 2D convolution layer\n",
    "#             Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(128),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=1, stride=1),\n",
    "            \n",
    "              #C1, we used 120 number of kernels with size (11\n",
    "              # × 11) using (4 × 4) stride setting without padding to extract\n",
    "              # initially hidden patterns from input data. \n",
    "              Conv2d(3, 120, kernel_size=(11,11), stride=(4,4), padding=0),\n",
    "              MaxPool2d(kernel_size=(3,3), stride=None),\n",
    "              Conv2d(120, 256, kernel_size=(5,5), stride=(1,1), padding='same'),\n",
    "              MaxPool2d(kernel_size=(3,3)),\n",
    "              Conv2d(256, 384, kernel_size=(3,3), padding='same'),\n",
    "#               MaxPool2d(kernel_size=1, stride=0),\n",
    "#               Conv2d(128, 1, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "              torch.nn.AvgPool2d(kernel_size=(3,3), stride=1),\n",
    "              BatchNorm2d(384),\n",
    "              ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(384 * 12 * 1, 256),\n",
    "            Linear(256, 64),\n",
    "            Linear(64, 2),\n",
    "        )\n",
    "\n",
    "        self.attention = CBAM(gate_channels=384)\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "#         x = x.view(-1, x.size(3),x.size(2),x.size(1))\n",
    "#         print(x.size)\n",
    "        x = self.LW_CNN(x)\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f81fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Att_Net(\n",
      "  (LW_CNN): Sequential(\n",
      "    (0): Conv2d(3, 120, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(120, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (3): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): AvgPool2d(kernel_size=(3, 3), stride=1, padding=0)\n",
      "    (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=4608, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (attention): CBAM(\n",
      "    (ChannelGate): ChannelGate(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten()\n",
      "        (1): Linear(in_features=384, out_features=24, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=24, out_features=384, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (SpatialGate): SpatialGate(\n",
      "      (compress): ChannelPool()\n",
      "      (spatial): BasicConv(\n",
      "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Att_Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477fd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 120, 126, 30]          43,680\n",
      "         MaxPool2d-2          [-1, 120, 42, 10]               0\n",
      "            Conv2d-3          [-1, 256, 42, 10]         768,256\n",
      "         MaxPool2d-4           [-1, 256, 14, 3]               0\n",
      "            Conv2d-5           [-1, 384, 14, 3]         885,120\n",
      "         AvgPool2d-6           [-1, 384, 12, 1]               0\n",
      "       BatchNorm2d-7           [-1, 384, 12, 1]             768\n",
      "              ReLU-8           [-1, 384, 12, 1]               0\n",
      "           Flatten-9                  [-1, 384]               0\n",
      "           Linear-10                   [-1, 24]           9,240\n",
      "             ReLU-11                   [-1, 24]               0\n",
      "           Linear-12                  [-1, 384]           9,600\n",
      "          Flatten-13                  [-1, 384]               0\n",
      "           Linear-14                   [-1, 24]           9,240\n",
      "             ReLU-15                   [-1, 24]               0\n",
      "           Linear-16                  [-1, 384]           9,600\n",
      "      ChannelGate-17           [-1, 384, 12, 1]               0\n",
      "      ChannelPool-18             [-1, 2, 12, 1]               0\n",
      "           Conv2d-19             [-1, 1, 12, 1]              98\n",
      "      BatchNorm2d-20             [-1, 1, 12, 1]               2\n",
      "        BasicConv-21             [-1, 1, 12, 1]               0\n",
      "      SpatialGate-22           [-1, 384, 12, 1]               0\n",
      "             CBAM-23           [-1, 384, 12, 1]               0\n",
      "           Linear-24                  [-1, 256]       1,179,904\n",
      "           Linear-25                   [-1, 64]          16,448\n",
      "           Linear-26                    [-1, 2]             130\n",
      "================================================================\n",
      "Total params: 2,932,086\n",
      "Trainable params: 2,932,086\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 5.10\n",
      "Params size (MB): 11.19\n",
      "Estimated Total Size (MB): 17.03\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 512, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a72cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.0016, val_loss: 5.9002, val_acc: 0.7027\n",
      "Epoch [1], train_loss: 0.0166, val_loss: 103.5496, val_acc: 0.3649\n",
      "Epoch [2], train_loss: 0.0063, val_loss: 46.2691, val_acc: 0.3649\n",
      "Epoch [3], train_loss: 0.0011, val_loss: 5.2873, val_acc: 0.7162\n",
      "Epoch [4], train_loss: 0.0002, val_loss: 3.9925, val_acc: 0.7027\n",
      "Epoch [5], train_loss: 0.0002, val_loss: 3.9091, val_acc: 0.6892\n",
      "Epoch [6], train_loss: 0.0001, val_loss: 3.5737, val_acc: 0.7027\n",
      "Epoch [7], train_loss: 0.0000, val_loss: 3.5762, val_acc: 0.7027\n",
      "Epoch [8], train_loss: 0.0000, val_loss: 3.5407, val_acc: 0.7027\n",
      "Epoch [9], train_loss: 0.0001, val_loss: 3.6545, val_acc: 0.7027\n",
      "Epoch [10], train_loss: 0.0000, val_loss: 3.8006, val_acc: 0.6892\n",
      "Epoch [11], train_loss: 0.0000, val_loss: 3.8855, val_acc: 0.6892\n",
      "Epoch [12], train_loss: 0.0000, val_loss: 3.8509, val_acc: 0.6892\n",
      "Epoch [13], train_loss: 0.0000, val_loss: 3.8161, val_acc: 0.7027\n",
      "Epoch [14], train_loss: 0.0000, val_loss: 3.7101, val_acc: 0.7027\n",
      "Epoch [15], train_loss: 0.0000, val_loss: 3.6805, val_acc: 0.6892\n",
      "Epoch [16], train_loss: 0.0000, val_loss: 3.8962, val_acc: 0.7432\n",
      "Epoch [17], train_loss: 0.0000, val_loss: 3.8095, val_acc: 0.6892\n",
      "Epoch [18], train_loss: 0.0000, val_loss: 3.7130, val_acc: 0.7162\n",
      "Epoch [19], train_loss: 0.0000, val_loss: 3.7060, val_acc: 0.6892\n",
      "Epoch [20], train_loss: 0.0000, val_loss: 4.0102, val_acc: 0.6892\n",
      "Epoch [21], train_loss: 0.0000, val_loss: 4.0584, val_acc: 0.6892\n",
      "Epoch [22], train_loss: 0.0000, val_loss: 4.1194, val_acc: 0.7027\n",
      "Epoch [23], train_loss: 0.0000, val_loss: 4.0812, val_acc: 0.6892\n",
      "Epoch [24], train_loss: 0.0000, val_loss: 3.9840, val_acc: 0.7027\n",
      "Epoch [25], train_loss: 0.0009, val_loss: 10.1666, val_acc: 0.5000\n",
      "Epoch [26], train_loss: 0.0054, val_loss: 7.7928, val_acc: 0.7297\n",
      "Epoch [27], train_loss: 0.0010, val_loss: 4.9815, val_acc: 0.6892\n",
      "Epoch [28], train_loss: 0.0004, val_loss: 4.1187, val_acc: 0.6757\n",
      "Epoch [29], train_loss: 0.0000, val_loss: 4.1366, val_acc: 0.7027\n",
      "Epoch [30], train_loss: 0.0004, val_loss: 4.7534, val_acc: 0.7162\n",
      "Epoch [31], train_loss: 0.0014, val_loss: 73.9349, val_acc: 0.3649\n",
      "Epoch [32], train_loss: 0.0028, val_loss: 149.7203, val_acc: 0.6351\n",
      "Epoch [33], train_loss: 0.0137, val_loss: 47.7006, val_acc: 0.6351\n",
      "Epoch [34], train_loss: 0.0097, val_loss: 44.9183, val_acc: 0.6351\n",
      "Epoch [35], train_loss: 0.0092, val_loss: 23.4118, val_acc: 0.3784\n",
      "Epoch [36], train_loss: 0.0336, val_loss: 68.0702, val_acc: 0.3649\n",
      "Epoch [37], train_loss: 0.0106, val_loss: 2.6043, val_acc: 0.6351\n",
      "Epoch [38], train_loss: 0.0003, val_loss: 3.2833, val_acc: 0.6486\n",
      "Epoch [39], train_loss: 0.0005, val_loss: 2.8173, val_acc: 0.6757\n",
      "Epoch [40], train_loss: 0.0001, val_loss: 2.8384, val_acc: 0.6757\n",
      "Epoch [41], train_loss: 0.0001, val_loss: 3.0729, val_acc: 0.6892\n",
      "Epoch [42], train_loss: 0.0001, val_loss: 3.3372, val_acc: 0.6757\n",
      "Epoch [43], train_loss: 0.0001, val_loss: 3.7392, val_acc: 0.6757\n",
      "Epoch [44], train_loss: 0.0011, val_loss: 4.7882, val_acc: 0.7027\n",
      "Epoch [45], train_loss: 0.0147, val_loss: 7.8055, val_acc: 0.7162\n",
      "Epoch [46], train_loss: 0.0035, val_loss: 1.7735, val_acc: 0.7297\n",
      "Epoch [47], train_loss: 0.0006, val_loss: 10.8775, val_acc: 0.4459\n",
      "Epoch [48], train_loss: 0.0044, val_loss: 6.7650, val_acc: 0.6081\n",
      "Epoch [49], train_loss: 0.0005, val_loss: 8.2742, val_acc: 0.7432\n",
      "Epoch [50], train_loss: 0.0007, val_loss: 5.8661, val_acc: 0.6081\n",
      "Epoch [51], train_loss: 0.0000, val_loss: 4.1165, val_acc: 0.6622\n",
      "Epoch [52], train_loss: 0.0001, val_loss: 3.8787, val_acc: 0.6892\n",
      "Epoch [53], train_loss: 0.0000, val_loss: 3.8540, val_acc: 0.6892\n",
      "Epoch [54], train_loss: 0.0000, val_loss: 3.9167, val_acc: 0.7027\n",
      "Epoch [55], train_loss: 0.0000, val_loss: 4.0387, val_acc: 0.6892\n",
      "Epoch [56], train_loss: 0.0000, val_loss: 4.0132, val_acc: 0.6892\n",
      "Epoch [57], train_loss: 0.0000, val_loss: 4.0678, val_acc: 0.6892\n",
      "Epoch [58], train_loss: 0.0000, val_loss: 4.1306, val_acc: 0.7027\n",
      "Epoch [59], train_loss: 0.0000, val_loss: 4.2279, val_acc: 0.7027\n",
      "Epoch [60], train_loss: 0.0000, val_loss: 4.1619, val_acc: 0.6892\n",
      "Epoch [61], train_loss: 0.0000, val_loss: 4.1994, val_acc: 0.6892\n",
      "Epoch [62], train_loss: 0.0000, val_loss: 4.2887, val_acc: 0.6892\n",
      "Epoch [63], train_loss: 0.0000, val_loss: 4.2543, val_acc: 0.7027\n",
      "Epoch [64], train_loss: 0.0000, val_loss: 4.0840, val_acc: 0.7027\n",
      "Epoch [65], train_loss: 0.0000, val_loss: 4.1598, val_acc: 0.6892\n",
      "Epoch [66], train_loss: 0.0000, val_loss: 4.1959, val_acc: 0.6622\n",
      "Epoch [67], train_loss: 0.0000, val_loss: 4.2032, val_acc: 0.7027\n",
      "Epoch [68], train_loss: 0.0000, val_loss: 4.2344, val_acc: 0.7027\n",
      "Epoch [69], train_loss: 0.0000, val_loss: 4.1105, val_acc: 0.6892\n",
      "Epoch [70], train_loss: 0.0000, val_loss: 4.0946, val_acc: 0.7162\n",
      "Epoch [71], train_loss: 0.0000, val_loss: 4.2312, val_acc: 0.6892\n",
      "Epoch [72], train_loss: 0.0000, val_loss: 4.2269, val_acc: 0.6892\n",
      "Epoch [73], train_loss: 0.0000, val_loss: 4.1840, val_acc: 0.6892\n",
      "Epoch [74], train_loss: 0.0000, val_loss: 4.1762, val_acc: 0.6892\n",
      "Epoch [75], train_loss: 0.0000, val_loss: 4.2104, val_acc: 0.6892\n",
      "Epoch [76], train_loss: 0.0000, val_loss: 4.0815, val_acc: 0.7027\n",
      "Epoch [77], train_loss: 0.0000, val_loss: 4.2472, val_acc: 0.6892\n",
      "Epoch [78], train_loss: 0.0000, val_loss: 4.3476, val_acc: 0.6757\n",
      "Epoch [79], train_loss: 0.0000, val_loss: 4.3043, val_acc: 0.6622\n",
      "Epoch [80], train_loss: 0.0000, val_loss: 4.2214, val_acc: 0.6892\n",
      "Epoch [81], train_loss: 0.0000, val_loss: 4.2746, val_acc: 0.6892\n",
      "Epoch [82], train_loss: 0.0000, val_loss: 4.3271, val_acc: 0.6892\n",
      "Epoch [83], train_loss: 0.0000, val_loss: 4.3006, val_acc: 0.6892\n",
      "Epoch [84], train_loss: 0.0000, val_loss: 4.2779, val_acc: 0.6892\n",
      "Epoch [85], train_loss: 0.0000, val_loss: 4.3197, val_acc: 0.6757\n",
      "Epoch [86], train_loss: 0.0000, val_loss: 4.3212, val_acc: 0.6757\n",
      "Epoch [87], train_loss: 0.0000, val_loss: 4.3176, val_acc: 0.6892\n",
      "Epoch [88], train_loss: 0.0000, val_loss: 4.3800, val_acc: 0.6892\n",
      "Epoch [89], train_loss: 0.0000, val_loss: 4.3805, val_acc: 0.6892\n",
      "Epoch [90], train_loss: 0.0000, val_loss: 4.4216, val_acc: 0.6892\n",
      "Epoch [91], train_loss: 0.0000, val_loss: 4.4444, val_acc: 0.6757\n",
      "Epoch [92], train_loss: 0.0000, val_loss: 4.4444, val_acc: 0.6892\n",
      "Epoch [93], train_loss: 0.0000, val_loss: 4.3894, val_acc: 0.6892\n",
      "Epoch [94], train_loss: 0.0000, val_loss: 4.4323, val_acc: 0.6892\n",
      "Epoch [95], train_loss: 0.0000, val_loss: 4.4572, val_acc: 0.6757\n",
      "Epoch [96], train_loss: 0.0000, val_loss: 4.4656, val_acc: 0.6892\n",
      "Epoch [97], train_loss: 0.0000, val_loss: 4.4192, val_acc: 0.6892\n",
      "Epoch [98], train_loss: 0.0000, val_loss: 4.5100, val_acc: 0.6622\n",
      "Epoch [99], train_loss: 0.0000, val_loss: 4.4923, val_acc: 0.6757\n"
     ]
    }
   ],
   "source": [
    "# CTX = torch.device('cuda')\n",
    "# train_dl.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # train_dl.train_labels.to(CTX)\n",
    "# # val_dl.train_data.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # val_dl.train_labels.to(CTX)\n",
    "num_epochs = 100\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26874318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "\n",
    "plot_accuracies(history)\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60afc6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432432174682617"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x['val_acc'] for x in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3164b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
