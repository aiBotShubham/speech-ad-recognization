{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00182459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_data(in_dir):\n",
    "    f = open(in_dir,'rb')\n",
    "    train_data,train_label,test_data,test_label,valid_data,valid_label,pernums_valid = pickle.load(f)\n",
    "    return train_data,train_label,test_data,test_label,valid_data,valid_label,pernums_valid\n",
    "\n",
    "data_path = 'adress.pkl'\n",
    "checkpoint = 'checkpoint/'\n",
    "\n",
    "train_data,train_label,test_data,test_label,valid_data,valid_label,pernums_valid = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdba731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2379, 300, 40, 3]), torch.Size([2379]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "\n",
    "\n",
    "# converting training images into torch format\n",
    "train_x = train_data\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_label\n",
    "train_y = train_y.reshape(2379).astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31305c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, mode='NORM', k=1, dilation=1):\n",
    "        \"\"\"\n",
    "        Pre-act residual block, the middle transformations are bottle-necked\n",
    "        :param inplanes:\n",
    "        :param planes:\n",
    "        :param stride:\n",
    "        :param downsample:\n",
    "        :param mode: NORM | UP\n",
    "        :param k: times of additive\n",
    "        \"\"\"\n",
    "\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.k = k\n",
    "\n",
    "        btnk_ch = planes // 4\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, btnk_ch, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(btnk_ch)\n",
    "        self.conv2 = nn.Conv2d(btnk_ch, btnk_ch, kernel_size=3, stride=stride, padding=dilation,\n",
    "                               dilation=dilation, bias=False)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(btnk_ch)\n",
    "        self.conv3 = nn.Conv2d(btnk_ch, planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if mode == 'UP':\n",
    "            self.shortcut = None\n",
    "        elif inplanes != planes or stride > 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.BatchNorm2d(inplanes),\n",
    "                self.relu,\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = None\n",
    "\n",
    "    def _pre_act_forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.mode == 'UP':\n",
    "            residual = self.squeeze_idt(x)\n",
    "        elif self.shortcut is not None:\n",
    "            residual = self.shortcut(residual)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        return out\n",
    "\n",
    "    def squeeze_idt(self, idt):\n",
    "        n, c, h, w = idt.size()\n",
    "        return idt.view(n, c // self.k, self.k, h, w).sum(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self._pre_act_forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fedf829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "__all__ = ['fish']\n",
    "\n",
    "\n",
    "class Fish(nn.Module):\n",
    "    def __init__(self, block, num_cls=1000, num_down_sample=5, num_up_sample=3, trans_map=(2, 1, 0, 6, 5, 4),\n",
    "                 network_planes=None, num_res_blks=None, num_trans_blks=None):\n",
    "        super(Fish, self).__init__()\n",
    "        self.block = block\n",
    "        self.trans_map = trans_map\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.down_sample = nn.MaxPool2d(2, stride=2)\n",
    "        self.num_cls = num_cls\n",
    "        self.num_down = num_down_sample\n",
    "        self.num_up = num_up_sample\n",
    "        self.network_planes = network_planes[1:]\n",
    "        self.depth = len(self.network_planes)\n",
    "        self.num_trans_blks = num_trans_blks\n",
    "        self.num_res_blks = num_res_blks\n",
    "        self.fish = self._make_fish(network_planes[0])\n",
    "\n",
    "    def _make_score(self, in_ch, out_ch=1000, has_pool=False):\n",
    "        bn = nn.BatchNorm2d(in_ch)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        conv_trans = nn.Conv2d(in_ch, in_ch // 2, kernel_size=1, bias=False)\n",
    "        bn_out = nn.BatchNorm2d(in_ch // 2)\n",
    "        conv = nn.Sequential(bn, relu, conv_trans, bn_out, relu)\n",
    "        if has_pool:\n",
    "            fc = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(in_ch // 2, out_ch, kernel_size=1, bias=True))\n",
    "        else:\n",
    "            fc = nn.Conv2d(in_ch // 2, out_ch, kernel_size=1, bias=True)\n",
    "        return [conv, fc]\n",
    "\n",
    "    def _make_se_block(self, in_ch, out_ch):\n",
    "        bn = nn.BatchNorm2d(in_ch)\n",
    "        sq_conv = nn.Conv2d(in_ch, out_ch // 16, kernel_size=1)\n",
    "        ex_conv = nn.Conv2d(out_ch // 16, out_ch, kernel_size=1)\n",
    "        return nn.Sequential(bn,\n",
    "                             nn.ReLU(inplace=True),\n",
    "                             nn.AdaptiveAvgPool2d(1),\n",
    "                             sq_conv,\n",
    "                             nn.ReLU(inplace=True),\n",
    "                             ex_conv,\n",
    "                             nn.Sigmoid())\n",
    "\n",
    "    def _make_residual_block(self, inplanes, outplanes, nstage, is_up=False, k=1, dilation=1):\n",
    "        layers = []\n",
    "\n",
    "        if is_up:\n",
    "            layers.append(self.block(inplanes, outplanes, mode='UP', dilation=dilation, k=k))\n",
    "        else:\n",
    "            layers.append(self.block(inplanes, outplanes, stride=1))\n",
    "        for i in range(1, nstage):\n",
    "            layers.append(self.block(outplanes, outplanes, stride=1, dilation=dilation))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, is_down_sample, inplanes, outplanes, n_blk, has_trans=True,\n",
    "                    has_score=False, trans_planes=0, no_sampling=False, num_trans=2, **kwargs):\n",
    "        sample_block = []\n",
    "        if has_score:\n",
    "            sample_block.extend(self._make_score(outplanes, outplanes * 2, has_pool=False))\n",
    "\n",
    "        if no_sampling or is_down_sample:\n",
    "            res_block = self._make_residual_block(inplanes, outplanes, n_blk, **kwargs)\n",
    "        else:\n",
    "            res_block = self._make_residual_block(inplanes, outplanes, n_blk, is_up=True, **kwargs)\n",
    "\n",
    "        sample_block.append(res_block)\n",
    "\n",
    "        if has_trans:\n",
    "            trans_in_planes = self.in_planes if trans_planes == 0 else trans_planes\n",
    "            sample_block.append(self._make_residual_block(trans_in_planes, trans_in_planes, num_trans))\n",
    "\n",
    "        if not no_sampling and is_down_sample:\n",
    "            sample_block.append(self.down_sample)\n",
    "        elif not no_sampling:  # Up-Sample\n",
    "            sample_block.append(self.upsample)\n",
    "\n",
    "        return nn.ModuleList(sample_block)\n",
    "\n",
    "    def _make_fish(self, in_planes):\n",
    "        def get_trans_planes(index):\n",
    "            map_id = self.trans_map[index-self.num_down-1] - 1\n",
    "            p = in_planes if map_id == -1 else cated_planes[map_id]\n",
    "            return p\n",
    "\n",
    "        def get_trans_blk(index):\n",
    "            return self.num_trans_blks[index-self.num_down-1]\n",
    "\n",
    "        def get_cur_planes(index):\n",
    "            return self.network_planes[index]\n",
    "\n",
    "        def get_blk_num(index):\n",
    "            return self.num_res_blks[index]\n",
    "\n",
    "        cated_planes, fish = [in_planes] * self.depth, []\n",
    "        for i in range(self.depth):\n",
    "            # even num for down-sample, odd for up-sample\n",
    "            is_down, has_trans, no_sampling = i not in range(self.num_down, self.num_down+self.num_up+1),\\\n",
    "                                              i > self.num_down, i == self.num_down\n",
    "            cur_planes, trans_planes, cur_blocks, num_trans =\\\n",
    "                get_cur_planes(i), get_trans_planes(i), get_blk_num(i), get_trans_blk(i)\n",
    "\n",
    "            stg_args = [is_down, cated_planes[i - 1], cur_planes, cur_blocks]\n",
    "\n",
    "            if is_down or no_sampling:\n",
    "                k, dilation = 1, 1\n",
    "            else:\n",
    "                k, dilation = cated_planes[i - 1] // cur_planes, 2 ** (i-self.num_down-1)\n",
    "\n",
    "            sample_block = self._make_stage(*stg_args, has_trans=has_trans, trans_planes=trans_planes,\n",
    "                                            has_score=(i==self.num_down), num_trans=num_trans, k=k, dilation=dilation,\n",
    "                                            no_sampling=no_sampling)\n",
    "            if i == self.depth - 1:\n",
    "                sample_block.extend(self._make_score(cur_planes + trans_planes, out_ch=self.num_cls, has_pool=True))\n",
    "            elif i == self.num_down:\n",
    "                sample_block.append(nn.Sequential(self._make_se_block(cur_planes*2, cur_planes)))\n",
    "\n",
    "            if i == self.num_down-1:\n",
    "                cated_planes[i] = cur_planes * 2\n",
    "            elif has_trans:\n",
    "                cated_planes[i] = cur_planes + trans_planes\n",
    "            else:\n",
    "                cated_planes[i] = cur_planes\n",
    "            fish.append(sample_block)\n",
    "        return nn.ModuleList(fish)\n",
    "\n",
    "    def _fish_forward(self, all_feat):\n",
    "        def _concat(a, b):\n",
    "            return torch.cat([a, b], dim=1)\n",
    "\n",
    "        def stage_factory(*blks):\n",
    "            def stage_forward(*inputs):\n",
    "                if stg_id < self.num_down:  # tail\n",
    "                    tail_blk = nn.Sequential(*blks[:2])\n",
    "                    return tail_blk(*inputs)\n",
    "                elif stg_id == self.num_down:\n",
    "                    score_blks = nn.Sequential(*blks[:2])\n",
    "                    score_feat = score_blks(inputs[0])\n",
    "                    att_feat = blks[3](score_feat)\n",
    "                    return blks[2](score_feat) * att_feat + att_feat\n",
    "                else:  # refine\n",
    "                    feat_trunk = blks[2](blks[0](inputs[0]))\n",
    "                    feat_branch = blks[1](inputs[1])\n",
    "                return _concat(feat_trunk, feat_branch)\n",
    "            return stage_forward\n",
    "\n",
    "        stg_id = 0\n",
    "        # tail:\n",
    "        while stg_id < self.depth:\n",
    "            stg_blk = stage_factory(*self.fish[stg_id])\n",
    "            if stg_id <= self.num_down:\n",
    "                in_feat = [all_feat[stg_id]]\n",
    "            else:\n",
    "                trans_id = self.trans_map[stg_id-self.num_down-1]\n",
    "                in_feat = [all_feat[stg_id], all_feat[trans_id]]\n",
    "\n",
    "            all_feat[stg_id + 1] = stg_blk(*in_feat)\n",
    "            stg_id += 1\n",
    "            # loop exit\n",
    "            if stg_id == self.depth:\n",
    "                score_feat = self.fish[self.depth-1][-2](all_feat[-1])\n",
    "                score = self.fish[self.depth-1][-1](score_feat)\n",
    "                return score\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_feat = [None] * (self.depth + 1)\n",
    "        all_feat[0] = x\n",
    "        return self._fish_forward(all_feat)\n",
    "\n",
    "\n",
    "class FishNet(nn.Module):\n",
    "    def __init__(self, block, **kwargs):\n",
    "        super(FishNet, self).__init__()\n",
    "\n",
    "        inplanes = kwargs['network_planes'][0]\n",
    "        # resolution: 224x224\n",
    "        self.conv1 = self._conv_bn_relu(3, inplanes // 2, stride=2)\n",
    "        self.conv2 = self._conv_bn_relu(inplanes // 2, inplanes // 2)\n",
    "        self.conv3 = self._conv_bn_relu(inplanes // 2, inplanes)\n",
    "        self.pool1 = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "        # construct fish, resolution 56x56\n",
    "        self.fish = Fish(block, **kwargs)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _conv_bn_relu(self, in_ch, out_ch, stride=1):\n",
    "        return nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "                             nn.BatchNorm2d(out_ch),\n",
    "                             nn.ReLU(inplace=True))\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool1(x)\n",
    "        score = self.fish(x)\n",
    "        # 1*1 output\n",
    "        out = score.view(x.size(0), -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def fish(**kwargs):\n",
    "    return FishNet(Bottleneck, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c67bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fishnet99(**kwargs):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_cfg = {\n",
    "        #  input size:   [224, 56, 28,  14  |  7,   7,  14,  28 | 56,   28,  14]\n",
    "        # output size:   [56,  28, 14,   7  |  7,  14,  28,  56 | 28,   14,   7]\n",
    "        #                  |    |    |   |     |    |    |    |    |     |    |\n",
    "        'network_planes': [64, 128, 256, 512, 512, 512, 384, 256, 320, 832, 1600],\n",
    "        'num_res_blks': [2, 2, 6, 2, 1, 1, 1, 1, 2, 2],\n",
    "        'num_trans_blks': [1, 1, 1, 1, 1, 4],\n",
    "        'num_cls': 1000,\n",
    "        'num_down_sample': 3,\n",
    "        'num_up_sample': 3,\n",
    "    }\n",
    "    cfg = {**net_cfg, **kwargs}\n",
    "    return fish(**cfg)\n",
    "\n",
    "\n",
    "def fishnet150(**kwargs):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_cfg = {\n",
    "        #  input size:   [224, 56, 28,  14  |  7,   7,  14,  28 | 56,   28,  14]\n",
    "        # output size:   [56,  28, 14,   7  |  7,  14,  28,  56 | 28,   14,   7]\n",
    "        #                  |    |    |   |     |    |    |    |    |     |    |\n",
    "        'network_planes': [64, 128, 256, 512, 512, 512, 384, 256, 320, 832, 1600],\n",
    "        'num_res_blks': [2, 4, 8, 4, 2, 2, 2, 2, 2, 4],\n",
    "        'num_trans_blks': [2, 2, 2, 2, 2, 4],\n",
    "        'num_cls': 1000,\n",
    "        'num_down_sample': 3,\n",
    "        'num_up_sample': 3,\n",
    "    }\n",
    "    cfg = {**net_cfg, **kwargs}\n",
    "    return fish(**cfg)\n",
    "\n",
    "\n",
    "def fishnet201(**kwargs):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net_cfg = {\n",
    "        #  input size:   [224, 56, 28,  14  |  7,   7,  14,  28 | 56,   28,  14]\n",
    "        # output size:   [56,  28, 14,   7  |  7,  14,  28,  56 | 28,   14,   7]\n",
    "        #                  |    |    |   |     |    |    |    |    |     |    |\n",
    "        'network_planes': [64, 128, 256, 512, 512, 512, 384, 256, 320, 832, 1600],\n",
    "        'num_res_blks': [3, 4, 12, 4, 2, 2, 2, 2, 3, 10],\n",
    "        'num_trans_blks': [2, 2, 2, 2, 2, 9],\n",
    "        'num_cls': 1000,\n",
    "        'num_down_sample': 3,\n",
    "        'num_up_sample': 3,\n",
    "    }\n",
    "    cfg = {**net_cfg, **kwargs}\n",
    "    return fish(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8eff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from utils.profile import count_params\n",
    "from utils.data_aug import ColorAugmentation\n",
    "import os\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85711361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
