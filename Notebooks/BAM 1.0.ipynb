{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33392872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import pickle\n",
    "def load_data(in_dir):\n",
    "    f = open(in_dir,'rb')\n",
    "    train_data,train_label,valid_data,valid_label = pickle.load(f)\n",
    "    return train_data,train_label,valid_data,valid_label\n",
    "\n",
    "# data_path = 'adress_512.pkl'\n",
    "data_path = 'adress_Att_Net.pkl'\n",
    "checkpoint = 'checkpoint/'\n",
    "\n",
    "train_data,train_label,valid_data,valid_label = load_data(data_path)\n",
    "\n",
    "# converting training images into torch format\n",
    "train_x = train_data\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_label\n",
    "train_y = train_y.reshape(1392).astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "# train_x.shape, train_y.shape\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "# my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "# tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "# tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "CTX = torch.device('cuda')\n",
    "\n",
    "train_dataset = TensorDataset(train_x.to(CTX),train_y.to(CTX)) # create your datset\n",
    "\n",
    " # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09537d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "val_x = valid_data\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = valid_label\n",
    "val_y = val_y.reshape(74).astype(float);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "# shape of training data\n",
    "\n",
    "val_dataset = TensorDataset(val_x,val_y) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4701d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 64\n",
    "val_size = 297\n",
    "# train_size = train_x.size(0) - val_size \n",
    "\n",
    "# train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "# print(f\"Length of Train Data : {len(train_data)}\")\n",
    "# print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 2379\n",
    "#Length of Validation Data : 297\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_dataset,batch_size, shuffle = True, num_workers = 0)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d492176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda())   # Calculate loss\n",
    "        acc = accuracy(out, labels.to(torch.int64).cuda())           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e9be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0],-1)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self,channel,reduction=16,num_layers=3):\n",
    "        super().__init__()\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(1)\n",
    "        gate_channels=[channel]\n",
    "        gate_channels+=[channel//reduction]*num_layers\n",
    "        gate_channels+=[channel]\n",
    "\n",
    "\n",
    "        self.ca=nn.Sequential()\n",
    "        self.ca.add_module('flatten',Flatten())\n",
    "        for i in range(len(gate_channels)-2):\n",
    "            self.ca.add_module('fc%d'%i,nn.Linear(gate_channels[i],gate_channels[i+1]))\n",
    "            self.ca.add_module('bn%d'%i,nn.BatchNorm1d(gate_channels[i+1]))\n",
    "            self.ca.add_module('relu%d'%i,nn.ReLU())\n",
    "        self.ca.add_module('last_fc',nn.Linear(gate_channels[-2],gate_channels[-1]))\n",
    "        \n",
    "\n",
    "    def forward(self, x) :\n",
    "        res=self.avgpool(x)\n",
    "        res=self.ca(res)\n",
    "        res=res.unsqueeze(-1).unsqueeze(-1).expand_as(x)\n",
    "        return res\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self,channel,reduction=16,num_layers=3,dia_val=2):\n",
    "        super().__init__()\n",
    "        self.sa=nn.Sequential()\n",
    "        self.sa.add_module('conv_reduce1',nn.Conv2d(kernel_size=1,in_channels=channel,out_channels=channel//reduction))\n",
    "        self.sa.add_module('bn_reduce1',nn.BatchNorm2d(channel//reduction))\n",
    "        self.sa.add_module('relu_reduce1',nn.ReLU())\n",
    "        for i in range(num_layers):\n",
    "            self.sa.add_module('conv_%d'%i,nn.Conv2d(kernel_size=3,in_channels=channel//reduction,out_channels=channel//reduction,padding=1,dilation=dia_val))\n",
    "            self.sa.add_module('bn_%d'%i,nn.BatchNorm2d(channel//reduction))\n",
    "            self.sa.add_module('relu_%d'%i,nn.ReLU())\n",
    "        self.sa.add_module('last_conv',nn.Conv2d(channel//reduction,1,kernel_size=1))\n",
    "\n",
    "    def forward(self, x) :\n",
    "        res=self.sa(x)\n",
    "        res=res.expand_as(x)\n",
    "        return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BAMBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, channel=512,reduction=16,dia_val=2):\n",
    "        super().__init__()\n",
    "        self.ca=ChannelAttention(channel=channel,reduction=reduction)\n",
    "        self.sa=SpatialAttention(channel=channel,reduction=reduction,dia_val=dia_val)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        sa_out=self.sa(x)\n",
    "        ca_out=self.ca(x)\n",
    "        weight=self.sigmoid(sa_out+ca_out)\n",
    "        out=(1+weight)*x\n",
    "        return out\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     input=torch.randn(50,512,7,7)\n",
    "#     bam = BAMBlock(channel=512,reduction=16,dia_val=2)\n",
    "#     output=bam(input)\n",
    "#     print(output.shape)\n",
    "    \n",
    "    \n",
    "class Att_Net(ImageClassificationBase):   \n",
    "    def __init__(self):\n",
    "        super(Att_Net, self).__init__()\n",
    "        #The LW_CNN module utilizes three convolutions (C), two max-pooling\n",
    "        # (MP), one average-pooling (AP), and one batch normalization\n",
    "        # (BN) layer.\n",
    "        self.LW_CNN = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "#             Conv2d(300, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(256),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Defining another 2D convolution layer\n",
    "#             Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(128),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=1, stride=1),\n",
    "            \n",
    "              #C1, we used 120 number of kernels with size (11\n",
    "              # × 11) using (4 × 4) stride setting without padding to extract\n",
    "              # initially hidden patterns from input data. \n",
    "              Conv2d(3, 120, kernel_size=(5,5), stride=(3,3), padding=0),\n",
    "              MaxPool2d(kernel_size=(2,2), stride=None),\n",
    "              Conv2d(120, 256, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "#               MaxPool2d(kernel_size=(2,2)),\n",
    "#               Conv2d(256, 384, kernel_size=(2,2), padding='same'),\n",
    "#               MaxPool2d(kernel_size=1, stride=0),\n",
    "#               Conv2d(128, 1, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "              torch.nn.AvgPool2d(kernel_size=(2,2), stride=1),\n",
    "              BatchNorm2d(256),\n",
    "              ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(256 * 84 * 20, 64),\n",
    "#             Linear(256, 64),\n",
    "            Linear(64, 2),\n",
    "        )\n",
    "\n",
    "        self.attention = BAMBlock(channel=256,reduction=4,dia_val=1)\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "#         x = x.view(-1, x.size(3),x.size(2),x.size(1))\n",
    "#         print(x.size)\n",
    "        x = self.LW_CNN(x)\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9f81fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Att_Net(\n",
      "  (LW_CNN): Sequential(\n",
      "    (0): Conv2d(3, 120, kernel_size=(5, 5), stride=(3, 3))\n",
      "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(120, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=430080, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (attention): BAMBlock(\n",
      "    (ca): ChannelAttention(\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (ca): Sequential(\n",
      "        (flatten): Flatten()\n",
      "        (fc0): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (bn0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu0): ReLU()\n",
      "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (last_fc): Linear(in_features=64, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (sa): SpatialAttention(\n",
      "      (sa): Sequential(\n",
      "        (conv_reduce1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn_reduce1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu_reduce1): ReLU()\n",
      "        (conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn_0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu_0): ReLU()\n",
      "        (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu_1): ReLU()\n",
      "        (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu_2): ReLU()\n",
      "        (last_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Att_Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "477fd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 120, 170, 42]           9,120\n",
      "         MaxPool2d-2          [-1, 120, 85, 21]               0\n",
      "            Conv2d-3          [-1, 256, 85, 21]         276,736\n",
      "         AvgPool2d-4          [-1, 256, 84, 20]               0\n",
      "       BatchNorm2d-5          [-1, 256, 84, 20]             512\n",
      "              ReLU-6          [-1, 256, 84, 20]               0\n",
      "            Conv2d-7           [-1, 64, 84, 20]          16,448\n",
      "       BatchNorm2d-8           [-1, 64, 84, 20]             128\n",
      "              ReLU-9           [-1, 64, 84, 20]               0\n",
      "           Conv2d-10           [-1, 64, 84, 20]          36,928\n",
      "      BatchNorm2d-11           [-1, 64, 84, 20]             128\n",
      "             ReLU-12           [-1, 64, 84, 20]               0\n",
      "           Conv2d-13           [-1, 64, 84, 20]          36,928\n",
      "      BatchNorm2d-14           [-1, 64, 84, 20]             128\n",
      "             ReLU-15           [-1, 64, 84, 20]               0\n",
      "           Conv2d-16           [-1, 64, 84, 20]          36,928\n",
      "      BatchNorm2d-17           [-1, 64, 84, 20]             128\n",
      "             ReLU-18           [-1, 64, 84, 20]               0\n",
      "           Conv2d-19            [-1, 1, 84, 20]              65\n",
      " SpatialAttention-20          [-1, 256, 84, 20]               0\n",
      "AdaptiveAvgPool2d-21            [-1, 256, 1, 1]               0\n",
      "          Flatten-22                  [-1, 256]               0\n",
      "           Linear-23                   [-1, 64]          16,448\n",
      "      BatchNorm1d-24                   [-1, 64]             128\n",
      "             ReLU-25                   [-1, 64]               0\n",
      "           Linear-26                   [-1, 64]           4,160\n",
      "      BatchNorm1d-27                   [-1, 64]             128\n",
      "             ReLU-28                   [-1, 64]               0\n",
      "           Linear-29                   [-1, 64]           4,160\n",
      "      BatchNorm1d-30                   [-1, 64]             128\n",
      "             ReLU-31                   [-1, 64]               0\n",
      "           Linear-32                  [-1, 256]          16,640\n",
      " ChannelAttention-33          [-1, 256, 84, 20]               0\n",
      "          Sigmoid-34          [-1, 256, 84, 20]               0\n",
      "         BAMBlock-35          [-1, 256, 84, 20]               0\n",
      "           Linear-36                   [-1, 64]      27,525,184\n",
      "           Linear-37                    [-1, 2]             130\n",
      "================================================================\n",
      "Total params: 27,981,283\n",
      "Trainable params: 27,981,283\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 44.49\n",
      "Params size (MB): 106.74\n",
      "Estimated Total Size (MB): 151.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 512, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "932937ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# input=torch.randn(50,256,7,7)\n",
    "# bam = BAMBlock(channel=256,reduction=16,dia_val=2)\n",
    "# output=bam(input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bf014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a72cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 81.3728, val_loss: 17.9444, val_acc: 0.6486\n",
      "Epoch [1], train_loss: 16.0315, val_loss: 5.9042, val_acc: 0.6486\n",
      "Epoch [2], train_loss: 9.8998, val_loss: 4.3326, val_acc: 0.6892\n",
      "Epoch [3], train_loss: 4.3135, val_loss: 2.2148, val_acc: 0.5270\n",
      "Epoch [4], train_loss: 8.0385, val_loss: 5.4534, val_acc: 0.6351\n",
      "Epoch [5], train_loss: 2.7859, val_loss: 3.8321, val_acc: 0.4459\n",
      "Epoch [6], train_loss: 1.5568, val_loss: 0.9557, val_acc: 0.6351\n",
      "Epoch [7], train_loss: 1.4210, val_loss: 0.9223, val_acc: 0.6757\n",
      "Epoch [8], train_loss: 0.6897, val_loss: 1.2254, val_acc: 0.4865\n",
      "Epoch [9], train_loss: 1.3776, val_loss: 1.7439, val_acc: 0.6351\n",
      "Epoch [10], train_loss: 1.0747, val_loss: 0.7533, val_acc: 0.7162\n",
      "Epoch [11], train_loss: 0.6932, val_loss: 0.7574, val_acc: 0.6622\n",
      "Epoch [12], train_loss: 0.5773, val_loss: 0.7871, val_acc: 0.6622\n",
      "Epoch [13], train_loss: 0.5948, val_loss: 0.8356, val_acc: 0.4865\n",
      "Epoch [14], train_loss: 0.5433, val_loss: 0.9564, val_acc: 0.4730\n",
      "Epoch [15], train_loss: 0.5490, val_loss: 0.6149, val_acc: 0.6757\n",
      "Epoch [16], train_loss: 0.5447, val_loss: 0.7188, val_acc: 0.5946\n",
      "Epoch [17], train_loss: 0.5260, val_loss: 0.6760, val_acc: 0.6622\n",
      "Epoch [18], train_loss: 0.5935, val_loss: 0.6656, val_acc: 0.6622\n",
      "Epoch [19], train_loss: 0.6152, val_loss: 0.7261, val_acc: 0.6757\n",
      "Epoch [20], train_loss: 0.5375, val_loss: 0.6983, val_acc: 0.6757\n",
      "Epoch [21], train_loss: 0.5343, val_loss: 0.6697, val_acc: 0.7027\n",
      "Epoch [22], train_loss: 0.5217, val_loss: 0.7016, val_acc: 0.6216\n",
      "Epoch [23], train_loss: 0.5730, val_loss: 0.7055, val_acc: 0.6351\n",
      "Epoch [24], train_loss: 0.4986, val_loss: 0.6880, val_acc: 0.5811\n",
      "Epoch [25], train_loss: 0.4960, val_loss: 0.6661, val_acc: 0.6486\n",
      "Epoch [26], train_loss: 0.5887, val_loss: 0.8869, val_acc: 0.4730\n",
      "Epoch [27], train_loss: 0.5348, val_loss: 0.7659, val_acc: 0.5135\n",
      "Epoch [28], train_loss: 0.5047, val_loss: 0.6547, val_acc: 0.5946\n",
      "Epoch [29], train_loss: 0.5117, val_loss: 0.7364, val_acc: 0.5405\n",
      "Epoch [30], train_loss: 0.4812, val_loss: 0.8493, val_acc: 0.5541\n",
      "Epoch [31], train_loss: 0.4748, val_loss: 0.7976, val_acc: 0.6351\n",
      "Epoch [32], train_loss: 0.4856, val_loss: 0.7768, val_acc: 0.5405\n",
      "Epoch [33], train_loss: 0.4732, val_loss: 0.7129, val_acc: 0.6081\n",
      "Epoch [34], train_loss: 0.4467, val_loss: 0.8014, val_acc: 0.5811\n",
      "Epoch [35], train_loss: 0.4886, val_loss: 0.7781, val_acc: 0.5811\n",
      "Epoch [36], train_loss: 0.5331, val_loss: 0.7009, val_acc: 0.6081\n",
      "Epoch [37], train_loss: 0.4568, val_loss: 0.9054, val_acc: 0.5135\n",
      "Epoch [38], train_loss: 0.4363, val_loss: 0.8159, val_acc: 0.6757\n",
      "Epoch [39], train_loss: 0.4689, val_loss: 0.7788, val_acc: 0.6351\n",
      "Epoch [40], train_loss: 0.5026, val_loss: 1.5104, val_acc: 0.4459\n",
      "Epoch [41], train_loss: 0.5114, val_loss: 0.9260, val_acc: 0.5135\n",
      "Epoch [42], train_loss: 0.5019, val_loss: 0.8446, val_acc: 0.5405\n",
      "Epoch [43], train_loss: 0.4309, val_loss: 0.7551, val_acc: 0.6351\n",
      "Epoch [44], train_loss: 0.4617, val_loss: 1.3634, val_acc: 0.4730\n",
      "Epoch [45], train_loss: 0.4342, val_loss: 0.7617, val_acc: 0.6351\n",
      "Epoch [46], train_loss: 0.3986, val_loss: 0.8572, val_acc: 0.6216\n",
      "Epoch [47], train_loss: 0.4222, val_loss: 1.1726, val_acc: 0.4865\n",
      "Epoch [48], train_loss: 0.4315, val_loss: 0.9311, val_acc: 0.5135\n",
      "Epoch [49], train_loss: 0.4799, val_loss: 0.8488, val_acc: 0.5405\n",
      "Epoch [50], train_loss: 0.3975, val_loss: 1.1698, val_acc: 0.4865\n",
      "Epoch [51], train_loss: 0.3885, val_loss: 0.8855, val_acc: 0.6081\n",
      "Epoch [52], train_loss: 0.3481, val_loss: 1.3526, val_acc: 0.5135\n",
      "Epoch [53], train_loss: 0.4241, val_loss: 0.7742, val_acc: 0.6216\n",
      "Epoch [54], train_loss: 0.3439, val_loss: 0.8069, val_acc: 0.7027\n",
      "Epoch [55], train_loss: 0.3975, val_loss: 1.0209, val_acc: 0.5270\n",
      "Epoch [56], train_loss: 0.3674, val_loss: 0.8098, val_acc: 0.6622\n",
      "Epoch [57], train_loss: 0.3610, val_loss: 1.1978, val_acc: 0.5676\n",
      "Epoch [58], train_loss: 0.3317, val_loss: 1.4810, val_acc: 0.5000\n",
      "Epoch [59], train_loss: 0.2968, val_loss: 0.9862, val_acc: 0.6622\n",
      "Epoch [60], train_loss: 0.3118, val_loss: 1.4021, val_acc: 0.5405\n",
      "Epoch [61], train_loss: 0.4166, val_loss: 1.0888, val_acc: 0.5946\n",
      "Epoch [62], train_loss: 0.3749, val_loss: 0.9322, val_acc: 0.6216\n",
      "Epoch [63], train_loss: 0.2403, val_loss: 1.3182, val_acc: 0.5946\n",
      "Epoch [64], train_loss: 0.4371, val_loss: 0.9608, val_acc: 0.6486\n",
      "Epoch [65], train_loss: 0.4225, val_loss: 1.0868, val_acc: 0.6351\n",
      "Epoch [66], train_loss: 0.3533, val_loss: 1.1452, val_acc: 0.5811\n",
      "Epoch [67], train_loss: 0.2058, val_loss: 1.2655, val_acc: 0.6081\n",
      "Epoch [68], train_loss: 0.2059, val_loss: 2.3389, val_acc: 0.5135\n",
      "Epoch [69], train_loss: 0.2077, val_loss: 1.2457, val_acc: 0.6081\n",
      "Epoch [70], train_loss: 0.2600, val_loss: 1.3376, val_acc: 0.6351\n",
      "Epoch [71], train_loss: 0.3363, val_loss: 0.9981, val_acc: 0.6081\n",
      "Epoch [72], train_loss: 0.1878, val_loss: 1.4885, val_acc: 0.5676\n",
      "Epoch [73], train_loss: 0.1166, val_loss: 1.5682, val_acc: 0.5405\n",
      "Epoch [74], train_loss: 0.1743, val_loss: 1.9965, val_acc: 0.5676\n",
      "Epoch [75], train_loss: 0.1437, val_loss: 1.6772, val_acc: 0.6081\n",
      "Epoch [76], train_loss: 0.1234, val_loss: 1.4399, val_acc: 0.5811\n",
      "Epoch [77], train_loss: 0.1784, val_loss: 1.5475, val_acc: 0.5946\n",
      "Epoch [78], train_loss: 0.2416, val_loss: 1.4089, val_acc: 0.6216\n",
      "Epoch [79], train_loss: 0.1396, val_loss: 1.7071, val_acc: 0.5676\n",
      "Epoch [80], train_loss: 0.1479, val_loss: 2.1705, val_acc: 0.5811\n",
      "Epoch [81], train_loss: 0.2357, val_loss: 2.6126, val_acc: 0.4730\n",
      "Epoch [82], train_loss: 0.2686, val_loss: 1.5200, val_acc: 0.5541\n",
      "Epoch [83], train_loss: 0.1601, val_loss: 2.7425, val_acc: 0.4730\n",
      "Epoch [84], train_loss: 0.1555, val_loss: 2.0394, val_acc: 0.5270\n",
      "Epoch [85], train_loss: 0.0820, val_loss: 1.9524, val_acc: 0.5811\n",
      "Epoch [86], train_loss: 0.0537, val_loss: 2.2518, val_acc: 0.5000\n",
      "Epoch [87], train_loss: 0.0394, val_loss: 1.9610, val_acc: 0.5541\n",
      "Epoch [88], train_loss: 0.0797, val_loss: 2.2619, val_acc: 0.5676\n",
      "Epoch [89], train_loss: 0.1590, val_loss: 1.7721, val_acc: 0.6622\n",
      "Epoch [90], train_loss: 0.1593, val_loss: 2.7686, val_acc: 0.5000\n",
      "Epoch [91], train_loss: 0.1608, val_loss: 1.6593, val_acc: 0.6081\n",
      "Epoch [92], train_loss: 0.0685, val_loss: 2.0152, val_acc: 0.5676\n",
      "Epoch [93], train_loss: 0.0436, val_loss: 2.2573, val_acc: 0.5270\n",
      "Epoch [94], train_loss: 0.0641, val_loss: 2.7266, val_acc: 0.5541\n",
      "Epoch [95], train_loss: 0.0730, val_loss: 2.5068, val_acc: 0.5811\n",
      "Epoch [96], train_loss: 0.0328, val_loss: 2.6575, val_acc: 0.5676\n",
      "Epoch [97], train_loss: 0.0264, val_loss: 3.2240, val_acc: 0.5541\n",
      "Epoch [98], train_loss: 0.0339, val_loss: 2.5328, val_acc: 0.6081\n",
      "Epoch [99], train_loss: 0.0219, val_loss: 3.5318, val_acc: 0.5946\n"
     ]
    }
   ],
   "source": [
    "# CTX = torch.device('cuda')\n",
    "# train_dl.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # train_dl.train_labels.to(CTX)\n",
    "# # val_dl.train_data.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # val_dl.train_labels.to(CTX)\n",
    "num_epochs = 100\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26874318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "\n",
    "plot_accuracies(history)\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60afc6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7162162065505981"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x['val_acc'] for x in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3164b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
