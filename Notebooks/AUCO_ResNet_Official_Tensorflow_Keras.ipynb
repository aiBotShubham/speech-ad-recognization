{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vincenzodentamaro/aucoresnet/blob/main/AUCO_ResNet_Official_Tensorflow_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqdbGOQcT0dz",
    "outputId": "b0762d0b-a27b-4c7d-c12f-1d409fe41c1b"
   },
   "outputs": [],
   "source": [
    "# !pip install kapre==0.3.4\n",
    "# #pip install git https://github.com/user/repo.git@branch\n",
    "# !pip install --upgrade tf_siren\n",
    "# !pip install --upgrade googledrivedownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMczZvA5Q29B",
    "outputId": "98a36766-44e7-4ad4-b2b9-26fcd0c6e718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in 1-thread CPU mode for fully reproducible results training a CNN and generating numpy randomness.  This mode may be slow...\n"
     ]
    }
   ],
   "source": [
    "print('Running in 1-thread CPU mode for fully reproducible results training a CNN and generating numpy randomness.  This mode may be slow...')\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 1\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "seed_value += 1\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "seed_value += 1\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "seed_value += 1\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2uCGQYdu0p9"
   },
   "source": [
    "This is a toy dataset extracted from Virufy (it is not the full Virufy dataset), thus accuracies are unreliable and not untruthful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pX-X79vOgXYY",
    "outputId": "10543cbb-b85b-4234-d836-d4793c8c8706"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/vincenzodentamaro/aucoresnet.git\n",
    "# !unzip aucoresnet/virufy_pickle.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v7xXKYzHG3kH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_13076/2521345378.py:31: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  wavedata = np.fromstring(str_data, dtype = np.short)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n",
      "44100\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# cam_task1_pos = pickle.load( open( \"Virufy_cough_noSplit_POS.p\", \"rb\" ) )\n",
    "# cam_task1_neg = pickle.load( open( \"Virufy_cough_noSplit_NEG.p\", \"rb\" ) )\n",
    "\n",
    "# SAMPLING_RATE = 22050\n",
    "import pandas as pd\n",
    "import wave\n",
    "import numpy as np\n",
    "import python_speech_features as ps\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from scipy.io import wavfile\n",
    "\n",
    "epsilon = 1e-5\n",
    "\n",
    "def wgn(x, snr):\n",
    "    snr = 10**(snr/10.0)\n",
    "    xpower = np.sum(x**2)/len(x)\n",
    "    npower = xpower / snr\n",
    "    return np.random.randn(len(x)) * np.sqrt(npower)\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    file = wave.open(filename,'r')    \n",
    "    audio_sample = wavfile.read(filename)  \n",
    "    # print(audio_sample[1])  \n",
    "    params = file.getparams()\n",
    "    nchannels, sampwidth, framerate, wav_length = params[:4]\n",
    "    str_data = file.readframes(wav_length)\n",
    "    wavedata = np.fromstring(str_data, dtype = np.short)\n",
    "    # librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "    time = np.arange(0,wav_length) * (1.0/framerate)\n",
    "    file.close()\n",
    "    return audio_sample[1], time, framerate\n",
    "\n",
    "rootdir = 'train/Normalised_audio-chunks/'\n",
    "\n",
    "data = []\n",
    "for control in os.listdir(rootdir):\n",
    "    Class = 0\n",
    "    if control == 'cc':\n",
    "        Class = 0.0\n",
    "    else:\n",
    "        Class = 1.0\n",
    "        \n",
    "    sub_dir = rootdir + '/' + control\n",
    "    \n",
    "    for sample in os.listdir(sub_dir):\n",
    "        audio, time, rate = read_file(sub_dir+'/'+sample)\n",
    "\n",
    "        data.append([sample[:4], audio, Class])\n",
    "        print(rate)\n",
    "        \n",
    "df_train = pd.DataFrame(data, columns = ['id', 'data', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S001</td>\n",
       "      <td>[-15013, -16108, -17248, -18372, -19389, -2046...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S001</td>\n",
       "      <td>[683, 609, 520, 494, 484, 425, 304, 141, -12, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S001</td>\n",
       "      <td>[-3938, -3704, -3489, -3310, -3134, -2988, -28...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S001</td>\n",
       "      <td>[214, 400, 628, 721, 711, 669, 628, 614, 618, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S001</td>\n",
       "      <td>[-2298, -2501, -2605, -2553, -2430, -2278, -21...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>S156</td>\n",
       "      <td>[1940, 1938, 1919, 1901, 1901, 1899, 1911, 191...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>S156</td>\n",
       "      <td>[-1418, -1051, -1015, -1066, -1030, -806, -433...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>S156</td>\n",
       "      <td>[220, 260, 260, 254, 281, 329, 348, 302, 275, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>S156</td>\n",
       "      <td>[1264, 1439, 1595, 1550, 1419, 1435, 1683, 196...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>S156</td>\n",
       "      <td>[482, 637, 818, 863, 759, 826, 1236, 1682, 176...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               data  labels\n",
       "0     S001  [-15013, -16108, -17248, -18372, -19389, -2046...     0.0\n",
       "1     S001  [683, 609, 520, 494, 484, 425, 304, 141, -12, ...     0.0\n",
       "2     S001  [-3938, -3704, -3489, -3310, -3134, -2988, -28...     0.0\n",
       "3     S001  [214, 400, 628, 721, 711, 669, 628, 614, 618, ...     0.0\n",
       "4     S001  [-2298, -2501, -2605, -2553, -2430, -2278, -21...     0.0\n",
       "...    ...                                                ...     ...\n",
       "2829  S156  [1940, 1938, 1919, 1901, 1901, 1899, 1911, 191...     1.0\n",
       "2830  S156  [-1418, -1051, -1015, -1066, -1030, -806, -433...     1.0\n",
       "2831  S156  [220, 260, 260, 254, 281, 329, 348, 302, 275, ...     1.0\n",
       "2832  S156  [1264, 1439, 1595, 1550, 1419, 1435, 1683, 196...     1.0\n",
       "2833  S156  [482, 637, 818, 863, 759, 826, 1236, 1682, 176...     1.0\n",
       "\n",
       "[2834 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "tmMQJyq4dEl6",
    "outputId": "62aae760-43c7-462e-9e0a-3bbf55bd0d23"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "patientids = []\n",
    "for i in df_train.index:\n",
    "    # print(value)\n",
    "    patientid = df_train['id'][i]\n",
    "    # print(patientid)\n",
    "    # for audio in value['data']:\n",
    "    X.append(df_train['data'][i])\n",
    "    # print(audio)\n",
    "    y.append(df_train['labels'][i])\n",
    "    patientids.append(patientid)\n",
    "        \n",
    "# for value in cam_task1_neg:\n",
    "#     patientid = value['id']\n",
    "#     # print(patientid)\n",
    "#     for audio in value['audio']:\n",
    "#         X.append(audio)\n",
    "#         y.append(0.0)\n",
    "#         patientids.append(patientid)\n",
    "# '''\n",
    "\n",
    "# for value in cos_breath_pos:\n",
    "#     patientid = value['id']\n",
    "#     for audio in value['audio']:\n",
    "#         X.append(audio)\n",
    "#         y.append(1.0)\n",
    "#         patientids.append(patientid)\n",
    "        \n",
    "# for value in cos_breath_neg:\n",
    "#     patientid = value['id']\n",
    "#     for audio in value['audio']:\n",
    "#         X.append(audio)\n",
    "#         y.append(0.0)\n",
    "#         patientids.append(patientid)\n",
    "# '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2834, 2834)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "QIBsgeWg1R3x",
    "outputId": "fca0a260-8a40-4153-e713-17893a5ba306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean secs\n",
      "1.2007655981705785\n",
      "Max secs\n",
      "10.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "SAMPLING_RATE = 44100\n",
    "lunghezze = []\n",
    "for r in X:\n",
    "  lunghezze.append(len(r))\n",
    "\n",
    "print('Mean secs')\n",
    "print(np.mean(lunghezze)/SAMPLING_RATE)\n",
    "print('Max secs')\n",
    "print(np.max(lunghezze)/SAMPLING_RATE)\n",
    "_ = plt.hist(np.asarray(lunghezze)/SAMPLING_RATE, bins=50)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1laK6IJaG6DX",
    "outputId": "86e6e60b-b0c6-49f6-abcd-6a73672a5883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "(1, 661500)\n",
      "Mean secs\n",
      "15.0\n",
      "Max secs\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "max_length = 15.#in secs\n",
    "max_samples =  max_length*SAMPLING_RATE\n",
    "for i in range(len(X)):\n",
    "\n",
    "  temp = X[i]\n",
    "  #temp = librosa.resample(temp, 20000, 16000)\n",
    "  temp = np.reshape(temp,(1,temp.shape[0]))  \n",
    "  \n",
    "  if temp.shape[1] < max_samples:\n",
    "    \n",
    "    offset = max_samples - len(temp)\n",
    "\n",
    "    shape = np.shape(temp)\n",
    "    tt = np.zeros((1,int(max_samples)))\n",
    "    tt[:shape[0],:shape[1]] = temp\n",
    "\n",
    "    temp = tt\n",
    "    \n",
    "     \n",
    "  if temp.shape[1] > max_samples:\n",
    "    temp = temp[0,:int((max_samples))]\n",
    "    temp = np.reshape(temp,(1,temp.shape[0]))  \n",
    "  X[i] = temp\n",
    "  \n",
    "  print(temp.shape)\n",
    "lens = []\n",
    "for it in X:\n",
    "  lens.append(it.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "print('Mean secs')\n",
    "print(np.mean(lens)/SAMPLING_RATE)\n",
    "print('Max secs')\n",
    "print(np.max(lens)/SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "olGy2H9GG-zL"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "rand = random.Random(42)\n",
    "#Dentamaro et al.\n",
    "def inter_patient_scheme(X_,lbls_,filenames, test_size = 0.2):\n",
    "  people_index = {}\n",
    "  people_class = {}\n",
    "  X = copy.deepcopy(X_)\n",
    "  lbls = copy.deepcopy(lbls_)\n",
    "  \n",
    "  for i in range(len(filenames)):\n",
    "        \n",
    "      usercode = filenames[i]\n",
    "      if not usercode in people_class:\n",
    "        people_class[usercode] = lbls[i]\n",
    "      #print(usercode)\n",
    "      if usercode in people_index:\n",
    "        people_index[usercode].append(i)\n",
    "      else:\n",
    "        people_index[usercode] = []\n",
    "        people_index[usercode].append(i)\n",
    "  #print(people_index)    \n",
    "  keys = list(people_index.keys())\n",
    "\n",
    "  rand.shuffle(keys)\n",
    "  #print(keys) \n",
    "  \n",
    "\n",
    "  peoples_in_train = math.floor(len(keys)*(1.-test_size))\n",
    "  people_in_test = len(keys)-peoples_in_train\n",
    "  temp_classes = []\n",
    "  j = 0\n",
    "  for k in keys:\n",
    "    if j < peoples_in_train:\n",
    "      temp_classes.append(people_class[k])\n",
    "    j += 1\n",
    "\n",
    "  unique, counts = np.unique(temp_classes, return_counts=True)\n",
    "  min_index = np.where(counts == np.min(counts))\n",
    "  min_people = np.min(counts)\n",
    "  min_class = unique[min_index]\n",
    "  print('minority class '+str(min_class))\n",
    "  print('minority people '+str(min_people))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #print(peoples_in_train)\n",
    "  training_items = []\n",
    "  testing_items = []\n",
    "\n",
    "  class_counter = {}\n",
    "\n",
    "  train_usercodes = []\n",
    "  test_usercodes = []\n",
    "  #per people balance \n",
    "  for j in range(peoples_in_train):\n",
    "    index = people_index[keys[j]]\n",
    "    \n",
    "    this_class = people_class[keys[j]]\n",
    "    #print(this_class)\n",
    "    #print(class_counter)\n",
    "    if not this_class in class_counter:\n",
    "      class_counter[this_class] = 0\n",
    "    \n",
    "    if this_class != np.any(min_class) and class_counter[this_class] < min_people:      \n",
    "      for h in index:\n",
    "        training_items.append(h)\n",
    "        train_usercodes.append(keys[j])\n",
    "      class_counter[this_class] += 1\n",
    "    elif this_class != np.any(min_class) and class_counter[this_class] >= min_people :\n",
    "       for h in index:\n",
    "          pass\n",
    "          #testing_items.append(h)\n",
    "       #class_counter[this_class] += 1\n",
    "    else:\n",
    "      for h in index:\n",
    "        training_items.append(h)\n",
    "        train_usercodes.append(keys[j])\n",
    "      class_counter[this_class] += 1\n",
    "  \n",
    "  temp_classes = []\n",
    "  j = 0\n",
    "  for k in keys:\n",
    "    if j >= peoples_in_train:\n",
    "      temp_classes.append(people_class[k])\n",
    "    j += 1\n",
    "\n",
    "  #print(temp_classes)\n",
    "  class_counter = {}\n",
    "  unique, counts = np.unique(temp_classes, return_counts=True)\n",
    "  min_index = np.where(counts == np.min(counts))\n",
    "  min_people = np.min(counts)\n",
    "  min_class = unique[min_index]\n",
    "  #print(min_people)\n",
    "  #print(min_class)\n",
    "  for j in range(peoples_in_train, len(keys)):\n",
    "    index = people_index[keys[j]]\n",
    "    \n",
    "    this_class = people_class[keys[j]]\n",
    "    #print(this_class)\n",
    "    #print(class_counter)\n",
    "    if not this_class in class_counter:\n",
    "      class_counter[this_class] = 0\n",
    "    \n",
    "    if this_class != min_class[0] and class_counter[this_class] < min_people:      \n",
    "      for h in index:\n",
    "        testing_items.append(h)\n",
    "        test_usercodes.append(keys[j])\n",
    "        #print('Negative index --> '+str(h))\n",
    "      \n",
    "      class_counter[this_class] += 1\n",
    "    elif this_class == min_class[0]:\n",
    "      for h in index:\n",
    "        testing_items.append(h)\n",
    "        test_usercodes.append(keys[j])\n",
    "        #print('Positive index --> '+str(h))\n",
    "    \n",
    "  \n",
    "\n",
    "  \n",
    "  testing_items = np.asarray(testing_items)\n",
    "  training_items = np.asarray(training_items)\n",
    "  #lbls = np.asarray(lbls)\n",
    "  yy = to_categorical(lbls)\n",
    "  X_train = X[training_items,:]\n",
    "  y_train = yy[training_items,:]\n",
    "  X_test = X[testing_items,:]\n",
    "  y_test = yy[testing_items,:]\n",
    "  #print(y_test)\n",
    "  ffn = np.asarray(filenames)[training_items]\n",
    "\n",
    "  #for j in range(len(lbls)):\n",
    "    #print(str(yy[j])+ ' --> '+str(lbls[j]))\n",
    "\n",
    "  return X_train, X_test, y_train, y_test,train_usercodes, test_usercodes\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwUtVrpeOi4c",
    "outputId": "4e11345f-1f46-4d6f-ed17-91931f4766c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Conv1D, Add, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tf_siren import SinusodialRepresentationDense, Sine\n",
    "def attach_attention_module(net, attention_module, activation=Activation('relu'), ratio = 8):\n",
    "  if attention_module == 'se_block': # SE_block\n",
    "    net = se_block(net, activation=activation, ratio=ratio)\n",
    "  elif attention_module == 'cbam_block': # CBAM_block\n",
    "    net = cbam_block(net, activation=activation, ratio=ratio)\n",
    "  elif attention_module == 'dbam_block': # CBAM_block\n",
    "    net = dbam_block(net, activation=activation)\n",
    "  elif attention_module == 'eca_block': # CBAM_block\n",
    "    net = ecanet(net)\n",
    "  else:\n",
    "    pass\n",
    "  return net\n",
    "\n",
    "def se_block(input_feature, ratio=8, activation='relu'):\n",
    "\t\"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\n",
    "\tAs described in https://arxiv.org/abs/1709.01507.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\tchannel = input_feature.shape[channel_axis]\n",
    "\n",
    "\tse_feature = GlobalAveragePooling2D()(input_feature)\n",
    "\tse_feature = Reshape((1, 1, channel))(se_feature)\n",
    "\tassert se_feature.shape[1:] == (1,1,channel)\n",
    "\n",
    "  \n",
    "\tse_feature = Dense(channel // ratio,\n",
    "\t\t\t\t\t   kernel_initializer='he_normal',\n",
    "\t\t\t\t\t   use_bias=True,\n",
    "\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n",
    "\tse_feature  = Activation(activation)(se_feature)\n",
    "\n",
    "\n",
    "\t#se_feature = SinusodialRepresentationDense(channel // ratio,activation='sine', w0=1.0)(se_feature)#72 auc\n",
    "\tassert se_feature.shape[1:] == (1,1,channel//ratio)\n",
    "\tse_feature = Dense(channel,\n",
    "\t\t\t\t\t   activation='sigmoid',\n",
    "\t\t\t\t\t   kernel_initializer='he_normal',\n",
    "\t\t\t\t\t   use_bias=True,\n",
    "\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n",
    "\tassert se_feature.shape[1:] == (1,1,channel)\n",
    "\tif K.image_data_format() == 'channels_first':\n",
    "\t\tse_feature = Permute((3, 1, 2))(se_feature)\n",
    "\n",
    "\tse_feature = multiply([input_feature, se_feature])\n",
    "\treturn se_feature\n",
    "def dbam_block(cbam_feature, ratio=8, activation='relu'):\n",
    "\n",
    "\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "\tAs described in https://arxiv.org/abs/1807.06521.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tcbam_feature = se_block(cbam_feature, ratio)#channel_attention(cbam_feature, ratio)\n",
    "\tcbam_feature = spatial_attention(cbam_feature)\n",
    "\treturn cbam_feature\n",
    "\t \n",
    "def cbam_block(cbam_feature, ratio=8, activation='relu'):\n",
    "\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "\tAs described in https://arxiv.org/abs/1807.06521.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tcbam_feature = channel_attention(cbam_feature, ratio)\n",
    "\tcbam_feature = spatial_attention(cbam_feature)\n",
    "\treturn cbam_feature\n",
    "\t \n",
    "\n",
    "def ecanet(input_feature,gamma=2,b=1,):\n",
    "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "  channels = input_feature.shape[channel_axis]\n",
    "  t = int(abs((math.log(channels,2)+b)/gamma))\n",
    "  k = t if t%2 else t+1\n",
    "  x_global_avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "  x = Reshape((channels,1))(x_global_avg_pool)\n",
    "  x = Conv1D(1,kernel_size=k,padding=\"same\")(x)\n",
    "  x = Activation('sigmoid')(x)  #shape=[batch,chnnels,1]\n",
    "  x = Reshape((1, 1, channels))(x)\n",
    "  output = multiply([input_feature,x])\n",
    "  return output\n",
    "\n",
    "\n",
    "def channel_attention(input_feature, ratio=8,activation='relu'):\n",
    "\t\n",
    "\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\tchannel = input_feature.shape[channel_axis]\n",
    "\t\n",
    "\tshared_layer_one = Dense(channel//ratio,\n",
    "\t\t\t\t\t\t\t activation=activation,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\tshared_layer_two = Dense(channel,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\t\n",
    "\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "\tavg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\tavg_pool = shared_layer_one(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tavg_pool = shared_layer_two(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tmax_pool = GlobalMaxPooling2D()(input_feature)\n",
    "\tmax_pool = Reshape((1,1,channel))(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\tmax_pool = shared_layer_one(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tmax_pool = shared_layer_two(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tcbam_feature = Add()([avg_pool,max_pool])\n",
    "\tcbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\n",
    "\treturn multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature,activation='relu'):\n",
    "\tkernel_size = 7\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tchannel = input_feature.shape[1]\n",
    "\t\tcbam_feature = Permute((2,3,1))(input_feature)\n",
    "\telse:\n",
    "\t\tchannel = input_feature.shape[-1]\n",
    "\t\tcbam_feature = input_feature\n",
    "\t\n",
    "\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert avg_pool.shape[-1] == 1\n",
    "\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert max_pool.shape[-1] == 1\n",
    "\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "\tassert concat.shape[-1] == 2\n",
    "\tcbam_feature = Conv2D(filters = 1,\n",
    "\t\t\t\t\tkernel_size=kernel_size,\n",
    "\t\t\t\t\tstrides=1,\n",
    "\t\t\t\t\tpadding='same',\n",
    "\t\t\t\t\tactivation='sigmoid',\n",
    "\t\t\t\t\tkernel_initializer='he_normal',\n",
    "\t\t\t\t\tuse_bias=False)(concat)\t\n",
    "\tassert cbam_feature.shape[-1] == 1\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\t\n",
    "\treturn multiply([input_feature, cbam_feature])\n",
    "\t\t\n",
    "\"\"\"Backend operations of Kapre.\n",
    "\n",
    "This module summarizes operations and functions that are used in Kapre layers.\n",
    "\n",
    "Attributes:\n",
    "    _CH_FIRST_STR (str): 'channels_first', a pre-defined string.\n",
    "    _CH_LAST_STR (str): 'channels_last', a pre-defined string.\n",
    "    _CH_DEFAULT_STR (str): 'default', a pre-defined string.\n",
    "\n",
    "\"\"\"\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow\n",
    "#tensorflow.random.set_seed(42)\n",
    "\n",
    "_CH_FIRST_STR = 'channels_first'\n",
    "_CH_LAST_STR = 'channels_last'\n",
    "_CH_DEFAULT_STR = 'default'\n",
    "\n",
    "\n",
    "def get_window_fn(window_name=None):\n",
    "    \"\"\"Return a window function given its name.\n",
    "    This function is used inside layers such as `STFT` to get a window function.\n",
    "\n",
    "    Args:\n",
    "        window_name (None or str): name of window function. On Tensorflow 2.3, there are five windows available in\n",
    "        `tf.signal` (`hamming_window`, `hann_window`, `kaiser_bessel_derived_window`, `kaiser_window`, `vorbis_window`).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if window_name is None:\n",
    "        return tf.signal.hann_window\n",
    "\n",
    "    available_windows = {\n",
    "        'hamming_window': tf.signal.hamming_window,\n",
    "        'hann_window': tf.signal.hann_window,\n",
    "    }\n",
    "    if hasattr(tf.signal, 'kaiser_bessel_derived_window'):\n",
    "        available_windows['kaiser_bessel_derived_window'] = tf.signal.kaiser_bessel_derived_window\n",
    "    if hasattr(tf.signal, 'kaiser_window'):\n",
    "        available_windows['kaiser_window'] = tf.signal.kaiser_window\n",
    "    if hasattr(tf.signal, 'vorbis_window'):\n",
    "        available_windows['vorbis_window'] = tf.signal.vorbis_window\n",
    "\n",
    "    if window_name not in available_windows:\n",
    "        raise NotImplementedError(\n",
    "            'Window name %s is not supported now. Currently, %d windows are'\n",
    "            'supported - %s'\n",
    "            % (\n",
    "                window_name,\n",
    "                len(available_windows),\n",
    "                ', '.join([k for k in available_windows.keys()]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return available_windows[window_name]\n",
    "\n",
    "\n",
    "def validate_data_format_str(data_format):\n",
    "    \"\"\"A function that validates the data format string.\"\"\"\n",
    "    if data_format not in (_CH_DEFAULT_STR, _CH_FIRST_STR, _CH_LAST_STR):\n",
    "        raise ValueError(\n",
    "            'data_format should be one of {}'.format(\n",
    "                str([_CH_FIRST_STR, _CH_LAST_STR, _CH_DEFAULT_STR])\n",
    "            )\n",
    "            + ' but we received {}'.format(data_format)\n",
    "        )\n",
    "\n",
    "\n",
    "def magnitude_to_decibel(x, ref_value=1.0, amin=1e-5, dynamic_range=80.0):\n",
    "    \"\"\"A function that converts magnitude to decibel scaling.\n",
    "    In essence, it runs `10 * log10(x)`, but with some other utility operations.\n",
    "\n",
    "    Similar to `librosa.amplitude_to_db` with `ref=1.0` and `top_db=dynamic_range`\n",
    "\n",
    "    Args:\n",
    "        x (`Tensor`): float tensor. Can be batch or not. Something like magnitude of STFT.\n",
    "        ref_value (`float`): an input value that would become 0 dB in the result.\n",
    "            For spectrogram magnitudes, ref_value=1.0 usually make the decibel-scaled output to be around zero\n",
    "            if the input audio was in [-1, 1].\n",
    "        amin (`float`): the noise floor of the input. An input that is smaller than `amin`, it's converted to `amin`.\n",
    "        dynamic_range (`float`): range of the resulting value. E.g., if the maximum magnitude is 30 dB,\n",
    "            the noise floor of the output would become (30 - dynamic_range) dB\n",
    "\n",
    "    Returns:\n",
    "        log_spec (`Tensor`): a decibel-scaled version of `x`.\n",
    "\n",
    "    Note:\n",
    "        In many deep learning based application, the input spectrogram magnitudes (e.g., abs(STFT)) are decibel-scaled\n",
    "        (=logarithmically mapped) for a better performance.\n",
    "\n",
    "    Example:\n",
    "        ::\n",
    "\n",
    "            input_shape = (2048, 1)  # mono signal\n",
    "            model = Sequential()\n",
    "            model.add(kapre.Frame(frame_length=1024, hop_length=512, input_shape=input_shape))\n",
    "            # now the shape is (batch, n_frame=3, frame_length=1024, ch=1)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _log10(x):\n",
    "        return tf.math.log(x) / tf.math.log(tf.constant(10, dtype=x.dtype))\n",
    "\n",
    "    if K.ndim(x) > 1:  # we assume x is batch in this case\n",
    "        max_axis = tuple(range(K.ndim(x))[1:])\n",
    "    else:\n",
    "        max_axis = None\n",
    "\n",
    "    if amin is None:\n",
    "        amin = 1e-5\n",
    "\n",
    "    log_spec = 10.0 * _log10(tf.math.maximum(x, amin))\n",
    "    log_spec = log_spec - 10.0 * _log10(tf.math.maximum(amin, ref_value))\n",
    "\n",
    "    log_spec = tf.math.maximum(\n",
    "        log_spec, tf.math.reduce_max(log_spec, axis=max_axis, keepdims=True) - dynamic_range\n",
    "    )\n",
    "\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def filterbank_mel(\n",
    "    sample_rate, n_freq, n_mels=128, f_min=0.0, f_max=None, htk=False, norm='slaney',trainable=False, num_classes=2\n",
    "):\n",
    "    \"\"\"A wrapper for librosa.filters.mel that additionally does transpose and tensor conversion\n",
    "\n",
    "    Args:\n",
    "        sample_rate (`int`): sample rate of the input audio\n",
    "        n_freq (`int`): number of frequency bins in the input STFT magnitude.\n",
    "        n_mels (`int`): the number of mel bands\n",
    "        f_min (`float`): lowest frequency that is going to be included in the mel filterbank (Hertz)\n",
    "        f_max (`float`): highest frequency that is going to be included in the mel filterbank (Hertz)\n",
    "        htk (bool): whether to use `htk` formula or not\n",
    "        norm: The default, 'slaney', would normalize the the mel weights by the width of the mel band.\n",
    "\n",
    "    Returns:\n",
    "        (`Tensor`): mel filterbanks. Shape=`(n_freq, n_mels)`\n",
    "    \"\"\"\n",
    "\n",
    "    filterbank = librosa.filters.mel(\n",
    "        sr=sample_rate,\n",
    "        n_fft=(n_freq - 1) * 2,\n",
    "        n_mels=n_mels,\n",
    "        fmin=f_min,\n",
    "        fmax=f_max,\n",
    "        htk=htk,\n",
    "        norm=norm,\n",
    "    ).astype(K.floatx())\n",
    "\n",
    "    ff = filterbank.T\n",
    "    print('FF shape',ff.shape)\n",
    "    \n",
    "    if trainable:\n",
    "      variables = []\n",
    "      for i in range(num_classes):\n",
    "        #variables.append(tf.Variable(tf.ones(shape=(ff.shape[0],ff.shape[1]), dtype=tf.float32),trainable=True, name='kernel_variable_'+str(i))*tf.Variable(ff,trainable=False))\n",
    "        variables.append(tf.Variable(ff,trainable=True))\n",
    "\n",
    "      \n",
    "      ff = tf.add_n(variables)# / num_classes #* tf.Variable(tf.convert_to_tensor(ff),trainable=False)\n",
    "      \n",
    "\n",
    "    print('Trainable mel spectrogram is '+str(trainable))\n",
    "    return ff\n",
    "\n",
    "\n",
    "def filterbank_log(sample_rate, n_freq, n_bins=84, bins_per_octave=12, f_min=None, spread=0.125, trainable = False):\n",
    "    \"\"\"A function that returns a approximation of constant-Q filter banks for a fixed-window STFT.\n",
    "    Each filter is a log-normal window centered at the corresponding frequency.\n",
    "\n",
    "    Args:\n",
    "        sample_rate (`int`): audio sampling rate\n",
    "        n_freq (`int`): number of the input frequency bins. E.g., `n_fft / 2 + 1`\n",
    "        n_bins (`int`): number of the resulting log-frequency bins.  Defaults to 84 (7 octaves).\n",
    "        bins_per_octave (`int`): number of bins per octave. Defaults to 12 (semitones).\n",
    "        f_min (`float`): lowest frequency that is going to be included in the log filterbank. Defaults to `C1 ~= 32.70`\n",
    "        spread (`float`): spread of each filter, as a fraction of a bin.\n",
    "\n",
    "    Returns:\n",
    "        (`Tensor`): log-frequency filterbanks. Shape=`(n_freq, n_bins)`\n",
    "\n",
    "    Note:\n",
    "        The code is originally from `logfrequency` in librosa 0.4 (deprecated) and copy-and-pasted.\n",
    "        `tuning` parameter was removed and we use `n_freq` instead of `n_fft`.\n",
    "    \"\"\"\n",
    "\n",
    "    if f_min is None:\n",
    "        f_min = 32.70319566\n",
    "\n",
    "    f_max = f_min * 2 ** (n_bins / bins_per_octave)\n",
    "    if f_max > sample_rate // 2:\n",
    "        raise RuntimeError(\n",
    "            'Maximum frequency of log filterbank should be lower or equal to the maximum'\n",
    "            'frequency of the input (defined by its sample rate), '\n",
    "            'but f_max=%f and maximum frequency is %f. \\n'\n",
    "            'Fix it by reducing n_bins, increasing bins_per_octave and/or reducing f_min.\\n'\n",
    "            'You can also do it by increasing sample_rate but it means you need to upsample'\n",
    "            'the input audio data, too.' % (f_max, sample_rate)\n",
    "        )\n",
    "\n",
    "    # What's the shape parameter for our log-normal filters?\n",
    "    sigma = float(spread) / bins_per_octave\n",
    "\n",
    "    # Construct the output matrix\n",
    "    basis = np.zeros((n_bins, n_freq))\n",
    "\n",
    "    # Get log frequencies of bins\n",
    "    log_freqs = np.log2(librosa.fft_frequencies(sample_rate, (n_freq - 1) * 2)[1:])\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        # What's the center (median) frequency of this filter?\n",
    "        c_freq = f_min * (2.0 ** (float(i) / bins_per_octave))\n",
    "\n",
    "        # Place a log-normal window around c_freq\n",
    "        basis[i, 1:] = np.exp(\n",
    "            -0.5 * ((log_freqs - np.log2(c_freq)) / sigma) ** 2 - np.log2(sigma) - log_freqs\n",
    "        )\n",
    "\n",
    "    # Normalize the filters\n",
    "    basis = librosa.util.normalize(basis, norm=1, axis=1)\n",
    "    basis = basis.astype(K.floatx())\n",
    "    print('Trainable mel spectrogram is '+str(trainable))\n",
    "    return tf.Variable(tf.convert_to_tensor(basis.T), trainable=trainable)\n",
    "\n",
    "\n",
    "def mu_law_encoding(signal, quantization_channels):\n",
    "    \"\"\"Encode signal based on mu-law companding. Also called mu-law compressing.\n",
    "\n",
    "    This algorithm assumes the signal has been scaled to between -1 and 1 and returns a signal encoded\n",
    "    with values from 0 to quantization_channels - 1.\n",
    "    See `Wikipedia <https://en.wikipedia.org/wiki/-law_algorithm>`_ for more details.\n",
    "\n",
    "    Args:\n",
    "        signal (float `Tensor`): audio signal to encode\n",
    "        quantization_channels (positive int): Number of channels. For 8-bit encoding, use 256.\n",
    "\n",
    "    Returns:\n",
    "        signal_mu (int `Tensor`): mu-encoded signal\n",
    "    \"\"\"\n",
    "    mu = quantization_channels - 1.0\n",
    "    signal_mu = tf.math.sign(signal) * tf.math.log1p(mu * tf.math.abs(signal)) / tf.math.log1p(mu)\n",
    "    signal_mu = tf.cast(((signal_mu + 1) / 2.0 * mu + 0.5), tf.int32)\n",
    "    return signal_mu\n",
    "\n",
    "\n",
    "def mu_law_decoding(signal_mu, quantization_channels):\n",
    "    \"\"\"Decode mu-law encoded signals based on mu-law companding. Also called mu-law expanding.\n",
    "\n",
    "    See `Wikipedia <https://en.wikipedia.org/wiki/-law_algorithm>`_ for more details.\n",
    "\n",
    "    Args:\n",
    "        signal_mu (int `Tensor`): mu-encoded signal to decode\n",
    "        quantization_channels (positive int): Number of channels. For 8-bit encoding, use 256.\n",
    "\n",
    "    Returns:\n",
    "        signal (float `Tensor`): decoded audio signal\n",
    "    \"\"\"\n",
    "    mu = quantization_channels - 1.0\n",
    "    signal_mu = K.cast_to_floatx(signal_mu)\n",
    "\n",
    "    signal = (signal_mu / mu) * 2 - 1.0\n",
    "    signal = (\n",
    "        tf.math.sign(signal) * (tf.math.exp(tf.math.abs(signal) * tf.math.log1p(mu)) - 1.0) / mu\n",
    "    )\n",
    "    return signal\n",
    "\n",
    "\n",
    "\n",
    "class ApplyFilterbank(tensorflow.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Apply a filterbank to the input spectrograms.\n",
    "    Args:\n",
    "        filterbank (`Tensor`): filterbank tensor in a shape of (n_freq, n_filterbanks)\n",
    "        data_format (`str`): specifies the data format of batch input/output\n",
    "        **kwargs: Keyword args for the parent keras layer (e.g., `name`)\n",
    "    Example:\n",
    "        ::\n",
    "            input_shape = (2048, 1)  # mono signal\n",
    "            n_fft = 1024\n",
    "            n_hop = n_fft // 2\n",
    "            kwargs = {\n",
    "                'sample_rate': 22050,\n",
    "                'n_freq': n_fft // 2 + 1,\n",
    "                'n_mels': 128,\n",
    "                'f_min': 0.0,\n",
    "                'f_max': 8000,\n",
    "            }\n",
    "            model = Sequential()\n",
    "            model.add(kapre.STFT(n_fft=n_fft, hop_length=n_hop, input_shape=input_shape))\n",
    "            model.add(Magnitude())\n",
    "            # (batch, n_frame=3, n_freq=n_fft // 2 + 1, ch=1) and dtype is float\n",
    "            model.add(ApplyFilterbank(type='mel', filterbank_kwargs=kwargs))\n",
    "            # (batch, n_frame=3, n_mels=128, ch=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, type, filterbank_kwargs, data_format='default', **kwargs,\n",
    "    ):\n",
    "\n",
    "        kapre.backend.validate_data_format_str(data_format)\n",
    "\n",
    "        self.type = type\n",
    "        self.filterbank_kwargs = filterbank_kwargs\n",
    "\n",
    "        if type == 'log':\n",
    "            self.filterbank = _log_filterbank = filterbank_log(**filterbank_kwargs)\n",
    "        elif type == 'mel':\n",
    "            self.filterbank = _mel_filterbank = filterbank_mel(**filterbank_kwargs)\n",
    "\n",
    "        if data_format == _CH_DEFAULT_STR:\n",
    "            self.data_format = K.image_data_format()\n",
    "        else:\n",
    "            self.data_format = data_format\n",
    "\n",
    "        if self.data_format == _CH_FIRST_STR:\n",
    "            self.freq_axis = 3\n",
    "        else:\n",
    "            self.freq_axis = 2\n",
    "        super(ApplyFilterbank, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Apply filterbank to `x`.\n",
    "        Args:\n",
    "            x (`Tensor`): float tensor in 2D batch shape.\n",
    "        \"\"\"\n",
    "\n",
    "        # x: 2d batch input. (b, t, fr, ch) or (b, ch, t, fr)\n",
    "        output = tf.tensordot(x, self.filterbank, axes=(self.freq_axis, 0))\n",
    "        # ch_last -> (b, t, ch, new_fr). ch_first -> (b, ch, t, new_fr)\n",
    "        if self.data_format == _CH_LAST_STR:\n",
    "            output = tf.transpose(output, (0, 1, 3, 2))\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ApplyFilterbank, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'type': self.type,\n",
    "                'filterbank_kwargs': self.filterbank_kwargs,\n",
    "                'data_format': self.data_format,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "#AUCORESNET V2 \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Lambda, Activation, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import Concatenate, Add\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, LambdaCallback, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import os\n",
    "from tf_siren import SinusodialRepresentationDense, Sine\n",
    "from matplotlib import pyplot as plt\n",
    "from kapre.time_frequency import (\n",
    "    STFT,\n",
    "    InverseSTFT,\n",
    "    Phase,\n",
    "    MagnitudeToDecibel, \n",
    "    ConcatenateFrequencyMap,\n",
    "    Magnitude\n",
    ")\n",
    "import kapre\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "#from spela.melspectrogram import Melspectrogram, Spectrogram\n",
    "\n",
    "import math\n",
    "class MagnitudeTR(Layer):\n",
    "\n",
    "  def __init__(self, trainable, **kwargs):\n",
    "    super(MagnitudeTR, self).__init__(**kwargs)\n",
    "    self.trainable = trainable\n",
    "\n",
    "    \"\"\"Compute the magnitude of the complex input, resulting in a float tensor\n",
    "    Example:\n",
    "        ::\n",
    "            input_shape = (2048, 1)  # mono signal\n",
    "            model = Sequential()\n",
    "            model.add(kapre.STFT(n_fft=1024, hop_length=512, input_shape=input_shape))\n",
    "            mode.add(Magnitude())\n",
    "            # now the shape is (batch, n_frame=3, n_freq=513, ch=1) and dtype is float\n",
    "    \"\"\"\n",
    "  def build(self, input_shape):\n",
    "        \n",
    "        self.u = self.add_weight(  shape=(input_shape[3], 1), initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        #self.kernel = self.add_weight(name='kernel',  initializer=tf.keras.initializers.GlorotUniform(), \n",
    "        #                               trainable=True,\n",
    "                                      #shape=(input_shape[-1], input_shape[-2]))\n",
    "        #                              shape=( input_shape[3], input_shape[2]))\n",
    "        super(MagnitudeTR, self).build(input_shape)\n",
    "\n",
    "  def call(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (complex `Tensor`): input complex tensor\n",
    "        Returns:\n",
    "            (float `Tensor`): magnitude of `x`\n",
    "        \"\"\"\n",
    "        xr = tf.math.real(x)\n",
    "        #xr = tf.reshape(xr,(tf.shape(xr)[0],tf.shape(xr)[1]))\n",
    "        if self.trainable:\n",
    "          xr = K.dot(xr,self.u)\n",
    "          #xr = tf.reshape(xr,(tf.shape(xr)[1],tf.shape(xr)[0], 1))\n",
    "\n",
    "        #tf.shape(xr)\n",
    "        #xr = xr.numpy()\n",
    "        xi = tf.math.imag(x)\n",
    "        #xr1 = tf.Variable(xr,trainable=self.trainable)\n",
    "        xb = tf.complex(xr,xi)\n",
    "        #x = tf.Variable(lambda:tf.math.abs(x),trainable=self.trainable)\n",
    "        \n",
    "        return tf.abs(xb)\n",
    "        #return tf.abs(x)\n",
    "#from tensorflow.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "#get_custom_objects().update({'custom_activation': SineReLU()})\n",
    "def sinc(x):\n",
    "    tf.keras.activations.swish(x)\n",
    "    #return  K.exp(-K.pow(x,2))\n",
    "    #x = tf.where(tf.abs(x) < 1e-20, 1e-20 * tf.ones_like(x), x)\n",
    "    #return tf.sin(x) / x\n",
    "\n",
    "class AUCOResNetV2:\n",
    "    def __init__(self, att='att2', gmode='concat', compatibilityfunction='pc', datasetname=\"covid\", input_shape=(1,64000),\n",
    "                 outputclasses=100, weight_decay=0.0005, optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy', 'AUC'],\n",
    "                 runs = [1, 8, 3, 5, 4], n_fft=1024,sample_rate=22050,n_mels=128, win_length =160, hop_length=344, \n",
    "                 return_decibel=True,input_data_format='channels_first', sinusoidal = False, trainable = True, pers_act = 'elu', attention_type='cbam_block',subsample_initial_block = True,strides=(2,2) , \n",
    "                 filters = 64, initial_kernel = (7, 7),debug=False):\n",
    "        \n",
    "        inputs = Input(shape=input_shape) #batch*x*y*3\n",
    "        self.history = None\n",
    "\n",
    "        #Layer 1\n",
    "        '''\n",
    "        if trainable:\n",
    "          fft_base_2 = pow(2, math.ceil(math.log(n_fft)/math.log(2)));\n",
    "\n",
    "          x = Melspectrogram(sr=sample_rate, n_mels=n_mels,n_dft=fft_base_2,  n_hop=hop_length, input_shape=input_shape,return_decibel_melgram=True, trainable_kernel=False,  trainable_fb=True) (inputs)\n",
    "          #x = Spectrogram( n_dft=fft_base_2, n_hop=hop_length, input_shape=(input_shape), win_length=win_length, return_decibel_spectrogram=True, power_spectrogram=2.0, trainable_kernel=True, name='static_stft') (inputs)\n",
    "          #x = Normalization2D(str_axis='freq')(x)\n",
    "        else:\n",
    "        '''\n",
    "        x = self.get_melspectrogram_layer(name='mel',n_fft=n_fft,sample_rate=sample_rate,n_mels=n_mels, hop_length=hop_length, return_decibel=return_decibel,input_data_format=input_data_format,  trainable = trainable, num_classes=outputclasses) (inputs)      \n",
    "        \n",
    "        if debug:\n",
    "          x = Conv2D(128,(1,1),  name='conv2dfirst')(x)\n",
    "        #x2 = get_log_frequency_spectrogram_layer(n_fft=2048,log_n_bins=84, sample_rate=16000,hop_length=344,input_data_format='channels_first',return_decibel=True)(inputs)\n",
    "\n",
    "        #x = keras.layers.Concatenate(axis=2)([x1,x2])#,x4])\n",
    "       \n",
    "        regularizer = keras.regularizers.l2(weight_decay)\n",
    "        self.datasetname = datasetname\n",
    "        self.outputclasses=outputclasses\n",
    "        #x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "        \n",
    "        if sinusoidal == False:\n",
    "            activ = pers_act\n",
    "        else:\n",
    "            print('ERROR --> Not implemented Sine Attention')\n",
    "            activ = 'relu'\n",
    "\n",
    "\n",
    "        if subsample_initial_block:\n",
    "          \n",
    "          initial_strides = strides\n",
    "        else:\n",
    "          \n",
    "          initial_strides = (1, 1)\n",
    "\n",
    "        x = Conv2D(filters, initial_kernel, kernel_initializer='he_normal', padding='same',\n",
    "               strides=initial_strides, use_bias=False, kernel_regularizer=regularizer)(x)\n",
    "        '''\n",
    "        if subsample_initial_block:\n",
    "          x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "          if sinusoidal == False:\n",
    "            x = Activation(pers_act)(x)\n",
    "          else:\n",
    "            x =Dentamaro(trainable=True)(x)\n",
    "          x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "        '''\n",
    "        x = attach_attention_module(x,'cbam_block',activation=activ, ratio = 2)\n",
    "        #END LAYER 1\n",
    "\n",
    "        #Layer 2\n",
    "        #block1, out batch*(x)*(y)*16\n",
    "\n",
    "        for i in range(0,runs[0]):\n",
    "          #if i == 0:\n",
    "          #   identity = Conv2D(filters,(2,2), padding='same', kernel_regularizer=regularizer, name='id1')(x)\n",
    "          x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer)(x)\n",
    "          x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "          if sinusoidal == False:\n",
    "            x = Activation(pers_act)(x)\n",
    "          else:\n",
    "            x =Dentamaro(trainable=True)(x)\n",
    "          #x = attach_attention_module(x,attention_type)\n",
    "          x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer)(x) #batch*x*y*16\n",
    "          x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "          if sinusoidal == False:\n",
    "            x = Activation(pers_act)(x)\n",
    "          else:\n",
    "            x =Dentamaro(trainable=True)(x)\n",
    "          #x = Add()([identity,x])\n",
    "        x = attach_attention_module(x,attention_type,activation=activ)\n",
    "\n",
    "        #x = Add()([identity,x])\n",
    "        #END Layer 2\n",
    "        \n",
    "        #Layer 3\n",
    "        #block2, out batch*(x/2)*(y/2)*64\n",
    "        for i in range(0,runs[1]):#was 18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters,(2,2), padding='same', kernel_regularizer=regularizer, name='block2dimchangeconv')(identity)\n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block2resblock'+str((i+1))+'conv1')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (3, 3), padding='same', kernel_regularizer=regularizer, name='block2resblock'+str((i+1))+'conv2')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer, name='block2resblock'+str((i+1))+'conv3')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "        \n",
    "        l1 = x #16 filters, 32x32 resolution\n",
    "        f1 = filters\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block2pool')(x)\n",
    "\n",
    "        #END Layer 3\n",
    "        #Layer 4\n",
    "\n",
    "        filters *= 2\n",
    "\n",
    "        #block3, out batch*(x/4)*(y/4)*128\n",
    "        for i in range(0,runs[2]):#was18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters, (2,2), padding='same', kernel_regularizer=regularizer, name='block3dimchangeconv')(identity)            \n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block3resblock'+str((i+1))+'conv1')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block3resblock'+str((i+1))+'conv2')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer, name='block3resblock'+str((i+1))+'conv3')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "        f2 = filters\n",
    "        l2 = x #256 filters, 16x16 resolution\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block3pool')(x)\n",
    "        #END Layer 4\n",
    "\n",
    "        #Layer 5\n",
    "        filters *= 2\n",
    "        #block4, out batch*(x/4)*(y/4)*256\n",
    "        for i in range(0,runs[3]):#was18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters, (2,2), padding='same', kernel_regularizer=regularizer, name='block4dimchangeconv')(identity)            \n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block4resblock'+str((i+1))+'conv1')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (3, 3), padding='same', kernel_regularizer=regularizer, name='block4resblock'+str((i+1))+'conv2')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer, name='block4resblock'+str((i+1))+'conv3')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "        l3 = x #512 filters, 8x8 resolution\n",
    "        f3 = filters\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block4pool')(x)#aggiunto\n",
    "        #END Layer 5\n",
    "        #Layer 6\n",
    "\n",
    "        filters *= 2\n",
    "        #block4, out batch*(x/4)*(y/4)*256\n",
    "        for i in range(0,runs[4]):#was18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters, (2,2), padding='same', kernel_regularizer=regularizer)(identity)            \n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer)(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (3, 3), padding='same', kernel_regularizer=regularizer)(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer)(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x) \n",
    "        l4 = x  \n",
    "        f4 = filters\n",
    "        \n",
    "        x = Conv2D(filters, (3, 3), padding='same', kernel_regularizer=regularizer, name='outconv')(x) \n",
    "        x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "        x = MaxPooling2D((2,2), strides=(2,2), name=\"gpool\")(x)\n",
    "        x = attach_attention_module(x,'cbam_block',activation=activ, ratio = 2)\n",
    "\n",
    "        gbase = Flatten(name='pregflatten')(x)\n",
    "        if True:\n",
    "          g64 = SinusodialRepresentationDense(f1, activation='sine', w0=1.0)(gbase)#added now 0.406\n",
    "          g128 = SinusodialRepresentationDense(f2, activation='sine', w0=1.0)(gbase)#added now \n",
    "          g256 = SinusodialRepresentationDense(f3, activation='sine', w0=1.0)(gbase)#added now \n",
    "          g4 = SinusodialRepresentationDense(f4, activation='sine', w0=1.0)(gbase)#added now \n",
    "        else:\n",
    "          g64 = Dense(f1, kernel_regularizer=regularizer, name='globalg64',activation=pers_act)(gbase)\n",
    "          g128 = Dense(f2, kernel_regularizer=regularizer, name='globalg128',activation=pers_act)(gbase)\n",
    "          g256 = Dense(f3, kernel_regularizer=regularizer, name='globalg256',activation=pers_act)(gbase)    \n",
    "          g4 = Dense(f4, kernel_regularizer=regularizer, name='globalg4',activation=pers_act)(gbase)       \n",
    "\n",
    "        #Learnable attention\n",
    "        c1 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc1')([l1, g64])  # batch*x*y\n",
    "        if compatibilityfunction == 'mha':\n",
    "            c1 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l1, g64])\n",
    "        if compatibilityfunction == 'dp':\n",
    "            c1 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp1')([l1, g64])  # batch*x*y\n",
    "        flatc1 = Flatten(name='flatc1')(c1)  # batch*xy\n",
    "        a1 = Activation('softmax', name='softmax1')(flatc1)  # batch*xy\n",
    "        reshaped1 = Reshape((-1,f1), name='reshape1')(l1)  # batch*xy*256.\n",
    "        if compatibilityfunction == 'mha':\n",
    "            g1 = a1\n",
    "        else:\n",
    "            g1 = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g1')([a1, reshaped1])  # batch*256.\n",
    "        \n",
    "        c2 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc2')([l2, g128])\n",
    "        if compatibilityfunction == 'mha':\n",
    "            c2 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l2, g128])\n",
    "        if compatibilityfunction == 'dp':\n",
    "            c2 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp2')([l2, g128])\n",
    "        flatc2 = Flatten(name='flatc2')(c2)\n",
    "        a2 = Activation('softmax', name='softmax2')(flatc2)\n",
    "        reshaped2 =  Reshape((-1,f2), name='reshape2')(l2)\n",
    "        if compatibilityfunction == 'mha':\n",
    "            g2 = a2\n",
    "        else:\n",
    "            g2 = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g2')([a2, reshaped2])\n",
    "\n",
    "        c3 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc3')([l3, g256])\n",
    "        if compatibilityfunction == 'mha':\n",
    "            c3 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l3, g256])\n",
    "        if compatibilityfunction == 'dp':\n",
    "            c3 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp3')([l3, g256])\n",
    "        flatc3 = Flatten(name='flatc3')(c3)\n",
    "        a3 = Activation('softmax', name='softmax3')(flatc3)\n",
    "        reshaped3 = Reshape((-1,f3), name='reshape3')(l3)\n",
    "        if compatibilityfunction == 'mha':\n",
    "            g3 = a3\n",
    "        else:\n",
    "            g3 = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g3')([a3, reshaped3])\n",
    "        \n",
    "        if runs[4] > 0:\n",
    "          c4 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc4')([l4, g4])\n",
    "          if compatibilityfunction == 'mha':\n",
    "              c4 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l4, g4])\n",
    "          if compatibilityfunction == 'dp':\n",
    "              c4 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp4')([l4, g4])\n",
    "          flatc4 = Flatten(name='flatc4')(c4)\n",
    "          a4 = Activation('softmax', name='softmax4')(flatc4)\n",
    "          reshaped4 = Reshape((-1,f4), name='reshape4')(l4)\n",
    "          if compatibilityfunction == 'mha':\n",
    "              g4_ = a4\n",
    "          else:\n",
    "              g4_ = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g4')([a4, reshaped4])\n",
    "\n",
    "        out = ''\n",
    "        if gmode == 'concat':\n",
    "            if runs[4] > 0:\n",
    "              glist = [g4_, g3, g2, g1]\n",
    "            else:\n",
    "              glist = [g3, g2, g1]\n",
    "            predictedG = Concatenate(axis=1, name='ConcatG')(glist)\n",
    "            x = Dense(outputclasses, kernel_regularizer=regularizer, name=str(outputclasses)+'ConcatG')(predictedG)\n",
    "            out = Activation(\"softmax\", name='concatsoftmaxout')(x)\n",
    "            \n",
    "        else:\n",
    "            gd3 = Dense(outputclasses, activation='softmax', name=str(outputclasses)+'indepsoftmaxg3')(g3)\n",
    "            gd4 = Dense(outputclasses, activation='softmax', name=str(outputclasses)+'indepsoftmaxg4')(g4_)\n",
    "            gd2 = Dense(outputclasses, activation='softmax', kernel_regularizer=regularizer, name=str(outputclasses)+'indepsoftmaxg2')(g2)\n",
    "            gd1 = Dense(outputclasses, activation='softmax', kernel_regularizer=regularizer, name=str(outputclasses)+'indepsoftmaxg1')(g1)\n",
    "            if runs[4] > 0:\n",
    "              out = Add(name='addg4g3g2g1')([gd1, gd2, gd3, gd4])\n",
    "              out = Lambda(lambda lam: lam/4, name='4average')(out)\n",
    "            else:\n",
    "              out = Add(name='addg4g3g2g1')([gd1, gd2, gd3])\n",
    "              out = Lambda(lambda lam: lam/3, name='4average')(out)\n",
    "\n",
    "        #END Layer 6\n",
    "        model = Model(inputs=inputs, outputs=out)\n",
    "        \n",
    "      \n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)#, run_eagerly=True)\n",
    "        tf.keras.utils.plot_model(\n",
    "            model, to_file='model.png', show_shapes=True, show_dtype=True,\n",
    "            show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
    "        )\n",
    "        name = (\"(RN-\"+att+\")-\"+gmode+\"-\"+compatibilityfunction).replace('att)', 'att1)')\n",
    "        print(\"Generated \"+name)\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "    \n",
    "    def StandardFit(self, datasetname=None, X=[], Y=[],initial_lr=0.01, min_delta=None, patience=3, datagen = None, validation_data=None, lrplateaufactor=None, lrplateaupatience=4, validation_split=0.3,batch_size=16,epochs=100,checkpointcall=None, class_weights=None, monitor_early='val_auc'):\n",
    "        #Y = keras.utils.to_categorical(Y,self.outputclasses)\n",
    "        if datasetname==None:\n",
    "            datasetname=self.datasetname\n",
    "        if os.path.isfile(\"weights/\"+self.name+\"-\"+datasetname+\" early.hdf5\"):\n",
    "            print(\"Found early-stopped weights for \"+self.name+\"-\"+datasetname)\n",
    "            return\n",
    "        scheduler = LearningRateScaler([20, 50, 80], 0.2, initial_lr)\n",
    "        \n",
    "        tboardcb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=3, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "        if checkpointcall ==None:\n",
    "            checkpoint = ModelCheckpoint(\"weights/\"+self.name+\"-\"+datasetname+\" {epoch}.hdf5\", \n",
    "                                         save_weights_only=True,monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "        else:\n",
    "            checkpoint = checkpointcall\n",
    "        epochprint = LambdaCallback(on_epoch_end=lambda epoch, logs: print(\"Passed epoch \"+str(epoch)))\n",
    "        \n",
    "        callbackslist = [ checkpoint, epochprint]#, tboardcb]\n",
    " \n",
    "         \n",
    "        if min_delta != None:\n",
    "              callbackslist.append(EarlyStopping(monitor=monitor_early, min_delta=min_delta, patience=patience))\n",
    "        if lrplateaufactor != None:\n",
    "              callbackslist.append(ReduceLROnPlateau(monitor='auc', factor = lrplateaufactor, patience = lrplateaupatience))\n",
    "        if lrplateaufactor != None:\n",
    "              callbackslist.append(ReduceLROnPlateau(monitor='accuracy', factor = lrplateaufactor, patience = lrplateaupatience))\n",
    "        if datagen != None:\n",
    "          self.history = self.model.fit(datagen, epochs=epochs, callbacks=callbackslist, shuffle=False,\n",
    "                               validation_data=(validation_data[0],validation_data[1]), verbose=1)\n",
    "        else:  \n",
    "          if validation_data == None:\n",
    "              self.history = self.model.fit(X, Y,  batch_size=batch_size, epochs=epochs, \n",
    "                                            callbacks=callbackslist, shuffle=False,validation_split=validation_split, verbose=1, class_weight=class_weights)#,class_weight=class_weights)    \n",
    "          else:\n",
    "              self.history = self.model.fit(X, Y,  batch_size=batch_size, epochs=epochs, callbacks=callbackslist, shuffle=False,\n",
    "                            validation_data=(validation_data[0],validation_data[1]), verbose=1, class_weight=class_weights)#,class_weight=class_weights)     \n",
    "        \n",
    "        \n",
    "        return self.model\n",
    "        \n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def save_plot(self, filename, history=None, title='AUCO ResNet Accuracy'):\n",
    "        \n",
    "        if history == None:\n",
    "            history = self.history\n",
    "       \n",
    "        plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "            \n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        #plt.plot(history.history['loss'])\n",
    "        #plt.plot(history.history['val_loss'])\n",
    "        plt.plot(history.history['auc'])\n",
    "        plt.plot(history.history['val_auc'])\n",
    "            \n",
    "\n",
    "        plt.title(title)\n",
    "        plt.ylabel('Accuracy / AUC')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['training accuracy', 'validation accuracy','training AUC','validation AUC'], loc='upper left')\n",
    "        plt.savefig(filename, format=\"svg\", cmap='nipy_spectral')\n",
    "        f = plt.figure()\n",
    "        f.clear()\n",
    "        plt.close(f)\n",
    "        plt.close('all')\n",
    "\n",
    " \n",
    "    def get_melspectrogram_layer(self,\n",
    "        input_shape=None,\n",
    "        n_fft=2048,\n",
    "        win_length=None,\n",
    "        hop_length=None,\n",
    "        window_name=None,\n",
    "        pad_begin=False,\n",
    "        pad_end=False,\n",
    "        sample_rate=22050,\n",
    "        n_mels=128,\n",
    "        mel_f_min=0.0,\n",
    "        mel_f_max=None,\n",
    "        mel_htk=False,\n",
    "        mel_norm='slaney',\n",
    "        return_decibel=False,\n",
    "        db_amin=1e-5,\n",
    "        db_ref_value=1.0,\n",
    "        db_dynamic_range=80.0,\n",
    "        input_data_format='default',\n",
    "        output_data_format='default',\n",
    "        trainable = True,\n",
    "        name='melspectrogram',\n",
    "        num_classes=2,\n",
    "    ):\n",
    "        \"\"\"A function that returns a melspectrogram layer, which is a `keras.Sequential` model consists of\n",
    "        `STFT`, `Magnitude`, `ApplyFilterbank(_mel_filterbank)`, and optionally `MagnitudeToDecibel`.\n",
    "        Args:\n",
    "            input_shape (None or tuple of integers): input shape of the model. Necessary only if this melspectrogram layer is\n",
    "                is the first layer of your model (see `keras.model.Sequential()` for more details)\n",
    "            n_fft (int): number of FFT points in `STFT`\n",
    "            win_length (int): window length of `STFT`\n",
    "            hop_length (int): hop length of `STFT`\n",
    "            window_name (str or None): *Name* of `tf.signal` function that returns a 1D tensor window that is used in analysis.\n",
    "                Defaults to `hann_window` which uses `tf.signal.hann_window`.\n",
    "                Window availability depends on Tensorflow version. More details are at `kapre.backend.get_window()`.\n",
    "            pad_begin (bool): Whether to pad with zeros along time axis (length: win_length - hop_length). Defaults to `False`.\n",
    "            pad_end (bool): whether to pad the input signal at the end in `STFT`.\n",
    "            sample_rate (int): sample rate of the input audio\n",
    "            n_mels (int): number of mel bins in the mel filterbank\n",
    "            mel_f_min (float): lowest frequency of the mel filterbank\n",
    "            mel_f_max (float): highest frequency of the mel filterbank\n",
    "            mel_htk (bool): whether to follow the htk mel filterbank fomula or not\n",
    "            mel_norm ('slaney' or int): normalization policy of the mel filterbank triangles\n",
    "            return_decibel (bool): whether to apply decibel scaling at the end\n",
    "            db_amin (float): noise floor of decibel scaling input. See `MagnitudeToDecibel` for more details.\n",
    "            db_ref_value (float): reference value of decibel scaling. See `MagnitudeToDecibel` for more details.\n",
    "            db_dynamic_range (float): dynamic range of the decibel scaling result.\n",
    "            input_data_format (str): the audio data format of input waveform batch.\n",
    "                `'channels_last'` if it's `(batch, time, channels)`\n",
    "                `'channels_first'` if it's `(batch, channels, time)`\n",
    "                Defaults to the setting of your Keras configuration. (tf.keras.backend.image_data_format())\n",
    "            output_data_format (str): the data format of output melspectrogram.\n",
    "                `'channels_last'` if you want `(batch, time, frequency, channels)`\n",
    "                `'channels_first'` if you want `(batch, channels, time, frequency)`\n",
    "                Defaults to the setting of your Keras configuration. (tf.keras.backend.image_data_format())\n",
    "            name (str): name of the returned layer\n",
    "        Note:\n",
    "            Melspectrogram is originally developed for speech applications and has been *very* widely used for audio signal\n",
    "            analysis including music information retrieval. As its mel-axis is a non-linear compression of (linear)\n",
    "            frequency axis, a melspectrogram can be an efficient choice as an input of a machine learning model.\n",
    "            We recommend to set `return_decibel=True`.\n",
    "            **References**:\n",
    "            `Automatic tagging using deep convolutional neural networks <https://arxiv.org/abs/1606.00298>`_,\n",
    "            `Deep content-based music recommendation <http://papers.nips.cc/paper/5004-deep-content-based-music-recommen>`_,\n",
    "            `CNN Architectures for Large-Scale Audio Classification <https://arxiv.org/abs/1609.09430>`_,\n",
    "            `Multi-label vs. combined single-label sound event detection with deep neural networks <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.711.74&rep=rep1&type=pdf>`_,\n",
    "            `Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification <https://arxiv.org/pdf/1608.04363.pdf>`_,\n",
    "            and way too many speech applications.\n",
    "        Example:\n",
    "            ::\n",
    "                input_shape = (2, 2048)  # stereo signal, audio is channels_first\n",
    "                melgram = get_melspectrogram_layer(input_shape=input_shape, n_fft=1024, return_decibel=True,\n",
    "                    n_mels=96, input_data_format='channels_first', output_data_format='channels_last')\n",
    "                model = Sequential()\n",
    "                model.add(melgram)\n",
    "                # now the shape is (batch, n_frame=3, n_mels=96, n_ch=2) because output_data_format is 'channels_last'\n",
    "                # and the dtype is float\n",
    "        \"\"\"\n",
    "        kapre.backend.validate_data_format_str(input_data_format)\n",
    "        kapre.backend.validate_data_format_str(output_data_format)\n",
    "\n",
    "        stft_kwargs = {}\n",
    "        if input_shape is not None:\n",
    "            stft_kwargs['input_shape'] = input_shape\n",
    "\n",
    "        waveform_to_stft = STFT(\n",
    "            **stft_kwargs,\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            window_name=window_name,\n",
    "            pad_begin=pad_begin,\n",
    "            pad_end=pad_end,\n",
    "            input_data_format=input_data_format,\n",
    "            output_data_format=output_data_format,\n",
    "        )\n",
    "\n",
    "        stft_to_stftm = Magnitude()\n",
    "\n",
    "        kwargs = {\n",
    "            'sample_rate': sample_rate,\n",
    "            'n_freq': n_fft // 2 + 1,\n",
    "            'n_mels': n_mels,\n",
    "            'f_min': mel_f_min,\n",
    "            'f_max': mel_f_max,\n",
    "            'htk': mel_htk,\n",
    "            'trainable': trainable,\n",
    "            'norm': mel_norm,\n",
    "            'num_classes':num_classes,\n",
    "        }\n",
    "        stftm_to_melgram = ApplyFilterbank(\n",
    "            type='mel', filterbank_kwargs=kwargs, data_format=output_data_format\n",
    "        )\n",
    "\n",
    "        \n",
    "        mag_to_decibel = MagnitudeToDecibel(\n",
    "                ref_value=db_ref_value, amin=db_amin, dynamic_range=db_dynamic_range\n",
    "            )\n",
    " \n",
    "         \n",
    "        layers = [waveform_to_stft, stft_to_stftm, stftm_to_melgram, mag_to_decibel] \n",
    "        return Sequential(layers, name=name)\n",
    "        \n",
    "\n",
    "class TrainableMel(Layer):\n",
    "\n",
    "    def __init__(self, kernel_regularizer=None, **kwargs):\n",
    "        super(TrainableMel, self).__init__(**kwargs)\n",
    "        if kernel_regularizer == None:\n",
    "          self.regularizer = keras.regularizers.l2(0.0005)#era 0.0005\n",
    "        else:\n",
    "          self.regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel',  initializer=tf.keras.initializers.GlorotUniform(), \n",
    "                                      regularizer = self.regularizer, trainable=True,\n",
    "                                      #shape=(input_shape[-1], input_shape[-2]))\n",
    "                                      shape=(input_shape[1], input_shape[2], input_shape[3]))\n",
    "        super(TrainableMel, self).build(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        \n",
    "        return config\n",
    "\n",
    "    def call(self, x):  \n",
    "        \n",
    "        #Hadamard product\n",
    "        #K.print_tensor(x, message='x = ')\n",
    "        #return x * self.kernel\n",
    "        return x*self.kernel\n",
    "        #return tf.keras.backend.dot(x,self.kernel)\n",
    "\n",
    "\n",
    "class ParametrisedCompatibility(Layer):\n",
    "\n",
    "    def __init__(self, kernel_regularizer=None, **kwargs):\n",
    "        super(ParametrisedCompatibility, self).__init__(**kwargs)\n",
    "        self.regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.u = self.add_weight(name='u', shape=(input_shape[0][3], 1), initializer='uniform',\n",
    "                                 regularizer=self.regularizer, trainable=True)\n",
    "        super(ParametrisedCompatibility, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):  # add l and g. Dot the sum with u.\n",
    "        return K.dot(K.map_fn(lambda lam: (lam[0]+lam[1]),elems=(x),dtype='float32'), self.u)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], input_shape[0][2])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        \n",
    "        return config\n",
    "\n",
    "\n",
    "\n",
    "class Dentamaro(Layer):\n",
    "\n",
    "    def __init__(self, alpha=1.0,  trainable=True, **kwargs):\n",
    "        super(Dentamaro, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.alpha = alpha\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.alpha_factor = K.variable(self.alpha,\n",
    "                                      dtype=K.floatx(),\n",
    "                                      name='alpha_factor')\n",
    "        if self.trainable:\n",
    "            self._trainable_weights.append(self.alpha_factor)\n",
    "\n",
    "        super(Dentamaro, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = inputs\n",
    "        #x +1 - (cos( 4x)-x/1.5) /(e^(-x/4)) \n",
    "        #t = x-tf.exp(x/self.alpha_factor) * (tf.cos(self.alpha_factor*x)-self.beta_factor*x) +1\n",
    "        #da provare ( sin(5x)/3 -1)+  e^x\n",
    "        #t = (tf.sin(self.alpha_factor*x)/self.beta_factor) -1 + x#tf.math.abs(x)#tf.math.log(1+tf.math.abs(x))#+ 2**x\n",
    "        #t = x + (1 - tf.sin(self.alpha_factor*x) +x/self.beta_factor) / self.alpha_factor\n",
    "        #t = (tf.sin(self.alpha_factor*x)/self.beta_factor)*tf.math.abs(x)+x\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        return tf.sin(self.alpha_factor*x)#(1-x*x)*tf.exp(-self.alpha_factor*x*x)\n",
    "        #or\n",
    "        #return 2.0*tf.sin(tf.pi*x)*x*tf.exp(-self.alpha_factor*x*x)\n",
    "        #\n",
    "        #return tf.sin(x*self.alpha_factor)#x + (1 - tf.cos(2 * self.alpha_factor * x)) / (2 * self.alpha_factor)\n",
    "        #return t\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'alpha': self.get_weights()[0] if self.trainable else self.alpha,\n",
    "                  'trainable': self.trainable}\n",
    "        base_config = super(Dentamaro, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "class TrainedKLDivergence(Layer):\n",
    "    #Dentamaro et al.\n",
    "    def __init__(self, kernel_regularizer=None, **kwargs):\n",
    "        super(TrainedKLDivergence, self).__init__(**kwargs)\n",
    "        self.regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.u = self.add_weight(name='u', shape=(input_shape[0][3], 1), initializer='uniform', regularizer=self.regularizer, trainable=True)\n",
    "        super(TrainedKLDivergence, self).build(input_shape)\n",
    "\n",
    "    '''\n",
    "    ## normalize p, q to probabilities\n",
    "    p, q = p/p.sum(), q/q.sum()\n",
    "    m = 1./2*(p + q)\n",
    "    return sp.stats.entropy(p,m, base=base)/2. +  sp.stats.entropy(q, m, base=base)/2.\n",
    "    '''\n",
    "\n",
    "    def call(self, x):\n",
    "        # Kullback-Leibler divergence \n",
    "\n",
    "        #p = x[0] / K.sum(x[0])\n",
    "        #q = x[1] / K.sum(x[1])\n",
    "        \n",
    "        mapping = K.map_fn(lambda lam: (K.pow(2.718,(lam[0]+lam[1]))),elems=(x),dtype='float32')\n",
    "        \n",
    "        #Dot the sum with u.\n",
    "        return K.dot(mapping, self.u)\n",
    "        #return K.dot(K.map_fn(lambda lam: (lam[0]+lam[1]),elems=(x),dtype='float32'), self.u)\n",
    "\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], input_shape[0][2])\n",
    "    def logbase(self, x,base):\n",
    "        numerator = K.log(x)\n",
    "        denominator = K.log(base)\n",
    "        return numerator / denominator\n",
    "\n",
    "       \n",
    "class LearningRateScaler(Callback):\n",
    "    \n",
    "    def __init__(self, epochs, multiplier, initial_lr=None):\n",
    "        self.multiplier = multiplier\n",
    "        self.epochs = epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.startingepoch = True\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if self.initial_lr == None:\n",
    "            self.initial_lr = K.get_value(self.model.optimizer.lr)\n",
    "        print(\"Initial lr=\"+str(self.initial_lr))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        #print(\"Current lr: \" + str(K.get_value(self.model.optimizer.lr)))\n",
    "        lr = self.initial_lr\n",
    "        #print('epochs')\n",
    "        #print(self.epochs)\n",
    "        if epoch>0 and epoch in self.epochs:\n",
    "                for i in range(0, self.epochs.index(epoch)+1):\n",
    "                    lr = lr * self.multiplier\n",
    "                K.set_value(self.model.optimizer.lr, lr)\n",
    "                #print(\"Updated learning rate to \"+str(lr))    \n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        startingepoch = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Fqx2XAv_ZIpU"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "aa = []\n",
    "saucs = []\n",
    "saa = []\n",
    "histories = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-kAqFfkT0d_",
    "outputId": "4445d588-6f1e-4556-af7a-2a3d963e5fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n",
      "minority class [0. 1.]\n",
      "minority people 43\n",
      "ACtivation  elu\n",
      "Sinusoida  False\n",
      "Attention is  se_block\n",
      "Subsample is  True\n",
      "AUCS len 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF shape (65, 150)\n",
      "Trainable mel spectrogram is True\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\backend.py:6309: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Generated (RN-att3)-concat-cp\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13076/3442333354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m           AUCOResNetV2_.StandardFit(datasetname='covid',X=X_train,Y=y_train,patience=5,validation_data=(X_test,y_test),\n\u001b[0m\u001b[0;32m    181\u001b[0m                                     batch_size=batch_size,epochs=100,checkpointcall = model_checkpoint_callback)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13076/939010016.py\u001b[0m in \u001b[0;36mStandardFit\u001b[1;34m(self, datasetname, X, Y, initial_lr, min_delta, patience, datagen, validation_data, lrplateaufactor, lrplateaupatience, validation_split, batch_size, epochs, checkpointcall, class_weights, monitor_early)\u001b[0m\n\u001b[0;32m    957\u001b[0m                                             callbacks=callbackslist, shuffle=False,validation_split=validation_split, verbose=1, class_weight=class_weights)#,class_weight=class_weights)    \n\u001b[0;32m    958\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m               self.history = self.model.fit(X, Y,  batch_size=batch_size, epochs=epochs, callbacks=callbackslist, shuffle=False,\n\u001b[0m\u001b[0;32m    960\u001b[0m                             validation_data=(validation_data[0],validation_data[1]), verbose=1, class_weight=class_weights)#,class_weight=class_weights)     \n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m                **kwargs):\n\u001b[0;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "#from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "\n",
    "def concilie_per_patient_res(predx, y_test, usercodes):\n",
    "    new_pred = []\n",
    "    new_y_test = []\n",
    "     \n",
    "    #print('Prediced shape')\n",
    "    #print(predx.shape)\n",
    "    \n",
    "    if y_test.shape[-1] < 2:\n",
    "      y_test = to_categorical(y_test)\n",
    "    patient = {}\n",
    "    for i in range(len(y_test)):\n",
    "      if not usercodes[i] in patient:\n",
    "        patient[usercodes[i]] = {}\n",
    "        patient[usercodes[i]]['predicted'] = []\n",
    "        patient[usercodes[i]]['y_test'] = []               \n",
    "      patient[usercodes[i]]['predicted'].append(predx[i])\n",
    "      patient[usercodes[i]]['y_test'].append(y_test[i])\n",
    "      #print(patient[usercodes[i]]['predicted'])\n",
    "    keys = list(patient.keys())\n",
    "    for key in keys:\n",
    "       predi = patient[key]['predicted']\n",
    "       yi = patient[key]['y_test']\n",
    "       mean_pred = np.asarray(predi).mean(axis=0)\n",
    "       mean_y = np.asarray(yi).mean(axis=0)\n",
    "       #print('Mean pred shape '+str(mean_pred.shape))\n",
    "       #print('Mean y shape '+str(mean_y.shape))\n",
    "       new_pred.append(mean_pred)\n",
    "       new_y_test.append(mean_y)\n",
    "\n",
    "    new_pred = np.asarray(new_pred)\n",
    "    #print(new_pred.shape)\n",
    "    new_y_test = np.asarray(new_y_test)\n",
    "    #print(new_y_test.shape)\n",
    "\n",
    "    return new_pred, new_y_test\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "def report_average(reports):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for report in reports:\n",
    "        print(report)\n",
    "        accuracy.append(report['accuracy'])\n",
    "        precision.append(report['weighted avg']['precision'])\n",
    "        recall.append(report['weighted avg']['recall'])\n",
    "        f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "    print('Mean accuracy '+str(np.mean(accuracy)))\n",
    "    print('Mean precision ' + str(np.mean(precision)))\n",
    "    print('Mean recall ' + str(np.mean(recall)))\n",
    "    print('Mean F1 ' + str(np.mean(f1)))\n",
    "\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "def custom_act_dentamaro(x):#inserire formula qui\n",
    "    #x +1 - (cos( 4x)-x/1.5) /(e^(-x/4)) \n",
    "   x = tf.convert_to_tensor(x)\n",
    "   return x + (1 - tf.cos(2*x) +x/5) / 2\n",
    "    #return x + (1 - tf.cos(2 * frequency * x)) / (2 * frequency)\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "          \n",
    "tf.random.set_seed(42)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    #K.clear_session()#puliamo la ram della GPU \n",
    "    #tf.keras.backend.clear_session()\n",
    " \n",
    "    y_new = copy.deepcopy(np.asarray(y,dtype=np.float32))\n",
    "    X_new = copy.deepcopy(np.asarray(X,dtype=np.float32))\n",
    "    y_size = 0\n",
    "\n",
    "    X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2)\n",
    "   \n",
    "    input_shape = (1, X_train[0].shape[1])\n",
    "     \n",
    "    fft = 128 #1792#128 #arriva a 2048\n",
    "    optimizer = 'RMSprop'\n",
    "    batch_size = 16\n",
    "    \n",
    "\n",
    "    subsample = True\n",
    "    test_AUCO = True\n",
    "    for k in range(1):\n",
    "      model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='best_model_aucoresnet_covid_iteration_'+str(i)+'.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "    \n",
    "      sinusoidal = False\n",
    "      pers_act = 'elu'\n",
    "      attention_type='se_block'\n",
    "      kernel_size = (5,5)\n",
    "      batch_size = 8\n",
    "      if k == 1:\n",
    "        kernel_size = (7,7)\n",
    "        pers_act = 'relu'\n",
    "        sinusoidal = False \n",
    "        \n",
    "          \n",
    "      if k == 2:\n",
    "        kernel_size = (13,13)\n",
    "        pers_act = 'relu'\n",
    "        sinusoidal = False \n",
    "        #fft = fft  \n",
    "       \n",
    "     \n",
    "        \n",
    "        #fft =  fft + 128\n",
    "      #print('FFT is '+str(fft))\n",
    "      print('ACtivation ',pers_act)\n",
    "      print('Sinusoida ', sinusoidal)\n",
    "      print('Attention is ', attention_type)\n",
    "      print('Subsample is ', subsample)\n",
    "      \n",
    "      #print('Spiking is '+str(spiking))\n",
    "      model2 = None\n",
    "      if test_AUCO == True:\n",
    "          print('AUCS len', len(aucs))\n",
    "          #Layer 1 =  13% , layer 2 = 11%, Layer 3 17%, Layer 4 10%, Layer 5 26%, Layer 6 22%\n",
    "          \n",
    "          AUCOResNetV2_ =  AUCOResNetV2(att='att3',gmode='concat',sample_rate = SAMPLING_RATE,compatibilityfunction='cp',#cp, mha, dp\n",
    "                                        datasetname='covid',input_shape=input_shape,\n",
    "                                        outputclasses=2,runs=[1,8,3,7,2],n_mels=150, win_length=140, hop_length=344, strides=(3,3),\n",
    "                                        n_fft=fft, sinusoidal = sinusoidal, trainable=True,\n",
    "                                        metrics = ['accuracy', 'AUC'], pers_act = pers_act,attention_type=attention_type, optimizer=optimizer,\n",
    "                                        subsample_initial_block=subsample, initial_kernel=kernel_size, debug=False)#78 auc medio con cbam\n",
    "          \n",
    "          \n",
    "          AUCOResNetV2_.StandardFit(datasetname='covid',X=X_train,Y=y_train,patience=5,validation_data=(X_test,y_test),\n",
    "                                    batch_size=batch_size,epochs=100,checkpointcall = model_checkpoint_callback)\n",
    "          \n",
    "         \n",
    "          model2 = AUCOResNetV2_.model\n",
    "          \n",
    "          histories.append(AUCOResNetV2_.history)\n",
    "          AUCOResNetV2_.save_plot('Iteration_'+str(i)+'_fft_'+str(fft)+'_activation_'+str(pers_act)+'_sinusoidal_'+str(sinusoidal)+'_'+str(optimizer)+'.svg')\n",
    "          \n",
    "      else:\n",
    "          input_shape = (1, X_train[0].shape[1]) \n",
    "          \n",
    "          pre = keras.layers.Input(input_shape)\n",
    "            \n",
    "\n",
    "          pre = AUCOResNetV2().get_melspectrogram_layer(n_fft=fft,sample_rate=SAMPLING_RATE,n_mels=150, win_length=140, hop_length=344, input_data_format='channels_first',trainable = False) (pre)# NICOLA QUI\n",
    "\n",
    "          #pre = AUCOResNetV2().get_log_frequency_spectrogram_layer(n_fft=2048,log_n_bins=84, sample_rate=16000,win_length=160,hop_length=344,input_data_format='channels_first',return_decibel=True, trainable=True)(pre)\n",
    "       \n",
    "\n",
    "          #concatenate both \n",
    "          x = tensorflow.keras.applications.ResNet50(\n",
    "              weights=None, input_tensor=pre,\n",
    "              include_top=False) \n",
    "          x.trainable = True\n",
    "\n",
    "          out = keras.layers.GlobalAveragePooling2D()(x.output)\n",
    "          #out = keras.layers.Dense(32,activation=pers_act)(out)\n",
    "          out = keras.layers.Dense(2,activation='softmax')(out)\n",
    "          model = keras.Model(inputs=x.input, outputs=out)\n",
    "\n",
    "          \n",
    "          model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy','AUC'])\n",
    "\n",
    "          history = model.fit(X_train,y_train, epochs=100, validation_data=(X_test,y_test), batch_size=batch_size,callbacks=[model_checkpoint_callback])\n",
    "          histories.append(history)\n",
    "          AUCOResNetV2().save_plot('Iteration_'+str(i)+'_fft_'+str(fft)+'_activation_'+str(pers_act)+'_DenseNet201_'+str(optimizer)+'.svg', history=history, title='DenseNet 201 Accuracy')\n",
    "          model2 = model\n",
    "        \n",
    "          \n",
    "          \n",
    "      if model2 != None:\n",
    "        model2.load_weights('best_model_aucoresnet_covid_iteration_'+str(i)+'.h5')\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "         \n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "        if sinusoidal:\n",
    "            saa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "        else:\n",
    "          aa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "        if sinusoidal:\n",
    "          saucs.append(roc_auc)\n",
    "        else:\n",
    "          aucs.append(roc_auc)\n",
    "        # Plot non-normalized confusion matrix\n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "\n",
    "print('Metric '+pers_act)\n",
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))\n",
    "\n",
    "print('Metric Sinusoidal')\n",
    "\n",
    "print(report_average(saa))\n",
    "print('AUC')\n",
    "print(np.mean(saucs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNVx_Dbrr-_u",
    "outputId": "2cd3c2af-e9f5-43e6-e040-3f56f5f8fc4b"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Metric '+pers_act)\n",
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))\n",
    "\n",
    "print('Metric Sinusoidal')\n",
    "\n",
    "print(report_average(saa))\n",
    "print('AUC')\n",
    "print(np.mean(saucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "AUCO ResNet Official Tensorflow-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
