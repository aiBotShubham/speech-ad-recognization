{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33392872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import pickle\n",
    "def load_data(in_dir):\n",
    "    f = open(in_dir,'rb')\n",
    "    train_data,train_label,valid_data,valid_label = pickle.load(f)\n",
    "    return train_data,train_label,valid_data,valid_label\n",
    "\n",
    "# data_path = 'adress_512.pkl'\n",
    "data_path = 'adress_Att_Net.pkl'\n",
    "checkpoint = 'checkpoint/'\n",
    "\n",
    "train_data,train_label,valid_data,valid_label = load_data(data_path)\n",
    "\n",
    "# converting training images into torch format\n",
    "train_x = train_data\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_label\n",
    "train_y = train_y.reshape(1392).astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "# shape of training data\n",
    "# train_x.shape, train_y.shape\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "# my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "# tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "# tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "CTX = torch.device('cuda')\n",
    "\n",
    "train_dataset = TensorDataset(train_x.to(CTX),train_y.to(CTX)) # create your datset\n",
    "\n",
    " # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09537d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "val_x = valid_data\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = valid_label\n",
    "val_y = val_y.reshape(74).astype(float);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "# shape of training data\n",
    "\n",
    "val_dataset = TensorDataset(val_x,val_y) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4701d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 64\n",
    "val_size = 297\n",
    "# train_size = train_x.size(0) - val_size \n",
    "\n",
    "# train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "# print(f\"Length of Train Data : {len(train_data)}\")\n",
    "# print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 2379\n",
    "#Length of Validation Data : 297\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_dataset,batch_size, shuffle = True, num_workers = 0)\n",
    "val_dl = DataLoader(val_dataset, batch_size*2, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d492176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images.to(CTX))                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.to(torch.int64).cuda())   # Calculate loss\n",
    "        acc = accuracy(out, labels.to(torch.int64).cuda())           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "\n",
    "class SpatialGroupEnhance(nn.Module):\n",
    "\n",
    "    def __init__(self, groups):\n",
    "        super().__init__()\n",
    "        self.groups=groups\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.weight=nn.Parameter(torch.zeros(1,groups,1,1))\n",
    "        self.bias=nn.Parameter(torch.zeros(1,groups,1,1))\n",
    "        self.sig=nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h,w=x.shape\n",
    "        x=x.view(b*self.groups,-1,h,w) #bs*g,dim//g,h,w\n",
    "        xn=x*self.avg_pool(x) #bs*g,dim//g,h,w\n",
    "        xn=xn.sum(dim=1,keepdim=True) #bs*g,1,h,w\n",
    "        t=xn.view(b*self.groups,-1) #bs*g,h*w\n",
    "\n",
    "        t=t-t.mean(dim=1,keepdim=True) #bs*g,h*w\n",
    "        std=t.std(dim=1,keepdim=True)+1e-5\n",
    "        t=t/std #bs*g,h*w\n",
    "        t=t.view(b,self.groups,h,w) #bs,g,h*w\n",
    "        \n",
    "        t=t*self.weight+self.bias #bs,g,h*w\n",
    "        t=t.view(b*self.groups,1,h,w) #bs*g,1,h*w\n",
    "        x=x*self.sig(t)\n",
    "        x=x.view(b,c,h,w)\n",
    "\n",
    "        return x \n",
    "\n",
    "# input=torch.randn(50,256,32,64)\n",
    "# sge = SpatialGroupEnhance(groups=8)\n",
    "# output=sge(input)\n",
    "# print(output.shape)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     input=torch.randn(50,512,7,7)\n",
    "#     bam = BAMBlock(channel=512,reduction=16,dia_val=2)\n",
    "#     output=bam(input)\n",
    "#     print(output.shape)\n",
    "    \n",
    "    \n",
    "class Att_Net(ImageClassificationBase):   \n",
    "    def __init__(self):\n",
    "        super(Att_Net, self).__init__()\n",
    "        #The LW_CNN module utilizes three convolutions (C), two max-pooling\n",
    "        # (MP), one average-pooling (AP), and one batch normalization\n",
    "        # (BN) layer.\n",
    "        self.LW_CNN = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "#             Conv2d(300, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(256),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # Defining another 2D convolution layer\n",
    "#             Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             BatchNorm2d(128),\n",
    "#             ReLU(inplace=True),\n",
    "#             MaxPool2d(kernel_size=1, stride=1),\n",
    "            \n",
    "              #C1, we used 120 number of kernels with size (11\n",
    "              # × 11) using (4 × 4) stride setting without padding to extract\n",
    "              # initially hidden patterns from input data. \n",
    "              Conv2d(3, 120, kernel_size=(5,5), stride=(3,3), padding=0),\n",
    "              MaxPool2d(kernel_size=(2,2), stride=None),\n",
    "              Conv2d(120, 256, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "#               MaxPool2d(kernel_size=(2,2)),\n",
    "#               Conv2d(256, 384, kernel_size=(2,2), padding='same'),\n",
    "#               MaxPool2d(kernel_size=1, stride=0),\n",
    "#               Conv2d(128, 1, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "              torch.nn.AvgPool2d(kernel_size=(2,2), stride=1),\n",
    "              BatchNorm2d(256),\n",
    "              ReLU(inplace=True),\n",
    "        )\n",
    "        self.LW_CNN2 = Sequential(\n",
    "              Conv2d(256, 120, kernel_size=(5,5), stride=(3,3), padding=0),\n",
    "              MaxPool2d(kernel_size=(2,2), stride=None),\n",
    "              Conv2d(120, 64, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "#               MaxPool2d(kernel_size=(2,2)),\n",
    "#               Conv2d(256, 384, kernel_size=(2,2), padding='same'),\n",
    "#               MaxPool2d(kernel_size=1, stride=0),\n",
    "#               Conv2d(128, 1, kernel_size=(3,3), stride=(1,1), padding='same'),\n",
    "              torch.nn.AvgPool2d(kernel_size=(2,2), stride=1),\n",
    "              BatchNorm2d(64),\n",
    "              ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(256 * 84 * 20, 64),\n",
    "#             Linear(256, 64),\n",
    "            Linear(64, 2),\n",
    "        )\n",
    "\n",
    "        self.attention = SpatialGroupEnhance(groups=8)\n",
    "        \n",
    "        self.linear_layers2 = Sequential(\n",
    "            Linear(64*12*2, 64),\n",
    "#             Linear(256, 64),\n",
    "            Linear(64, 32),\n",
    "            Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "#         x = x.view(-1, x.size(3),x.size(2),x.size(1))\n",
    "#         print(x.size)\n",
    "        x = self.LW_CNN(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.LW_CNN2(x)\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         x = self.linear_layers2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f81fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Att_Net(\n",
      "  (LW_CNN): Sequential(\n",
      "    (0): Conv2d(3, 120, kernel_size=(5, 5), stride=(3, 3))\n",
      "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(120, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (LW_CNN2): Sequential(\n",
      "    (0): Conv2d(256, 120, kernel_size=(5, 5), stride=(3, 3))\n",
      "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(120, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=430080, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (attention): SpatialGroupEnhance(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (sig): Sigmoid()\n",
      "  )\n",
      "  (linear_layers2): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Att_Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477fd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 120, 170, 42]           9,120\n",
      "         MaxPool2d-2          [-1, 120, 85, 21]               0\n",
      "            Conv2d-3          [-1, 256, 85, 21]         276,736\n",
      "         AvgPool2d-4          [-1, 256, 84, 20]               0\n",
      "       BatchNorm2d-5          [-1, 256, 84, 20]             512\n",
      "              ReLU-6          [-1, 256, 84, 20]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "           Sigmoid-8            [-1, 1, 84, 20]               0\n",
      "SpatialGroupEnhance-9          [-1, 256, 84, 20]              16\n",
      "           Conv2d-10           [-1, 120, 27, 6]         768,120\n",
      "        MaxPool2d-11           [-1, 120, 13, 3]               0\n",
      "           Conv2d-12            [-1, 64, 13, 3]          69,184\n",
      "        AvgPool2d-13            [-1, 64, 12, 2]               0\n",
      "      BatchNorm2d-14            [-1, 64, 12, 2]             128\n",
      "             ReLU-15            [-1, 64, 12, 2]               0\n",
      "AdaptiveAvgPool2d-16              [-1, 8, 1, 1]               0\n",
      "          Sigmoid-17             [-1, 1, 12, 2]               0\n",
      "SpatialGroupEnhance-18            [-1, 64, 12, 2]              16\n",
      "================================================================\n",
      "Total params: 1,123,832\n",
      "Trainable params: 1,123,832\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 25.05\n",
      "Params size (MB): 4.29\n",
      "Estimated Total Size (MB): 30.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 512, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932937ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input=torch.randn(50,256,7,7)\n",
    "# bam = BAMBlock(channel=256,reduction=16,dia_val=2)\n",
    "# output=bam(input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a72cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 6.0006, val_loss: 8.7741, val_acc: 0.0000\n",
      "Epoch [1], train_loss: 5.6380, val_loss: 6.1396, val_acc: 0.0135\n",
      "Epoch [2], train_loss: 5.4617, val_loss: 5.4063, val_acc: 0.6351\n",
      "Epoch [3], train_loss: 5.2924, val_loss: 5.1181, val_acc: 0.6351\n",
      "Epoch [4], train_loss: 5.1167, val_loss: 4.9773, val_acc: 0.6351\n",
      "Epoch [5], train_loss: 4.9571, val_loss: 4.9098, val_acc: 0.6351\n",
      "Epoch [6], train_loss: 4.7824, val_loss: 4.6379, val_acc: 0.6351\n",
      "Epoch [7], train_loss: 4.6051, val_loss: 4.4587, val_acc: 0.6351\n",
      "Epoch [8], train_loss: 4.4411, val_loss: 4.3396, val_acc: 0.6351\n",
      "Epoch [9], train_loss: 4.2661, val_loss: 4.2584, val_acc: 0.6351\n",
      "Epoch [10], train_loss: 4.1033, val_loss: 3.8430, val_acc: 0.6351\n",
      "Epoch [11], train_loss: 3.9361, val_loss: 3.9029, val_acc: 0.6351\n",
      "Epoch [12], train_loss: 3.7768, val_loss: 3.6491, val_acc: 0.6622\n",
      "Epoch [13], train_loss: 3.6227, val_loss: 3.4210, val_acc: 0.6622\n",
      "Epoch [14], train_loss: 3.4727, val_loss: 3.2879, val_acc: 0.6622\n",
      "Epoch [15], train_loss: 3.3420, val_loss: 3.0549, val_acc: 0.7027\n",
      "Epoch [16], train_loss: 3.1909, val_loss: 2.8740, val_acc: 0.6892\n",
      "Epoch [17], train_loss: 3.0482, val_loss: 3.1211, val_acc: 0.6081\n",
      "Epoch [18], train_loss: 2.9207, val_loss: 2.8760, val_acc: 0.6757\n",
      "Epoch [19], train_loss: 2.7879, val_loss: 2.8916, val_acc: 0.6216\n",
      "Epoch [20], train_loss: 2.6797, val_loss: 2.6714, val_acc: 0.6351\n",
      "Epoch [21], train_loss: 2.5492, val_loss: 2.5485, val_acc: 0.6081\n",
      "Epoch [22], train_loss: 2.4378, val_loss: 2.3794, val_acc: 0.5946\n",
      "Epoch [23], train_loss: 2.3401, val_loss: 2.2579, val_acc: 0.6216\n",
      "Epoch [24], train_loss: 2.2449, val_loss: 2.2725, val_acc: 0.6351\n",
      "Epoch [25], train_loss: 2.1468, val_loss: 2.2088, val_acc: 0.6081\n",
      "Epoch [26], train_loss: 2.0393, val_loss: 2.2847, val_acc: 0.5676\n",
      "Epoch [27], train_loss: 1.9552, val_loss: 2.2411, val_acc: 0.4865\n",
      "Epoch [28], train_loss: 1.9051, val_loss: 1.9167, val_acc: 0.6216\n",
      "Epoch [29], train_loss: 1.8081, val_loss: 1.7912, val_acc: 0.6216\n",
      "Epoch [30], train_loss: 1.7287, val_loss: 1.8162, val_acc: 0.5946\n",
      "Epoch [31], train_loss: 1.6556, val_loss: 1.7758, val_acc: 0.5811\n",
      "Epoch [32], train_loss: 1.6150, val_loss: 1.7615, val_acc: 0.6757\n",
      "Epoch [33], train_loss: 1.5520, val_loss: 1.6196, val_acc: 0.6622\n",
      "Epoch [34], train_loss: 1.5253, val_loss: 1.6297, val_acc: 0.5541\n",
      "Epoch [35], train_loss: 1.4397, val_loss: 1.6201, val_acc: 0.6216\n",
      "Epoch [36], train_loss: 1.3777, val_loss: 1.5031, val_acc: 0.6757\n",
      "Epoch [37], train_loss: 1.3224, val_loss: 1.3537, val_acc: 0.5811\n",
      "Epoch [38], train_loss: 1.2973, val_loss: 1.6637, val_acc: 0.4730\n",
      "Epoch [39], train_loss: 1.2463, val_loss: 1.5110, val_acc: 0.6216\n",
      "Epoch [40], train_loss: 1.2252, val_loss: 1.2846, val_acc: 0.5676\n",
      "Epoch [41], train_loss: 1.1854, val_loss: 1.3023, val_acc: 0.6486\n",
      "Epoch [42], train_loss: 1.1281, val_loss: 1.2143, val_acc: 0.5811\n",
      "Epoch [43], train_loss: 1.0823, val_loss: 1.1752, val_acc: 0.6622\n",
      "Epoch [44], train_loss: 1.0259, val_loss: 1.1567, val_acc: 0.7162\n",
      "Epoch [45], train_loss: 1.0140, val_loss: 1.3692, val_acc: 0.6622\n",
      "Epoch [46], train_loss: 1.0009, val_loss: 1.1161, val_acc: 0.5811\n",
      "Epoch [47], train_loss: 0.9620, val_loss: 1.1955, val_acc: 0.6216\n",
      "Epoch [48], train_loss: 0.8876, val_loss: 1.1446, val_acc: 0.7162\n",
      "Epoch [49], train_loss: 0.8309, val_loss: 1.0726, val_acc: 0.7027\n",
      "Epoch [50], train_loss: 0.7556, val_loss: 0.9211, val_acc: 0.6892\n",
      "Epoch [51], train_loss: 0.7465, val_loss: 1.3612, val_acc: 0.7027\n",
      "Epoch [52], train_loss: 0.6613, val_loss: 1.0924, val_acc: 0.7162\n",
      "Epoch [53], train_loss: 0.6535, val_loss: 1.3038, val_acc: 0.5811\n",
      "Epoch [54], train_loss: 0.5768, val_loss: 1.2741, val_acc: 0.6216\n",
      "Epoch [55], train_loss: 0.5228, val_loss: 1.3258, val_acc: 0.6622\n",
      "Epoch [56], train_loss: 0.4106, val_loss: 1.1655, val_acc: 0.6486\n",
      "Epoch [57], train_loss: 0.3617, val_loss: 1.1401, val_acc: 0.6757\n",
      "Epoch [58], train_loss: 0.3158, val_loss: 0.8957, val_acc: 0.7027\n",
      "Epoch [59], train_loss: 0.3214, val_loss: 1.2125, val_acc: 0.6892\n",
      "Epoch [60], train_loss: 0.2663, val_loss: 1.2961, val_acc: 0.6216\n",
      "Epoch [61], train_loss: 0.2098, val_loss: 1.0920, val_acc: 0.6622\n",
      "Epoch [62], train_loss: 0.1640, val_loss: 1.1952, val_acc: 0.7027\n",
      "Epoch [63], train_loss: 0.1394, val_loss: 1.1262, val_acc: 0.6757\n",
      "Epoch [64], train_loss: 0.1259, val_loss: 1.2881, val_acc: 0.6892\n",
      "Epoch [65], train_loss: 0.1026, val_loss: 1.2064, val_acc: 0.7162\n",
      "Epoch [66], train_loss: 0.0924, val_loss: 1.2397, val_acc: 0.6892\n",
      "Epoch [67], train_loss: 0.0788, val_loss: 1.3505, val_acc: 0.7162\n",
      "Epoch [68], train_loss: 0.0706, val_loss: 1.3917, val_acc: 0.6892\n",
      "Epoch [69], train_loss: 0.0627, val_loss: 1.4376, val_acc: 0.7162\n",
      "Epoch [70], train_loss: 0.0592, val_loss: 1.3929, val_acc: 0.6892\n",
      "Epoch [71], train_loss: 0.0594, val_loss: 1.3310, val_acc: 0.7297\n",
      "Epoch [72], train_loss: 0.0540, val_loss: 1.3325, val_acc: 0.6757\n",
      "Epoch [73], train_loss: 0.0504, val_loss: 1.3612, val_acc: 0.6757\n",
      "Epoch [74], train_loss: 0.0471, val_loss: 1.3031, val_acc: 0.6892\n",
      "Epoch [75], train_loss: 0.0425, val_loss: 1.4171, val_acc: 0.6757\n",
      "Epoch [76], train_loss: 0.0392, val_loss: 1.3918, val_acc: 0.7027\n",
      "Epoch [77], train_loss: 0.0374, val_loss: 1.5242, val_acc: 0.6757\n",
      "Epoch [78], train_loss: 0.0355, val_loss: 1.5052, val_acc: 0.6892\n",
      "Epoch [79], train_loss: 0.0335, val_loss: 1.5015, val_acc: 0.6622\n",
      "Epoch [80], train_loss: 0.0321, val_loss: 1.4199, val_acc: 0.6892\n",
      "Epoch [81], train_loss: 0.0321, val_loss: 1.5463, val_acc: 0.6757\n",
      "Epoch [82], train_loss: 0.0294, val_loss: 1.4483, val_acc: 0.6757\n",
      "Epoch [83], train_loss: 0.0285, val_loss: 1.5592, val_acc: 0.6892\n",
      "Epoch [84], train_loss: 0.0281, val_loss: 1.4997, val_acc: 0.6892\n",
      "Epoch [85], train_loss: 0.0263, val_loss: 1.5435, val_acc: 0.6757\n",
      "Epoch [86], train_loss: 0.0254, val_loss: 1.5054, val_acc: 0.6757\n",
      "Epoch [87], train_loss: 0.0256, val_loss: 1.5672, val_acc: 0.6622\n",
      "Epoch [88], train_loss: 0.0236, val_loss: 1.4716, val_acc: 0.6757\n",
      "Epoch [89], train_loss: 0.0237, val_loss: 1.5361, val_acc: 0.7027\n",
      "Epoch [90], train_loss: 0.0224, val_loss: 1.5343, val_acc: 0.7027\n",
      "Epoch [91], train_loss: 0.0216, val_loss: 1.7417, val_acc: 0.6757\n",
      "Epoch [92], train_loss: 0.0219, val_loss: 1.5798, val_acc: 0.6622\n",
      "Epoch [93], train_loss: 0.0219, val_loss: 1.4438, val_acc: 0.6622\n",
      "Epoch [94], train_loss: 0.0218, val_loss: 1.5033, val_acc: 0.6622\n",
      "Epoch [95], train_loss: 0.0212, val_loss: 1.5324, val_acc: 0.6486\n",
      "Epoch [96], train_loss: 0.0204, val_loss: 1.5863, val_acc: 0.6757\n",
      "Epoch [97], train_loss: 0.0192, val_loss: 1.5575, val_acc: 0.6622\n",
      "Epoch [98], train_loss: 0.0186, val_loss: 1.4855, val_acc: 0.6892\n",
      "Epoch [99], train_loss: 0.0180, val_loss: 1.5012, val_acc: 0.6622\n",
      "Epoch [100], train_loss: 0.0174, val_loss: 1.5118, val_acc: 0.6757\n",
      "Epoch [101], train_loss: 0.0168, val_loss: 1.6627, val_acc: 0.6216\n",
      "Epoch [102], train_loss: 0.0167, val_loss: 1.5278, val_acc: 0.6892\n",
      "Epoch [103], train_loss: 0.0166, val_loss: 1.5502, val_acc: 0.6622\n",
      "Epoch [104], train_loss: 0.0160, val_loss: 1.5861, val_acc: 0.6757\n",
      "Epoch [105], train_loss: 0.0156, val_loss: 1.5570, val_acc: 0.7027\n",
      "Epoch [106], train_loss: 0.0152, val_loss: 1.6399, val_acc: 0.6351\n",
      "Epoch [107], train_loss: 0.0150, val_loss: 1.6009, val_acc: 0.6486\n",
      "Epoch [108], train_loss: 0.0147, val_loss: 1.5637, val_acc: 0.6757\n",
      "Epoch [109], train_loss: 0.0147, val_loss: 1.6163, val_acc: 0.6622\n",
      "Epoch [110], train_loss: 0.0144, val_loss: 1.6744, val_acc: 0.6486\n",
      "Epoch [111], train_loss: 0.0144, val_loss: 1.6071, val_acc: 0.6622\n",
      "Epoch [112], train_loss: 0.0146, val_loss: 1.6451, val_acc: 0.6757\n",
      "Epoch [113], train_loss: 0.0142, val_loss: 1.5834, val_acc: 0.6757\n",
      "Epoch [114], train_loss: 0.0139, val_loss: 1.5622, val_acc: 0.6622\n",
      "Epoch [115], train_loss: 0.0138, val_loss: 1.6269, val_acc: 0.6351\n",
      "Epoch [116], train_loss: 0.0138, val_loss: 1.5612, val_acc: 0.6892\n",
      "Epoch [117], train_loss: 0.0132, val_loss: 1.5616, val_acc: 0.6486\n",
      "Epoch [118], train_loss: 0.0132, val_loss: 1.6832, val_acc: 0.6351\n",
      "Epoch [119], train_loss: 0.0128, val_loss: 1.6172, val_acc: 0.7027\n",
      "Epoch [120], train_loss: 0.0131, val_loss: 1.5788, val_acc: 0.6622\n",
      "Epoch [121], train_loss: 0.0129, val_loss: 1.5895, val_acc: 0.6757\n",
      "Epoch [122], train_loss: 0.0125, val_loss: 1.5540, val_acc: 0.6757\n",
      "Epoch [123], train_loss: 0.0126, val_loss: 1.6810, val_acc: 0.6216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124], train_loss: 0.0121, val_loss: 1.5679, val_acc: 0.6892\n",
      "Epoch [125], train_loss: 0.0123, val_loss: 1.7391, val_acc: 0.6622\n",
      "Epoch [126], train_loss: 0.0122, val_loss: 1.5501, val_acc: 0.6757\n",
      "Epoch [127], train_loss: 0.0120, val_loss: 1.5940, val_acc: 0.6486\n",
      "Epoch [128], train_loss: 0.0116, val_loss: 1.5565, val_acc: 0.6757\n",
      "Epoch [129], train_loss: 0.0115, val_loss: 1.5229, val_acc: 0.6757\n",
      "Epoch [130], train_loss: 0.0113, val_loss: 1.5862, val_acc: 0.6892\n",
      "Epoch [131], train_loss: 0.0113, val_loss: 1.7388, val_acc: 0.6216\n",
      "Epoch [132], train_loss: 0.0118, val_loss: 1.5934, val_acc: 0.6622\n",
      "Epoch [133], train_loss: 0.0118, val_loss: 1.5547, val_acc: 0.6486\n",
      "Epoch [134], train_loss: 0.0113, val_loss: 1.5761, val_acc: 0.6757\n",
      "Epoch [135], train_loss: 0.0109, val_loss: 1.5864, val_acc: 0.6757\n",
      "Epoch [136], train_loss: 0.0106, val_loss: 1.5469, val_acc: 0.6757\n",
      "Epoch [137], train_loss: 0.0106, val_loss: 1.6142, val_acc: 0.6622\n",
      "Epoch [138], train_loss: 0.0102, val_loss: 1.4781, val_acc: 0.6757\n",
      "Epoch [139], train_loss: 0.0100, val_loss: 1.6459, val_acc: 0.6622\n",
      "Epoch [140], train_loss: 0.0096, val_loss: 1.6164, val_acc: 0.6486\n",
      "Epoch [141], train_loss: 0.0094, val_loss: 1.5493, val_acc: 0.6757\n",
      "Epoch [142], train_loss: 0.0093, val_loss: 1.6573, val_acc: 0.6622\n",
      "Epoch [143], train_loss: 0.0092, val_loss: 1.5404, val_acc: 0.6622\n",
      "Epoch [144], train_loss: 0.0092, val_loss: 1.6344, val_acc: 0.6351\n",
      "Epoch [145], train_loss: 0.0093, val_loss: 1.6466, val_acc: 0.6622\n",
      "Epoch [146], train_loss: 0.0094, val_loss: 1.6591, val_acc: 0.6622\n",
      "Epoch [147], train_loss: 0.0089, val_loss: 1.5175, val_acc: 0.6892\n",
      "Epoch [148], train_loss: 0.0087, val_loss: 1.6231, val_acc: 0.6757\n",
      "Epoch [149], train_loss: 0.0086, val_loss: 1.6365, val_acc: 0.6486\n",
      "Epoch [150], train_loss: 0.0089, val_loss: 1.5961, val_acc: 0.6486\n",
      "Epoch [151], train_loss: 0.0088, val_loss: 1.5053, val_acc: 0.6622\n",
      "Epoch [152], train_loss: 0.0087, val_loss: 1.5989, val_acc: 0.6757\n",
      "Epoch [153], train_loss: 0.0086, val_loss: 1.5996, val_acc: 0.6757\n",
      "Epoch [154], train_loss: 0.0085, val_loss: 1.5220, val_acc: 0.6622\n",
      "Epoch [155], train_loss: 0.0083, val_loss: 1.5146, val_acc: 0.6892\n",
      "Epoch [156], train_loss: 0.0085, val_loss: 1.6084, val_acc: 0.6892\n",
      "Epoch [157], train_loss: 0.0089, val_loss: 1.6104, val_acc: 0.6757\n",
      "Epoch [158], train_loss: 0.0093, val_loss: 1.5571, val_acc: 0.6622\n",
      "Epoch [159], train_loss: 0.0094, val_loss: 1.5692, val_acc: 0.6216\n",
      "Epoch [160], train_loss: 0.0093, val_loss: 1.4909, val_acc: 0.6622\n",
      "Epoch [161], train_loss: 0.0088, val_loss: 1.6185, val_acc: 0.6486\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18604/3785865250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#fitting the model on training data and record the result after each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18604/1190722326.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-btp\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CTX = torch.device('cuda')\n",
    "# train_dl.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # train_dl.train_labels.to(CTX)\n",
    "# # val_dl.train_data.to(CTX)  #train_dataset.train_data is a Tensor(input data)\n",
    "# # val_dl.train_labels.to(CTX)\n",
    "num_epochs = 256\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26874318",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18604/1234022371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mplot_accuracies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "\n",
    "plot_accuracies(history)\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max([x['val_acc'] for x in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3164b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
