{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "info_line = re.compile(r'\\[.+\\]\\n', re.IGNORECASE)\n",
    "\n",
    "start_times, end_times, wav_file_names, emotions, vals, acts, doms = [], [], [], [], [], [], []\n",
    "\n",
    "for sess in range(1, 6):\n",
    "    emo_evaluation_dir = 'IEMOCAP_full_release/Session{}/dialog/EmoEvaluation/'.format(sess)\n",
    "    evaluation_files = [l for l in os.listdir(emo_evaluation_dir) if 'Ses' in l]\n",
    "    for file in evaluation_files:\n",
    "        with open(emo_evaluation_dir + file) as f:\n",
    "            content = f.read()\n",
    "        info_lines = re.findall(info_line, content)\n",
    "        for line in info_lines[1:]:  # the first line is a header\n",
    "            start_end_time, wav_file_name, emotion, val_act_dom = line.strip().split('\\t')\n",
    "            start_time, end_time = start_end_time[1:-1].split('-')\n",
    "            val, act, dom = val_act_dom[1:-1].split(',')\n",
    "            val, act, dom = float(val), float(act), float(dom)\n",
    "            start_time, end_time = float(start_time), float(end_time)\n",
    "            start_times.append(start_time)\n",
    "            end_times.append(end_time)\n",
    "            wav_file_names.append(wav_file_name)\n",
    "            emotions.append(emotion)\n",
    "            vals.append(val)\n",
    "            acts.append(act)\n",
    "            doms.append(dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_iemocap = pd.DataFrame(columns=['start_time', 'end_time', 'wav_file', 'emotion', 'val', 'act', 'dom'])\n",
    "\n",
    "df_iemocap['start_time'] = start_times\n",
    "df_iemocap['end_time'] = end_times\n",
    "df_iemocap['wav_file'] = wav_file_names\n",
    "df_iemocap['emotion'] = emotions\n",
    "df_iemocap['val'] = vals\n",
    "df_iemocap['act'] = acts\n",
    "df_iemocap['dom'] = doms\n",
    "\n",
    "df_iemocap.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e27d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iemocap.to_csv('pre-processed/df_iemocap.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "labels_df = pd.read_csv('pre-processed/df_iemocap.csv')\n",
    "iemocap_dir = 'IEMOCAP_full_release/'\n",
    "\n",
    "sr = 44100\n",
    "audio_vectors = {}\n",
    "for sess in range(1, 6):  # using one session due to memory constraint, can replace [5] with range(1, 6)\n",
    "    wav_file_path = '{}Session{}/dialog/wav/'.format(iemocap_dir, sess)\n",
    "    orig_wav_files = os.listdir(wav_file_path)\n",
    "    for orig_wav_file in tqdm(orig_wav_files):\n",
    "        try:\n",
    "            orig_wav_vector, _sr = librosa.load(wav_file_path + orig_wav_file, sr=sr)\n",
    "            orig_wav_file, file_format = orig_wav_file.split('.')\n",
    "            for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n",
    "                start_time, end_time, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row['end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n",
    "                start_frame = math.floor(start_time * sr)\n",
    "                end_frame = math.floor(end_time * sr)\n",
    "                truncated_wav_vector = orig_wav_vector[start_frame:end_frame + 1]\n",
    "                audio_vectors[truncated_wav_file_name] = truncated_wav_vector\n",
    "        except:\n",
    "            print('An exception occured for {}'.format(orig_wav_file))\n",
    "    with open('pre-processed/audio_vectors_{}.pkl'.format(sess), 'wb') as f:\n",
    "        pickle.dump(audio_vectors, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
